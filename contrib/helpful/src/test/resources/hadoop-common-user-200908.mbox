From common-user-return-16474-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 01 01:35:45 2009
Return-Path: <common-user-return-16474-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11232 invoked from network); 1 Aug 2009 01:35:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 1 Aug 2009 01:35:45 -0000
Received: (qmail 4821 invoked by uid 500); 1 Aug 2009 01:07:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 4729 invoked by uid 500); 1 Aug 2009 01:07:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 4718 invoked by uid 99); 1 Aug 2009 01:07:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 01 Aug 2009 01:07:47 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [64.78.17.18] (HELO EXHUB018-3.exch018.msoutlookonline.net) (64.78.17.18)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 01 Aug 2009 01:07:35 +0000
Received: from EXVMBX018-1.exch018.msoutlookonline.net ([64.78.17.47]) by
 EXHUB018-3.exch018.msoutlookonline.net ([64.78.17.18]) with mapi; Fri, 31 Jul
 2009 18:07:13 -0700
From: Scott Carey <scott@richrelevance.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Fri, 31 Jul 2009 18:07:10 -0700
Subject: Re: Map performance with custom binary format
Thread-Topic: Map performance with custom binary format
Thread-Index: AcoRXVEk4ga0vfRKTIKslsNwoS0kOQA5xQmV
Message-ID: <C698E34E.DF5D%scott@richrelevance.com>
In-Reply-To: <928bdd8e0907301432m5b159008hfe9a961640539ec7@mail.gmail.com>
Accept-Language: en-US
Content-Language: en
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

On 7/30/09 2:32 PM, "william kinney" <william.kinney@gmail.com> wrote:
>
> "If even a single task on a single large file is slower in MB/sec than yo=
ur
> test program, then I suspect read/write buffer issues or misuse somewhere=
."
>   - Do you know of an instance where I'd have buffer issues with the
> Child process, and not local? The only difference I can think of is of
> course how the buffer is filled, FileInputStream vs FSDataInputStream.
> But once it is filled, why would reading portions of that buffer (ie,
> Arrays.copyOfRange()) take long in one instance but not another?

Is your local test writing to HDFS or local files?  Likewise, what happens
if your local test reads from HDFS instead of a local file?

If both tests use HDFS on both ends and the performance difference is still
there, then we have narrowed it down.  If the performance becomes much more
similar, we have likewise narrowed it down.

>
> Would it be helpful to get a histogram of the Arrays.copyOfRange(),
> rather than the average and total? Perhaps for the most part it is
> fine (~ 120 ns), but chokes sometimes (thefore increasing total time
> and average).
>
> Thanks for the help,
> Will
>
>
> On Thu, Jul 30, 2009 at 2:19 PM, Scott Carey<scott@richrelevance.com> wro=
te:
>> Comments inline:
>>
>> On 7/30/09 7:37 AM, "william kinney" <william.kinney@gmail.com> wrote:
>>
>>> Local is executed on a Hadoop node (when no job is running), So same
>>> JRE/hardware.
>>>
>>> JRE:
>>> java version "1.6.0_13"
>>> Java(TM) SE Runtime Environment (build 1.6.0_13-b03)
>>> Java HotSpot(TM) 64-Bit Server VM (build 11.3-b02, mixed mode)
>>>
>>> JVM arguments for child task:
>>> /usr/java/jdk1.6.0_13/jre/bin/java
>>> -Djava.library.path=3D/usr/lib/hadoop/lib/native/Linux-amd64-64:/disk1/=
hadoop/
>>> ma
>>> pred/local/taskTracker/jobcache/job_200907242015_0048/attempt_200907242=
015_0
>>> 04
>>> 8_m_000008_0/work
>>> -Xmx486m
>>
>> You might benefit from JVM 1.6.0_14 with -XX:+UseCompressedOops, but tha=
t
>> would probably help both roughly equally.  It won't help much if you are=
n't
>> creating significant work for the garbage collector thouth.
>>
>>>
>>> Local call has no JVM arguments, just:
>>> java -cp <myjar>.jar com......RecordReaderTest <fileToTest>
>>>
>>
>> You might want to try -Xmx486m as an experiment on the local test to see=
 if
>> it affects the behavior.  If you are doing a lot of garbage creation it =
may.
>>
>>
>>>
>>> Data is not compressed.
>>
>> Hmm, that was a random guess, because it would obviously affect CPU use.
>> Another thing to try -- make sure your writer that is writing into HDFS =
is
>> wrapped with a buffer (try 32k or 64k).  That's another random guess for
>> something that might not show up well in stack traces without a profiler=
 --
>> but also might already be done.
>>
>>>
>>> JobTracker:
>>> Running: Started around 20, but as the job progressed it slowly
>>> increased to at the end: 432 (when Pending was 0). Running dropped to
>>> 0/Status was marked Succeeded about 10 seconds after that. Is this
>>> normal? The total # of Tasks was 1449.
>>
>> This is the "one new task per heartbeat" scheduler slowness.  The next
>> version of the Fair Scheduler will schedule many tasks in one heartbeat
>> which should make this faster.
>> Its a big reason that fewer, larger files was faster.  Though if you are=
 CPU
>> bound, you only need 2 tasks running at the same time per node on your
>> hardware to be at near top efficiency.  Fewer tasks per node (say, 4) wi=
th
>> more RAM each (800MB) might do better on this sort of workload.
>>
>>
>>>
>>> Stack Traces.
>>> Looked at about 20 stack traces from 2 different nodes. Consistently sa=
w:
>>> 2 x org.apache.hadoop.dfs.DFSClient$LeaseChecker @ Thread.sleep()
>>> "Comm thread for attempt_200907242015_0050_m_001409_0" @ Thread.sleep()
>>> "IPC Client (47) connection to <master-hostname>/192.168.1.100:8020
>>> from wkinney" @ Object.wait()
>>> "IPC Client (47) connection to /127.0.0.1:49202 from an unknown user"
>>> @ Object.wait()
>>> VM, GC, Signal Dispatcher, Low Memory Detector, CompilerThread,
>>> Finalizer, Reference Handler...
>>
>> Sounds like the usual threads that don't do much.
>>
>>>
>>> Then would sometimes see FastDateFormat thread, parseFrom(), or
>>> somewhere near there (e.g. MapRunner.run())
>>
>> The meat of the task.
>>
>>>
>>> Finally, I consistently saw this:
>>> "Thread-5" daemon prio=3D10 tid=3D0x0000000040bbfc00 nid=3D0x2f87 in
>>> Object.wait() [0x00007fb7498ce000..0x00007fb7498cebf0]
>>>    java.lang.Thread.State: TIMED_WAITING (on object monitor)
>>>         at java.lang.Object.wait(Native Method)
>>>         - waiting on <0x00007fb769fdec00> (a java.util.LinkedList)
>>>         at
>>> org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSCli=
ent.j
>>> av
>>> a:1905)
>>>         - locked <0x00007fb769fdec00> (a java.util.LinkedList)
>>> I'm guessing this is normal DataNode activity...
>>
>> Yes, this is the normal dfs thread.  It can be hard to catch it doing wo=
rk
>> with just stack traces and no profiler attached.
>>
>>>
>>> Will
>>>
>>>
>>
>> There is definitely a mystery here.  I expect the task scheduling delays=
 and
>> some startup inefficiency but the overall difference is odd.  What about=
 a
>> local test on a single, larger file versus a hadoop job on that same sin=
gle,
>> larger file (which would have just one map job)?  This test may be very
>> enlightening.
>>
>>
>>> On Thu, Jul 30, 2009 at 1:31 AM, Scott Carey<scott@richrelevance.com> w=
rote:
>>>> What is the JRE for the Hadoop nodes versus local?  What are the JVM
>>>> arguments for the child tasks and the local version (and heap size)?  =
What
>>>> is
>>>> the hardware and platform details for the nodes versus the local test?
>>>> Is the data compressed in Hadoop (check the config)?
>>>>
>>>> You mention the TaskTracker web inerface during a job, but what about =
the
>>>> JobTracker interface?  This should show the global view of currently
>>>> scheduled maps versus total slots.
>>>>
>>>> Lastly, check out some more stack traces on the tasks.  If they are al=
l
>>>> still
>>>> in the DateFormat stuff?  Surely some of them should be in your parseF=
rom()
>>>> method too?
>>>>
>>>>
>>>> On 7/29/09 9:07 PM, "william kinney" <william.kinney@gmail.com> wrote:
>>>>
>>>> OK:
>>>>  implemented some iotop/iostat monitoring in ganglia. Looks pretty
>>>> standard (job was 23:00 to 23:06):
>>>>   - Single Node Disk Read: http://imagebin.org/57716
>>>>   - Single Node Disk Write: http://imagebin.org/57717
>>>>
>>>> On each node, noticed that the two TaskTracker$Child processes were
>>>> consuming close to 90% of each core. The TaskTracker and DataNode were
>>>> close to 0%. For the TT children, I did jstack dumps, but didn't
>>>> really see much that popped out other than a lot of time spent in a
>>>> SimpleDateFormat section and the protobuf parse. I switched the SDF
>>>> out with commons.lang FastDateFormat, which reduced the total time for
>>>> both the Hadoop job and the local/non-hadoop test, so still a
>>>> discrepancy between local and hadoop runs.
>>>>
>>>> "You can look at the logs for an individual task, and see how much dat=
a it
>>>> read, and how long it took.  It might be hitting your 50MB/sec or clos=
e in
>>>> a
>>>> burst, or perhaps not."
>>>>  - I decided to log the performance of each RecordReader use within
>>>> hadoop, which is essentially 1:1 for TaskTracker$Child process since I
>>>> have 1 InputSplit per file (ie, no splitting), right?. Saw:
>>>> Example 1) 527639090 bytes in : 18050 ms. (27.8778 MB/s)
>>>> Example 2) 533770314 bytes in : 23494 ms. (21.6669 MB/s)
>>>> Example 3) 529711886 bytes in : 20092 ms. (25.1429 MB/s)
>>>> ...etc
>>>> For reference, the non-hadoop/local test:
>>>> 530710906 bytes in : 9133 ms. (55.41721 MB/s)
>>>>
>>>> Regarding the JobTracker only doing 1 task / node / 2 seconds, that
>>>> will definitely hurt. Although the above discrepancy takes priority
>>>> for me, for now.
>>>>
>>>> "What does the web interface tell you about the number of concurrent m=
ap
>>>> tasks during the run?  Does it approach the max task slots?"
>>>>  - Yeah it definitely does, from the TaskTracker page on each node,
>>>> I'm seeing almost always 2 "RUNNING" tasks (and an accumulating list
>>>> of "COMMIT_PENDING" tasks under Non-Running, which slowly grows as the
>>>> job progresses). Normal?
>>>>
>>>> Also, I used a profiler to profile a local/non-hadoop test of the
>>>> RecordReader/Map():
>>>>  class: %Time
>>>>      org.apache.commons.lang.time.FastDateFormat.format(long):  46%
>>>>      com......parseFrom(byte[]):  42%
>>>>      java.io.FileInputStream.read(byte[], int, int): 5%
>>>>      ...rest are 1%'ish
>>>>  I guess this doesn't show anything helpful. I'll try to attach it to
>>>> hadoop remotely...anyone have any experience doing this w/ YourKit
>>>> Java Profiler?
>>>>
>>>> Anyways, decided to test the "large files" vs "small files" theory aga=
in:
>>>>  Small files (1449 files, ranging 10-100MB. average: 32 MB)
>>>>    - HDFS bytes read  49,057,491,374
>>>>    - Map input records  737,850,142
>>>>    - Finished in: 7mins, 26sec
>>>>    ... 104.898 MB/s
>>>>  Large files (22 files, around 500MB. average 514MB)
>>>>    - HDFS bytes read  11,852,421,152
>>>>    - Map input records 179,657,432
>>>>    - Finished in: 1mins, 8sec
>>>>    ... 166.225 MB/s
>>>>
>>>>   Not sure why before the large files were taking longer, perhaps the
>>>> SimpleDateFormat>FastDateFormat change? Anyways, good to see where I
>>>> need to take the file sizes too...but still 166 MB is not the rate I
>>>> was hoping for (given the # of nodes and local performance).
>>>>
>>>> So I guess in summary, hadoop TaskTracker$Child processes that are
>>>> doing the Map() and RecordReader are about 50% slower than the normal,
>>>> local non-hadoop version. In addition, their rate (~25MB/s) * Num
>>>> Nodes (10) suggests ~ 250MB/s total job performance, but I'm only
>>>> seeing ~166MB/s.
>>>>
>>>> Will
>>>>
>>>> On Tue, Jul 28, 2009 at 6:35 PM, Scott Carey<scott@richrelevance.com>
>>>> wrote:
>>>>> See below:
>>>>>
>>>>>
>>>>> On 7/28/09 12:15 PM, "william kinney" <william.kinney@gmail.com> wrot=
e:
>>>>>
>>>>>> Sorry, forgot to include that detail.
>>>>>>
>>>>>> Some data from ganglia:
>>>>>>
>>>>>>   CPU:
>>>>>>     - on all 10 nodes, I am seeing for the life of the job 85-95% CP=
U
>>>>>> usage, with about 10% of that being "System" CPU, vs "User".
>>>>>>     - Single node graph: http://imagebin.org/57520
>>>>>>     - Cluster graph: http://imagebin.org/57523
>>>>>
>>>>> Ok, CPU is definitely loaded.  Identify which processes are primarily
>>>>> responsible (Tasks? Datanode? Tasktracker?) You'll want to make the
>>>>> processes eating CPU during a run spit out some stack traces to 'prof=
ile'
>>>>> the activity.  Use either the 'jstack' utility with the JDK, or do a =
'kill
>>>>> -3 <pid>' on a java process to spit out the stack trace to stdout.  Y=
ou'll
>>>>> want to do this a handful of times on a single job if possible to ide=
ntify
>>>>> any trends.
>>>>>
>>>>>>
>>>>>>   Memory:
>>>>>>     - Memory used before job is about 0.4GB, During job it fluctuate=
s
>>>>>> up to 0.6GB and 0.7GB, then back down to 0.4GB. Most of the node
>>>>>> memory (8GB) is showing as "Cached".
>>>>>>     - Single node graph: http://imagebin.org/57522
>>>>>
>>>>> So the OS is mostly just caching disk files in RAM.
>>>>>
>>>>>>
>>>>>>   Network:
>>>>>>     - IN and OUT: Each node 6-12MB/s, cumulative about 30-44MB/s.
>>>>>>     - Single node graph: http://imagebin.org/57521
>>>>>>     - Cluster graph: http://imagebin.org/57525
>>>>>>
>>>>>
>>>>> That is a not insignificant, but cumulative across the cluster its no=
t
>>>>> much.
>>>>>
>>>>>> iostat (disk) (sampled most of the nodes, below values are ranges I =
saw):
>>>>>>     tps: 0.41-1.27
>>>>>>     Blk_read/s: 46-58
>>>>>>     Blk_wrtn/s: 20-23
>>>>>> (have two disks per node, both SAS, 10k RPM)
>>>>>>
>>>>>
>>>>> Did you do iostat with a parameter to have it spit out more than one =
row?
>>>>> By default, it spits out data averaged since boot time, like vmstat.
>>>>> My favorite iostat params for monitoring are:
>>>>> iostat -mx 5
>>>>> iostat -dmx 5
>>>>> (or 10 or 15 or 60 second intervals depending on what I'm doing)  Gan=
glia
>>>>> might have some I/O info -- you want both iops and some sort of bytes=
/sec
>>>>> measurement.
>>>>>
>>>>>> ---
>>>>>> Are those Blk_read/wrtn/s as in block size (4096?) =3D bytes/second?
>>>>>>
>>>>>
>>>>> I think its the 512 byte block notion, but I always use -m to put it =
in
>>>>> useful units.
>>>>>
>>>>>> Also, from the job page (different job, same Map method, just more
>>>>>> data...~40GB. 781 files):
>>>>>> Map input records       629,738,080
>>>>>> Map input bytes         41,538,992,880
>>>>>>
>>>>>> Anything else I can look into?
>>>>>
>>>>> Based on your other email:
>>>>>
>>>>> There are almost 800 map tasks, these seem to mostly be data local.  =
The
>>>>> current implementation of the JobTracker schedules rather slowly, and=
 can
>>>>> at
>>>>> best place one new task per node per 2 seconds or so on a small clust=
er.
>>>>> So, with 10 servers, it will take at least 80 seconds just to schedul=
e all
>>>>> the tasks.
>>>>> If each server can run 8 tasks concurrently, then if the average task
>>>>> doesn't take somewhat longer than 16 seconds, the system will not rea=
ch
>>>>> full
>>>>> utilization.
>>>>>
>>>>> What does the web interface tell you about the number of concurrent m=
ap
>>>>> tasks during the run?  Does it approach the max task slots?
>>>>>
>>>>> You can look at the logs for an individual task, and see how much dat=
a it
>>>>> read, and how long it took.  It might be hitting your 50MB/sec or clo=
se in
>>>>> a
>>>>> burst, or perhaps not.
>>>>>
>>>>> Given the sort of bottlenecks I often see, I suspect the scheduling. =
 But,
>>>>> you have almost maxed CPU use, so its probably not that.  Getting sta=
ck
>>>>> dumps to see what the processor is doing during your test will help n=
arrow
>>>>> it down.
>>>>>
>>>>>
>>>>>>
>>>>>> Do my original numbers (only 2x performance) jump out at you as bein=
g
>>>>>> way off? Or it is common to see that a setup similar to mine?
>>>>>>
>>>>>> I should also note that given its a custom binary format, I do not
>>>>>> support Splitting (isSplittable() is false). I don't think that woul=
d
>>>>>> count for such a large discrepancy in expected performance, would it=
?
>>>>>>
>>>>>
>>>>> If the files are all larger than the block size, it would cause a lot=
 more
>>>>> network activity -- but unless your switch or network is broken or no=
t
>>>>> gigabit -- there is a lot of capacity left in the network.
>>>>>
>>>>>> Thanks for the help,
>>>>>> Will
>>>>>>
>>>>>>
>>>>>> On Tue, Jul 28, 2009 at 12:58 PM, Scott Carey<scott@richrelevance.co=
m>
>>>>>> wrote:
>>>>>>> Well, the first thing to do in any performance bottleneck investiga=
tion
>>>>>>> is
>>>>>>> to look at the machine hardware resource usage.
>>>>>>>
>>>>>>> During your test, what is the CPU use and disk usage?  What about
>>>>>>> network
>>>>>>> utilization?
>>>>>>> Top, vmstat, iostat, and some network usage monitoring would be use=
ful.
>>>>>>>  It
>>>>>>> could be many things causing your lack of scalability, but without
>>>>>>> actually
>>>>>>> monitoring your machines to see if there is an obvious bottleneck i=
ts
>>>>>>> just
>>>>>>> random guessing and hunches.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On 7/28/09 8:18 AM, "william kinney" <william.kinney@gmail.com> wro=
te:
>>>>>>>
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> Thanks in advance for the help!
>>>>>>>>
>>>>>>>> I have a performance question relating to how fast I can expect Ha=
doop
>>>>>>>> to scale. Running Cloudera's 0.18.3-10.
>>>>>>>>
>>>>>>>> I have custom binary format, which is just Google Protocol Buffer
>>>>>>>> (protobuf) serialized data:
>>>>>>>>
>>>>>>>>   669 files, ~30GB total size (ranging 10MB to 100MB each).
>>>>>>>>   128MB block size.
>>>>>>>>   10 Hadoop Nodes.
>>>>>>>>
>>>>>>>> I tested my InputFormat and RecordReader for my input format, and =
it
>>>>>>>> showed about 56MB/s performance (single thread, no hadoop, passed =
in
>>>>>>>> test file via FileInputFormat instead of FSDataInputStream) on
>>>>>>>> hardware similar to what I have in my cluster.
>>>>>>>> I also then tested some simple Map logic along w/ the above, and g=
ot
>>>>>>>> around 54MB/s. I believe that difference can be accounted for pars=
ing
>>>>>>>> the protobuf data into java objects.
>>>>>>>>
>>>>>>>> Anyways, when I put this logic into a job that has
>>>>>>>>   - no reduce (.setNumReduceTasks(0);)
>>>>>>>>   - no emit
>>>>>>>>   - just protobuf parsing calls (like above)
>>>>>>>>
>>>>>>>> I get a finish time of 10mins, 25sec, which is about 106.24 MB/s.
>>>>>>>>
>>>>>>>> So my question, why is the rate only 2x what I see on a single thr=
ead,
>>>>>>>> non-hadoop test? Would it not be:
>>>>>>>>   54MB/s x 10 (Num Nodes) - small hadoop overhead ?
>>>>>>>>
>>>>>>>> Is there any area of my configuration I should look into for tunin=
g?
>>>>>>>>
>>>>>>>> Anyway I could get more accurate performance monitoring of my job?
>>>>>>>>
>>>>>>>> On a side note, I tried the same job after combining the files int=
o
>>>>>>>> about 11 files (still 30GB in size), and actually saw a decrease i=
n
>>>>>>>> performance (~90MB/s).
>>>>>>>>
>>>>>>>> Any help is appreciated. Thanks!
>>>>>>>>
>>>>>>>> Will
>>>>>>>>
>>>>>>>> some hadoop-site.xml values:
>>>>>>>> dfs.replication  3
>>>>>>>> io.file.buffer.size   65536
>>>>>>>> dfs.datanode.handler.count  3
>>>>>>>> mapred.tasktracker.map.tasks.maximum  6
>>>>>>>> dfs.namenode.handler.count  5
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>
>>
>>
>


From common-user-return-16475-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 02 04:54:04 2009
Return-Path: <common-user-return-16475-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 40977 invoked from network); 2 Aug 2009 04:54:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 2 Aug 2009 04:54:04 -0000
Received: (qmail 11086 invoked by uid 500); 2 Aug 2009 04:54:05 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10995 invoked by uid 500); 2 Aug 2009 04:54:05 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10985 invoked by uid 99); 2 Aug 2009 04:54:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 02 Aug 2009 04:54:05 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of prashullegaddi@gmail.com designates 209.85.216.198 as permitted sender)
Received: from [209.85.216.198] (HELO mail-px0-f198.google.com) (209.85.216.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 02 Aug 2009 04:53:56 +0000
Received: by pxi36 with SMTP id 36so2033154pxi.2
        for <common-user@hadoop.apache.org>; Sat, 01 Aug 2009 21:53:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=f6sB2wCn16BC0iVoHFTlgHhNgxjM942T45ZOH0e3bwY=;
        b=vGs3IKuCW8+NEfCLNJnhTHyH477YYSsotlfBSjyf0o2dBeIMBv8sny/pKjnwYxOSXQ
         8OvUR6XqtWN4cJq9vN7FZbktXXXcalAbGOL47YD/8ODLoQ1evpLWKHwb1qIGBVOfOpVW
         uLEe0m3C/2xvRD73KS1CcSN+bf7Fvd36vMF40=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=tAUa7rGjQ/cE5b1XMGX+sk44hDWeP/6oLjPrxLZPZVapjTdsjB1M8cBMHXjZHRBnBH
         gAe9LxAiMy8OEXvb7t7as4j8Bx8JRArqBwY7NAVoiAWgzb5nc2x8+DcKiDCg3JPkaEzq
         iADw928Dauuq8TFEILqEthWRBlCNSaP6CdEM8=
MIME-Version: 1.0
Received: by 10.141.28.19 with SMTP id f19mr2918881rvj.67.1249188814739; Sat, 
	01 Aug 2009 21:53:34 -0700 (PDT)
Date: Sun, 2 Aug 2009 10:23:34 +0530
Message-ID: <ac6e61fc0908012153o5f6f5ee9ocbcdef8b21dda20b@mail.gmail.com>
Subject: Counting no. of keys.
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd1a9068f59af0470216fd3
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd1a9068f59af0470216fd3
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

I've say 800 sequence files written using SequenceFileOutputFormat. Is there
any way to know
no. of unique keys in those sequence files?

Thanks,
Prashant.

--000e0cd1a9068f59af0470216fd3--

From common-user-return-16476-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 02 06:09:20 2009
Return-Path: <common-user-return-16476-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 62780 invoked from network); 2 Aug 2009 06:09:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 2 Aug 2009 06:09:20 -0000
Received: (qmail 28949 invoked by uid 500); 2 Aug 2009 06:09:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 28861 invoked by uid 500); 2 Aug 2009 06:09:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 28851 invoked by uid 99); 2 Aug 2009 06:09:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 02 Aug 2009 06:09:21 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 02 Aug 2009 06:09:12 +0000
Received: by gxk18 with SMTP id 18so4638403gxk.5
        for <common-user@hadoop.apache.org>; Sat, 01 Aug 2009 23:08:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=m829590fMIJ6z1gpcGAhlOtUPqrStD/YpKX6uK0os6A=;
        b=ZWepRZDNaJPZvIFsRMj+LKuqckN39tYRwzyp29Gz8mCidQDXfdiPDmAYNe6pQZS/jl
         hVp/Ja7sBS53/JjAkSzEwZHUhpimU+m4fQJTruqe0RpXyOrmFa9mdnjYZEgYE/Yi3pc/
         l6kkcLKX4YckPLygEc2+tKx0BHgsMuDkrspdI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=pbfWufcbAiosT8FDxVuJ1eeueQuqkDQOTckYHWQLnCi1VTrbR7ILHbylvazLtG5NlO
         8xhAp2tROlll6naNfMrjCE8fdwlrQPvFA73Zq+58icdH3c+2Qov7OCFcfeK7eh0QheNZ
         rCe1Rt8dT08uJ1L2wITq4tstJVnzOTBkhjDfw=
MIME-Version: 1.0
Received: by 10.150.215.8 with SMTP id n8mr7877159ybg.41.1249193331193; Sat, 
	01 Aug 2009 23:08:51 -0700 (PDT)
In-Reply-To: <ac6e61fc0908012153o5f6f5ee9ocbcdef8b21dda20b@mail.gmail.com>
References: <ac6e61fc0908012153o5f6f5ee9ocbcdef8b21dda20b@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Sat, 1 Aug 2009 23:08:31 -0700
Message-ID: <c7d45fc70908012308i2764a7f4g1c86dfe90880194e@mail.gmail.com>
Subject: Re: Counting no. of keys.
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd59ce0c2f7ec0470227c9e
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd59ce0c2f7ec0470227c9e
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Sure.  Write a word count map-reduce program.  The mapper outputs the key
from the sequence file as the output key and includes a count.  Then you do
the normal combiner and reducer from a normal word count program.

On Sat, Aug 1, 2009 at 9:53 PM, prashant ullegaddi <prashullegaddi@gmail.com
> wrote:

> Hi,
>
> I've say 800 sequence files written using SequenceFileOutputFormat. Is
> there
> any way to know
> no. of unique keys in those sequence files?
>
> Thanks,
> Prashant.
>



-- 
Ted Dunning, CTO
DeepDyve

--000e0cd59ce0c2f7ec0470227c9e--

From common-user-return-16477-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 02 11:31:01 2009
Return-Path: <common-user-return-16477-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 33331 invoked from network); 2 Aug 2009 11:31:00 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 2 Aug 2009 11:31:00 -0000
Received: (qmail 51727 invoked by uid 500); 2 Aug 2009 11:31:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 51639 invoked by uid 500); 2 Aug 2009 11:31:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 51629 invoked by uid 500); 2 Aug 2009 11:31:01 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 51625 invoked by uid 99); 2 Aug 2009 11:31:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 02 Aug 2009 11:31:01 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 02 Aug 2009 11:30:51 +0000
Received: by fxm25 with SMTP id 25so2135920fxm.29
        for <core-user@hadoop.apache.org>; Sun, 02 Aug 2009 04:30:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=bKYcV1CNMgXMua+I+ZXzXgn5iItf4a4KLIj0GWl92lQ=;
        b=kg1IPBR2zNdJbgTFXxK6UmhFFQbIzOYaIAHErbODruiRZ7cvA73PfdHzvhsW2JzvBv
         muGwGWD/3duPh5UkiFHYLyw9HTwStokWUwAKak2vwL3jwTicDa+kV7mvOruW+yzSJ+Ks
         Igl9XHwMNNLCWw73vZpfVh+fBfbvtGCDm6ULM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=H3djBAMjeV7gvhZheBxVUU4pCzVb7P4BkzBxtZSHhtrZqhwnKBbt36nNelRiNGgKVc
         e5WVYLGyCewZQXO8zcJxXsfT7ioGA+E+8BOYZBnIVDuZ7NV9BPTrJFbVRtJQz3wf17bn
         HnMiaxV+Un8mRxytq6KnslNGsGOvGmuH9T4Ik=
MIME-Version: 1.0
Received: by 10.223.117.75 with SMTP id p11mr2058738faq.75.1249212631590; Sun, 
	02 Aug 2009 04:30:31 -0700 (PDT)
In-Reply-To: <77938bc20906231427u6f0b4db2p9905c626962f4076@mail.gmail.com>
References: <77938bc20906210306q152c8681g2af43dd34b3f6ed0@mail.gmail.com>
	 <77938bc20906220609y29ae0627n1816dd4f56e4c6f3@mail.gmail.com>
	 <4A3FECA4.7010809@apache.org>
	 <77938bc20906221358l13da4fa6sa741202557a87ad8@mail.gmail.com>
	 <77938bc20906230131u2f853032ydd4e94e97d652918@mail.gmail.com>
	 <4A40F7C6.3070905@yahoo-inc.com> <4A412D22.9050000@yahoo-inc.com>
	 <77938bc20906231327r5b8e779i93e2b45de9732780@mail.gmail.com>
	 <4A414034.2050405@yahoo-inc.com>
	 <77938bc20906231427u6f0b4db2p9905c626962f4076@mail.gmail.com>
Date: Sun, 2 Aug 2009 14:30:31 +0300
Message-ID: <77938bc20908020430i17276096mc5f597bd52f2c272@mail.gmail.com>
Subject: Re: "Too many open files" error, which gets resolved after some time
From: Stas Oskin <stas.oskin@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c5b1ef27a8cf047026fba5
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5b1ef27a8cf047026fba5
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

I'd like to raise this issue once again, just to clarify a point.

If I have only one thread writing to HDFS, the amount of fd's should be 4,
resulting from:

1) input
2) output
3) epoll
4) stream itself

And these 4 fds should be cleared out after 10 seconds.

Is this correct?

Thanks in advance for the information!

2009/6/24 Stas Oskin <stas.oskin@gmail.com>

> Hi.
>
> So if I open one stream, it should be 4?
>
>
>
> 2009/6/23 Raghu Angadi <rangadi@yahoo-inc.com>
>
>>
>> how many threads do you have? Number of active threads is very important.
>> Normally,
>>
>> #fds = (3 * #threads_blocked_on_io) + #streams
>>
>> 12 per stream is certainly way off.
>>
>> Raghu.
>>
>>
>> Stas Oskin wrote:
>>
>>> Hi.
>>>
>>> In my case it was actually ~ 12 fd's per stream, which included pipes and
>>> epolls.
>>>
>>> Could it be that HDFS opens 3 x 3 (input - output - epoll) fd's per each
>>> thread, which make it close to the number I mentioned? Or it always 3 at
>>> maximum per thread / stream?
>>>
>>> Up to 10 sec looks quite the correct number, it seems it gets freed
>>> arround
>>> this time indeed.
>>>
>>> Regards.
>>>
>>> 2009/6/23 Raghu Angadi <rangadi@yahoo-inc.com>
>>>
>>>  To be more accurate, once you have HADOOP-4346,
>>>>
>>>> fds for epoll and pipes = 3 * threads blocked on Hadoop I/O
>>>>
>>>> Unless you have hundreds of threads at a time, you should not see
>>>> hundreds
>>>> of these. These fds stay up to 10sec even after the
>>>> threads exit.
>>>>
>>>> I am a bit confused about your exact situation. Please check number of
>>>> threads if you still facing the problem.
>>>>
>>>> Raghu.
>>>>
>>>>
>>>> Raghu Angadi wrote:
>>>>
>>>>  since you have HADOOP-4346, you should not have excessive epoll/pipe
>>>>> fds
>>>>> open. First of all do you still have the problem? If yes, how many
>>>>> hadoop
>>>>> streams do you have at a time?
>>>>>
>>>>> System.gc() won't help if you have HADOOP-4346.
>>>>>
>>>>> Ragu.
>>>>>
>>>>>  Thanks for your opinion!
>>>>>
>>>>>> 2009/6/22 Stas Oskin <stas.oskin@gmail.com>
>>>>>>
>>>>>>  Ok, seems this issue is already patched in the Hadoop distro I'm
>>>>>> using
>>>>>>
>>>>>>> (Cloudera).
>>>>>>>
>>>>>>> Any idea if I still should call GC manually/periodically to clean out
>>>>>>> all
>>>>>>> the stale pipes / epolls?
>>>>>>>
>>>>>>> 2009/6/22 Steve Loughran <stevel@apache.org>
>>>>>>>
>>>>>>>  Stas Oskin wrote:
>>>>>>>
>>>>>>>>  Hi.
>>>>>>>>
>>>>>>>>  So what would be the recommended approach to pre-0.20.x series?
>>>>>>>>>
>>>>>>>>> To insure each file is used only by one thread, and then it safe to
>>>>>>>>> close
>>>>>>>>> the handle in that thread?
>>>>>>>>>
>>>>>>>>> Regards.
>>>>>>>>>
>>>>>>>>>  good question -I'm not sure. For anythiong you get with
>>>>>>>>>
>>>>>>>> FileSystem.get(),
>>>>>>>> its now dangerous to close, so try just setting the reference to
>>>>>>>> null
>>>>>>>> and
>>>>>>>> hoping that GC will do the finalize() when needed
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>
>>

--001636c5b1ef27a8cf047026fba5--

From common-user-return-16478-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 00:37:46 2009
Return-Path: <common-user-return-16478-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 131 invoked from network); 3 Aug 2009 00:37:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 00:37:46 -0000
Received: (qmail 63006 invoked by uid 500); 3 Aug 2009 00:37:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 62907 invoked by uid 500); 3 Aug 2009 00:37:48 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 62897 invoked by uid 99); 3 Aug 2009 00:37:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 00:37:48 +0000
X-ASF-Spam-Status: No, hits=1.0 required=10.0
	tests=FS_LARGE_PERCENT2,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [217.72.192.248] (HELO fmmailgate07.web.de) (217.72.192.248)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 00:37:38 +0000
Received: from web.de 
	by fmmailgate07.web.de (Postfix) with SMTP id 190DBE260
	for <common-user@hadoop.apache.org>; Mon,  3 Aug 2009 02:37:18 +0200 (CEST)
Received: from [134.96.63.233] by freemailng5303.web.de with HTTP;
 Mon, 03 Aug 2009 02:37:16 +0200
Date: Mon, 03 Aug 2009 02:37:16 +0200
Message-Id: <1181233090@web.de>
MIME-Version: 1.0
From: 20seconds@web.de
To: common-user@hadoop.apache.org
Subject: Job status task attempt 120%:
Organization: http://freemail.web.de/
X-Provags-Id: V01U2FsdGVkX18aRNyMwTaDY9+A6Zf90MVPZ/l7oatzqKFfBbc6OZYAGi5PN
 Fs1e59TVI00dzNRfNKCC0tmdeA+xQvoSN1hIS0prhtZvQhRqXM=
Content-Type: text/plain; charset=iso-8859-15
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi, 
when I check my running jobs via the jobtracker web interface I see that one task attempt is at 120% .
Is there a logical explanation?
Thanks


From common-user-return-16479-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 01:03:59 2009
Return-Path: <common-user-return-16479-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 4249 invoked from network); 3 Aug 2009 01:03:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 01:03:58 -0000
Received: (qmail 74944 invoked by uid 500); 3 Aug 2009 01:04:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 74864 invoked by uid 500); 3 Aug 2009 01:04:01 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 74854 invoked by uid 99); 3 Aug 2009 01:04:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 01:04:01 +0000
X-ASF-Spam-Status: No, hits=-4.0 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of SHANI@il.ibm.com designates 195.212.17.162 as permitted sender)
Received: from [195.212.17.162] (HELO mtagate2.de.ibm.com) (195.212.17.162)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 01:03:51 +0000
Received: from d12nrmr1707.megacenter.de.ibm.com (d12nrmr1707.megacenter.de.ibm.com [9.149.167.81])
	by mtagate2.de.ibm.com (8.13.1/8.13.1) with ESMTP id n7313TwK000893
	for <common-user@hadoop.apache.org>; Mon, 3 Aug 2009 01:03:29 GMT
Received: from d12av06.megacenter.de.ibm.com (d12av06.megacenter.de.ibm.com [9.149.165.230])
	by d12nrmr1707.megacenter.de.ibm.com (8.13.8/8.13.8/NCO v10.0) with ESMTP id n7313TBf2048138
	for <common-user@hadoop.apache.org>; Mon, 3 Aug 2009 03:03:29 +0200
Received: from d12av06.megacenter.de.ibm.com (loopback [127.0.0.1])
	by d12av06.megacenter.de.ibm.com (8.14.3/8.13.1/NCO v10.0 AVout) with ESMTP id n7313TfG022424
	for <common-user@hadoop.apache.org>; Mon, 3 Aug 2009 03:03:29 +0200
Received: from d12mc102.megacenter.de.ibm.com (d12mc102.megacenter.de.ibm.com [9.149.167.114])
	by d12av06.megacenter.de.ibm.com (8.14.3/8.13.1/NCO v10.0 AVin) with ESMTP id n7313SGc022418
	for <common-user@hadoop.apache.org>; Mon, 3 Aug 2009 03:03:28 +0200
Subject: AUTO: Uri Shani is out of the office (returning 25/08/2009)
Auto-Submitted: auto-generated
From: Uri Shani <SHANI@il.ibm.com>
To: common-user@hadoop.apache.org
Message-ID: <OF05DB13E0.FC6CBE61-ONC2257607.0005CFA0-C2257607.0005CFA0@il.ibm.com>
Date: Mon, 3 Aug 2009 04:03:28 +0300
X-MIMETrack: Serialize by Router on D12MC102/12/M/IBM(Release 8.5|December 05, 2008) at
 03/08/2009 04:03:28
MIME-Version: 1.0
Content-type: text/plain; charset=US-ASCII
X-Virus-Checked: Checked by ClamAV on apache.org


I am out of the office until 25/08/2009.

Parial email access.
More affordable access to uri.shani@gmail.com


Note: This is an automated response to your message  "Job status task
attempt 120%:" sent on 3/8/09 3:37:16.

This is the only notification you will receive while this person is away.


From common-user-return-16480-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 02:09:58 2009
Return-Path: <common-user-return-16480-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 24998 invoked from network); 3 Aug 2009 02:09:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 02:09:58 -0000
Received: (qmail 97803 invoked by uid 500); 3 Aug 2009 02:10:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 97690 invoked by uid 500); 3 Aug 2009 02:10:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 97680 invoked by uid 99); 3 Aug 2009 02:10:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 02:10:00 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of public@hugh.gmane.org designates 80.91.229.8 as permitted sender)
Received: from [80.91.229.8] (HELO hugh.gmane.org) (80.91.229.8)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 02:09:48 +0000
Received: from public by hugh.gmane.org with local (Exim 4.63)
	(envelope-from <public@hugh.gmane.org>)
	id 1MXmzM-0002rf-Dk
	for common-user@hadoop.apache.org; Mon, 03 Aug 2009 04:09:24 +0200
Received: from smtp106.sbc.mail.mud.yahoo.com ([68.142.198.205])
	by hugh.gmane.org with smtp (Exim 4.63)
	(envelope-from <billy_pearson@sbcglobal.net>)
	id 1MXmzG-0002mx-5s
	for public-common-user-7ArZoLwFLBtd/SJB6HiN2Ni2O/JbrIOy@hugh.gmane.org; Mon, 03 Aug 2009 04:09:18 +0200
Received: (qmail 36807 invoked from network); 3 Aug 2009 02:09:16 -0000
DomainKey-Signature: a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=sbcglobal.net;
  h=Received:X-YMail-OSG:X-Yahoo-Newman-Property:Message-ID:From:To:References:In-Reply-To:Subject:Date:MIME-Version:Content-Type:Content-Transfer-Encoding:X-Priority:X-MSMail-Priority:X-Mailer:X-MimeOLE;
  b=fTFyap9H+vNj56qS3Djmz8mldGIigZCcrHlLAjZlGCg8/uRWwE250I2ww7/ePpLcqnOJYiL+bJ3mfh5Zhcce6cqVBtcQdMXE1HGlFhoUUTt5SgupJ6t2FwxAdCKIi7PB9FSxNlfAPlXdyNSKYYs/B2mu8ou3nTwwqA+ULY3COeQ=  ;
Received: from unknown (HELO BillyPC) (billy_pearson@75.48.250.198 with login)
  by smtp106.sbc.mail.mud.yahoo.com with SMTP; 3 Aug 2009 02:09:16 -0000
X-YMail-OSG: O_OubuAVM1kA0b6MJDntk0jHIUrhw7CxBBJ6ozXM2lQ7368nSyQ_6IUdYi4L98bfuS3VNPUIXfubTlZL.l65D68v7.CWsFpd6c4CCcnoJSt3F8nnLb76supbDjL8wyIJX4IIgG1MKHDd021afY_CKe8kJ_H9O4XTNNFWsZldNiTHHnUlP9UpNsM5MqEFuVimg8P_tykrgco9Ts759ugMpMtK4lIDBtZzm4t0F2PAdW0mf2.KPEEc6tGjEz1atBPAO5vzYfVH5G3n_bYQcUOUCPWR63wXFSGhsq7rwe0lkKs8EQwY0C4sT73fy99vJfpdGf_4b0Xn0oZx5YKfFivG
X-Yahoo-Newman-Property: ymail-3
Message-ID: <39FE7BFBE62D4305970B2EB1B3469FF5@BillyPC>
From: "Billy Pearson" <billy_pearson@sbcglobal.net>
To: <public-common-user-7ArZoLwFLBtd/SJB6HiN2Ni2O/JbrIOy@hugh.gmane.org>
References: <32dca9ed0907280553u5d604296kd73c86cc246d76c1@mail.gmail.com>
In-Reply-To: <32dca9ed0907280553u5d604296kd73c86cc246d76c1@mail.gmail.com>
Subject: Re: MapFile performance
Date: Sun, 2 Aug 2009 21:09:21 -0500
MIME-Version: 1.0
Content-Type: text/plain;
	format=flowed;
	charset="iso-8859-1";
	reply-type=original
Content-Transfer-Encoding: 7bit
X-Priority: 3
X-MSMail-Priority: Normal
X-Mailer: Microsoft Windows Mail 6.0.6002.18005
X-MimeOLE: Produced By Microsoft MimeOLE V6.0.6002.18005
X-Virus-Checked: Checked by ClamAV on apache.org



not sure if its still there but there was a parm in the hadoop-site conf 
file that would allow you to skip x number if index when reading it in to 
memory.
>From what I understand we scan find the key offset just before the data and 
seek once and read until we find the key.

Billy


----- Original Message ----- 
From: "Andy Liu" <andyliu1227-Re5JQEeQqe8AvxtiuMwx3w@public.gmane.org>
Newsgroups: gmane.comp.jakarta.lucene.hadoop.user
To: <core-user-7ArZoLwFLBtd/SJB6HiN2Ni2O/JbrIOy@public.gmane.org>
Sent: Tuesday, July 28, 2009 7:53 AM
Subject: MapFile performance


>I have a bunch of Map/Reduce jobs that process documents and writes the
> results out to a few MapFiles.  These MapFiles are subsequently searched 
> in
> an interactive application.
>
> One problem I'm running into is that if the values in the MapFile data 
> file
> are fairly large, lookup can be slow.  This is because the MapFile index
> only stores every 128th key by default (io.map.index.interval), and after
> the binary search it may have to scan/skip through up to 127 values (off 
> of
> disk) before it finds the matching record.  I've tried 
> io.map.index.interval
> = 1, which brings average get() times from 1200ms to 200ms, but at the 
> cost
> of memory during runtime, which is undesirable.
>
> One possible solution is to have the MapFile index store every single 
> <key,
> offset> pair.  Then MapFile.Reader, upon startup, would read every 128th 
> key
> in memory.  MapFile.Reader.get() would behave the same way except instead 
> of
> seeking through the values SequenceFile it would seek through the index
> SequenceFile until it finds the matching record, and then it can seek to 
> the
> corresponding offset in the values.  I'm going off the assumption that 
> it's
> much faster to scan through the index (small keys) than it is to scan
> through the values (large values).
>
> Or maybe the index can be some kind of disk-based btree or bdb-like
> implementation?
>
> Anybody encounter this problem before?
>
> Andy
> 



From common-user-return-16481-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 04:28:03 2009
Return-Path: <common-user-return-16481-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 69722 invoked from network); 3 Aug 2009 04:28:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 04:28:03 -0000
Received: (qmail 82296 invoked by uid 500); 3 Aug 2009 04:28:06 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82212 invoked by uid 500); 3 Aug 2009 04:28:05 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82202 invoked by uid 99); 3 Aug 2009 04:28:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 04:28:05 +0000
X-ASF-Spam-Status: No, hits=3.2 required=10.0
	tests=FS_LARGE_PERCENT2,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of prashullegaddi@gmail.com designates 209.85.198.227 as permitted sender)
Received: from [209.85.198.227] (HELO rv-out-0506.google.com) (209.85.198.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 04:27:56 +0000
Received: by rv-out-0506.google.com with SMTP id k40so953953rvb.29
        for <common-user@hadoop.apache.org>; Sun, 02 Aug 2009 21:27:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=cst35QrByfyVcMxUTNOd5t1962+JIcL5TyEKCxPuyr0=;
        b=fM7LdFP2gcnO5nazSjr88zPqqGFj4KJyV4xM9mug/DxIXQOBCKaOn7q47S/KkHPCVy
         taf6MUPUgFlKhiAeOcVr/bCOqA9zyhKqfydZYfhaHHcI72UNWCyDlJKq/I20+KnJkhac
         4Si6vBM2kK6XFCizYIvqmx8ckZyZjgJoqLUgo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=ntkLUbJ+klAVfEOkycxzlWacG4drvgpYdRLMafVVzztwqeqFvAwQnZjSxO30mzP2z6
         96UXUv4ZGBCik34pLtOix6/vX/Tkc9NM0wZ2Im0NXW9IzabYUq/hXwuhDqU71yE65e++
         KLL0yeXZIisIRUqUiNZW+zu/qgcB+AZ0SyYDg=
MIME-Version: 1.0
Received: by 10.141.37.8 with SMTP id p8mr3331956rvj.239.1249273655559; Sun, 
	02 Aug 2009 21:27:35 -0700 (PDT)
In-Reply-To: <1181233090@web.de>
References: <1181233090@web.de>
Date: Mon, 3 Aug 2009 09:57:35 +0530
Message-ID: <ac6e61fc0908022127j5975ac6coa21e1f6254da8413@mail.gmail.com>
Subject: Re: Job status task attempt 120%:
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd22c1677854e04703530f9
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd22c1677854e04703530f9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Take a look at this post:
http://mail-archives.apache.org/mod_mbox/hadoop-common-user/200907.mbox/%3Ce4fc0d2a0907091445t7ddd1837w8477480deb5a9ce9@mail.gmail.com%3E

Thanks,
Prashant.

On Mon, Aug 3, 2009 at 6:07 AM, <20seconds@web.de> wrote:

> Hi,
> when I check my running jobs via the jobtracker web interface I see that
> one task attempt is at 120% .
> Is there a logical explanation?
> Thanks
>
>

--000e0cd22c1677854e04703530f9--

From common-user-return-16482-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 04:35:38 2009
Return-Path: <common-user-return-16482-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70313 invoked from network); 3 Aug 2009 04:35:38 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 04:35:38 -0000
Received: (qmail 87544 invoked by uid 500); 3 Aug 2009 04:35:41 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87457 invoked by uid 500); 3 Aug 2009 04:35:41 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87446 invoked by uid 99); 3 Aug 2009 04:35:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 04:35:41 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pallavi.palleti@corp.aol.com designates 205.188.249.133 as permitted sender)
Received: from [205.188.249.133] (HELO omr-d35.mx.aol.com) (205.188.249.133)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 04:35:31 +0000
Received: from AOLDTCMEH01.ad.office.aol.com (aoldtcmeh01.office.aol.com [10.180.121.20]) by omr-d35.mx.aol.com (v117.7) with ESMTP id MAILOMRD355-7ef64a7668fa384; Mon, 03 Aug 2009 00:35:06 -0400
Received: from AOLMTCMEI04.ad.office.aol.com ([10.178.3.24]) by AOLDTCMEH01.ad.office.aol.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Mon, 3 Aug 2009 00:35:06 -0400
Received: from localhost ([10.178.3.11]) by AOLMTCMEI04.ad.office.aol.com over TLS secured channel with Microsoft SMTPSVC(6.0.3790.3959);
	 Mon, 3 Aug 2009 00:35:06 -0400
Date: Mon, 3 Aug 2009 10:05:00 +0530 (GMT+05:30)
From: Pallavi Palleti <pallavi.palleti@corp.aol.com>
To: common-user@hadoop.apache.org
Message-ID: <32527729.1341249274095137.JavaMail.pallavi@e1a31053e.in.office.aol.com>
In-Reply-To: <24861273.1321249273926980.JavaMail.pallavi@e1a31053e.in.office.aol.com>
Subject: No Space Left On Device though space is available
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-OriginalArrivalTime: 03 Aug 2009 04:35:06.0804 (UTC) FILETIME=[C6E02740:01CA13F3]
X-AOL-IP: 10.180.121.20
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

We are having a 60 node cluster running hadoop-0.18.2. We are seeing "No Space Left On Device" and the detailed error is 
 org.apache.hadoop.ipc.RemoteException: java.io.IOException: java.lang.RuntimeException: javax.xml.transfor
m.TransformerException: java.io.IOException: No space left on device
        at org.apache.hadoop.conf.Configuration.write(Configuration.java:996)
        at org.apache.hadoop.mapred.JobHistory$JobInfo.logSubmitted(JobHistory.java:530)
        at org.apache.hadoop.mapred.JobInProgress.<init>(JobInProgress.java:196)
        at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:1783)
        at sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)

        at org.apache.hadoop.ipc.Client.call(Client.java:715)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
        at org.apache.hadoop.mapred.$Proxy1.submitJob(Unknown Source)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:788)
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1026)

Surprisingly, there is no space issue. Still, it is giving above error. Can someone kindly let me know what could be the issue?

Thanks
Pallavi

From common-user-return-16483-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 04:40:20 2009
Return-Path: <common-user-return-16483-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70883 invoked from network); 3 Aug 2009 04:40:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 04:40:20 -0000
Received: (qmail 92129 invoked by uid 500); 3 Aug 2009 04:40:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 92026 invoked by uid 500); 3 Aug 2009 04:40:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 92016 invoked by uid 99); 3 Aug 2009 04:40:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 04:40:22 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of prashullegaddi@gmail.com designates 209.85.198.232 as permitted sender)
Received: from [209.85.198.232] (HELO rv-out-0506.google.com) (209.85.198.232)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 04:40:14 +0000
Received: by rv-out-0506.google.com with SMTP id k40so955670rvb.29
        for <common-user@hadoop.apache.org>; Sun, 02 Aug 2009 21:39:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=nvuALa9jZyWT1dcTCW2Tk7smddkKFjdFOG+6oFD+f28=;
        b=qNaJTo5dxhNsp1Qu0oA6Utn1rtiVdcKM/Homi/HkCK22q+J4QOHnqjlSuIVYfzhHjA
         05V6y2LlTPqzpmrqUjmH8AG+WS6jub9Qp/mDVJl03Ed/xqt17+mgVULKw0dI7rgHLKZW
         cCuW7H6VAgFvv+rnuX5l/AbeeSiNh19Ac7llI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=F2phQCad/Y/NyvckWnFx16ukexR67Byh5gCXS3DefSHNZLkOmkivCfYC5W8AXvhBdn
         5rY8H7QoVj6T6xNHZktRcCfRTKOTEmz6klhLWpzqQa2iyQKnnoUcC+x7BAAjtiC0og7P
         0HS3AHItnlAR1kTmx6KFzyxueMMSn83XFybk0=
MIME-Version: 1.0
Received: by 10.140.169.4 with SMTP id r4mr3348169rve.265.1249274394563; Sun, 
	02 Aug 2009 21:39:54 -0700 (PDT)
In-Reply-To: <32527729.1341249274095137.JavaMail.pallavi@e1a31053e.in.office.aol.com>
References: <24861273.1321249273926980.JavaMail.pallavi@e1a31053e.in.office.aol.com>
	 <32527729.1341249274095137.JavaMail.pallavi@e1a31053e.in.office.aol.com>
Date: Mon, 3 Aug 2009 10:09:54 +0530
Message-ID: <ac6e61fc0908022139va75a7d7k75ee37ea33da9d11@mail.gmail.com>
Subject: Re: No Space Left On Device though space is available
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd2c0e083d4800470355c2c
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd2c0e083d4800470355c2c
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Are you using any space on local nodes? When we indexed 1TB on 8 nodes, we
were creating index on local file system and
then copying the same to DFS. It so happened that there wasn't any space
left. After that we started moving the index instead of copying it.
Everything worked fine.  Probably that could be a problem with your
application as well.

Thanks,
Prashant.

On Mon, Aug 3, 2009 at 10:05 AM, Pallavi Palleti <
pallavi.palleti@corp.aol.com> wrote:

> Hi all,
>
> We are having a 60 node cluster running hadoop-0.18.2. We are seeing "No
> Space Left On Device" and the detailed error is
>  org.apache.hadoop.ipc.RemoteException: java.io.IOException:
> java.lang.RuntimeException: javax.xml.transfor
> m.TransformerException: java.io.IOException: No space left on device
>        at
> org.apache.hadoop.conf.Configuration.write(Configuration.java:996)
>        at
> org.apache.hadoop.mapred.JobHistory$JobInfo.logSubmitted(JobHistory.java:530)
>        at
> org.apache.hadoop.mapred.JobInProgress.<init>(JobInProgress.java:196)
>        at
> org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:1783)
>        at sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)
>        at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
>        at java.lang.reflect.Method.invoke(Method.java:597)
>        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
>        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
>
>        at org.apache.hadoop.ipc.Client.call(Client.java:715)
>        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
>        at org.apache.hadoop.mapred.$Proxy1.submitJob(Unknown Source)
>        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:788)
>        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1026)
>
> Surprisingly, there is no space issue. Still, it is giving above error. Can
> someone kindly let me know what could be the issue?
>
> Thanks
> Pallavi
>

--000e0cd2c0e083d4800470355c2c--

From common-user-return-16484-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 05:13:32 2009
Return-Path: <common-user-return-16484-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75127 invoked from network); 3 Aug 2009 05:13:32 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 05:13:32 -0000
Received: (qmail 5263 invoked by uid 500); 3 Aug 2009 05:13:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 5178 invoked by uid 500); 3 Aug 2009 05:13:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 5168 invoked by uid 99); 3 Aug 2009 05:13:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:13:35 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pallavi.palleti@corp.aol.com designates 64.12.143.151 as permitted sender)
Received: from [64.12.143.151] (HELO omr-m31.mx.aol.com) (64.12.143.151)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:13:27 +0000
Received: from AOLMTCMEH01.ad.office.aol.com (aolmtcmeh01.office.aol.com [10.178.121.20]) by omr-m31.mx.aol.com (v117.7) with ESMTP id MAILOMRM315-7f064a7671dd107; Mon, 03 Aug 2009 01:13:01 -0400
Received: from EVSBNG01.ad.office.aol.com ([10.146.190.242]) by AOLMTCMEH01.ad.office.aol.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Mon, 3 Aug 2009 01:13:00 -0400
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
Subject: RE: No Space Left On Device though space is available
Date: Mon, 3 Aug 2009 10:43:00 +0530
Message-ID: <2AAFC2B9E4C5DC4F859F154FB664CF5F061A8BE9@EVSBNG01.ad.office.aol.com>
In-Reply-To: <ac6e61fc0908022139va75a7d7k75ee37ea33da9d11@mail.gmail.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: No Space Left On Device though space is available
Thread-Index: AcoT9Ij2uwCYJSvOT8eEsgeKr4mCVgAAMZaQ
References: <24861273.1321249273926980.JavaMail.pallavi@e1a31053e.in.office.aol.com> <32527729.1341249274095137.JavaMail.pallavi@e1a31053e.in.office.aol.com> <ac6e61fc0908022139va75a7d7k75ee37ea33da9d11@mail.gmail.com>
From: "Palleti, Pallavi" <pallavi.palleti@corp.aol.com>
To: <common-user@hadoop.apache.org>
X-OriginalArrivalTime: 03 Aug 2009 05:13:00.0799 (UTC) FILETIME=[124840F0:01CA13F9]
X-AOL-IP: 10.178.121.20
X-Virus-Checked: Checked by ClamAV on apache.org

No. These are production jobs which were working pretty fine and
suddenly, we started seeing these issues. And, if you see the error log,
the jobs are failing at the time of submission itself while copying the
application jar. And, when I see the client machine disk size and also
HDFS, it is only 60% full.

Thanks
Pallavi

-----Original Message-----
From: prashant ullegaddi [mailto:prashullegaddi@gmail.com]=20
Sent: Monday, August 03, 2009 10:10 AM
To: common-user@hadoop.apache.org
Subject: Re: No Space Left On Device though space is available

Are you using any space on local nodes? When we indexed 1TB on 8 nodes,
we
were creating index on local file system and
then copying the same to DFS. It so happened that there wasn't any space
left. After that we started moving the index instead of copying it.
Everything worked fine.  Probably that could be a problem with your
application as well.

Thanks,
Prashant.

On Mon, Aug 3, 2009 at 10:05 AM, Pallavi Palleti <
pallavi.palleti@corp.aol.com> wrote:

> Hi all,
>
> We are having a 60 node cluster running hadoop-0.18.2. We are seeing
"No
> Space Left On Device" and the detailed error is
>  org.apache.hadoop.ipc.RemoteException: java.io.IOException:
> java.lang.RuntimeException: javax.xml.transfor
> m.TransformerException: java.io.IOException: No space left on device
>        at
> org.apache.hadoop.conf.Configuration.write(Configuration.java:996)
>        at
>
org.apache.hadoop.mapred.JobHistory$JobInfo.logSubmitted(JobHistory.java
:530)
>        at
> org.apache.hadoop.mapred.JobInProgress.<init>(JobInProgress.java:196)
>        at
> org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:1783)
>        at sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)
>        at
>
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessor
Impl.java:25)
>        at java.lang.reflect.Method.invoke(Method.java:597)
>        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
>        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
>
>        at org.apache.hadoop.ipc.Client.call(Client.java:715)
>        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
>        at org.apache.hadoop.mapred.$Proxy1.submitJob(Unknown Source)
>        at
org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:788)
>        at
org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1026)
>
> Surprisingly, there is no space issue. Still, it is giving above
error. Can
> someone kindly let me know what could be the issue?
>
> Thanks
> Pallavi
>

From common-user-return-16485-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 05:13:35 2009
Return-Path: <common-user-return-16485-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75203 invoked from network); 3 Aug 2009 05:13:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 05:13:35 -0000
Received: (qmail 6879 invoked by uid 500); 3 Aug 2009 05:13:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 6818 invoked by uid 500); 3 Aug 2009 05:13:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 6785 invoked by uid 500); 3 Aug 2009 05:13:37 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 6771 invoked by uid 99); 3 Aug 2009 05:13:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:13:37 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sugandha.n87@gmail.com designates 209.85.132.243 as permitted sender)
Received: from [209.85.132.243] (HELO an-out-0708.google.com) (209.85.132.243)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:13:29 +0000
Received: by an-out-0708.google.com with SMTP id c38so1908335ana.29
        for <core-user@hadoop.apache.org>; Sun, 02 Aug 2009 22:13:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=/wX3vLm7FSn2GrVNpbqA5sKB/ByZnC92QJAiz8gZ8Hg=;
        b=fiJNZLGHXzo/65IMdbihdZeSVi53KJPN+QXHveXxzRXzaLLj7rZz6NgKS91eTFD8Uu
         iWC8BBueNDM8xaLGKl6kOkb5sWfUsonZYK8m0TpKI98rHV9iNyH2uEVjlGHKrFYXG5/2
         h2EFd6SXN2wHHh1mOI8M/s+ze0uewtNQs9Yrw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=WNrwiEUrXd/HRZmgaVge/FOg1kMjH1QG4aHwdfNh9Ven5+Q5p/LuYGUJnosDauJEqE
         WBo5rWuZKKvyPVQo9oFlpKRQGPkUUwbPwXW4C+dMVmTaW0tlGiHD94f6cComZwQnaEY5
         Qup/DoD7pP/pC0GznX8Diu7MsB2zwYKTwqx7I=
MIME-Version: 1.0
Received: by 10.231.38.140 with SMTP id b12mr1375119ibe.29.1249276388366; Sun, 
	02 Aug 2009 22:13:08 -0700 (PDT)
Date: Mon, 3 Aug 2009 10:43:08 +0530
Message-ID: <6f72e2db0908022213u1f215976nda908f32c2495ae1@mail.gmail.com>
Subject: Few issues::!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0003255746f25ad9dc047035d3b3
X-Virus-Checked: Checked by ClamAV on apache.org

--0003255746f25ad9dc047035d3b3
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello!

Can any kind of testing be done on Namenode and the hadoop cluster in order
to judge and measure the overall performance of Hadoop cluster in order to
prove the power,efficiency and all those quality factors.?


-- 
Regards!
Sugandha

--0003255746f25ad9dc047035d3b3--

From common-user-return-16486-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 05:15:37 2009
Return-Path: <common-user-return-16486-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75846 invoked from network); 3 Aug 2009 05:15:37 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 05:15:37 -0000
Received: (qmail 10661 invoked by uid 500); 3 Aug 2009 05:15:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10579 invoked by uid 500); 3 Aug 2009 05:15:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10523 invoked by uid 500); 3 Aug 2009 05:15:40 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 10503 invoked by uid 99); 3 Aug 2009 05:15:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:15:40 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sugandha.n87@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:15:32 +0000
Received: by gxk18 with SMTP id 18so5102252gxk.5
        for <core-user@hadoop.apache.org>; Sun, 02 Aug 2009 22:15:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=q+4spKPiEgk+UQHciAXeA78KIe0Z+Wcmp+Rb6PhFrk0=;
        b=O1SY5QaM7fQHOyJyk3Z/aRAbHLvi9DJ0/VKxSi6D46VSAWzJA0tXa8l015uYsp25FA
         qTGkOWHJNR273drxvPEcL6wJ6t9WegNib/Bc1+13pHBijoHkz2xAHXIcWFu4SOGoquhE
         +jxjzaavxu6+PDqlLTHLBk6Ymp8XneZ12Xxm0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=xnL4RY00L6ycYuG+ZhzjslW7XlMM/y6WwBjv55Hwst6MVXEKvslkcDbA7dQFyFn3NL
         6D0qUHgKjFlIzkmIfx6OjTBFyuC7tw46rOcrsDd4L9gjUVyNILMELEncAS68MXI4KBAg
         gsaHWc2j+OjK+oN1Qmu4Qvgfnz5kLUmI2Y3gY=
MIME-Version: 1.0
Received: by 10.231.35.140 with SMTP id p12mr1419308ibd.7.1249276511181; Sun, 
	02 Aug 2009 22:15:11 -0700 (PDT)
Date: Mon, 3 Aug 2009 10:45:11 +0530
Message-ID: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
Subject: Re::!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=002215048957acddc9047035daa8
X-Virus-Checked: Checked by ClamAV on apache.org

--002215048957acddc9047035daa8
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I want to compress the data first and then place it in HDFS. Again, while
retrieving the same, I want to uncompress it and place on the desired
destination. Can this be possible. How to get started? Also, I want to get
started with actual coding part of compression and MAP reduce. PLease
suggest me aptly...!



-- 
Regards!
Sugandha

--002215048957acddc9047035daa8--

From common-user-return-16487-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 05:18:47 2009
Return-Path: <common-user-return-16487-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 77112 invoked from network); 3 Aug 2009 05:18:47 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 05:18:47 -0000
Received: (qmail 14198 invoked by uid 500); 3 Aug 2009 05:18:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 14172 invoked by uid 500); 3 Aug 2009 05:18:48 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 14162 invoked by uid 99); 3 Aug 2009 05:18:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:18:47 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of prashullegaddi@gmail.com designates 209.85.198.235 as permitted sender)
Received: from [209.85.198.235] (HELO rv-out-0506.google.com) (209.85.198.235)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:18:38 +0000
Received: by rv-out-0506.google.com with SMTP id k40so960844rvb.29
        for <common-user@hadoop.apache.org>; Sun, 02 Aug 2009 22:18:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=EIoCCBUG217UPSD68Q8iHp/Qc2KUjWH2mfzX1RN0gr4=;
        b=XFJAVokcm8/5aYiKackb9n6HYJHDuXp6z5LE1U7gt0M1g51rZBGIMboeNTcwq/70E2
         HhFurizyrX6peFYW+UeSEb9N17Ev+ueWCoR6j3HoyGbQ5V8G5ssqWnPD5VuO8qtAnv+/
         41kbUNOu5ipum236mRJpouVSI3sTUU7LdDP0s=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=Rm+WNlFY8SiGK7VLR43QgKT6ZJ3O8VgwEK8BxMuAtyAQt8SX2qb47WMukegKjXgJNi
         mwMQeh+1/ioLU6JFCdyYlFue/OQYScLCfvggLAwFETYCoMls/PArbSEUpQw9N9l66Q/5
         1ABdHha6ETLpv17Yuoqgz1yMblr4Jm1mzH79A=
MIME-Version: 1.0
Received: by 10.140.202.20 with SMTP id z20mr3296238rvf.228.1249276697200; 
	Sun, 02 Aug 2009 22:18:17 -0700 (PDT)
In-Reply-To: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
References: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
Date: Mon, 3 Aug 2009 10:48:17 +0530
Message-ID: <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com>
Subject: Re: :!
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd29cb8c3476d047035e5e4
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd29cb8c3476d047035e5e4
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

By "I want to compress the data first and then place it in HDFS", do you
mean you want to compress the data
locally and then copy to DFS?

What's the size of your data? What's the capacity of HDFS?

On Mon, Aug 3, 2009 at 10:45 AM, Sugandha Naolekar
<sugandha.n87@gmail.com>wrote:

> I want to compress the data first and then place it in HDFS. Again, while
> retrieving the same, I want to uncompress it and place on the desired
> destination. Can this be possible. How to get started? Also, I want to get
> started with actual coding part of compression and MAP reduce. PLease
> suggest me aptly...!
>
>
>
> --
> Regards!
> Sugandha
>

--000e0cd29cb8c3476d047035e5e4--

From common-user-return-16488-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 05:33:04 2009
Return-Path: <common-user-return-16488-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 82245 invoked from network); 3 Aug 2009 05:33:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 05:33:04 -0000
Received: (qmail 29551 invoked by uid 500); 3 Aug 2009 05:33:07 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 29495 invoked by uid 500); 3 Aug 2009 05:33:07 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 29485 invoked by uid 99); 3 Aug 2009 05:33:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:33:07 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sugandha.n87@gmail.com designates 209.85.211.202 as permitted sender)
Received: from [209.85.211.202] (HELO mail-yw0-f202.google.com) (209.85.211.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:32:59 +0000
Received: by ywh40 with SMTP id 40so3594041ywh.29
        for <common-user@hadoop.apache.org>; Sun, 02 Aug 2009 22:32:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=pco4x0lcGhrjuPPZdicrp9x/4ROTFf0jPUGZNf3bXS4=;
        b=PYtbVnOCRvhodM+ZqRiZus4V2iwrsK1QA5gr7C99WIF0bzqjH+PbNknsfFN7oc74xu
         AkzhiD5NFKDzPpS52dlABMlKOqIoetbIjo7QmM1zRdCIqzQ17QcFgw1GDZ9qf0jVqOLX
         u45FpR/Mn776p+wIR9hYV0eyv2eZJIZXNc74o=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=pN09EXS5pDoSwRNVuP4wkpmf9QvudQV5gmeXBD9KthQOhJ/j78Rvjq9EMHaHOWrDUA
         958FvSZzFScktCnqVP1oeTN8qfykP8dsgbZiQRI0wwrAMF8FP6OTMtma7jHS6cSlOSvY
         lRx2yheQwxKUW7dDA3ZvC/9cre0le6ly86RSo=
MIME-Version: 1.0
Received: by 10.231.38.140 with SMTP id b12mr1378964ibe.29.1249277558320; Sun, 
	02 Aug 2009 22:32:38 -0700 (PDT)
In-Reply-To: <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com>
References: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
	 <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com>
Date: Mon, 3 Aug 2009 11:02:38 +0530
Message-ID: <6f72e2db0908022232g61528382hafcd4c6821243df5@mail.gmail.com>
Subject: Re: :!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0003255746f216eee0047036197e
X-Virus-Checked: Checked by ClamAV on apache.org

--0003255746f216eee0047036197e
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Yes, You are right. Here goes the details related::

-> I have a Hadoop cluster of 7 nodes. Now there is this 8th machine, which
is not a part of the hadoop cluster.
-> I want to place the data of that machine into the HDFS. Thus, before
placing it in HDFS, I want to compress it, and then dump in the HDFS.
-> I have 4 datanodes in my cluster. also, data might get extended upto tera
bytes.
-> Also, i have set thr replication factor as 2.
-> I guess, for compression, I will have to run map reduce...? right..please
tel me the complete approach that is needed to be followed.

On Mon, Aug 3, 2009 at 10:48 AM, prashant ullegaddi <
prashullegaddi@gmail.com> wrote:

> By "I want to compress the data first and then place it in HDFS", do you
> mean you want to compress the data
> locally and then copy to DFS?
>
> What's the size of your data? What's the capacity of HDFS?
>
> On Mon, Aug 3, 2009 at 10:45 AM, Sugandha Naolekar
> <sugandha.n87@gmail.com>wrote:
>
> > I want to compress the data first and then place it in HDFS. Again, while
> > retrieving the same, I want to uncompress it and place on the desired
> > destination. Can this be possible. How to get started? Also, I want to
> get
> > started with actual coding part of compression and MAP reduce. PLease
> > suggest me aptly...!
> >
> >
> >
> > --
> > Regards!
> > Sugandha
> >
>



-- 
Regards!
Sugandha

--0003255746f216eee0047036197e--

From common-user-return-16489-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 05:47:00 2009
Return-Path: <common-user-return-16489-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 87455 invoked from network); 3 Aug 2009 05:47:00 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 05:47:00 -0000
Received: (qmail 39463 invoked by uid 500); 3 Aug 2009 05:47:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 39366 invoked by uid 500); 3 Aug 2009 05:47:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 39356 invoked by uid 99); 3 Aug 2009 05:47:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:47:02 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 05:46:50 +0000
Received: from EGL-EX07CAS01.ds.corp.yahoo.com (egl-ex07cas01.eglbp.corp.yahoo.com [203.83.248.208])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n735jolA051258
	for <common-user@hadoop.apache.org>; Sun, 2 Aug 2009 22:45:51 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=D2dc27oQIOj57UEK0KAK8qyBsukwR3+/x5+RKLI4hoS8E05gY3ITuNC+43uCuL5a
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.205]) by
 EGL-EX07CAS01.ds.corp.yahoo.com ([203.83.248.215]) with mapi; Mon, 3 Aug 2009
 11:15:50 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Mon, 3 Aug 2009 11:14:55 +0530
Subject: RE: setting parameters for a hadoop job
Thread-Topic: setting parameters for a hadoop job
Thread-Index: AcoSJV9ArP2+/8zTSzOPwZAXp7zr5AB2AWww
Message-ID: <616DA47B2EF5B944B91846785B512FF4AAC0D534A0@EGL-EX07VS01.ds.corp.yahoo.com>
References: <c9b0d8bd0907311416o74b88a4enada08dd3b4a55d1b@mail.gmail.com>
In-Reply-To: <c9b0d8bd0907311416o74b88a4enada08dd3b4a55d1b@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Ideally should be done using generic options parser. Please have a look at =
ToolRunner for more info.

Thanks,
Amogh

-----Original Message-----
From: Mark Kerzner [mailto:markkerzner@gmail.com]=20
Sent: Saturday, August 01, 2009 2:47 AM
To: common-user@hadoop.apache.org
Subject: setting parameters for a hadoop job

Hi,
what is the preferred way of passing parameters to my job? I would want to
put them all in a properties file and pass that file as an argument, after
input and output. But I am not sure if this is recommended.

Thank you,
Mark

From common-user-return-16490-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 06:37:51 2009
Return-Path: <common-user-return-16490-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 13134 invoked from network); 3 Aug 2009 06:37:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 06:37:50 -0000
Received: (qmail 73227 invoked by uid 500); 3 Aug 2009 06:37:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 73127 invoked by uid 500); 3 Aug 2009 06:37:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 73117 invoked by uid 99); 3 Aug 2009 06:37:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 06:37:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of prashullegaddi@gmail.com designates 209.85.216.198 as permitted sender)
Received: from [209.85.216.198] (HELO mail-px0-f198.google.com) (209.85.216.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 06:37:45 +0000
Received: by pxi36 with SMTP id 36so2409359pxi.2
        for <common-user@hadoop.apache.org>; Sun, 02 Aug 2009 23:37:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=oQBagG/h1+3WBwcKMSDinc2858X0I8ZfrroIYOu8dYk=;
        b=WXc9U8i9gDMiQXsw+O2zdGJZuTwOGbTPpWiOjo+bNvPSc4jXjeep5hb8z5gGN36+Mk
         BYeQmsVrdFgEzcOSW+k0pQ5SiSRfxVIrUQ8pvjFZ5/6TV/VFuYuqxhvzz4f/kX8MkaTD
         9ZS2VOkNsUzP87hXUXp7Wc5aTl0Xyd4jLtAoQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=pxU0Scs23LK9pw9x6ay7YYonolAS+vuJI3QzEkyqqFBTE25XPVJVXQMI/2L8HHSG/r
         4xadjjMezKHpgoQTi+emIBg5AyCn+SOZ+4E4Pb78a2bGFjz/lglfJU/UsqAaUbQuuR8e
         UrSc5IFe+lKY14NbnDWiVwzLoZckQBSITtJ9o=
MIME-Version: 1.0
Received: by 10.140.191.12 with SMTP id o12mr3405249rvf.140.1249281445299; 
	Sun, 02 Aug 2009 23:37:25 -0700 (PDT)
In-Reply-To: <6f72e2db0908022232g61528382hafcd4c6821243df5@mail.gmail.com>
References: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
	 <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com>
	 <6f72e2db0908022232g61528382hafcd4c6821243df5@mail.gmail.com>
Date: Mon, 3 Aug 2009 12:07:25 +0530
Message-ID: <ac6e61fc0908022337l2b30be49m6d314fb2b9be2f0c@mail.gmail.com>
Subject: Re: :!
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd2297ac5883c047037006c
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd2297ac5883c047037006c
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I don't think you will be able to compress some data unless it's on HDFS.
What you can do is
1. Manually compress the data on the machine where the data resides. Then,
copy the same to
 HDFS. or
2. Copy the data without compressing to HDFS, then run a job which just
emits the data as it reads
 in key/value pair. You can set
FileOutputFormat.setOutputCompressorClass(job,GzipCodec.class) so
 that output gets gzipped.

Does that solve your problem?

btw you didn't exactly specify your data size (how many TBs).

On Mon, Aug 3, 2009 at 11:02 AM, Sugandha Naolekar
<sugandha.n87@gmail.com>wrote:

> Yes, You are right. Here goes the details related::
>
> -> I have a Hadoop cluster of 7 nodes. Now there is this 8th machine, which
> is not a part of the hadoop cluster.
> -> I want to place the data of that machine into the HDFS. Thus, before
> placing it in HDFS, I want to compress it, and then dump in the HDFS.
> -> I have 4 datanodes in my cluster. also, data might get extended upto
> tera
> bytes.
> -> Also, i have set thr replication factor as 2.
> -> I guess, for compression, I will have to run map reduce...?
> right..please
> tel me the complete approach that is needed to be followed.
>
> On Mon, Aug 3, 2009 at 10:48 AM, prashant ullegaddi <
> prashullegaddi@gmail.com> wrote:
>
> > By "I want to compress the data first and then place it in HDFS", do you
> > mean you want to compress the data
> > locally and then copy to DFS?
> >
> > What's the size of your data? What's the capacity of HDFS?
> >
> > On Mon, Aug 3, 2009 at 10:45 AM, Sugandha Naolekar
> > <sugandha.n87@gmail.com>wrote:
> >
> > > I want to compress the data first and then place it in HDFS. Again,
> while
> > > retrieving the same, I want to uncompress it and place on the desired
> > > destination. Can this be possible. How to get started? Also, I want to
> > get
> > > started with actual coding part of compression and MAP reduce. PLease
> > > suggest me aptly...!
> > >
> > >
> > >
> > > --
> > > Regards!
> > > Sugandha
> > >
> >
>
>
>
> --
> Regards!
> Sugandha
>

--000e0cd2297ac5883c047037006c--

From common-user-return-16491-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 07:02:23 2009
Return-Path: <common-user-return-16491-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 17868 invoked from network); 3 Aug 2009 07:02:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 07:02:23 -0000
Received: (qmail 95694 invoked by uid 500); 3 Aug 2009 07:02:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95614 invoked by uid 500); 3 Aug 2009 07:02:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95455 invoked by uid 99); 3 Aug 2009 07:02:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:02:25 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sugandha.n87@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:02:15 +0000
Received: by gxk18 with SMTP id 18so5134978gxk.5
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 00:01:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=+Wn911VOp95anaKAo57QT8b078nq1iJlhnkuVYl3jfM=;
        b=tFXkItFB/g8x3u5bVtuQ1mR+PjLP7cK/gAjKnea+5yn5h43t70D5WB6dhdjbJ7BS80
         TKFluVvfnCJKzgIdBoDuiS2rqRehSDoVAPe/ybMICSGPct7CNDp5J3N8D6vM0YTsgSKJ
         LDYxT+GZWdwEbLLYzUOf3BrdEBVy6CvtYvVbk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=aq75S56rBSHXPYR5CXKPn9Q7Jy2oIGvbzNGOhpDJlAldA7LmjcNJhsg+OjrFLrtMuQ
         +4J5SBi+MiTDB5rnbyWSBP9bnjKyp0BxMILyiTY+4sGkjVTspc1Cj8zCpqGPoc+Y3Rmt
         5h6GwBSZAt1wHjeUmbz2NyhNVuxDhrue3Xsw4=
MIME-Version: 1.0
Received: by 10.231.34.3 with SMTP id j3mr1440153ibd.43.1249282914018; Mon, 03 
	Aug 2009 00:01:54 -0700 (PDT)
In-Reply-To: <ac6e61fc0908022337l2b30be49m6d314fb2b9be2f0c@mail.gmail.com>
References: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
	 <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com>
	 <6f72e2db0908022232g61528382hafcd4c6821243df5@mail.gmail.com>
	 <ac6e61fc0908022337l2b30be49m6d314fb2b9be2f0c@mail.gmail.com>
Date: Mon, 3 Aug 2009 12:31:53 +0530
Message-ID: <6f72e2db0908030001o2789db9dt512a777173ed59a8@mail.gmail.com>
Subject: Re: :!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221532cda450669a04703758cc
X-Virus-Checked: Checked by ClamAV on apache.org

--00221532cda450669a04703758cc
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

dats fine. But, if I place the data in HDFS and then run map reduce code to
provide compression, then the data will get compressed in sequence files
but, even the original data will reside in the memory;thereby leading or
causing a kind of redundancy of data...

Can u pls suggest me a way out?/

On Mon, Aug 3, 2009 at 12:07 PM, prashant ullegaddi <
prashullegaddi@gmail.com> wrote:

> I don't think you will be able to compress some data unless it's on HDFS.
> What you can do is
> 1. Manually compress the data on the machine where the data resides. Then,
> copy the same to
>  HDFS. or
> 2. Copy the data without compressing to HDFS, then run a job which just
> emits the data as it reads
>  in key/value pair. You can set
> FileOutputFormat.setOutputCompressorClass(job,GzipCodec.class) so
>  that output gets gzipped.
>
> Does that solve your problem?
>
> btw you didn't exactly specify your data size (how many TBs).
>
> On Mon, Aug 3, 2009 at 11:02 AM, Sugandha Naolekar
> <sugandha.n87@gmail.com>wrote:
>
> > Yes, You are right. Here goes the details related::
> >
> > -> I have a Hadoop cluster of 7 nodes. Now there is this 8th machine,
> which
> > is not a part of the hadoop cluster.
> > -> I want to place the data of that machine into the HDFS. Thus, before
> > placing it in HDFS, I want to compress it, and then dump in the HDFS.
> > -> I have 4 datanodes in my cluster. also, data might get extended upto
> > tera
> > bytes.
> > -> Also, i have set thr replication factor as 2.
> > -> I guess, for compression, I will have to run map reduce...?
> > right..please
> > tel me the complete approach that is needed to be followed.
> >
> > On Mon, Aug 3, 2009 at 10:48 AM, prashant ullegaddi <
> > prashullegaddi@gmail.com> wrote:
> >
> > > By "I want to compress the data first and then place it in HDFS", do
> you
> > > mean you want to compress the data
> > > locally and then copy to DFS?
> > >
> > > What's the size of your data? What's the capacity of HDFS?
> > >
> > > On Mon, Aug 3, 2009 at 10:45 AM, Sugandha Naolekar
> > > <sugandha.n87@gmail.com>wrote:
> > >
> > > > I want to compress the data first and then place it in HDFS. Again,
> > while
> > > > retrieving the same, I want to uncompress it and place on the desired
> > > > destination. Can this be possible. How to get started? Also, I want
> to
> > > get
> > > > started with actual coding part of compression and MAP reduce. PLease
> > > > suggest me aptly...!
> > > >
> > > >
> > > >
> > > > --
> > > > Regards!
> > > > Sugandha
> > > >
> > >
> >
> >
> >
> > --
> > Regards!
> > Sugandha
> >
>



-- 
Regards!
Sugandha

--00221532cda450669a04703758cc--

From common-user-return-16492-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 07:03:50 2009
Return-Path: <common-user-return-16492-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 18056 invoked from network); 3 Aug 2009 07:03:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 07:03:50 -0000
Received: (qmail 97884 invoked by uid 500); 3 Aug 2009 07:03:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 97795 invoked by uid 500); 3 Aug 2009 07:03:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 97785 invoked by uid 99); 3 Aug 2009 07:03:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:03:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bluecoder008@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:03:45 +0000
Received: by ewy26 with SMTP id 26so2809869ewy.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 00:03:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=D6WeqdHK5tqnBX5lENS4o4JOVJYvE18OVHIplBrG84c=;
        b=tEVBLiCzmiynAVpQ8evf6Qgujah3wmzdpXXXeaKudtwVdgGnkMMDA5KKequvkyW0qu
         0BSlo+u9WoKx4TYauKtb3FlEuaRdLCpPZyYxmBP8EpJs4cNKy6w+DRJIhk1RdMKB3mAa
         gIYpVg5YLMcLJSkuwkIunAMmQgs0l+L7nspYY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=kYOs76RbTcZGPYhl5VDLoU2UEWkDVKsyk9RMjexospzJ+tsYW41aFwmuXB/NMMHGNA
         eFvdqnUffLeNSuex6AlleJQYtW50weA06IoGlSUA/YWsd06KHUPPIZJQvdEXjEl9By78
         bx+YKBHJkyX5ndq1MVVwHHVVoiwQU/QswLkNI=
MIME-Version: 1.0
Received: by 10.211.199.11 with SMTP id b11mr6888830ebq.68.1249283003839; Mon, 
	03 Aug 2009 00:03:23 -0700 (PDT)
In-Reply-To: <6f72e2db0908030001o2789db9dt512a777173ed59a8@mail.gmail.com>
References: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
	 <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com>
	 <6f72e2db0908022232g61528382hafcd4c6821243df5@mail.gmail.com>
	 <ac6e61fc0908022337l2b30be49m6d314fb2b9be2f0c@mail.gmail.com>
	 <6f72e2db0908030001o2789db9dt512a777173ed59a8@mail.gmail.com>
Date: Mon, 3 Aug 2009 00:03:23 -0700
Message-ID: <6967a3fe0908030003r4414235ay2b9ce9e828eeac52@mail.gmail.com>
Subject: Re: :!
From: A BlueCoder <bluecoder008@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175933a6aaf6ac0470375d5f
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175933a6aaf6ac0470375d5f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

unsubscribe

On Mon, Aug 3, 2009 at 12:01 AM, Sugandha Naolekar
<sugandha.n87@gmail.com>wrote:

> dats fine. But, if I place the data in HDFS and then run map reduce code to
> provide compression, then the data will get compressed in sequence files
> but, even the original data will reside in the memory;thereby leading or
> causing a kind of redundancy of data...
>
> Can u pls suggest me a way out?/
>
> On Mon, Aug 3, 2009 at 12:07 PM, prashant ullegaddi <
> prashullegaddi@gmail.com> wrote:
>
> > I don't think you will be able to compress some data unless it's on HDFS.
> > What you can do is
> > 1. Manually compress the data on the machine where the data resides.
> Then,
> > copy the same to
> >  HDFS. or
> > 2. Copy the data without compressing to HDFS, then run a job which just
> > emits the data as it reads
> >  in key/value pair. You can set
> > FileOutputFormat.setOutputCompressorClass(job,GzipCodec.class) so
> >  that output gets gzipped.
> >
> > Does that solve your problem?
> >
> > btw you didn't exactly specify your data size (how many TBs).
> >
> > On Mon, Aug 3, 2009 at 11:02 AM, Sugandha Naolekar
> > <sugandha.n87@gmail.com>wrote:
> >
> > > Yes, You are right. Here goes the details related::
> > >
> > > -> I have a Hadoop cluster of 7 nodes. Now there is this 8th machine,
> > which
> > > is not a part of the hadoop cluster.
> > > -> I want to place the data of that machine into the HDFS. Thus, before
> > > placing it in HDFS, I want to compress it, and then dump in the HDFS.
> > > -> I have 4 datanodes in my cluster. also, data might get extended upto
> > > tera
> > > bytes.
> > > -> Also, i have set thr replication factor as 2.
> > > -> I guess, for compression, I will have to run map reduce...?
> > > right..please
> > > tel me the complete approach that is needed to be followed.
> > >
> > > On Mon, Aug 3, 2009 at 10:48 AM, prashant ullegaddi <
> > > prashullegaddi@gmail.com> wrote:
> > >
> > > > By "I want to compress the data first and then place it in HDFS", do
> > you
> > > > mean you want to compress the data
> > > > locally and then copy to DFS?
> > > >
> > > > What's the size of your data? What's the capacity of HDFS?
> > > >
> > > > On Mon, Aug 3, 2009 at 10:45 AM, Sugandha Naolekar
> > > > <sugandha.n87@gmail.com>wrote:
> > > >
> > > > > I want to compress the data first and then place it in HDFS. Again,
> > > while
> > > > > retrieving the same, I want to uncompress it and place on the
> desired
> > > > > destination. Can this be possible. How to get started? Also, I want
> > to
> > > > get
> > > > > started with actual coding part of compression and MAP reduce.
> PLease
> > > > > suggest me aptly...!
> > > > >
> > > > >
> > > > >
> > > > > --
> > > > > Regards!
> > > > > Sugandha
> > > > >
> > > >
> > >
> > >
> > >
> > > --
> > > Regards!
> > > Sugandha
> > >
> >
>
>
>
> --
> Regards!
> Sugandha
>

--0015175933a6aaf6ac0470375d5f--

From common-user-return-16493-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 07:08:26 2009
Return-Path: <common-user-return-16493-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 19186 invoked from network); 3 Aug 2009 07:08:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 07:08:26 -0000
Received: (qmail 3327 invoked by uid 500); 3 Aug 2009 07:08:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 3252 invoked by uid 500); 3 Aug 2009 07:08:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 3242 invoked by uid 500); 3 Aug 2009 07:08:29 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 3239 invoked by uid 99); 3 Aug 2009 07:08:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:08:29 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sugandha.n87@gmail.com designates 209.85.211.202 as permitted sender)
Received: from [209.85.211.202] (HELO mail-yw0-f202.google.com) (209.85.211.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:08:21 +0000
Received: by ywh40 with SMTP id 40so3628777ywh.29
        for <core-user@hadoop.apache.org>; Mon, 03 Aug 2009 00:08:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=bHK8zHrYwM4lNtr+oKm/b6RKurtAmgdKBNtKpWExCR4=;
        b=dplICU0n0smXjpT99PZHJGVfuLP80WSuPnUVlclXwwHBPiD+vc4Xi74TBlWdoKEVE4
         RmbS1d+u9bG06U0+AJNShO+tI7NsRxGsbweI3s7B5Ol6AJoIbpQFodEOvbqtJHKounej
         v5X5X399Itz+N5kw5BMYgVSiNUul/o2j/qW8k=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=dNcKu6K69U7yedC2wSxExSGFC+npZnQ3toXdlS8c+xZNquGAptf8KTZ7Y9DpqNpDwL
         bnrGMNfyu0BIk92V32988qs/KY2y5iTsl5DzCTj49CIxdxGHR4TSJGnwTiPWxmPD2P5m
         JECQrCqp3s/CroI363O64goiCDejb2w+KEVyA=
MIME-Version: 1.0
Received: by 10.231.13.69 with SMTP id b5mr1366666iba.40.1249283280395; Mon, 
	03 Aug 2009 00:08:00 -0700 (PDT)
Date: Mon, 3 Aug 2009 12:38:00 +0530
Message-ID: <6f72e2db0908030008g168695d1obe3af9f1d20f4fe4@mail.gmail.com>
Subject: Compression related issues..!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=002215046cab26de460470376ea2
X-Virus-Checked: Checked by ClamAV on apache.org

--002215046cab26de460470376ea2
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

hello, I want to use standard compression algorithms for data compression.
This would be possible by writing a code supporting map reduce. Also, there
is an utility or a class in hadoop api, that simply zips the data or files
while emitting keys-values pairs. But, How much does it help? It won;t
compress to much extent-I guess.

How to proceed with map reduce and compression, which algorithms to be
supported, and things like that.

Please reply as per.

-- 
Regards!
Sugandha

--002215046cab26de460470376ea2--

From common-user-return-16494-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 07:09:34 2009
Return-Path: <common-user-return-16494-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 19323 invoked from network); 3 Aug 2009 07:09:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 07:09:34 -0000
Received: (qmail 5210 invoked by uid 500); 3 Aug 2009 07:09:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 5139 invoked by uid 500); 3 Aug 2009 07:09:36 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 5129 invoked by uid 99); 3 Aug 2009 07:09:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:09:36 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sugandha.n87@gmail.com designates 209.85.211.202 as permitted sender)
Received: from [209.85.211.202] (HELO mail-yw0-f202.google.com) (209.85.211.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:09:27 +0000
Received: by ywh40 with SMTP id 40so3629192ywh.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 00:09:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=PopbCMDUYvtW6440Qyu8kYy+WJsv09y1K4iLhATQSQE=;
        b=s/EzGSwD/DcpS+snDwys2iSlzAFeyR5A2tuvh8Vet/ha3gMK6GaOGqw6VAzUNlR5Ae
         V+YsrsaUz2X9qZh1YQUjKr8Q+hG2c0ksgP8+J3LlLMmqbL7p6pYMGSW5UlHV+bTdBgXJ
         2y/xBDyW+C6SKPNyl74dQNEE07eWrCJeAiB/c=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=U5E3MybIgy/m7JGIMXqA4EHHP3jeHB3eb2cr1dkIeLaDyim6xkrBSTTEZ87FaBh5hi
         knC4fxJMtE5nIEUZcQOHPWqh5GTlKw0Qcp+MT4geWdYNoDcsrxKPN7vKzprGOKPQyrCX
         inJKwYXYOrNg2ERf4r1XVFTQW+F1DC8AT6DZs=
MIME-Version: 1.0
Received: by 10.231.36.138 with SMTP id t10mr1353996ibd.44.1249283345896; Mon, 
	03 Aug 2009 00:09:05 -0700 (PDT)
In-Reply-To: <6967a3fe0908030003r4414235ay2b9ce9e828eeac52@mail.gmail.com>
References: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
	 <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com>
	 <6f72e2db0908022232g61528382hafcd4c6821243df5@mail.gmail.com>
	 <ac6e61fc0908022337l2b30be49m6d314fb2b9be2f0c@mail.gmail.com>
	 <6f72e2db0908030001o2789db9dt512a777173ed59a8@mail.gmail.com>
	 <6967a3fe0908030003r4414235ay2b9ce9e828eeac52@mail.gmail.com>
Date: Mon, 3 Aug 2009 12:39:05 +0530
Message-ID: <6f72e2db0908030009s3f622c22u5432dd03d9490335@mail.gmail.com>
Subject: Re: :!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221504892b0e598304703772d3
X-Virus-Checked: Checked by ClamAV on apache.org

--00221504892b0e598304703772d3
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

This is ridiculous. What do you mean by unsubscribe.?? I have few queries
and dats why have logged in to the corresponding forum.

On Mon, Aug 3, 2009 at 12:33 PM, A BlueCoder <bluecoder008@gmail.com> wrote:

> unsubscribe
>
> On Mon, Aug 3, 2009 at 12:01 AM, Sugandha Naolekar
> <sugandha.n87@gmail.com>wrote:
>
> > dats fine. But, if I place the data in HDFS and then run map reduce code
> to
> > provide compression, then the data will get compressed in sequence files
> > but, even the original data will reside in the memory;thereby leading or
> > causing a kind of redundancy of data...
> >
> > Can u pls suggest me a way out?/
> >
> > On Mon, Aug 3, 2009 at 12:07 PM, prashant ullegaddi <
> > prashullegaddi@gmail.com> wrote:
> >
> > > I don't think you will be able to compress some data unless it's on
> HDFS.
> > > What you can do is
> > > 1. Manually compress the data on the machine where the data resides.
> > Then,
> > > copy the same to
> > >  HDFS. or
> > > 2. Copy the data without compressing to HDFS, then run a job which just
> > > emits the data as it reads
> > >  in key/value pair. You can set
> > > FileOutputFormat.setOutputCompressorClass(job,GzipCodec.class) so
> > >  that output gets gzipped.
> > >
> > > Does that solve your problem?
> > >
> > > btw you didn't exactly specify your data size (how many TBs).
> > >
> > > On Mon, Aug 3, 2009 at 11:02 AM, Sugandha Naolekar
> > > <sugandha.n87@gmail.com>wrote:
> > >
> > > > Yes, You are right. Here goes the details related::
> > > >
> > > > -> I have a Hadoop cluster of 7 nodes. Now there is this 8th machine,
> > > which
> > > > is not a part of the hadoop cluster.
> > > > -> I want to place the data of that machine into the HDFS. Thus,
> before
> > > > placing it in HDFS, I want to compress it, and then dump in the HDFS.
> > > > -> I have 4 datanodes in my cluster. also, data might get extended
> upto
> > > > tera
> > > > bytes.
> > > > -> Also, i have set thr replication factor as 2.
> > > > -> I guess, for compression, I will have to run map reduce...?
> > > > right..please
> > > > tel me the complete approach that is needed to be followed.
> > > >
> > > > On Mon, Aug 3, 2009 at 10:48 AM, prashant ullegaddi <
> > > > prashullegaddi@gmail.com> wrote:
> > > >
> > > > > By "I want to compress the data first and then place it in HDFS",
> do
> > > you
> > > > > mean you want to compress the data
> > > > > locally and then copy to DFS?
> > > > >
> > > > > What's the size of your data? What's the capacity of HDFS?
> > > > >
> > > > > On Mon, Aug 3, 2009 at 10:45 AM, Sugandha Naolekar
> > > > > <sugandha.n87@gmail.com>wrote:
> > > > >
> > > > > > I want to compress the data first and then place it in HDFS.
> Again,
> > > > while
> > > > > > retrieving the same, I want to uncompress it and place on the
> > desired
> > > > > > destination. Can this be possible. How to get started? Also, I
> want
> > > to
> > > > > get
> > > > > > started with actual coding part of compression and MAP reduce.
> > PLease
> > > > > > suggest me aptly...!
> > > > > >
> > > > > >
> > > > > >
> > > > > > --
> > > > > > Regards!
> > > > > > Sugandha
> > > > > >
> > > > >
> > > >
> > > >
> > > >
> > > > --
> > > > Regards!
> > > > Sugandha
> > > >
> > >
> >
> >
> >
> > --
> > Regards!
> > Sugandha
> >
>



-- 
Regards!
Sugandha

--00221504892b0e598304703772d3--

From common-user-return-16495-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 07:10:02 2009
Return-Path: <common-user-return-16495-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 19391 invoked from network); 3 Aug 2009 07:10:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 07:10:02 -0000
Received: (qmail 6997 invoked by uid 500); 3 Aug 2009 07:10:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 6913 invoked by uid 500); 3 Aug 2009 07:10:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 6903 invoked by uid 99); 3 Aug 2009 07:10:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:10:04 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of prashullegaddi@gmail.com designates 209.85.216.198 as permitted sender)
Received: from [209.85.216.198] (HELO mail-px0-f198.google.com) (209.85.216.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:09:54 +0000
Received: by pxi36 with SMTP id 36so2421341pxi.2
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 00:09:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=ybaUiWYZOAGrnp4DzTKSexSCa1694JD26PHpCqYkX+s=;
        b=PQAXv6Hq7gvty2jUeB+ss/9r1YsQ5BMoDpUE7mf54D/4lgh/tFuyy/96+pmBh7T6ke
         aQjuNqHx3kf3Bh0NTdr2uIk08gmuRXNxo9pmHXIQkjP8Ag+8APpIUtK5Jkg/l5SqwYb5
         EVaoLBkxOdEwWzD9hT1HfOstB8CZjGLjlHN7M=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=glSmTMtg5GVanOf1TcXn9FtvIQcY6s6ATUgXOUWAiTS/RfkYYw35iv0WXFHmYaa8in
         gEq3Vg9A0Vt9ehomY/zI/vGRIMfeaoB0wjON3hiL/u5iYe8MMr2MI83JqJ0jU+oDx1SN
         bO/jf0j6FoOG9WaT0Hpy4dwS2Lk4Fd1FDygzw=
MIME-Version: 1.0
Received: by 10.141.21.3 with SMTP id y3mr3351828rvi.279.1249283373459; Mon, 
	03 Aug 2009 00:09:33 -0700 (PDT)
In-Reply-To: <6f72e2db0908030001o2789db9dt512a777173ed59a8@mail.gmail.com>
References: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
	 <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com>
	 <6f72e2db0908022232g61528382hafcd4c6821243df5@mail.gmail.com>
	 <ac6e61fc0908022337l2b30be49m6d314fb2b9be2f0c@mail.gmail.com>
	 <6f72e2db0908030001o2789db9dt512a777173ed59a8@mail.gmail.com>
Date: Mon, 3 Aug 2009 12:39:33 +0530
Message-ID: <ac6e61fc0908030009i7491a28j2fd367ee2f997b31@mail.gmail.com>
Subject: Re: :!
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd1a234b2e88804703773a6
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd1a234b2e88804703773a6
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

How files are written can be controlled. Maybe you are using
SequenceFileOutputFormat.
You can setOutputFormat() to TextOutputFormat.

I guess, this must solve your problem!

On Mon, Aug 3, 2009 at 12:31 PM, Sugandha Naolekar
<sugandha.n87@gmail.com>wrote:

> dats fine. But, if I place the data in HDFS and then run map reduce code to
> provide compression, then the data will get compressed in sequence files
> but, even the original data will reside in the memory;thereby leading or
> causing a kind of redundancy of data...
>
> Can u pls suggest me a way out?/
>
> On Mon, Aug 3, 2009 at 12:07 PM, prashant ullegaddi <
> prashullegaddi@gmail.com> wrote:
>
> > I don't think you will be able to compress some data unless it's on HDFS.
> > What you can do is
> > 1. Manually compress the data on the machine where the data resides.
> Then,
> > copy the same to
> >  HDFS. or
> > 2. Copy the data without compressing to HDFS, then run a job which just
> > emits the data as it reads
> >  in key/value pair. You can set
> > FileOutputFormat.setOutputCompressorClass(job,GzipCodec.class) so
> >  that output gets gzipped.
> >
> > Does that solve your problem?
> >
> > btw you didn't exactly specify your data size (how many TBs).
> >
> > On Mon, Aug 3, 2009 at 11:02 AM, Sugandha Naolekar
> > <sugandha.n87@gmail.com>wrote:
> >
> > > Yes, You are right. Here goes the details related::
> > >
> > > -> I have a Hadoop cluster of 7 nodes. Now there is this 8th machine,
> > which
> > > is not a part of the hadoop cluster.
> > > -> I want to place the data of that machine into the HDFS. Thus, before
> > > placing it in HDFS, I want to compress it, and then dump in the HDFS.
> > > -> I have 4 datanodes in my cluster. also, data might get extended upto
> > > tera
> > > bytes.
> > > -> Also, i have set thr replication factor as 2.
> > > -> I guess, for compression, I will have to run map reduce...?
> > > right..please
> > > tel me the complete approach that is needed to be followed.
> > >
> > > On Mon, Aug 3, 2009 at 10:48 AM, prashant ullegaddi <
> > > prashullegaddi@gmail.com> wrote:
> > >
> > > > By "I want to compress the data first and then place it in HDFS", do
> > you
> > > > mean you want to compress the data
> > > > locally and then copy to DFS?
> > > >
> > > > What's the size of your data? What's the capacity of HDFS?
> > > >
> > > > On Mon, Aug 3, 2009 at 10:45 AM, Sugandha Naolekar
> > > > <sugandha.n87@gmail.com>wrote:
> > > >
> > > > > I want to compress the data first and then place it in HDFS. Again,
> > > while
> > > > > retrieving the same, I want to uncompress it and place on the
> desired
> > > > > destination. Can this be possible. How to get started? Also, I want
> > to
> > > > get
> > > > > started with actual coding part of compression and MAP reduce.
> PLease
> > > > > suggest me aptly...!
> > > > >
> > > > >
> > > > >
> > > > > --
> > > > > Regards!
> > > > > Sugandha
> > > > >
> > > >
> > >
> > >
> > >
> > > --
> > > Regards!
> > > Sugandha
> > >
> >
>
>
>
> --
> Regards!
> Sugandha
>

--000e0cd1a234b2e88804703773a6--

From common-user-return-16496-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 07:20:33 2009
Return-Path: <common-user-return-16496-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 22192 invoked from network); 3 Aug 2009 07:20:33 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 07:20:33 -0000
Received: (qmail 14961 invoked by uid 500); 3 Aug 2009 07:20:36 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 14867 invoked by uid 500); 3 Aug 2009 07:20:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 14857 invoked by uid 99); 3 Aug 2009 07:20:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:20:35 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 07:20:24 +0000
Received: from EGL-EX07CAS01.ds.corp.yahoo.com (egl-ex07cas01.eglbp.corp.yahoo.com [203.83.248.208])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n737J6JB021580
	for <common-user@hadoop.apache.org>; Mon, 3 Aug 2009 00:19:07 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=U5iOmmHtQM6MfblVD4qxQrRYTsEL1JLBQ1MxFDmKvgUyYVjQEMURaQyDBdcHe/nF
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.205]) by
 EGL-EX07CAS01.ds.corp.yahoo.com ([203.83.248.215]) with mapi; Mon, 3 Aug 2009
 12:49:06 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Mon, 3 Aug 2009 12:48:09 +0530
Subject: RE: :!
Thread-Topic: :!
Thread-Index: AcoUCHoDqD45Bfn6SV6NZaGM9cZYUQAAJytw
Message-ID: <616DA47B2EF5B944B91846785B512FF4AAC0D534BC@EGL-EX07VS01.ds.corp.yahoo.com>
References: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
	 <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com>
	 <6f72e2db0908022232g61528382hafcd4c6821243df5@mail.gmail.com>
	 <ac6e61fc0908022337l2b30be49m6d314fb2b9be2f0c@mail.gmail.com>
 <6f72e2db0908030001o2789db9dt512a777173ed59a8@mail.gmail.com>
In-Reply-To: <6f72e2db0908030001o2789db9dt512a777173ed59a8@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org


Maybe I'm missing the point, but in terms of execution performance benefit,=
 what does copying to dfs and then compressing to be fed to a map/reduce jo=
b provide? Isn't it better to compress "offline" / outside latency window a=
nd make available on dfs?
Also, your mapreduce program will launch one map task per compressed file, =
so make sure you design your compression accordingly.

Thanks,
Amogh
-----Original Message-----
From: Sugandha Naolekar [mailto:sugandha.n87@gmail.com]=20
Sent: Monday, August 03, 2009 12:32 PM
To: common-user@hadoop.apache.org
Subject: Re: :!

dats fine. But, if I place the data in HDFS and then run map reduce code to
provide compression, then the data will get compressed in sequence files
but, even the original data will reside in the memory;thereby leading or
causing a kind of redundancy of data...

Can u pls suggest me a way out?/

On Mon, Aug 3, 2009 at 12:07 PM, prashant ullegaddi <
prashullegaddi@gmail.com> wrote:

> I don't think you will be able to compress some data unless it's on HDFS.
> What you can do is
> 1. Manually compress the data on the machine where the data resides. Then=
,
> copy the same to
>  HDFS. or
> 2. Copy the data without compressing to HDFS, then run a job which just
> emits the data as it reads
>  in key/value pair. You can set
> FileOutputFormat.setOutputCompressorClass(job,GzipCodec.class) so
>  that output gets gzipped.
>
> Does that solve your problem?
>
> btw you didn't exactly specify your data size (how many TBs).
>
> On Mon, Aug 3, 2009 at 11:02 AM, Sugandha Naolekar
> <sugandha.n87@gmail.com>wrote:
>
> > Yes, You are right. Here goes the details related::
> >
> > -> I have a Hadoop cluster of 7 nodes. Now there is this 8th machine,
> which
> > is not a part of the hadoop cluster.
> > -> I want to place the data of that machine into the HDFS. Thus, before
> > placing it in HDFS, I want to compress it, and then dump in the HDFS.
> > -> I have 4 datanodes in my cluster. also, data might get extended upto
> > tera
> > bytes.
> > -> Also, i have set thr replication factor as 2.
> > -> I guess, for compression, I will have to run map reduce...?
> > right..please
> > tel me the complete approach that is needed to be followed.
> >
> > On Mon, Aug 3, 2009 at 10:48 AM, prashant ullegaddi <
> > prashullegaddi@gmail.com> wrote:
> >
> > > By "I want to compress the data first and then place it in HDFS", do
> you
> > > mean you want to compress the data
> > > locally and then copy to DFS?
> > >
> > > What's the size of your data? What's the capacity of HDFS?
> > >
> > > On Mon, Aug 3, 2009 at 10:45 AM, Sugandha Naolekar
> > > <sugandha.n87@gmail.com>wrote:
> > >
> > > > I want to compress the data first and then place it in HDFS. Again,
> > while
> > > > retrieving the same, I want to uncompress it and place on the desir=
ed
> > > > destination. Can this be possible. How to get started? Also, I want
> to
> > > get
> > > > started with actual coding part of compression and MAP reduce. PLea=
se
> > > > suggest me aptly...!
> > > >
> > > >
> > > >
> > > > --
> > > > Regards!
> > > > Sugandha
> > > >
> > >
> >
> >
> >
> > --
> > Regards!
> > Sugandha
> >
>



--=20
Regards!
Sugandha

From common-user-return-16497-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 08:48:19 2009
Return-Path: <common-user-return-16497-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 38321 invoked from network); 3 Aug 2009 08:48:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 08:48:19 -0000
Received: (qmail 70975 invoked by uid 500); 3 Aug 2009 08:48:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 70876 invoked by uid 500); 3 Aug 2009 08:48:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 70863 invoked by uid 99); 3 Aug 2009 08:48:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 08:48:22 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of verma.vibhooti@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 08:48:14 +0000
Received: by yxe15 with SMTP id 15so5441490yxe.5
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 01:47:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=DUheRRThWMUQTxCYmS56AHEOfuhz15ijWBs2Eq7mbF0=;
        b=NkEHA2DPHPH3yWOoEbPqujbHqrAm2VVZyaZlkwCSPYq1NoDysbaUBkI07G8wvo2AE7
         ysIcHImyAWeRI+B6bYCZsOnlxirKYbVvKmHpwHP0Rng7eQHl5kx2hWsVcZk9zEq7ZZ3h
         qQWmMowF33BrMZ99c1ahu5o839+RmltWqENFQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=o+a3G5OZEggk/ApE6fkiQYrJSSwm7gCrt9jLDHytaPR9dQ1fuflnJLVEZ6M2rYHoXz
         3K2aEY5kxhlwg8BUiVAQdFtGI3gAREmlwUYmEhCEknFd2A2RjGqxmng4BTr3/Is+wPfn
         9nxXgs9A8Od57hkLOp+egqOpSNRE3JtNdrcfc=
MIME-Version: 1.0
Received: by 10.100.44.4 with SMTP id r4mr7775449anr.13.1249289273145; Mon, 03 
	Aug 2009 01:47:53 -0700 (PDT)
In-Reply-To: <616DA47B2EF5B944B91846785B512FF4AAC0D534BC@EGL-EX07VS01.ds.corp.yahoo.com>
References: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com>
	 <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com>
	 <6f72e2db0908022232g61528382hafcd4c6821243df5@mail.gmail.com>
	 <ac6e61fc0908022337l2b30be49m6d314fb2b9be2f0c@mail.gmail.com>
	 <6f72e2db0908030001o2789db9dt512a777173ed59a8@mail.gmail.com>
	 <616DA47B2EF5B944B91846785B512FF4AAC0D534BC@EGL-EX07VS01.ds.corp.yahoo.com>
Date: Mon, 3 Aug 2009 14:17:52 +0530
Message-ID: <99484d560908030147u454bfe0mbcaf01a11247cdfa@mail.gmail.com>
Subject: Re: :!
From: Vibhooti Verma <verma.vibhooti@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e640817a58fd07047038d36b
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e640817a58fd07047038d36b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

In my opinion it is best to compress it outside and then copy to HDFS. IN
case you want to compress while copying the files to HDFS, you can make use
of  GZIPOutputStream to open a the file and write content to it . This will
be compressed automatically.


On Mon, Aug 3, 2009 at 12:48 PM, Amogh Vasekar <amogh@yahoo-inc.com> wrote:

>
> Maybe I'm missing the point, but in terms of execution performance benefit,
> what does copying to dfs and then compressing to be fed to a map/reduce job
> provide? Isn't it better to compress "offline" / outside latency window and
> make available on dfs?
> Also, your mapreduce program will launch one map task per compressed file,
> so make sure you design your compression accordingly.
>
> Thanks,
> Amogh
> -----Original Message-----
> From: Sugandha Naolekar [mailto:sugandha.n87@gmail.com]
> Sent: Monday, August 03, 2009 12:32 PM
> To: common-user@hadoop.apache.org
> Subject: Re: :!
>
> dats fine. But, if I place the data in HDFS and then run map reduce code to
> provide compression, then the data will get compressed in sequence files
> but, even the original data will reside in the memory;thereby leading or
> causing a kind of redundancy of data...
>
> Can u pls suggest me a way out?/
>
> On Mon, Aug 3, 2009 at 12:07 PM, prashant ullegaddi <
> prashullegaddi@gmail.com> wrote:
>
> > I don't think you will be able to compress some data unless it's on HDFS.
> > What you can do is
> > 1. Manually compress the data on the machine where the data resides.
> Then,
> > copy the same to
> >  HDFS. or
> > 2. Copy the data without compressing to HDFS, then run a job which just
> > emits the data as it reads
> >  in key/value pair. You can set
> > FileOutputFormat.setOutputCompressorClass(job,GzipCodec.class) so
> >  that output gets gzipped.
> >
> > Does that solve your problem?
> >
> > btw you didn't exactly specify your data size (how many TBs).
> >
> > On Mon, Aug 3, 2009 at 11:02 AM, Sugandha Naolekar
> > <sugandha.n87@gmail.com>wrote:
> >
> > > Yes, You are right. Here goes the details related::
> > >
> > > -> I have a Hadoop cluster of 7 nodes. Now there is this 8th machine,
> > which
> > > is not a part of the hadoop cluster.
> > > -> I want to place the data of that machine into the HDFS. Thus, before
> > > placing it in HDFS, I want to compress it, and then dump in the HDFS.
> > > -> I have 4 datanodes in my cluster. also, data might get extended upto
> > > tera
> > > bytes.
> > > -> Also, i have set thr replication factor as 2.
> > > -> I guess, for compression, I will have to run map reduce...?
> > > right..please
> > > tel me the complete approach that is needed to be followed.
> > >
> > > On Mon, Aug 3, 2009 at 10:48 AM, prashant ullegaddi <
> > > prashullegaddi@gmail.com> wrote:
> > >
> > > > By "I want to compress the data first and then place it in HDFS", do
> > you
> > > > mean you want to compress the data
> > > > locally and then copy to DFS?
> > > >
> > > > What's the size of your data? What's the capacity of HDFS?
> > > >
> > > > On Mon, Aug 3, 2009 at 10:45 AM, Sugandha Naolekar
> > > > <sugandha.n87@gmail.com>wrote:
> > > >
> > > > > I want to compress the data first and then place it in HDFS. Again,
> > > while
> > > > > retrieving the same, I want to uncompress it and place on the
> desired
> > > > > destination. Can this be possible. How to get started? Also, I want
> > to
> > > > get
> > > > > started with actual coding part of compression and MAP reduce.
> PLease
> > > > > suggest me aptly...!
> > > > >
> > > > >
> > > > >
> > > > > --
> > > > > Regards!
> > > > > Sugandha
> > > > >
> > > >
> > >
> > >
> > >
> > > --
> > > Regards!
> > > Sugandha
> > >
> >
>
>
>
> --
> Regards!
> Sugandha
>



-- 
cheers,
Vibhooti

--0016e640817a58fd07047038d36b--

From common-user-return-16498-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 08:57:48 2009
Return-Path: <common-user-return-16498-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 40983 invoked from network); 3 Aug 2009 08:57:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 08:57:48 -0000
Received: (qmail 80540 invoked by uid 500); 3 Aug 2009 08:57:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80451 invoked by uid 500); 3 Aug 2009 08:57:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 80441 invoked by uid 99); 3 Aug 2009 08:57:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 08:57:51 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 08:57:42 +0000
Received: by ewy26 with SMTP id 26so2861968ewy.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 01:57:21 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.216.45.65 with SMTP id o43mr1117705web.4.1249289841586; Mon, 
	03 Aug 2009 01:57:21 -0700 (PDT)
In-Reply-To: <39FE7BFBE62D4305970B2EB1B3469FF5@BillyPC>
References: <32dca9ed0907280553u5d604296kd73c86cc246d76c1@mail.gmail.com>
	 <39FE7BFBE62D4305970B2EB1B3469FF5@BillyPC>
Date: Mon, 3 Aug 2009 09:57:21 +0100
Message-ID: <ac79ea400908030157q5f9de8dfue08cc7f54849f22d@mail.gmail.com>
Subject: Re: MapFile performance
From: Tom White <tom@cloudera.com>
To: common-user@hadoop.apache.org
Cc: public-common-user-7ArZoLwFLBtd/SJB6HiN2Ni2O/JbrIOy@hugh.gmane.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Mon, Aug 3, 2009 at 3:09 AM, Billy
Pearson<billy_pearson@sbcglobal.net> wrote:
>
>
> not sure if its still there but there was a parm in the hadoop-site conf
> file that would allow you to skip x number if index when reading it in to
> memory.

This is io.map.index.skip (default 0), which will skip this number of
keys for every key in the index. For example, if set to 2, one third
of the keys will end up in memory.

> From what I understand we scan find the key offset just before the data a=
nd
> seek once and read until we find the key.
>
> Billy
>
>
> ----- Original Message ----- From: "Andy Liu"
> <andyliu1227-Re5JQEeQqe8AvxtiuMwx3w@public.gmane.org>
> Newsgroups: gmane.comp.jakarta.lucene.hadoop.user
> To: <core-user-7ArZoLwFLBtd/SJB6HiN2Ni2O/JbrIOy@public.gmane.org>
> Sent: Tuesday, July 28, 2009 7:53 AM
> Subject: MapFile performance
>
>
>> I have a bunch of Map/Reduce jobs that process documents and writes the
>> results out to a few MapFiles. =A0These MapFiles are subsequently search=
ed
>> in
>> an interactive application.
>>
>> One problem I'm running into is that if the values in the MapFile data
>> file
>> are fairly large, lookup can be slow. =A0This is because the MapFile ind=
ex
>> only stores every 128th key by default (io.map.index.interval), and afte=
r
>> the binary search it may have to scan/skip through up to 127 values (off
>> of
>> disk) before it finds the matching record. =A0I've tried
>> io.map.index.interval
>> =3D 1, which brings average get() times from 1200ms to 200ms, but at the
>> cost
>> of memory during runtime, which is undesirable.
>>
>> One possible solution is to have the MapFile index store every single
>> <key,
>> offset> pair. =A0Then MapFile.Reader, upon startup, would read every 128=
th
>> key
>> in memory. =A0MapFile.Reader.get() would behave the same way except inst=
ead
>> of
>> seeking through the values SequenceFile it would seek through the index
>> SequenceFile until it finds the matching record, and then it can seek to
>> the
>> corresponding offset in the values. =A0I'm going off the assumption that
>> it's
>> much faster to scan through the index (small keys) than it is to scan
>> through the values (large values).
>>
>> Or maybe the index can be some kind of disk-based btree or bdb-like
>> implementation?
>>
>> Anybody encounter this problem before?
>>
>> Andy
>>
>
>
>

From common-user-return-16499-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 09:27:49 2009
Return-Path: <common-user-return-16499-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 49438 invoked from network); 3 Aug 2009 09:27:49 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 09:27:49 -0000
Received: (qmail 13555 invoked by uid 500); 3 Aug 2009 09:27:52 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 13482 invoked by uid 500); 3 Aug 2009 09:27:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 13472 invoked by uid 99); 3 Aug 2009 09:27:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 09:27:51 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mathias.herberts@gmail.com designates 72.14.220.156 as permitted sender)
Received: from [72.14.220.156] (HELO fg-out-1718.google.com) (72.14.220.156)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 09:27:43 +0000
Received: by fg-out-1718.google.com with SMTP id l26so445651fgb.12
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 02:27:22 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=Xm7GpGUIvzKgwFGYQLcZ0dTiTF+Gxt/Uf/8/P7uuNpQ=;
        b=eEMCSq5JaztAGAXnYTfNYVWj7xowdxRpBl6BLM0BA5eJZcM7pURei20aXQGJWDES6F
         4SxWaGWUWh4miuVeMQb+xZnSInsqu08MbCp6Z0DvZEmgZ1+FGq5Z1L1BePN1FhobGUC/
         QGQGisV/xm6y90huWiGPAfoxGq/r4nOlcwnGo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=QeH4YSx6L5mjBtt5Ed38l7gq6EfOook/Sy4c8NqwcinIWBxm1ssIuSIo/7tL+Adgpb
         8FYYUWJd/+AZ0wah7R0gHC9nYQLM7fdGawNhf6z6Ap6cISvX/nHNaFMZ5TGCO4wqslpG
         i+2JFYI8PsDqCdD/Q3eIFtv+tKFe/tBskD0HU=
MIME-Version: 1.0
Received: by 10.86.9.10 with SMTP id 10mr2035117fgi.48.1249291642457; Mon, 03 
	Aug 2009 02:27:22 -0700 (PDT)
In-Reply-To: <2AAFC2B9E4C5DC4F859F154FB664CF5F061A8BE9@EVSBNG01.ad.office.aol.com>
References: <24861273.1321249273926980.JavaMail.pallavi@e1a31053e.in.office.aol.com>
	 <32527729.1341249274095137.JavaMail.pallavi@e1a31053e.in.office.aol.com>
	 <ac6e61fc0908022139va75a7d7k75ee37ea33da9d11@mail.gmail.com>
	 <2AAFC2B9E4C5DC4F859F154FB664CF5F061A8BE9@EVSBNG01.ad.office.aol.com>
Date: Mon, 3 Aug 2009 11:27:22 +0200
Message-ID: <1c5747850908030227r5d75ce2nffd35a538d4774f2@mail.gmail.com>
Subject: Re: RE: No Space Left On Device though space is available
From: Mathias Herberts <mathias.herberts@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd2482691cea104703960b9
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd2482691cea104703960b9
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

no quota on the fs?

On Aug 3, 2009 7:13 AM, "Palleti, Pallavi" <pallavi.palleti@corp.aol.com>
wrote:

No. These are production jobs which were working pretty fine and
suddenly, we started seeing these issues. And, if you see the error log,
the jobs are failing at the time of submission itself while copying the
application jar. And, when I see the client machine disk size and also
HDFS, it is only 60% full.

Thanks
Pallavi

-----Original Message----- From: prashant ullegaddi [mailto:
prashullegaddi@gmail.com] Sent: Monday...

--000e0cd2482691cea104703960b9--

From common-user-return-16500-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 10:11:56 2009
Return-Path: <common-user-return-16500-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70425 invoked from network); 3 Aug 2009 10:11:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 10:11:56 -0000
Received: (qmail 64133 invoked by uid 500); 3 Aug 2009 10:11:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 64001 invoked by uid 500); 3 Aug 2009 10:11:58 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 63724 invoked by uid 99); 3 Aug 2009 10:11:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 10:11:58 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 10:11:47 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1550685qwh.35
        for <multiple recipients>; Mon, 03 Aug 2009 03:11:26 -0700 (PDT)
MIME-Version: 1.0
Sender: edward@udanax.org
Received: by 10.224.11.11 with SMTP id r11mr4466913qar.219.1249294286186; Mon, 
	03 Aug 2009 03:11:26 -0700 (PDT)
In-Reply-To: <2a7683240908030233r1a69d32eyb88c68498661f6a2@mail.gmail.com>
References: <2a7683240908030233r1a69d32eyb88c68498661f6a2@mail.gmail.com>
Date: Mon, 3 Aug 2009 19:11:26 +0900
X-Google-Sender-Auth: c92d329d88fd95dd
Message-ID: <eb4706e0908030311l1e6b5e70n3ee33f1f70cf2fce@mail.gmail.com>
Subject: Re: FYI X-RIME: Hadoop based large scale social network analysis 
	released
From: "Edward J. Yoon" <edwardyoon@apache.org>
To: hama-user@incubator.apache.org
Cc: common-user@hadoop.apache.org, general@hadoop.apache.org, 
	mahout-user@lucene.apache.org, mapreduce-dev@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

That's really cool. BTW, Have you tried these algorithms on the
distributed environment?

On Mon, Aug 3, 2009 at 6:33 PM, Bin Cai<caibinbupt@gmail.com> wrote:
> *X-RIM**E**(http://xrime.sourceforge.net/): Hadoop based large scale social
> network analysis*
> *
> Motivation*
> Today's telecom service providers and Internet-based social network sites
> possess huge user communities. They hold large amount of data about their
> users and want to generate core competency from the data. A key enabler for
> this is a cost efficient solution for social data management and social
> network analysis (SNA).
>
> Such a solution faces a few challenges. The most important one is that the
> solution should be able to handle massive and heterogeneous data sets.
> Facing this challenge, the traditional data warehouse based solutions are
> usually not cost efficient enough. On the other hand, existing SNA tools are
> mostly used in single workstation mode, and not scalable enough. To this
> end, low cost and highly scalable data management and processing
> technologies from cloud computing society should be brought in to help.
>
> However, most of existing cloud based data analysis solutions are trying to
> provide SQL-like general purpose query languages, and do not directly
> support social network analysis. This makes them hard to optimize and hard
> to use for SNA users. So, we came up with X-RIME to fix this gap.
>
> So, briefly speaking, X-RIME wants to provide a few value-added layers on
> top of existing cloud infrastructure, to support smart decision loops based
> on massive data sets and SNA. To end users, X-RIME is a library consists of
> Map-Reduce programs, which are used to do raw data pre-processing,
> transformation, SNA metrics and structures calculation, and graph / network
> visualization. The library could be integrated with other Hadoop based data
> warehouses (e.g., HIVE) to build more comprehensive solutions.
>
> *Currently Supported SNA Metrics and Structures*
> vertex degree statistics
> weakly connected components (WCC)
> strongly connected components (SCC)
> bi-connected components (BCC)
> ego-centric density
> bread first search / single source shortest path (BFS/SSSP)
> K-core
> maximal cliques
> pagerank
> hyperlink-induced topic search (HITS)
> minimal spanning tree (MST)
>



-- 
Best Regards, Edward J. Yoon @ NHN, corp.
edwardyoon@apache.org
http://blog.udanax.org

From common-user-return-16501-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 10:16:23 2009
Return-Path: <common-user-return-16501-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 73049 invoked from network); 3 Aug 2009 10:16:22 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 10:16:22 -0000
Received: (qmail 70277 invoked by uid 500); 3 Aug 2009 10:16:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 70191 invoked by uid 500); 3 Aug 2009 10:16:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 70181 invoked by uid 500); 3 Aug 2009 10:16:25 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 70178 invoked by uid 99); 3 Aug 2009 10:16:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 10:16:25 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sugandha.n87@gmail.com designates 209.85.211.202 as permitted sender)
Received: from [209.85.211.202] (HELO mail-yw0-f202.google.com) (209.85.211.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 10:16:16 +0000
Received: by ywh40 with SMTP id 40so3702857ywh.29
        for <core-user@hadoop.apache.org>; Mon, 03 Aug 2009 03:15:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=ZrJEWaJhbj+D5Atv/XfmLg0dy7wWTdDcuHlyzwFPIqM=;
        b=Z5LMaZncBg/dkkjl/at8yOyOW4ZnLXHZ+Qg035lQ0Be4v2+47MTu+SnSN1YlvkMbsk
         BhomIFThOXyk0ZcaANSivs4u898lapLvgF+LhS0rkEI4AxsPI+/xng9iASme6nUkJUaP
         V6IagbFwTh1EFO9bZO9tDBpQ2Z78kiMsPp874=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=qZlSB9XeKFbAZMzaZRUWD52kJw5S/mv4HyUFnYnzwPtPPi29Z1iOxyAJXi8LciggUn
         bNzcWl4ZsnwyttHf/bDEx6ucp4IC2DS+XD+7vniOWYqnSVMcWMaSDLNSOpoJNkzqBZSa
         4F2q1caEGR00S1ntaLYgCD4Gid05k9tOVga2k=
MIME-Version: 1.0
Received: by 10.231.36.12 with SMTP id r12mr1371829ibd.21.1249294555138; Mon, 
	03 Aug 2009 03:15:55 -0700 (PDT)
Date: Mon, 3 Aug 2009 15:45:55 +0530
Message-ID: <6f72e2db0908030315h12d1e537ie223c355ec826eb8@mail.gmail.com>
Subject: Some issues!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0022152d5f712dca9b04703a0eb4
X-Virus-Checked: Checked by ClamAV on apache.org

--0022152d5f712dca9b04703a0eb4
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I want to encrypt the data that would be placed in HDFS. So I will have to
use some kind of encryption algorithms, right?
Also, This encryption is to be done on data before placing it in HDFS. How
this can be done? Any special API's available in HADOOP for the above
purpose?

-- 
Regards!
Sugandha

--0022152d5f712dca9b04703a0eb4--

From common-user-return-16502-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 10:29:45 2009
Return-Path: <common-user-return-16502-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80156 invoked from network); 3 Aug 2009 10:29:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 10:29:45 -0000
Received: (qmail 83295 invoked by uid 500); 3 Aug 2009 10:29:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 83213 invoked by uid 500); 3 Aug 2009 10:29:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 83198 invoked by uid 99); 3 Aug 2009 10:29:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 10:29:47 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [192.6.10.2] (HELO colossus.hpl.hp.com) (192.6.10.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 10:29:35 +0000
Received: from localhost (localhost [127.0.0.1])
	by colossus.hpl.hp.com (Postfix) with ESMTP id A1D531BA3DF
	for <common-user@hadoop.apache.org>; Mon,  3 Aug 2009 11:29:13 +0100 (BST)
X-Virus-Scanned: Debian amavisd-new at hpl.hp.com
Received: from colossus.hpl.hp.com ([127.0.0.1])
	by localhost (colossus.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id i+bEvZU-1v92 for <common-user@hadoop.apache.org>;
	Mon,  3 Aug 2009 11:29:03 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by colossus.hpl.hp.com (Postfix) with ESMTPS id 932E21BA3D9
	for <common-user@hadoop.apache.org>; Mon,  3 Aug 2009 11:29:03 +0100 (BST)
MailScanner-NULL-Check: 1249900131.54403@blgiPA9ytJ6+qbH9lA3Vzw
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n73ASomX020436
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Mon, 3 Aug 2009 11:28:51 +0100 (BST)
Message-ID: <4A76BBE2.7030705@apache.org>
Date: Mon, 03 Aug 2009 11:28:50 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Some issues!
References: <6f72e2db0908030315h12d1e537ie223c355ec826eb8@mail.gmail.com>
In-Reply-To: <6f72e2db0908030315h12d1e537ie223c355ec826eb8@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n73ASomX020436
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

Sugandha Naolekar wrote:
> I want to encrypt the data that would be placed in HDFS. So I will have to
> use some kind of encryption algorithms, right?
> Also, This encryption is to be done on data before placing it in HDFS. How
> this can be done? Any special API's available in HADOOP for the above
> purpose?
> 

1. Can I point you to the "how to ask questions" article, which 
emphasises the value in having meaningful titles
http://catb.org/~esr/faqs/smart-questions.html

2. no encryption layers in Hadoop -not much of any security, in fact. 
javax.crypto is what you have to play with




From common-user-return-16503-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 10:35:50 2009
Return-Path: <common-user-return-16503-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81326 invoked from network); 3 Aug 2009 10:35:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 10:35:50 -0000
Received: (qmail 87588 invoked by uid 500); 3 Aug 2009 10:35:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87485 invoked by uid 500); 3 Aug 2009 10:35:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87475 invoked by uid 99); 3 Aug 2009 10:35:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 10:35:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sugandha.n87@gmail.com designates 209.85.211.202 as permitted sender)
Received: from [209.85.211.202] (HELO mail-yw0-f202.google.com) (209.85.211.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 10:35:41 +0000
Received: by ywh40 with SMTP id 40so3711066ywh.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 03:35:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=s8e0lam1GNG5ccuuqW313rs6K6+LJSDagVS6imxezy0=;
        b=iIFy6cOH7HMmrQQmEUSAfdF6VLtDQP/L7s9sifDzgGUY4rl9QRIg9ctqRsRbcXQVGI
         0+jL7J2ExBEsi1jwmmQSAv0sa0of5KqBPZJFuNkUW8hhT86rYd4gkYrw4fVCMdzlQvt/
         jZ3RcKgd/cD/eHYi2MRKuBuBcAAxW5BGYKU2w=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=D8TN8PwcD6nqDrXbept7oxb9yMxwd42NnE/f1VsJ0OBFMP+LOs20apXTejP/pc+DXZ
         IuCzZVPeB0YCiaWFSaSYcqtveUuPs+nL4aA4F0vdvdSxtqQm8SUeGAVYtbPnHvTyJq8y
         6qWSWyARbi5l1arNBzx2/JJZ70dH3c1ZZ4xjk=
MIME-Version: 1.0
Received: by 10.231.36.138 with SMTP id t10mr1392499ibd.44.1249295720258; Mon, 
	03 Aug 2009 03:35:20 -0700 (PDT)
In-Reply-To: <4A76BBE2.7030705@apache.org>
References: <6f72e2db0908030315h12d1e537ie223c355ec826eb8@mail.gmail.com>
	 <4A76BBE2.7030705@apache.org>
Date: Mon, 3 Aug 2009 16:05:20 +0530
Message-ID: <6f72e2db0908030335y1b034a5bh6387efa08b864a17@mail.gmail.com>
Subject: Re: Some issues!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221504892ba01d2704703a5367
X-Virus-Checked: Checked by ClamAV on apache.org

--00221504892ba01d2704703a5367
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I am very sorry for the inconvenience caused. From next time, will take care
of the questions to be asked in a precise manner.

On Mon, Aug 3, 2009 at 3:58 PM, Steve Loughran <stevel@apache.org> wrote:

> Sugandha Naolekar wrote:
>
>> I want to encrypt the data that would be placed in HDFS. So I will have to
>> use some kind of encryption algorithms, right?
>> Also, This encryption is to be done on data before placing it in HDFS. How
>> this can be done? Any special API's available in HADOOP for the above
>> purpose?
>>
>>
> 1. Can I point you to the "how to ask questions" article, which emphasises
> the value in having meaningful titles
> http://catb.org/~esr/faqs/smart-questions.html<http://catb.org/%7Eesr/faqs/smart-questions.html>
>
> 2. no encryption layers in Hadoop -not much of any security, in fact.
> javax.crypto is what you have to play with
>
>
>
>


-- 
Regards!
Sugandha

--00221504892ba01d2704703a5367--

From common-user-return-16504-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 10:40:45 2009
Return-Path: <common-user-return-16504-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81950 invoked from network); 3 Aug 2009 10:40:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 10:40:45 -0000
Received: (qmail 91441 invoked by uid 500); 3 Aug 2009 10:40:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91339 invoked by uid 500); 3 Aug 2009 10:40:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91329 invoked by uid 500); 3 Aug 2009 10:40:47 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 91326 invoked by uid 99); 3 Aug 2009 10:40:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 10:40:47 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sugandha.n87@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 10:40:38 +0000
Received: by gxk18 with SMTP id 18so5205643gxk.5
        for <core-user@hadoop.apache.org>; Mon, 03 Aug 2009 03:40:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=bydhluBhnSmTv9d3Jv0dyeYutuBcMIijVu7SrVG/iqs=;
        b=G4xr+ABLwUY7UMbPxyQrZ1S3nlYpvOiO5z+fBaqcU4i6SVymaPTgYhCXg3rbNOhDAo
         BddPpx8rmHfaxYTW5qW5oObLnyoFuAc3mqaul6jxvvDP0IH09+zhTSRM0AvfEP4PykzR
         9e2BzW40JqwAH1SPPgq52poSHQiuuFFsAH9bg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=BNJfhbpjKeSzjxYk9N/eP+Pm5g+u0MMJ+95bSdmA7uLFd+AIT0O+ERQD4o3h6lt1nw
         zMDx+yi4YdM9KGaLOYYpNChyPWSF09dC5kURI1Q9glbQ1Rs6j70eSxQimjvxbq2OvQs/
         c4qAOZEvQOHV6hbRLQKa2nep0CfOSt2gC20Wo=
MIME-Version: 1.0
Received: by 10.231.13.69 with SMTP id b5mr1405909iba.40.1249296017245; Mon, 
	03 Aug 2009 03:40:17 -0700 (PDT)
Date: Mon, 3 Aug 2009 16:10:17 +0530
Message-ID: <6f72e2db0908030340g78d9dd17v8c08ba73a8337ada@mail.gmail.com>
Subject: Compression related issues..!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=002215046cab53c75d04703a6535
X-Virus-Checked: Checked by ClamAV on apache.org

--002215046cab53c75d04703a6535
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello!

I want to know - what's the difference between zipping a file(compressing)
and actually implementing compression algorithms for compressing some sort
of data?

How much difference does it make and which one is preferable.

I want to compress data to be placed in HDFS.

Thanking You,

-- 
Regards!
Sugandha

--002215046cab53c75d04703a6535--

From common-user-return-16505-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 12:51:01 2009
Return-Path: <common-user-return-16505-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 26584 invoked from network); 3 Aug 2009 12:51:01 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 12:51:01 -0000
Received: (qmail 47874 invoked by uid 500); 3 Aug 2009 12:51:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 47778 invoked by uid 500); 3 Aug 2009 12:51:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 47768 invoked by uid 99); 3 Aug 2009 12:51:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 12:51:03 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.200.169 as permitted sender)
Received: from [209.85.200.169] (HELO wf-out-1314.google.com) (209.85.200.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 12:50:55 +0000
Received: by wf-out-1314.google.com with SMTP id 23so976427wfg.2
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 05:50:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:from:date:message-id
         :subject:to:content-type;
        bh=qOHN9dP0GtjnqNfOOiT7ucM3AO6xaa/pdMiaFa35XfE=;
        b=kwKGTGc1ivme46wX/RH6dQjLYuKcOG0rncz18tpG2Pn1vFpxwLin9eRF/UqsnJuByg
         OzUbNtVS1zz2pYw40XQ2kVXy1BZ5AqGE1EJSBTsT2tJz0xFwaNq9wAShNuhJNXfw23ni
         bvcnYjIZtZIt707lBJfcixqiVWpWs2ve9k5jw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:from:date:message-id:subject:to:content-type;
        b=cqiElfRDiAYN2xCU09lUY6w5yMdrj7NoaO92/w4ksUWgvpGWNtAByXSbM/qhQFwOum
         Sngrl/NUNwgZ1ZXy7u1cIuO1/53d1DIkiMdPgwNWP7aT5JCCT53hEIm8SCQxLaIP9pwW
         7o6LEPHgLiZrKsV4/6fTYLYWTyUWqtMlupWkw=
MIME-Version: 1.0
Received: by 10.142.52.7 with SMTP id z7mr457866wfz.328.1249303834103; Mon, 03 
	Aug 2009 05:50:34 -0700 (PDT)
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Mon, 3 Aug 2009 18:20:14 +0530
Message-ID: <e01b80590908030550gd2eeb76g366f1f5e06349c93@mail.gmail.com>
Subject: Difference between "Killed Task Attempts" and "Killed Tasks"
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd2146c3f91c904703c37c7
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd2146c3f91c904703c37c7
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

Anyone can tell me what's the difference between "Killed Task Attempts" and
"Killed Tasks"? I ran a big job (14820 maps and 0 reduces). In the
job-details page, the web GUI reports 62 "killed task attempts". I'm
assuming this is due to "speculative execution". Now when I go to the
job-history page for the job, it reports 54 "killed tasks" (and 14820
successful map-tasks as expected).

A few questions:

* Why 62 killed task attempts vs 54 killed tasks?
* Under speculative execution, does hadoop launch a new MapTask with new
task-id or does it just launch a new MapTaskAttempt with a new
task-attempt-id?
* When a MapTaskAttempt fails, and when hadoop tries to re-launch the
MapTask, does it create a new task-id or just a new task-attempt-id?
* Does 'mapred.map.max.attempts' include all attempts launched due to
speculative-execution?

Btw this job is basically a trivial no-op job - it just scans around 1TB of
data and does nothing else in the map. I looked at the killed tasks' syslog
output and I didn't see any errors.

-- 
Harish Mallipeddi
http://blog.poundbang.in

--000e0cd2146c3f91c904703c37c7--

From common-user-return-16506-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 12:54:23 2009
Return-Path: <common-user-return-16506-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 27152 invoked from network); 3 Aug 2009 12:54:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 12:54:23 -0000
Received: (qmail 53214 invoked by uid 500); 3 Aug 2009 12:54:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 53151 invoked by uid 500); 3 Aug 2009 12:54:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 53112 invoked by uid 99); 3 Aug 2009 12:54:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 12:54:24 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of enis.soz@gmail.com designates 74.125.78.25 as permitted sender)
Received: from [74.125.78.25] (HELO ey-out-2122.google.com) (74.125.78.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 12:54:15 +0000
Received: by ey-out-2122.google.com with SMTP id 22so859896eye.35
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 05:53:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:date:from
         :user-agent:mime-version:to:subject:references:in-reply-to
         :content-type:content-transfer-encoding;
        bh=s9VAIKB4KoChaGvxsnpXaqDD7Gnfrl9h2X5qFCJ1354=;
        b=P1ARznRGXaFatVeeJ8YPXL5yw5EvGDCITu66dhbqv3uHBzFsmavxmRck8WSh28KeH3
         N308JkMIiMqruRbch9h0cAZfJ6rY+PNgOKd9b/xitOGLDI0uXiD5ZSl0IW7raz0mDuSw
         PhZsER6a4TUMVWz7Po4+baRfQCw/RAFUwnVVg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        b=TgT+kdwT/mVagBXHh5p1cT5qMuh4VWkNwGkr/5YZIc7GiVzalUm8O5gD6Fdy0EIeGf
         KHLYv6sxZ9SFt0g4uvAU98nVdC5gs70sG5s+mgnfGQdcLslRmeno6ZIomURKVI/yti0l
         njD7xxoCgZ0ZrcZD35zLcgbQM3s+n9wTZK7yA=
Received: by 10.216.87.207 with SMTP id y57mr1190662wee.94.1249304034132;
        Mon, 03 Aug 2009 05:53:54 -0700 (PDT)
Received: from ?192.168.2.15? ([85.105.135.220])
        by mx.google.com with ESMTPS id p10sm23709595gvf.4.2009.08.03.05.53.52
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Mon, 03 Aug 2009 05:53:53 -0700 (PDT)
Message-ID: <4A76DDCE.60503@gmail.com>
Date: Mon, 03 Aug 2009 15:53:34 +0300
From: Enis Soztutar <enis.soz@gmail.com>
User-Agent: Thunderbird 2.0.0.19 (X11/20090105)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Counting no. of keys.
References: <ac6e61fc0908012153o5f6f5ee9ocbcdef8b21dda20b@mail.gmail.com>
In-Reply-To: <ac6e61fc0908012153o5f6f5ee9ocbcdef8b21dda20b@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

prashant ullegaddi wrote:
> Hi,
>
> I've say 800 sequence files written using SequenceFileOutputFormat. Is there
> any way to know
> no. of unique keys in those sequence files?
>
> Thanks,
> Prashant.
>
>   
You can use the counters "map output records" and "reduce output 
records" for this. If you can guarantee that every output key from 
reduce is unique, then the reduce output records is what you're looking 
for. If you're not using the reduce phase, then use map output records.

From common-user-return-16507-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 13:01:36 2009
Return-Path: <common-user-return-16507-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 31270 invoked from network); 3 Aug 2009 13:01:36 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 13:01:36 -0000
Received: (qmail 63277 invoked by uid 500); 3 Aug 2009 13:01:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 63208 invoked by uid 500); 3 Aug 2009 13:01:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 63198 invoked by uid 99); 3 Aug 2009 13:01:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:01:38 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of wangzhong.neu@gmail.com designates 209.85.216.198 as permitted sender)
Received: from [209.85.216.198] (HELO mail-px0-f198.google.com) (209.85.216.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:01:29 +0000
Received: by pxi36 with SMTP id 36so2536718pxi.2
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 06:01:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=J9VKHuowWHyB3PeT6eeel+vQQIg86CtYfgqcSBoEUKI=;
        b=x8yCOH3lUNRWeIRjYeC8U4+IbFvCYsTnL91zculiVz+0llMJTzYPZyqsqQaDq18sY6
         NW9Ec5FexyX4kfAPKBdJr+FG75ucjoLigwKaITdrByIkipAFYjduoz9fNeCZpfinP8da
         Mr0DNcw7Rh2RO52j+gV6AJnuIsca6ytqAwYaY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=AnsPtgcZF49xx5gEMGDL4/vpp5IFWFVdlLX1DG2DXvmYBCGPP8IRaQV34W0zXIq0sm
         /1f8EQKdj/OFqBnvEdWmkmiohFLX2xdYlLXwXP6gK8FPhDx006lN/gNSlStUrTjtlo27
         BxLtPwIxO0xfBicrJ9+0MNOABjBBRjLn+UXcQ=
MIME-Version: 1.0
Received: by 10.114.77.9 with SMTP id z9mr5886011waa.76.1249304468477; Mon, 03 
	Aug 2009 06:01:08 -0700 (PDT)
In-Reply-To: <c7d45fc70908012308i2764a7f4g1c86dfe90880194e@mail.gmail.com>
References: <ac6e61fc0908012153o5f6f5ee9ocbcdef8b21dda20b@mail.gmail.com>
	 <c7d45fc70908012308i2764a7f4g1c86dfe90880194e@mail.gmail.com>
Date: Mon, 3 Aug 2009 21:01:08 +0800
Message-ID: <de9d20b80908030601y7dc91ce5m34e6e913a65ec149@mail.gmail.com>
Subject: Re: Counting no. of keys.
From: Zhong Wang <wangzhong.neu@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

I have the same question, but i want to use map records number in
reduce phase exactly after the map. This is very useful in solving
problems like TF-IDF. In reduce (IDF calculating) phase, you must know
the total number of all documents. Is there any method to solve the
problem without running two Map-Reduce jobs?

On Sun, Aug 2, 2009 at 2:08 PM, Ted Dunning<ted.dunning@gmail.com> wrote:
> Sure. =C2=A0Write a word count map-reduce program. =C2=A0The mapper outpu=
ts the key
> from the sequence file as the output key and includes a count. =C2=A0Then=
 you do
> the normal combiner and reducer from a normal word count program.
>
> On Sat, Aug 1, 2009 at 9:53 PM, prashant ullegaddi <prashullegaddi@gmail.=
com
>> wrote:
>
>> Hi,
>>
>> I've say 800 sequence files written using SequenceFileOutputFormat. Is
>> there
>> any way to know
>> no. of unique keys in those sequence files?
>>
>> Thanks,
>> Prashant.
>>
>
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>



--=20
Zhong Wang

From common-user-return-16508-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 13:12:14 2009
Return-Path: <common-user-return-16508-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 35902 invoked from network); 3 Aug 2009 13:12:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 13:12:14 -0000
Received: (qmail 81610 invoked by uid 500); 3 Aug 2009 13:12:16 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 81557 invoked by uid 500); 3 Aug 2009 13:12:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 81547 invoked by uid 99); 3 Aug 2009 13:12:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:12:16 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of enis.soz@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:12:05 +0000
Received: by fxm25 with SMTP id 25so2601528fxm.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 06:11:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:date:from
         :user-agent:mime-version:to:subject:references:in-reply-to
         :content-type:content-transfer-encoding;
        bh=6GY0bbP+rSZ3fdXO7f6Vc/BuSIPQ7Ekzs0ftN9J1BTw=;
        b=Z6kRtWXJw7gTbJSbFGTzqQIejrxu6j6tlXbS/hA4+3Mjl4Yy9pUfnK9wiG368cqMnc
         ZpYX65xEyXaABI98MH9WjfY3zpgmtny/EnNl6c2vnbRzNhnLoLga98o9HpwoBAAZfwbe
         EcL1hBYHH9G5BrdObH5YDi8p0AzB24JfWWO3A=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        b=OaLDEyDgBVGMkuoSCyv6vuMJ4hD7chSeBa/9ah/ZZMlEWqsdNu0Tt20e+M/NT99+kc
         2MyVYqO0n25iusLE4bhAKF9Z9b6Pj6ks9m+h/+if752vLD5Y1uNejMmk6+a8O5jycSM0
         E9t2Ja9+y9ytInXmwvsTo7mXVBkPpbpEkT9so=
Received: by 10.204.102.14 with SMTP id e14mr837872bko.183.1249305105488;
        Mon, 03 Aug 2009 06:11:45 -0700 (PDT)
Received: from ?192.168.2.15? ([85.105.135.220])
        by mx.google.com with ESMTPS id 18sm14950991fkq.59.2009.08.03.06.11.44
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Mon, 03 Aug 2009 06:11:44 -0700 (PDT)
Message-ID: <4A76E204.50308@gmail.com>
Date: Mon, 03 Aug 2009 16:11:32 +0300
From: Enis Soztutar <enis.soz@gmail.com>
User-Agent: Thunderbird 2.0.0.19 (X11/20090105)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Difference between "Killed Task Attempts" and "Killed Tasks"
References: <e01b80590908030550gd2eeb76g366f1f5e06349c93@mail.gmail.com>
In-Reply-To: <e01b80590908030550gd2eeb76g366f1f5e06349c93@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

Task attempt is an attempt to a task. At any given time, one or 
more(speculative exec.) of task attempts can be running. For a task, 
there can be many attempts at different nodes. A task is complete if any 
of its attempts is complete.  For a task to be marked as failed all of 
mapred.map.max.attempts should fail. For every task in the job, a TaskID 
is assigned. For every attempt, a TaskAttemptID is assigned (which ends 
with _0, _1, etc).

Harish Mallipeddi wrote:
> Hi,
>
> Anyone can tell me what's the difference between "Killed Task Attempts" and
> "Killed Tasks"? I ran a big job (14820 maps and 0 reduces). In the
> job-details page, the web GUI reports 62 "killed task attempts". I'm
> assuming this is due to "speculative execution". Now when I go to the
> job-history page for the job, it reports 54 "killed tasks" (and 14820
> successful map-tasks as expected).
>
> A few questions:
>
> * Why 62 killed task attempts vs 54 killed tasks?
> * Under speculative execution, does hadoop launch a new MapTask with new
> task-id or does it just launch a new MapTaskAttempt with a new
> task-attempt-id?
> * When a MapTaskAttempt fails, and when hadoop tries to re-launch the
> MapTask, does it create a new task-id or just a new task-attempt-id?
> * Does 'mapred.map.max.attempts' include all attempts launched due to
> speculative-execution?
>
> Btw this job is basically a trivial no-op job - it just scans around 1TB of
> data and does nothing else in the map. I looked at the killed tasks' syslog
> output and I didn't see any errors.
>
>   


From common-user-return-16509-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 13:19:46 2009
Return-Path: <common-user-return-16509-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 40560 invoked from network); 3 Aug 2009 13:19:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 13:19:46 -0000
Received: (qmail 92420 invoked by uid 500); 3 Aug 2009 13:19:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 92319 invoked by uid 500); 3 Aug 2009 13:19:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 92309 invoked by uid 99); 3 Aug 2009 13:19:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:19:49 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.222.189 as permitted sender)
Received: from [209.85.222.189] (HELO mail-pz0-f189.google.com) (209.85.222.189)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:19:40 +0000
Received: by pzk27 with SMTP id 27so2542159pzk.2
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 06:19:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=3QTkrZuYiciqbZhConuGOMe+wVWN8CGj+00MQKjckf8=;
        b=Z1lsJgj4tz9Rk2FlQcvst0sFpBuqG/u+9M/PV5pYephBceaN0PXtIN0lmZ3JmXoH+q
         FS/3Wr1bin7ka7J6PJkfKF0qlEkgmY+mQ4lNoAb0aV9l4p9KgTcMxmGoHv+IsBwuz5Ln
         V3d4oqUyMSL+LYre4zPEUHBbk5S9Nra1b2SNA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=ar1ntc9VxpJ2dNrGvixm9CeDgEtlpk/RmrpGqjb9AkVDJkXLsi4IReGyJBy2gG1Es1
         JXZPes7PTgZZuNonqWSksFM84WGNdmbu+2MAawn1vHw8UhsvLbRvULDfNcAS1LB14nZB
         +B2OVhpDrO7g82OWSOWe7htnuANxEKSmg7jKk=
MIME-Version: 1.0
Received: by 10.142.127.7 with SMTP id z7mr325296wfc.280.1249305559120; Mon, 
	03 Aug 2009 06:19:19 -0700 (PDT)
In-Reply-To: <4A76E204.50308@gmail.com>
References: <e01b80590908030550gd2eeb76g366f1f5e06349c93@mail.gmail.com> 
	<4A76E204.50308@gmail.com>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Mon, 3 Aug 2009 18:48:59 +0530
Message-ID: <e01b80590908030618v50fb1a51t9912ddbca7f3f01d@mail.gmail.com>
Subject: Re: Difference between "Killed Task Attempts" and "Killed Tasks"
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd32cdc113b5b04703c9e80
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd32cdc113b5b04703c9e80
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Agreed. But how did I manage to get 54 killed tasks vs 62 killed
task-attempts? I understand what a "failed task" is (a task for which
'mapred.map.max.attempts' attempts have failed). But what's a "killed task"?

On Mon, Aug 3, 2009 at 6:41 PM, Enis Soztutar <enis.soz@gmail.com> wrote:

> Hi,
>
> Task attempt is an attempt to a task. At any given time, one or
> more(speculative exec.) of task attempts can be running. For a task, there
> can be many attempts at different nodes. A task is complete if any of its
> attempts is complete.  For a task to be marked as failed all of
> mapred.map.max.attempts should fail. For every task in the job, a TaskID is
> assigned. For every attempt, a TaskAttemptID is assigned (which ends with
> _0, _1, etc).
>
>
> Harish Mallipeddi wrote:
>
>> Hi,
>>
>> Anyone can tell me what's the difference between "Killed Task Attempts"
>> and
>> "Killed Tasks"? I ran a big job (14820 maps and 0 reduces). In the
>> job-details page, the web GUI reports 62 "killed task attempts". I'm
>> assuming this is due to "speculative execution". Now when I go to the
>> job-history page for the job, it reports 54 "killed tasks" (and 14820
>> successful map-tasks as expected).
>>
>> A few questions:
>>
>> * Why 62 killed task attempts vs 54 killed tasks?
>> * Under speculative execution, does hadoop launch a new MapTask with new
>> task-id or does it just launch a new MapTaskAttempt with a new
>> task-attempt-id?
>> * When a MapTaskAttempt fails, and when hadoop tries to re-launch the
>> MapTask, does it create a new task-id or just a new task-attempt-id?
>> * Does 'mapred.map.max.attempts' include all attempts launched due to
>> speculative-execution?
>>
>> Btw this job is basically a trivial no-op job - it just scans around 1TB
>> of
>> data and does nothing else in the map. I looked at the killed tasks'
>> syslog
>> output and I didn't see any errors.
>>
>>
>>
>
>


-- 
Harish Mallipeddi
http://blog.poundbang.in

--000e0cd32cdc113b5b04703c9e80--

From common-user-return-16510-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 13:33:31 2009
Return-Path: <common-user-return-16510-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 51556 invoked from network); 3 Aug 2009 13:33:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 13:33:31 -0000
Received: (qmail 18975 invoked by uid 500); 3 Aug 2009 13:33:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 18858 invoked by uid 500); 3 Aug 2009 13:33:30 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 18837 invoked by uid 99); 3 Aug 2009 13:33:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:33:30 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:33:19 +0000
Received: by ewy26 with SMTP id 26so3021336ewy.29
        for <multiple recipients>; Mon, 03 Aug 2009 06:32:57 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.216.3.79 with SMTP id 57mr1128512weg.166.1249306376759; Mon, 
	03 Aug 2009 06:32:56 -0700 (PDT)
In-Reply-To: <6d10e930907280437j3c90955dr73aa9bf7f45e4b6b@mail.gmail.com>
References: <6d10e930907280437j3c90955dr73aa9bf7f45e4b6b@mail.gmail.com>
Date: Mon, 3 Aug 2009 14:32:56 +0100
Message-ID: <ac79ea400908030632x6b3c7086p5149e6779cae9b35@mail.gmail.com>
Subject: Re: Status of 0.19.2
From: Tom White <tom@cloudera.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I've now updated the news section, and the documentation on the
website to reflect the 0.19.2 release.

There were several reports of it being more stable than 0.19.1 in the
voting thread: http://www.mail-archive.com/common-dev@hadoop.apache.org/msg00051.html

Cheers,
Tom

On Tue, Jul 28, 2009 at 12:37 PM, Tamir Kamara <tamirkamara@gmail.com> wrote:
>
> Hi,
>
> I've seen that the 0.19.2 version was added recently to the downloads but
> there's no entry under the news section.
> Is it stable enough for deployment?
>
> Thanks,
> Tamir

From common-user-return-16511-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 13:33:31 2009
Return-Path: <common-user-return-16511-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 51564 invoked from network); 3 Aug 2009 13:33:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 13:33:31 -0000
Received: (qmail 18978 invoked by uid 500); 3 Aug 2009 13:33:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 18862 invoked by uid 500); 3 Aug 2009 13:33:30 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 18842 invoked by uid 500); 3 Aug 2009 13:33:30 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 18837 invoked by uid 99); 3 Aug 2009 13:33:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:33:30 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:33:19 +0000
Received: by ewy26 with SMTP id 26so3021336ewy.29
        for <multiple recipients>; Mon, 03 Aug 2009 06:32:57 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.216.3.79 with SMTP id 57mr1128512weg.166.1249306376759; Mon, 
	03 Aug 2009 06:32:56 -0700 (PDT)
In-Reply-To: <6d10e930907280437j3c90955dr73aa9bf7f45e4b6b@mail.gmail.com>
References: <6d10e930907280437j3c90955dr73aa9bf7f45e4b6b@mail.gmail.com>
Date: Mon, 3 Aug 2009 14:32:56 +0100
Message-ID: <ac79ea400908030632x6b3c7086p5149e6779cae9b35@mail.gmail.com>
Subject: Re: Status of 0.19.2
From: Tom White <tom@cloudera.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I've now updated the news section, and the documentation on the
website to reflect the 0.19.2 release.

There were several reports of it being more stable than 0.19.1 in the
voting thread: http://www.mail-archive.com/common-dev@hadoop.apache.org/msg00051.html

Cheers,
Tom

On Tue, Jul 28, 2009 at 12:37 PM, Tamir Kamara <tamirkamara@gmail.com> wrote:
>
> Hi,
>
> I've seen that the 0.19.2 version was added recently to the downloads but
> there's no entry under the news section.
> Is it stable enough for deployment?
>
> Thanks,
> Tamir

From common-user-return-16512-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 13:37:17 2009
Return-Path: <common-user-return-16512-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 54426 invoked from network); 3 Aug 2009 13:37:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 13:37:17 -0000
Received: (qmail 27883 invoked by uid 500); 3 Aug 2009 13:37:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 27819 invoked by uid 500); 3 Aug 2009 13:37:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 25970 invoked by uid 99); 3 Aug 2009 09:34:22 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of caibinbupt@gmail.com designates 209.85.217.218 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=iVaRNFdyPHiTCbLiMaDVOEZAgIZl6jAcMK1969uLniw=;
        b=qYG5SuQpf4lNgKJ4GY49hjl7I+b1gL8upMoQ46yiqMR76nnkv5FD9nmrbmbsyalppH
         1KSfjKexVpKG+T86YoLNFzOErPog0MolnkU7QiYvxE6h6Mj81TGjkSnvc8r0ES6Fflob
         rMhqlFBBH+ZEI79KvCE3+kdW/z2c4ycuVP2uc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=bkytEUbRcJOjmTNOX33QmUFNza2YB8nrJkOdfZZNTaPXHEs/Fy0NB9+mlUnWZ4NfsF
         NHbgv4aK2OV4YkRG/K4TQAOzonbICYHae4fzWkdzM4b7dMesgBN6g8hn1xhj3Yqz2OEd
         ePY9gVDEoXi/yq1H31iGIPDFsXq92yVbxR9Vk=
MIME-Version: 1.0
Date: Mon, 3 Aug 2009 17:33:51 +0800
Message-ID: <2a7683240908030233r1a69d32eyb88c68498661f6a2@mail.gmail.com>
Subject: FYI X-RIME: Hadoop based large scale social network analysis released
From: Bin Cai <caibinbupt@gmail.com>
To: common-user@hadoop.apache.org, general@hadoop.apache.org, 
	hama-user@incubator.apache.org, mahout-user@lucene.apache.org, 
	mapreduce-dev@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd6ad48d7f7f80470397749
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd6ad48d7f7f80470397749
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

*X-RIM**E**(http://xrime.sourceforge.net/): Hadoop based large scale social
network analysis*
*
Motivation*
Today's telecom service providers and Internet-based social network sites
possess huge user communities. They hold large amount of data about their
users and want to generate core competency from the data. A key enabler for
this is a cost efficient solution for social data management and social
network analysis (SNA).

Such a solution faces a few challenges. The most important one is that the
solution should be able to handle massive and heterogeneous data sets.
Facing this challenge, the traditional data warehouse based solutions are
usually not cost efficient enough. On the other hand, existing SNA tools are
mostly used in single workstation mode, and not scalable enough. To this
end, low cost and highly scalable data management and processing
technologies from cloud computing society should be brought in to help.

However, most of existing cloud based data analysis solutions are trying to
provide SQL-like general purpose query languages, and do not directly
support social network analysis. This makes them hard to optimize and hard
to use for SNA users. So, we came up with X-RIME to fix this gap.

So, briefly speaking, X-RIME wants to provide a few value-added layers on
top of existing cloud infrastructure, to support smart decision loops based
on massive data sets and SNA. To end users, X-RIME is a library consists of
Map-Reduce programs, which are used to do raw data pre-processing,
transformation, SNA metrics and structures calculation, and graph / network
visualization. The library could be integrated with other Hadoop based data
warehouses (e.g., HIVE) to build more comprehensive solutions.

*Currently Supported SNA Metrics and Structures*
vertex degree statistics
weakly connected components (WCC)
strongly connected components (SCC)
bi-connected components (BCC)
ego-centric density
bread first search / single source shortest path (BFS/SSSP)
K-core
maximal cliques
pagerank
hyperlink-induced topic search (HITS)
minimal spanning tree (MST)

--000e0cd6ad48d7f7f80470397749--

From common-user-return-16513-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 13:37:48 2009
Return-Path: <common-user-return-16513-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 54873 invoked from network); 3 Aug 2009 13:37:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 13:37:48 -0000
Received: (qmail 29774 invoked by uid 500); 3 Aug 2009 13:37:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 29680 invoked by uid 500); 3 Aug 2009 13:37:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 58341 invoked by uid 99); 3 Aug 2009 00:19:25 -0000
X-ASF-Spam-Status: No, hits=1.0 required=10.0
	tests=FS_LARGE_PERCENT2,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Date: Mon, 03 Aug 2009 02:18:52 +0200
Message-Id: <1181230094@web.de>
MIME-Version: 1.0
From: joerg.schad@email.de
To: common-user@hadoop.apache.org
Subject: Job status task attempt 120%:
Organization: http://freemail.web.de/
X-Sender: 20seconds@web.de
X-Provags-Id: V01U2FsdGVkX1+Z/0CqVEYd9PWCpgMS69F4SygJywBLjF2TVTvkl3z6fHEMz
 LQkgN6OHluD8X1+O3c5ETpVa7Kn7/y+q8pl/+JAgA+yG3QK8aE=
Content-Type: text/plain; charset=iso-8859-15
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi, 
when I check my running jobs via the jobtracker web interface I see that one task attempt is at 120% .
Is there a logical explanation?
Thanks


From common-user-return-16514-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 13:39:41 2009
Return-Path: <common-user-return-16514-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 56447 invoked from network); 3 Aug 2009 13:39:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 13:39:41 -0000
Received: (qmail 36624 invoked by uid 500); 3 Aug 2009 13:39:43 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 36552 invoked by uid 500); 3 Aug 2009 13:39:43 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 36541 invoked by uid 99); 3 Aug 2009 13:39:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:39:43 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mathias.demare@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:39:34 +0000
Received: by fxm25 with SMTP id 25so2618204fxm.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 06:39:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:from:date
         :message-id:subject:to:content-type;
        bh=8R7KifJRrRIfAWD2E8ULbM8fKKe8DLmK4QD/KbcS59g=;
        b=BrZ1YLsiy9nltL/W3qPU06BDfGFJlxeJbXIJdzeZspxLdWhFB9EMYApiEjwxfKaRBU
         JgnC99uvPTTbhqxFQwmbD6hGo2VFXk9VoK6uJVYw7qjCmu4D1izWlXm26PhnK18e0slO
         NKUqXzSnWcjnspIPSv4Ed6d1DbfNYB/NlzRnU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:from:date:message-id:subject:to:content-type;
        b=vrgdjRt2d5CsLWySXEd6PwQGp/zO8xGVGmS2SHtSbtsiXJR+YFCiPoiEGO5oc1ZGR1
         8IFgHhN4FFYVivg4KMpGi4iFbOwqW6Vp6lflEJdI118rBEZJzTNOQ+eQDh0xo0woVLOS
         HYdfdZgrmelLloDnXTynyj/OlqAbwrvN+fm4w=
MIME-Version: 1.0
Received: by 10.223.111.196 with SMTP id t4mr581404fap.40.1249306754282; Mon, 
	03 Aug 2009 06:39:14 -0700 (PDT)
Reply-To: mathias.demare@gmail.com
From: =?UTF-8?Q?Mathias_De_Mar=C3=A9?= <mathias.demare@gmail.com>
Date: Mon, 3 Aug 2009 15:38:54 +0200
Message-ID: <375c60f40908030638s636e02b6tf633493bfac58316@mail.gmail.com>
Subject: Task process exit with nonzero status of 255
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6d385d84df52e04703ce5b8
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6d385d84df52e04703ce5b8
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I'm getting a rather cryptic error while running a Map job with
MultithreadedMapper (no idea if it has anything to do with the
MultithreadedMapper).
It only occurs sometimes, occurs at different times during the Map
(sometimes at the start, sometimes at a random location), and it doesn't
really give any information.

Task Id : attempt_200908031207_0009_m_000000_0, Status : FAILED
java.io.IOException: Task process exit with nonzero status of 255.
    at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:418)

I'm a bit at a loss. The only results I'm finding from Google are a few
other people who have had the same problem, but nobody with a solution.

Mathias De Mar=C3=A9

--0016e6d385d84df52e04703ce5b8--

From common-user-return-16515-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 13:56:11 2009
Return-Path: <common-user-return-16515-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70176 invoked from network); 3 Aug 2009 13:56:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 13:56:11 -0000
Received: (qmail 68724 invoked by uid 500); 3 Aug 2009 13:56:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 68626 invoked by uid 500); 3 Aug 2009 13:56:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 68616 invoked by uid 99); 3 Aug 2009 13:56:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:56:13 +0000
X-ASF-Spam-Status: No, hits=3.2 required=10.0
	tests=FS_LARGE_PERCENT2,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of prashullegaddi@gmail.com designates 209.85.198.235 as permitted sender)
Received: from [209.85.198.235] (HELO rv-out-0506.google.com) (209.85.198.235)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:56:04 +0000
Received: by rv-out-0506.google.com with SMTP id k40so1033034rvb.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 06:55:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=YmHvmJ3gJQJFCsrCNIIF3cy9HhNZpP9iBF8fsC58xWM=;
        b=VZFZI0nnoxwxHBUPKHYVn+Nrs885ti7mukH/0QuAZRQrJOPNiQqwhQJ5Ez7lCE5KZ9
         Hh0sV8p+K+jKJWKE5fnR+slZUN5DL3M60SQ2O+de+xzScg8tSxMFGpr7OTDTxSyydDH7
         mNtvY2bcghxDwxoWYgMEiuIMAtCcRjCFn7ytI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=LME+fFUqcIbP58idwGg/DNBpbRM0cyX1AIfzf9NRQ55kjJ0TUBL1nkyBXmSG6ZdOJl
         0HVXnBKXa0V13CzltFfgxdg7mNN5K6heZxEdtP/+wgEgxpKqoewNMjLGY4e3TF5vWLRq
         QRvzvX6YbEbuzSUUe5251d7whhA1cAFQE48Fg=
MIME-Version: 1.0
Received: by 10.140.192.14 with SMTP id p14mr3784401rvf.253.1249307743421; 
	Mon, 03 Aug 2009 06:55:43 -0700 (PDT)
In-Reply-To: <1181230094@web.de>
References: <1181230094@web.de>
Date: Mon, 3 Aug 2009 19:25:43 +0530
Message-ID: <ac6e61fc0908030655u2cfd9eebwf9454bf311111de5@mail.gmail.com>
Subject: Re: Job status task attempt 120%:
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd2179643063a04703d20c9
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd2179643063a04703d20c9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Take a look at it:
http://mail-archives.apache.org/mod_mbox/hadoop-common-user/200907.mbox/%3Ce4fc0d2a0907091445t7ddd1837w8477480deb5a9ce9@mail.gmail.com%3E

~ Prashant.

On Mon, Aug 3, 2009 at 5:48 AM, <joerg.schad@email.de> wrote:

> Hi,
> when I check my running jobs via the jobtracker web interface I see that
> one task attempt is at 120% .
> Is there a logical explanation?
> Thanks
>
>

--000e0cd2179643063a04703d20c9--

From common-user-return-16516-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 13:58:43 2009
Return-Path: <common-user-return-16516-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 71533 invoked from network); 3 Aug 2009 13:58:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 13:58:42 -0000
Received: (qmail 72408 invoked by uid 500); 3 Aug 2009 13:58:45 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 72340 invoked by uid 500); 3 Aug 2009 13:58:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 72330 invoked by uid 99); 3 Aug 2009 13:58:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:58:45 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jason.hadoop@gmail.com designates 74.125.92.27 as permitted sender)
Received: from [74.125.92.27] (HELO qw-out-2122.google.com) (74.125.92.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 13:58:36 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1593157qwh.35
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 06:58:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=fF7XFexlTdjl6/yqFaq/SHo2M3/LihpkV+0OyMOJ+uc=;
        b=XOX5zYC9XvW2caQo4TRi4IFIbrJO5v+ondYSZv60DrWKOkDn9TJRaV26Bj7otZaAWJ
         jD24bkVNSDN4A7dCMdOsRBZiPBVLKlKZfe/1E5SpJTxn09JIOeIxxEzcvtxB4YLCfqUX
         zQmH42Pvx6FXo6U7jxNuU6rVT5Ibi9l68tVtE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=gLd1O+5vMQ+AGpo88/T5RsoR8dUWgTD+TeEvKlmZty7roaiFARMC0N7o0RWHrHIswA
         uGcp2aMRfDHXKFDYJtiRoD6NPWGylkUunCGBnpSlxx8g8/FezKk+S3MPh8X+xGjxL1NP
         Hy35Y5AD2ITyfHBtF4sPPur8sisylV7/hE0t8=
MIME-Version: 1.0
Received: by 10.220.45.205 with SMTP id g13mr4721066vcf.24.1249307894365; Mon, 
	03 Aug 2009 06:58:14 -0700 (PDT)
In-Reply-To: <375c60f40908030638s636e02b6tf633493bfac58316@mail.gmail.com>
References: <375c60f40908030638s636e02b6tf633493bfac58316@mail.gmail.com>
Date: Mon, 3 Aug 2009 06:58:14 -0700
Message-ID: <314098690908030658y36cfaad1t93d809891b8fc425@mail.gmail.com>
Subject: Re: Task process exit with nonzero status of 255
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org, mathias.demare@gmail.com
Content-Type: multipart/alternative; boundary=0016364ec868423dce04703d29ef
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364ec868423dce04703d29ef
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable

That generally means that the process that is running the task, crashed.
The actual map/reduce task is run in a separate jvm by the task tracker, an=
d
that JVM is exiting abnormally.
This used to happen to my jobs quite a bit when they were using a buggy
native library via jni.

If you are trying to use the colorspace transforms via the java imaging
APIs, it is not thread safe (at least through 1.6.10 under linux).

There may be additional information available in the per task logs.

2009/8/3 Mathias De Mar=E9 <mathias.demare@gmail.com>

> I'm getting a rather cryptic error while running a Map job with
> MultithreadedMapper (no idea if it has anything to do with the
> MultithreadedMapper).
> It only occurs sometimes, occurs at different times during the Map
> (sometimes at the start, sometimes at a random location), and it doesn't
> really give any information.
>
> Task Id : attempt_200908031207_0009_m_000000_0, Status : FAILED
> java.io.IOException: Task process exit with nonzero status of 255.
>    at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:418)
>
> I'm a bit at a loss. The only results I'm finding from Google are a few
> other people who have had the same problem, but nobody with a solution.
>
> Mathias De Mar=E9
>



--=20
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--0016364ec868423dce04703d29ef--

From common-user-return-16517-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 14:00:17 2009
Return-Path: <common-user-return-16517-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 72767 invoked from network); 3 Aug 2009 14:00:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 14:00:17 -0000
Received: (qmail 75268 invoked by uid 500); 3 Aug 2009 14:00:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 75164 invoked by uid 500); 3 Aug 2009 14:00:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 75153 invoked by uid 99); 3 Aug 2009 14:00:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 14:00:20 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 14:00:09 +0000
Received: by vws40 with SMTP id 40so1070691vws.2
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 06:59:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=0Jxz9hEpeQEzoKWHxFuWGW7Utt+OO91JRuGkVyunk6Y=;
        b=ZwYan69e4nMY0eu1XFdiuySkP+rfPuGA6aeKe6z41COfyD1SxQcFNFxlTo7Rrma/X3
         JojHrDy22KD+NdufDhGr1VV82FOxk4bvOu1+jgfTYIg9ib0nF2uM+r2JqBfypAUHzfeM
         Lh8fuk+bAeMLv7Sv1ZzetJZ8UEt8aqDKMD1tA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=x1ztDl4m2YPMGp8vxsm9mcGZsNdMW9bx70HmScz7vFNtl5wFJC0ugtS0gwj7AeMYBo
         vRbQ2ylhJBl7mcOIXvWMTmpD7UG5q3S/wMMeFCHSWnaOoWavaOcnwUsQ9/6ldFvjSz4S
         3ZvriL81Q1LRhJ2jctTDNE2igRG0ASetDlyTY=
MIME-Version: 1.0
Received: by 10.220.95.5 with SMTP id b5mr4691980vcn.22.1249307987738; Mon, 03 
	Aug 2009 06:59:47 -0700 (PDT)
In-Reply-To: <e01b80590908030618v50fb1a51t9912ddbca7f3f01d@mail.gmail.com>
References: <e01b80590908030550gd2eeb76g366f1f5e06349c93@mail.gmail.com>
	 <4A76E204.50308@gmail.com>
	 <e01b80590908030618v50fb1a51t9912ddbca7f3f01d@mail.gmail.com>
Date: Mon, 3 Aug 2009 06:59:47 -0700
Message-ID: <314098690908030659q266940bam87e589494f179bb8@mail.gmail.com>
Subject: Re: Difference between "Killed Task Attempts" and "Killed Tasks"
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e648082ad301ee04703d2e3c
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e648082ad301ee04703d2e3c
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

You only get the killed tasks, when speculative execution is enabled, when
one of a pair of identical tasks are running, finishes, the other task is
killed, but it is not considered an attempt.


On Mon, Aug 3, 2009 at 6:18 AM, Harish Mallipeddi <
harish.mallipeddi@gmail.com> wrote:

> Agreed. But how did I manage to get 54 killed tasks vs 62 killed
> task-attempts? I understand what a "failed task" is (a task for which
> 'mapred.map.max.attempts' attempts have failed). But what's a "killed
> task"?
>
> On Mon, Aug 3, 2009 at 6:41 PM, Enis Soztutar <enis.soz@gmail.com> wrote:
>
> > Hi,
> >
> > Task attempt is an attempt to a task. At any given time, one or
> > more(speculative exec.) of task attempts can be running. For a task,
> there
> > can be many attempts at different nodes. A task is complete if any of its
> > attempts is complete.  For a task to be marked as failed all of
> > mapred.map.max.attempts should fail. For every task in the job, a TaskID
> is
> > assigned. For every attempt, a TaskAttemptID is assigned (which ends with
> > _0, _1, etc).
> >
> >
> > Harish Mallipeddi wrote:
> >
> >> Hi,
> >>
> >> Anyone can tell me what's the difference between "Killed Task Attempts"
> >> and
> >> "Killed Tasks"? I ran a big job (14820 maps and 0 reduces). In the
> >> job-details page, the web GUI reports 62 "killed task attempts". I'm
> >> assuming this is due to "speculative execution". Now when I go to the
> >> job-history page for the job, it reports 54 "killed tasks" (and 14820
> >> successful map-tasks as expected).
> >>
> >> A few questions:
> >>
> >> * Why 62 killed task attempts vs 54 killed tasks?
> >> * Under speculative execution, does hadoop launch a new MapTask with new
> >> task-id or does it just launch a new MapTaskAttempt with a new
> >> task-attempt-id?
> >> * When a MapTaskAttempt fails, and when hadoop tries to re-launch the
> >> MapTask, does it create a new task-id or just a new task-attempt-id?
> >> * Does 'mapred.map.max.attempts' include all attempts launched due to
> >> speculative-execution?
> >>
> >> Btw this job is basically a trivial no-op job - it just scans around 1TB
> >> of
> >> data and does nothing else in the map. I looked at the killed tasks'
> >> syslog
> >> output and I didn't see any errors.
> >>
> >>
> >>
> >
> >
>
>
> --
> Harish Mallipeddi
> http://blog.poundbang.in
>



-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--0016e648082ad301ee04703d2e3c--

From common-user-return-16518-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 15:03:15 2009
Return-Path: <common-user-return-16518-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11275 invoked from network); 3 Aug 2009 15:03:15 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 15:03:15 -0000
Received: (qmail 46776 invoked by uid 500); 3 Aug 2009 15:03:18 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 46663 invoked by uid 500); 3 Aug 2009 15:03:17 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 46653 invoked by uid 99); 3 Aug 2009 15:03:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 15:03:17 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [128.8.132.61] (HELO mrouter3.umiacs.umd.edu) (128.8.132.61)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 15:03:07 +0000
Received: from [192.168.93.19] (unknown [128.8.118.5])
	by mrouter3.umiacs.umd.edu (Postfix) with ESMTP id DA5D213D376
	for <common-user@hadoop.apache.org>; Mon,  3 Aug 2009 11:02:43 -0400 (EDT)
Message-ID: <4A76FC13.4080108@umd.edu>
Date: Mon, 03 Aug 2009 11:02:43 -0400
From: Jimmy Lin <jimmylin@umd.edu>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Save the date! NSF/Google/IBM CLuE PI Meeting 2009 (10/5/2009 in
 bay area)
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

The Cluster Exploratory (CLuE) program of the National Science
Foundation (NSF), led by Jim French, in partnership with the
Google/IBM Academic Cloud Computing Initiative (ACCI), has been
funding over a dozen Hadoop and cloud related projects for the past
year or so.  The CLuE PI Meeting will be held Monday, October 5, 2009
(location TBA, but near Mountain View).  This all-day event will be
open to the public and will provide a venue for reaching out to the
cloud community in the bay area.  Save the date and come find out
about exciting research from academia!

We are currently in the planning stages of this event, so please stay
tuned for details.  However, for planning purposes, we would like to
get a sense of interest.  If you are interested in attending this
event, please let us know at the following URL (Google docs
spreadsheet):

http://tinyurl.com/kj7ehx

This is not a formal registration for the event, but an informal poll
to help us in planning.  However, respondents here will get priority
when the official registration site opens.  There will be a nominal
registration fee associated with the event.


From common-user-return-16519-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 15:49:11 2009
Return-Path: <common-user-return-16519-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 50809 invoked from network); 3 Aug 2009 15:49:10 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 15:49:10 -0000
Received: (qmail 8063 invoked by uid 500); 3 Aug 2009 15:49:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 7973 invoked by uid 500); 3 Aug 2009 15:49:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 7963 invoked by uid 99); 3 Aug 2009 15:49:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 15:49:13 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 15:49:02 +0000
Received: from [216.145.54.158] (socks1.corp.yahoo.com [216.145.54.158])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n73FlF0c080092
	for <common-user@hadoop.apache.org>; Mon, 3 Aug 2009 08:47:15 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=M8AXIwdr93Rx14vzaroKAaB7Vlt+RbMFwDMiLs6FsuB8/fJ643jQmGCnrj7vAJe+
Message-ID: <4A770682.6000405@yahoo-inc.com>
Date: Mon, 03 Aug 2009 08:47:14 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090608)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: "Too many open files" error, which gets resolved after some time
References: <77938bc20906210306q152c8681g2af43dd34b3f6ed0@mail.gmail.com>	 <77938bc20906220609y29ae0627n1816dd4f56e4c6f3@mail.gmail.com>	 <4A3FECA4.7010809@apache.org>	 <77938bc20906221358l13da4fa6sa741202557a87ad8@mail.gmail.com>	 <77938bc20906230131u2f853032ydd4e94e97d652918@mail.gmail.com>	 <4A40F7C6.3070905@yahoo-inc.com> <4A412D22.9050000@yahoo-inc.com>	 <77938bc20906231327r5b8e779i93e2b45de9732780@mail.gmail.com>	 <4A414034.2050405@yahoo-inc.com>	 <77938bc20906231427u6f0b4db2p9905c626962f4076@mail.gmail.com> <77938bc20908020430i17276096mc5f597bd52f2c272@mail.gmail.com>
In-Reply-To: <77938bc20908020430i17276096mc5f597bd52f2c272@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

For writes, there is an extra thread waiting on i/o. So it would be 3 
fds more. To simplify earlier equation, on the client side :

for writes :  max fds (for io bound load) = 7 * #write_streams
for reads  :  max fds (for io bound load) = 4 * #read_streams

The main socket is cleared as soon as you close the stream.
The rest of fds stay for 10 sec (they get reused if you open more 
streams meanwhile).

I hope this is clear enough.

Raghu.

Stas Oskin wrote:
> Hi.
> 
> I'd like to raise this issue once again, just to clarify a point.
> 
> If I have only one thread writing to HDFS, the amount of fd's should be 4,
> resulting from:
> 
> 1) input
> 2) output
> 3) epoll
> 4) stream itself
> 
> And these 4 fds should be cleared out after 10 seconds.
> 
> Is this correct?
> 
> Thanks in advance for the information!
> 
> 2009/6/24 Stas Oskin <stas.oskin@gmail.com>
> 
>> Hi.
>>
>> So if I open one stream, it should be 4?
>>
>>
>>
>> 2009/6/23 Raghu Angadi <rangadi@yahoo-inc.com>
>>
>>> how many threads do you have? Number of active threads is very important.
>>> Normally,
>>>
>>> #fds = (3 * #threads_blocked_on_io) + #streams
>>>
>>> 12 per stream is certainly way off.
>>>
>>> Raghu.
>>>
>>>
>>> Stas Oskin wrote:
>>>
>>>> Hi.
>>>>
>>>> In my case it was actually ~ 12 fd's per stream, which included pipes and
>>>> epolls.
>>>>
>>>> Could it be that HDFS opens 3 x 3 (input - output - epoll) fd's per each
>>>> thread, which make it close to the number I mentioned? Or it always 3 at
>>>> maximum per thread / stream?
>>>>
>>>> Up to 10 sec looks quite the correct number, it seems it gets freed
>>>> arround
>>>> this time indeed.
>>>>
>>>> Regards.
>>>>
>>>> 2009/6/23 Raghu Angadi <rangadi@yahoo-inc.com>
>>>>
>>>>  To be more accurate, once you have HADOOP-4346,
>>>>> fds for epoll and pipes = 3 * threads blocked on Hadoop I/O
>>>>>
>>>>> Unless you have hundreds of threads at a time, you should not see
>>>>> hundreds
>>>>> of these. These fds stay up to 10sec even after the
>>>>> threads exit.
>>>>>
>>>>> I am a bit confused about your exact situation. Please check number of
>>>>> threads if you still facing the problem.
>>>>>
>>>>> Raghu.
>>>>>
>>>>>
>>>>> Raghu Angadi wrote:
>>>>>
>>>>>  since you have HADOOP-4346, you should not have excessive epoll/pipe
>>>>>> fds
>>>>>> open. First of all do you still have the problem? If yes, how many
>>>>>> hadoop
>>>>>> streams do you have at a time?
>>>>>>
>>>>>> System.gc() won't help if you have HADOOP-4346.
>>>>>>
>>>>>> Ragu.
>>>>>>
>>>>>>  Thanks for your opinion!
>>>>>>
>>>>>>> 2009/6/22 Stas Oskin <stas.oskin@gmail.com>
>>>>>>>
>>>>>>>  Ok, seems this issue is already patched in the Hadoop distro I'm
>>>>>>> using
>>>>>>>
>>>>>>>> (Cloudera).
>>>>>>>>
>>>>>>>> Any idea if I still should call GC manually/periodically to clean out
>>>>>>>> all
>>>>>>>> the stale pipes / epolls?
>>>>>>>>
>>>>>>>> 2009/6/22 Steve Loughran <stevel@apache.org>
>>>>>>>>
>>>>>>>>  Stas Oskin wrote:
>>>>>>>>
>>>>>>>>>  Hi.
>>>>>>>>>
>>>>>>>>>  So what would be the recommended approach to pre-0.20.x series?
>>>>>>>>>> To insure each file is used only by one thread, and then it safe to
>>>>>>>>>> close
>>>>>>>>>> the handle in that thread?
>>>>>>>>>>
>>>>>>>>>> Regards.
>>>>>>>>>>
>>>>>>>>>>  good question -I'm not sure. For anythiong you get with
>>>>>>>>>>
>>>>>>>>> FileSystem.get(),
>>>>>>>>> its now dangerous to close, so try just setting the reference to
>>>>>>>>> null
>>>>>>>>> and
>>>>>>>>> hoping that GC will do the finalize() when needed
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
> 


From common-user-return-16520-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 17:19:17 2009
Return-Path: <common-user-return-16520-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 84923 invoked from network); 3 Aug 2009 17:19:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 17:19:17 -0000
Received: (qmail 69563 invoked by uid 500); 3 Aug 2009 17:19:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 69479 invoked by uid 500); 3 Aug 2009 17:19:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 69469 invoked by uid 99); 3 Aug 2009 17:19:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 17:19:20 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 17:19:09 +0000
Received: from pcp088917pcs.unl.edu (pcp088917pcs.unl.edu [129.93.158.32])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n73HIX5W012252
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Mon, 3 Aug 2009 12:18:46 -0500
Message-Id: <509118AE-DCAB-4DB2-8FF9-492CD4053319@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <6f72e2db0908030009s3f622c22u5432dd03d9490335@mail.gmail.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v935.3)
Subject: Re: :!
Date: Mon, 3 Aug 2009 12:18:46 -0500
References: <6f72e2db0908022215h6eddfabcr87767125ffbb1fc1@mail.gmail.com> <ac6e61fc0908022218u5b421355w2d40fa2fae296345@mail.gmail.com> <6f72e2db0908022232g61528382hafcd4c6821243df5@mail.gmail.com> <ac6e61fc0908022337l2b30be49m6d314fb2b9be2f0c@mail.gmail.com> <6f72e2db0908030001o2789db9dt512a777173ed59a8@mail.gmail.com> <6967a3fe0908030003r4414235ay2b9ce9e828eeac52@mail.gmail.com> <6f72e2db0908030009s3f622c22u5432dd03d9490335@mail.gmail.com>
X-Mailer: Apple Mail (2.935.3)
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Sugandha,

It's a common mistake - I think he was trying to unsubscribe to the  
mailing list (which is done by sending a message to a specific email  
address with the command "unsubscribe"), not telling you to unsubscribe.

Brian

On Aug 3, 2009, at 2:09 AM, Sugandha Naolekar wrote:

> This is ridiculous. What do you mean by unsubscribe.?? I have few  
> queries
> and dats why have logged in to the corresponding forum.
>
> On Mon, Aug 3, 2009 at 12:33 PM, A BlueCoder  
> <bluecoder008@gmail.com> wrote:
>
>> unsubscribe
>>
>> On Mon, Aug 3, 2009 at 12:01 AM, Sugandha Naolekar
>> <sugandha.n87@gmail.com>wrote:
>>
>>> dats fine. But, if I place the data in HDFS and then run map  
>>> reduce code
>> to
>>> provide compression, then the data will get compressed in sequence  
>>> files
>>> but, even the original data will reside in the memory;thereby  
>>> leading or
>>> causing a kind of redundancy of data...
>>>
>>> Can u pls suggest me a way out?/
>>>
>>> On Mon, Aug 3, 2009 at 12:07 PM, prashant ullegaddi <
>>> prashullegaddi@gmail.com> wrote:
>>>
>>>> I don't think you will be able to compress some data unless it's on
>> HDFS.
>>>> What you can do is
>>>> 1. Manually compress the data on the machine where the data  
>>>> resides.
>>> Then,
>>>> copy the same to
>>>> HDFS. or
>>>> 2. Copy the data without compressing to HDFS, then run a job  
>>>> which just
>>>> emits the data as it reads
>>>> in key/value pair. You can set
>>>> FileOutputFormat.setOutputCompressorClass(job,GzipCodec.class) so
>>>> that output gets gzipped.
>>>>
>>>> Does that solve your problem?
>>>>
>>>> btw you didn't exactly specify your data size (how many TBs).
>>>>
>>>> On Mon, Aug 3, 2009 at 11:02 AM, Sugandha Naolekar
>>>> <sugandha.n87@gmail.com>wrote:
>>>>
>>>>> Yes, You are right. Here goes the details related::
>>>>>
>>>>> -> I have a Hadoop cluster of 7 nodes. Now there is this 8th  
>>>>> machine,
>>>> which
>>>>> is not a part of the hadoop cluster.
>>>>> -> I want to place the data of that machine into the HDFS. Thus,
>> before
>>>>> placing it in HDFS, I want to compress it, and then dump in the  
>>>>> HDFS.
>>>>> -> I have 4 datanodes in my cluster. also, data might get extended
>> upto
>>>>> tera
>>>>> bytes.
>>>>> -> Also, i have set thr replication factor as 2.
>>>>> -> I guess, for compression, I will have to run map reduce...?
>>>>> right..please
>>>>> tel me the complete approach that is needed to be followed.
>>>>>
>>>>> On Mon, Aug 3, 2009 at 10:48 AM, prashant ullegaddi <
>>>>> prashullegaddi@gmail.com> wrote:
>>>>>
>>>>>> By "I want to compress the data first and then place it in HDFS",
>> do
>>>> you
>>>>>> mean you want to compress the data
>>>>>> locally and then copy to DFS?
>>>>>>
>>>>>> What's the size of your data? What's the capacity of HDFS?
>>>>>>
>>>>>> On Mon, Aug 3, 2009 at 10:45 AM, Sugandha Naolekar
>>>>>> <sugandha.n87@gmail.com>wrote:
>>>>>>
>>>>>>> I want to compress the data first and then place it in HDFS.
>> Again,
>>>>> while
>>>>>>> retrieving the same, I want to uncompress it and place on the
>>> desired
>>>>>>> destination. Can this be possible. How to get started? Also, I
>> want
>>>> to
>>>>>> get
>>>>>>> started with actual coding part of compression and MAP reduce.
>>> PLease
>>>>>>> suggest me aptly...!
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Regards!
>>>>>>> Sugandha
>>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Regards!
>>>>> Sugandha
>>>>>
>>>>
>>>
>>>
>>>
>>> --
>>> Regards!
>>> Sugandha
>>>
>>
>
>
>
> -- 
> Regards!
> Sugandha


From common-user-return-16521-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 17:27:41 2009
Return-Path: <common-user-return-16521-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 88608 invoked from network); 3 Aug 2009 17:27:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 17:27:40 -0000
Received: (qmail 82088 invoked by uid 500); 3 Aug 2009 17:27:43 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82019 invoked by uid 500); 3 Aug 2009 17:27:43 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82009 invoked by uid 99); 3 Aug 2009 17:27:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 17:27:43 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 17:27:35 +0000
Received: by fxm25 with SMTP id 25so2758468fxm.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 10:27:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=7dCpYjbc6a3Ki3p8yqOQhbV5dkjgwFOXasp93waKXSs=;
        b=fMQ/ds0b0zo8oyI4APb0zD3yCXf7ewDamIbVIfigQu+5PCfYyDYFmd61xjk5Ollhm4
         I2H8PQpyeBUr5fQHzc6ZX1KCgVX63/M8SnM0gKnV1RCfmTCnf+8Gfhpy7D2DBySWckxr
         U+6H4whDHipeQkNBpt2PSWfXTdt0DRCf2Iezc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=DJmiTPbrKaFYQMDR/MmnmhkjgTwqS9qJ6xfz334vJTJUJxrryYcYdSLhRdud9mghsZ
         vUBTWw9XU8hVWXdrpgtOV2qzMj7tzWGMGeX9SHA1SMbNtjNx6/ZinQC2zUFnGzqpK194
         d7tKXd1PQHyKRKc10QvpZV2EM0sj1lvGlq/k0=
MIME-Version: 1.0
Received: by 10.223.126.10 with SMTP id a10mr2719446fas.17.1249320433551; Mon, 
	03 Aug 2009 10:27:13 -0700 (PDT)
In-Reply-To: <4A770682.6000405@yahoo-inc.com>
References: <77938bc20906210306q152c8681g2af43dd34b3f6ed0@mail.gmail.com>
	 <77938bc20906221358l13da4fa6sa741202557a87ad8@mail.gmail.com>
	 <77938bc20906230131u2f853032ydd4e94e97d652918@mail.gmail.com>
	 <4A40F7C6.3070905@yahoo-inc.com> <4A412D22.9050000@yahoo-inc.com>
	 <77938bc20906231327r5b8e779i93e2b45de9732780@mail.gmail.com>
	 <4A414034.2050405@yahoo-inc.com>
	 <77938bc20906231427u6f0b4db2p9905c626962f4076@mail.gmail.com>
	 <77938bc20908020430i17276096mc5f597bd52f2c272@mail.gmail.com>
	 <4A770682.6000405@yahoo-inc.com>
Date: Mon, 3 Aug 2009 20:27:13 +0300
Message-ID: <77938bc20908031027s417615c9v247f6b2e7e5446d7@mail.gmail.com>
Subject: Re: "Too many open files" error, which gets resolved after some time
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c5ab40a708c60470401495
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5ab40a708c60470401495
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

Thanks for the explanation.

Just to clarify, the extra thread waiting on writing, is happens in
multi-threading as well?

Meaning if I have 10 writing threads for example, it would be actually 70
fd's?

Regards.

2009/8/3 Raghu Angadi <rangadi@yahoo-inc.com>

> For writes, there is an extra thread waiting on i/o. So it would be 3 fds
> more. To simplify earlier equation, on the client side :
>
> for writes :  max fds (for io bound load) = 7 * #write_streams
> for reads  :  max fds (for io bound load) = 4 * #read_streams
>
> The main socket is cleared as soon as you close the stream.
> The rest of fds stay for 10 sec (they get reused if you open more streams
> meanwhile).
>
> I hope this is clear enough.
>
>
> Raghu.
>
> Stas Oskin wrote:
>
>> Hi.
>>
>> I'd like to raise this issue once again, just to clarify a point.
>>
>> If I have only one thread writing to HDFS, the amount of fd's should be 4,
>> resulting from:
>>
>> 1) input
>> 2) output
>> 3) epoll
>> 4) stream itself
>>
>> And these 4 fds should be cleared out after 10 seconds.
>>
>> Is this correct?
>>
>> Thanks in advance for the information!
>>
>> 2009/6/24 Stas Oskin <stas.oskin@gmail.com>
>>
>>  Hi.
>>>
>>> So if I open one stream, it should be 4?
>>>
>>>
>>>
>>> 2009/6/23 Raghu Angadi <rangadi@yahoo-inc.com>
>>>
>>>  how many threads do you have? Number of active threads is very
>>>> important.
>>>> Normally,
>>>>
>>>> #fds = (3 * #threads_blocked_on_io) + #streams
>>>>
>>>> 12 per stream is certainly way off.
>>>>
>>>> Raghu.
>>>>
>>>>
>>>> Stas Oskin wrote:
>>>>
>>>>  Hi.
>>>>>
>>>>> In my case it was actually ~ 12 fd's per stream, which included pipes
>>>>> and
>>>>> epolls.
>>>>>
>>>>> Could it be that HDFS opens 3 x 3 (input - output - epoll) fd's per
>>>>> each
>>>>> thread, which make it close to the number I mentioned? Or it always 3
>>>>> at
>>>>> maximum per thread / stream?
>>>>>
>>>>> Up to 10 sec looks quite the correct number, it seems it gets freed
>>>>> arround
>>>>> this time indeed.
>>>>>
>>>>> Regards.
>>>>>
>>>>> 2009/6/23 Raghu Angadi <rangadi@yahoo-inc.com>
>>>>>
>>>>>  To be more accurate, once you have HADOOP-4346,
>>>>>
>>>>>> fds for epoll and pipes = 3 * threads blocked on Hadoop I/O
>>>>>>
>>>>>> Unless you have hundreds of threads at a time, you should not see
>>>>>> hundreds
>>>>>> of these. These fds stay up to 10sec even after the
>>>>>> threads exit.
>>>>>>
>>>>>> I am a bit confused about your exact situation. Please check number of
>>>>>> threads if you still facing the problem.
>>>>>>
>>>>>> Raghu.
>>>>>>
>>>>>>
>>>>>> Raghu Angadi wrote:
>>>>>>
>>>>>>  since you have HADOOP-4346, you should not have excessive epoll/pipe
>>>>>>
>>>>>>> fds
>>>>>>> open. First of all do you still have the problem? If yes, how many
>>>>>>> hadoop
>>>>>>> streams do you have at a time?
>>>>>>>
>>>>>>> System.gc() won't help if you have HADOOP-4346.
>>>>>>>
>>>>>>> Ragu.
>>>>>>>
>>>>>>>  Thanks for your opinion!
>>>>>>>
>>>>>>>  2009/6/22 Stas Oskin <stas.oskin@gmail.com>
>>>>>>>>
>>>>>>>>  Ok, seems this issue is already patched in the Hadoop distro I'm
>>>>>>>> using
>>>>>>>>
>>>>>>>>  (Cloudera).
>>>>>>>>>
>>>>>>>>> Any idea if I still should call GC manually/periodically to clean
>>>>>>>>> out
>>>>>>>>> all
>>>>>>>>> the stale pipes / epolls?
>>>>>>>>>
>>>>>>>>> 2009/6/22 Steve Loughran <stevel@apache.org>
>>>>>>>>>
>>>>>>>>>  Stas Oskin wrote:
>>>>>>>>>
>>>>>>>>>   Hi.
>>>>>>>>>>
>>>>>>>>>>  So what would be the recommended approach to pre-0.20.x series?
>>>>>>>>>>
>>>>>>>>>>> To insure each file is used only by one thread, and then it safe
>>>>>>>>>>> to
>>>>>>>>>>> close
>>>>>>>>>>> the handle in that thread?
>>>>>>>>>>>
>>>>>>>>>>> Regards.
>>>>>>>>>>>
>>>>>>>>>>>  good question -I'm not sure. For anythiong you get with
>>>>>>>>>>>
>>>>>>>>>>>  FileSystem.get(),
>>>>>>>>>> its now dangerous to close, so try just setting the reference to
>>>>>>>>>> null
>>>>>>>>>> and
>>>>>>>>>> hoping that GC will do the finalize() when needed
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>
>

--001636c5ab40a708c60470401495--

From common-user-return-16522-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 17:47:33 2009
Return-Path: <common-user-return-16522-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 12406 invoked from network); 3 Aug 2009 17:47:33 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 17:47:33 -0000
Received: (qmail 18580 invoked by uid 500); 3 Aug 2009 17:47:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 18510 invoked by uid 500); 3 Aug 2009 17:47:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 18500 invoked by uid 99); 3 Aug 2009 17:47:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 17:47:35 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mathias.demare@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 17:47:26 +0000
Received: by fxm25 with SMTP id 25so2769815fxm.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 10:47:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:cc:content-type;
        bh=FvNvf45gEGGA6QYMDmcx0Lk9/semh5dZ25HNucYGtis=;
        b=m2iVdbIHp5pbfo8XWG5ANMCVy5AB75kSfwhPCK4YHZq5+4w6ptJEWpWt0KajeySlIl
         BxPUcvC8mGmTvDCDScPNmWe0UZAYRKIhrXlCPdItG1Pi+9kl4fepljpp6tmm+B1fNCnu
         WMbsKae8htTSaufKDY+NJBsSbOBzLSx7dkO2s=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        b=S+vKF4AHHX/S8l3Ga92XCIlALin1NhZX+vE2xSuXMM1+PiJV7sseGZOwSf1GKLidyE
         sKZCeEsOOwYsrwUh4o8S1x+3uOlU8kUR1gMuHb5OVtygdyFLlWcoX7zCzgb0gmdi25rb
         YgdUp8KPa10/jp5pcpiuKvIuuE3CS4UseqkTE=
MIME-Version: 1.0
Received: by 10.223.111.196 with SMTP id t4mr745643fap.40.1249321624486; Mon, 
	03 Aug 2009 10:47:04 -0700 (PDT)
Reply-To: mathias.demare@gmail.com
In-Reply-To: <314098690908030658y36cfaad1t93d809891b8fc425@mail.gmail.com>
References: <375c60f40908030638s636e02b6tf633493bfac58316@mail.gmail.com> 
	<314098690908030658y36cfaad1t93d809891b8fc425@mail.gmail.com>
From: =?UTF-8?Q?Mathias_De_Mar=C3=A9?= <mathias.demare@gmail.com>
Date: Mon, 3 Aug 2009 19:46:44 +0200
Message-ID: <375c60f40908031046m25c4ebc6s5f1ac98a95834888@mail.gmail.com>
Subject: Re: Task process exit with nonzero status of 255
To: Jason Venner <jason.hadoop@gmail.com>
Cc: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6d385d8a345350470405b39
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6d385d8a345350470405b39
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thanks! Because of your information, I managed to find out that my crashes
have to do with the somewhat standard 'Too many open files'.
I added some 'close' and 'disconnect' to my InputStreams and
HttpURLConnections, but that only works up to a certain point.
The strange thing is that I do execute 'ulimit -n 32768', but I'm thinking
it somehow 'won't' stick.
The other alternative is that Hadoop is using 32768 file descriptors, but
that seems a bit over the top, as I'm using at most 200 threads (each of
which only sets up one HttpURLConnection).

Suggestions are welcome :-)

On Mon, Aug 3, 2009 at 3:58 PM, Jason Venner <jason.hadoop@gmail.com> wrote=
:

> That generally means that the process that is running the task, crashed.
> The actual map/reduce task is run in a separate jvm by the task tracker,
> and that JVM is exiting abnormally.
> This used to happen to my jobs quite a bit when they were using a buggy
> native library via jni.
>
> If you are trying to use the colorspace transforms via the java imaging
> APIs, it is not thread safe (at least through 1.6.10 under linux).
>
> There may be additional information available in the per task logs.
>
> 2009/8/3 Mathias De Mar=C3=A9 <mathias.demare@gmail.com>
>
> I'm getting a rather cryptic error while running a Map job with
>> MultithreadedMapper (no idea if it has anything to do with the
>> MultithreadedMapper).
>> It only occurs sometimes, occurs at different times during the Map
>> (sometimes at the start, sometimes at a random location), and it doesn't
>> really give any information.
>>
>> Task Id : attempt_200908031207_0009_m_000000_0, Status : FAILED
>> java.io.IOException: Task process exit with nonzero status of 255.
>>    at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:418)
>>
>> I'm a bit at a loss. The only results I'm finding from Google are a few
>> other people who have had the same problem, but nobody with a solution.
>>
>> Mathias De Mar=C3=A9
>>
>
>
>
> --
> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
> www.prohadoopbook.com a community for Hadoop Professionals
>

--0016e6d385d8a345350470405b39--

From common-user-return-16523-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 19:09:15 2009
Return-Path: <common-user-return-16523-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 58361 invoked from network); 3 Aug 2009 19:09:15 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 19:09:15 -0000
Received: (qmail 16548 invoked by uid 500); 3 Aug 2009 19:09:18 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 16463 invoked by uid 500); 3 Aug 2009 19:09:17 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 16453 invoked by uid 500); 3 Aug 2009 19:09:17 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 16449 invoked by uid 99); 3 Aug 2009 19:09:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 19:09:14 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bharathvissapragada1990@gmail.com designates 209.85.221.188 as permitted sender)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 19:09:05 +0000
Received: by qyk26 with SMTP id 26so4366201qyk.5
        for <core-user@hadoop.apache.org>; Mon, 03 Aug 2009 12:08:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:from:date:message-id
         :subject:to:content-type;
        bh=x+ILcus+4e0sTqg+xscvB79xmHlqq85n9g+b6DIp0Og=;
        b=QsUaoG6RPO/BIBM9S/iSGVddqX7BxqVwoulbr0MzxQ5bFH94AULJoVAQ1dGd9B2p0g
         PTHsfKgAlBv3XRhB59panE2kckHfBevrCPbKxSOnlWBmEFV0mN1ug6KScDCkh9N9H+/H
         +hDMoLGjbv16p2msTdyhE3/N6L2Y/A+S/8FFc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:from:date:message-id:subject:to:content-type;
        b=Z7nka7FQ+7EauwlDaN2QyoAsANpMqE0TqDlxFZ3ha4NDOL0vhvhK++XL9QAKZt0xxO
         LlfUeuRpbTPuie1JTqCuElCcsXJo4GUFPumFQs4IEa6N4FtbSs4an/OtHwxqLJXWZw/n
         eaDpxHgftZ6czkWxzxghyw/hU2rhIVodgpFpU=
MIME-Version: 1.0
Received: by 10.229.85.17 with SMTP id m17mr1436520qcl.43.1249326524123; Mon, 
	03 Aug 2009 12:08:44 -0700 (PDT)
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Tue, 4 Aug 2009 00:38:23 +0530
Message-ID: <73d592f60908031208p41a4fcb0ob90523eddfedd01e@mail.gmail.com>
Subject: namenode -upgrade problem
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016364edf6eadcd060470417ff4
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364edf6eadcd060470417ff4
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi all ,

I have noticed some problem in my cluster when i changed the hadoop version
on the same DFS directory .. The namenode log on the master says the
following ..


ile system image contains an old layout version -16.
An upgrade to version -18 is required.
Please restart NameNode with -upgrade option.
    at
org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
    at
org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
    at
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
    at
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
2009-08-04 00:27:51,498 INFO org.apache.hadoop.ipc.Server: Stopping server
on 54310
2009-08-04 00:27:51,498 ERROR
org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException:
File system image contains an old layout version -16.
An upgrade to version -18 is required.
Please restart NameNode with -upgrade option.
    at
org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
    at
org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
    at
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
    at
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)

2009-08-04 00:27:51,499 INFO
org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG

Can anyone explain me the reason ... i googled it .. but those explanations
weren't quite useful

Thanks

--0016364edf6eadcd060470417ff4--

From common-user-return-16524-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 19:22:31 2009
Return-Path: <common-user-return-16524-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 62184 invoked from network); 3 Aug 2009 19:22:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 19:22:31 -0000
Received: (qmail 32957 invoked by uid 500); 3 Aug 2009 19:22:34 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 32875 invoked by uid 500); 3 Aug 2009 19:22:34 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 32865 invoked by uid 99); 3 Aug 2009 19:22:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 19:22:34 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.211.202] (HELO mail-yw0-f202.google.com) (209.85.211.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 19:22:24 +0000
Received: by ywh40 with SMTP id 40so4143044ywh.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 12:22:03 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.100.136.15 with SMTP id j15mr7523034and.101.1249327322980; 
	Mon, 03 Aug 2009 12:22:02 -0700 (PDT)
In-Reply-To: <73d592f60908031208p41a4fcb0ob90523eddfedd01e@mail.gmail.com>
References: <73d592f60908031208p41a4fcb0ob90523eddfedd01e@mail.gmail.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Mon, 3 Aug 2009 12:21:42 -0700
Message-ID: <45f85f70908031221h256cd12bq10316f7a96ec6170@mail.gmail.com>
Subject: Re: namenode -upgrade problem
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e644cee04b60f8047041afdf
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e644cee04b60f8047041afdf
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Mon, Aug 3, 2009 at 12:08 PM, bharath vissapragada <
bharathvissapragada1990@gmail.com> wrote:

> Hi all ,
>
> I have noticed some problem in my cluster when i changed the hadoop version
> on the same DFS directory .. The namenode log on the master says the
> following ..
>
>
> ile system image contains an old layout version -16.
> *An upgrade to version -18 is required.
> Please restart NameNode with -upgrade option.
> *


See bolded text above -- you need to run namenode -upgrade to upgrade your
metadata format to the current version.

-Todd

   at
>

>
> org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> 2009-08-04 00:27:51,498 INFO org.apache.hadoop.ipc.Server: Stopping server
> on 54310
> 2009-08-04 00:27:51,498 ERROR
> org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException:
> File system image contains an old layout version -16.
> An upgrade to version -18 is required.
> Please restart NameNode with -upgrade option.
>    at
>
> org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
>
> 2009-08-04 00:27:51,499 INFO
> org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG
>
> Can anyone explain me the reason ... i googled it .. but those explanations
> weren't quite useful
>
> Thanks
>

--0016e644cee04b60f8047041afdf--

From common-user-return-16525-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 19:28:20 2009
Return-Path: <common-user-return-16525-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 65993 invoked from network); 3 Aug 2009 19:28:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 19:28:20 -0000
Received: (qmail 43577 invoked by uid 500); 3 Aug 2009 19:28:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 43512 invoked by uid 500); 3 Aug 2009 19:28:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 43502 invoked by uid 99); 3 Aug 2009 19:28:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 19:28:22 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 19:28:10 +0000
Received: from [10.72.106.226] (heighthigh-lx.corp.yahoo.com [10.72.106.226])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n73JQs7x072332
	for <common-user@hadoop.apache.org>; Mon, 3 Aug 2009 12:26:54 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=eJsCfkJLvS1zFNzpQ0pYoXQBUTePe3jUV6h4ofVE118OQtIkrXfwLeUhKv1oJ6Ce
Message-ID: <4A7739FE.5030106@yahoo-inc.com>
Date: Mon, 03 Aug 2009 12:26:54 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: "Too many open files" error, which gets resolved after some time
References: <77938bc20906210306q152c8681g2af43dd34b3f6ed0@mail.gmail.com>	 <77938bc20906221358l13da4fa6sa741202557a87ad8@mail.gmail.com>	 <77938bc20906230131u2f853032ydd4e94e97d652918@mail.gmail.com>	 <4A40F7C6.3070905@yahoo-inc.com> <4A412D22.9050000@yahoo-inc.com>	 <77938bc20906231327r5b8e779i93e2b45de9732780@mail.gmail.com>	 <4A414034.2050405@yahoo-inc.com>	 <77938bc20906231427u6f0b4db2p9905c626962f4076@mail.gmail.com>	 <77938bc20908020430i17276096mc5f597bd52f2c272@mail.gmail.com>	 <4A770682.6000405@yahoo-inc.com> <77938bc20908031027s417615c9v247f6b2e7e5446d7@mail.gmail.com>
In-Reply-To: <77938bc20908031027s417615c9v247f6b2e7e5446d7@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Stas Oskin wrote:
> Hi.
> 
> Thanks for the explanation.
> 
> Just to clarify, the extra thread waiting on writing, is happens in
> multi-threading as well?
> 
> Meaning if I have 10 writing threads for example, it would be actually 70
> fd's?

unfortunately, yes.

There are different proposals to fix this : async I/O in Hadoop, RPCs 
for data transfers.

It is not just the fds, the applications that hit fd limits hit thread 
limits as well. Obviously Hadoop can not sustain this as the range of 
applications increases. It will be fixed one way or the other.

Raghu.

> Regards.
> 
> 2009/8/3 Raghu Angadi <rangadi@yahoo-inc.com>
> 
>> For writes, there is an extra thread waiting on i/o. So it would be 3 fds
>> more. To simplify earlier equation, on the client side :
>>
>> for writes :  max fds (for io bound load) = 7 * #write_streams
>> for reads  :  max fds (for io bound load) = 4 * #read_streams
>>
>> The main socket is cleared as soon as you close the stream.
>> The rest of fds stay for 10 sec (they get reused if you open more streams
>> meanwhile).
>>
>> I hope this is clear enough.
>>
>>
>> Raghu.
>>
>> Stas Oskin wrote:
>>
>>> Hi.
>>>
>>> I'd like to raise this issue once again, just to clarify a point.
>>>
>>> If I have only one thread writing to HDFS, the amount of fd's should be 4,
>>> resulting from:
>>>
>>> 1) input
>>> 2) output
>>> 3) epoll
>>> 4) stream itself
>>>
>>> And these 4 fds should be cleared out after 10 seconds.
>>>
>>> Is this correct?
>>>
>>> Thanks in advance for the information!
>>>
>>> 2009/6/24 Stas Oskin <stas.oskin@gmail.com>
>>>
>>>  Hi.
>>>> So if I open one stream, it should be 4?
>>>>
>>>>
>>>>
>>>> 2009/6/23 Raghu Angadi <rangadi@yahoo-inc.com>
>>>>
>>>>  how many threads do you have? Number of active threads is very
>>>>> important.
>>>>> Normally,
>>>>>
>>>>> #fds = (3 * #threads_blocked_on_io) + #streams
>>>>>
>>>>> 12 per stream is certainly way off.
>>>>>
>>>>> Raghu.
>>>>>
>>>>>
>>>>> Stas Oskin wrote:
>>>>>
>>>>>  Hi.
>>>>>> In my case it was actually ~ 12 fd's per stream, which included pipes
>>>>>> and
>>>>>> epolls.
>>>>>>
>>>>>> Could it be that HDFS opens 3 x 3 (input - output - epoll) fd's per
>>>>>> each
>>>>>> thread, which make it close to the number I mentioned? Or it always 3
>>>>>> at
>>>>>> maximum per thread / stream?
>>>>>>
>>>>>> Up to 10 sec looks quite the correct number, it seems it gets freed
>>>>>> arround
>>>>>> this time indeed.
>>>>>>
>>>>>> Regards.
>>>>>>
>>>>>> 2009/6/23 Raghu Angadi <rangadi@yahoo-inc.com>
>>>>>>
>>>>>>  To be more accurate, once you have HADOOP-4346,
>>>>>>
>>>>>>> fds for epoll and pipes = 3 * threads blocked on Hadoop I/O
>>>>>>>
>>>>>>> Unless you have hundreds of threads at a time, you should not see
>>>>>>> hundreds
>>>>>>> of these. These fds stay up to 10sec even after the
>>>>>>> threads exit.
>>>>>>>
>>>>>>> I am a bit confused about your exact situation. Please check number of
>>>>>>> threads if you still facing the problem.
>>>>>>>
>>>>>>> Raghu.
>>>>>>>
>>>>>>>
>>>>>>> Raghu Angadi wrote:
>>>>>>>
>>>>>>>  since you have HADOOP-4346, you should not have excessive epoll/pipe
>>>>>>>
>>>>>>>> fds
>>>>>>>> open. First of all do you still have the problem? If yes, how many
>>>>>>>> hadoop
>>>>>>>> streams do you have at a time?
>>>>>>>>
>>>>>>>> System.gc() won't help if you have HADOOP-4346.
>>>>>>>>
>>>>>>>> Ragu.
>>>>>>>>
>>>>>>>>  Thanks for your opinion!
>>>>>>>>
>>>>>>>>  2009/6/22 Stas Oskin <stas.oskin@gmail.com>
>>>>>>>>>  Ok, seems this issue is already patched in the Hadoop distro I'm
>>>>>>>>> using
>>>>>>>>>
>>>>>>>>>  (Cloudera).
>>>>>>>>>> Any idea if I still should call GC manually/periodically to clean
>>>>>>>>>> out
>>>>>>>>>> all
>>>>>>>>>> the stale pipes / epolls?
>>>>>>>>>>
>>>>>>>>>> 2009/6/22 Steve Loughran <stevel@apache.org>
>>>>>>>>>>
>>>>>>>>>>  Stas Oskin wrote:
>>>>>>>>>>
>>>>>>>>>>   Hi.
>>>>>>>>>>>  So what would be the recommended approach to pre-0.20.x series?
>>>>>>>>>>>
>>>>>>>>>>>> To insure each file is used only by one thread, and then it safe
>>>>>>>>>>>> to
>>>>>>>>>>>> close
>>>>>>>>>>>> the handle in that thread?
>>>>>>>>>>>>
>>>>>>>>>>>> Regards.
>>>>>>>>>>>>
>>>>>>>>>>>>  good question -I'm not sure. For anythiong you get with
>>>>>>>>>>>>
>>>>>>>>>>>>  FileSystem.get(),
>>>>>>>>>>> its now dangerous to close, so try just setting the reference to
>>>>>>>>>>> null
>>>>>>>>>>> and
>>>>>>>>>>> hoping that GC will do the finalize() when needed
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
> 


From common-user-return-16526-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 20:28:29 2009
Return-Path: <common-user-return-16526-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 87271 invoked from network); 3 Aug 2009 20:28:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 20:28:29 -0000
Received: (qmail 31400 invoked by uid 500); 3 Aug 2009 20:28:31 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 31303 invoked by uid 500); 3 Aug 2009 20:28:31 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 31293 invoked by uid 99); 3 Aug 2009 20:28:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 20:28:31 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of erikholstad@gmail.com designates 74.125.92.24 as permitted sender)
Received: from [74.125.92.24] (HELO qw-out-2122.google.com) (74.125.92.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 20:28:22 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1727081qwh.35
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 13:28:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=992Sy2+S5vSaYX+PcFbWOr6+P9qVvUEnoTyD2ncidhQ=;
        b=sHaKh22jT6cvBrmDlGukxWSUADpITT6XB5M6iumnXpFzDWdB8chXqoq4st4LEq+8TV
         CfeGA2oxLkDiBLi+JYo3pV0P3jeNLcZQ7T3wUc0v5WpP36lST5iizZjeexh6nDMlwH1Q
         H2zNf5gmBnybCiyuziWlvUPUbDknNwrvuBwtM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=dqraRxZf/ShImplCkgD18+SOKMRC2gKPus5JrOMVrriP4mTY2b9zaoAxxQLxh5y7mm
         DzR966nSfPY2vpbZ7WDTmA2bOoTApZBt5mPp3oZsr7AEMmMTwQEGDQeLXRcJe9SHZmEZ
         +vvze+k7rVICy7nbnskvtiq4MCs1VnyRjye1g=
MIME-Version: 1.0
Received: by 10.224.45.212 with SMTP id g20mr4329829qaf.262.1249331279904; 
	Mon, 03 Aug 2009 13:27:59 -0700 (PDT)
Date: Mon, 3 Aug 2009 13:27:59 -0700
Message-ID: <74f4d40b0908031327w10c0e90es957bee0a84e0047a@mail.gmail.com>
Subject: Problem getting scheduler to work.
From: Erik Holstad <erikholstad@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175cb62e2540100470429b5f
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175cb62e2540100470429b5f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi!
I'm testing out the FairScheduler and I'm getting it to start and the Pools
that I've defined in the pools.xml file shows up and everything.
But when trying to submit a job, I don't really know where to put the name
of the pool to use for the job. All the examples that I've seen are
using JobConf and I'm currently on 0.20. I tried to put the name on the
Configuration like:

conf.set("mapred.job.queue.name", "fast");
but just getting

org.apache.hadoop.ipc.RemoteException: java.io.IOException: Queue "fast"
does not exist

So, how and where to I set the pool to use for the individual jobs?
Erik

--0015175cb62e2540100470429b5f--

From common-user-return-16527-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 20:52:34 2009
Return-Path: <common-user-return-16527-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 95161 invoked from network); 3 Aug 2009 20:52:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 20:52:34 -0000
Received: (qmail 57756 invoked by uid 500); 3 Aug 2009 20:52:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 57670 invoked by uid 500); 3 Aug 2009 20:52:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 57660 invoked by uid 99); 3 Aug 2009 20:52:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 20:52:37 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 20:52:28 +0000
Received: by fxm25 with SMTP id 25so2878828fxm.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 13:52:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=V56UwikPLWKlZt0ERVqNfD+eQ+iWMsot0IDPieEzdUE=;
        b=S8vWSL0OLQLjP/1pRpdqmEeM4KXSV13kgjjqE1LatI2/ZewmTnn4n7XYpG2BS+8f25
         TKNEweysE7OdlMwvVwC5EoZu9ayK5z2WI/JOjE2MpmIy6KyJH+KuurkA2THzKGu+0Hgc
         +cYdD8CcYGlkCjEIlvj9H9xIFfFy16BoB22X8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=c9xLBOPCahlExHefOSG3mLHlCbz8y9+BCJX/Jqgs/2/azI28kJ8SAJIiUJ1NW01kUg
         rClCpyeJRQxDEnaVWNGeXOwEWtMIroUS1SQlxvDs0VhsePmLzmOVJeUBm6MILMqew0mu
         eKlMgPXKkbIaByMO1X3Iyt9kbzklRptI/PcGU=
MIME-Version: 1.0
Received: by 10.223.115.201 with SMTP id j9mr667975faq.105.1249332726132; Mon, 
	03 Aug 2009 13:52:06 -0700 (PDT)
In-Reply-To: <4A7739FE.5030106@yahoo-inc.com>
References: <77938bc20906210306q152c8681g2af43dd34b3f6ed0@mail.gmail.com>
	 <4A40F7C6.3070905@yahoo-inc.com> <4A412D22.9050000@yahoo-inc.com>
	 <77938bc20906231327r5b8e779i93e2b45de9732780@mail.gmail.com>
	 <4A414034.2050405@yahoo-inc.com>
	 <77938bc20906231427u6f0b4db2p9905c626962f4076@mail.gmail.com>
	 <77938bc20908020430i17276096mc5f597bd52f2c272@mail.gmail.com>
	 <4A770682.6000405@yahoo-inc.com>
	 <77938bc20908031027s417615c9v247f6b2e7e5446d7@mail.gmail.com>
	 <4A7739FE.5030106@yahoo-inc.com>
Date: Mon, 3 Aug 2009 23:52:05 +0300
Message-ID: <77938bc20908031352y51779745h2ad40ffbe0f3c737@mail.gmail.com>
Subject: Re: "Too many open files" error, which gets resolved after some time
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c5c18958ee72047042f173
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5c18958ee72047042f173
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Raghu.

Thanks for the clarification and for explaining the potential issue.

It is not just the fds, the applications that hit fd limits hit thread
> limits as well. Obviously Hadoop can not sustain this as the range of
> applications increases. It will be fixed one way or the other.
>

Can you please clarify the thread limit matter?

AFAIK it only happens if the allocated stack too large, and we speak about
thousands of threads ( a possible solution described here:
http://candrews.integralblue.com/2009/01/preventing-outofmemoryerror-native-thread/
).

So how it's tied to fd's?

Thanks.

--001636c5c18958ee72047042f173--

From common-user-return-16528-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 23:15:22 2009
Return-Path: <common-user-return-16528-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70733 invoked from network); 3 Aug 2009 23:15:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 23:15:21 -0000
Received: (qmail 56653 invoked by uid 500); 3 Aug 2009 23:15:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 56521 invoked by uid 500); 3 Aug 2009 23:15:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 56484 invoked by uid 99); 3 Aug 2009 23:15:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 23:15:20 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [216.86.168.183] (HELO mxout-08.mxes.net) (216.86.168.183)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 23:15:10 +0000
Received: from [192.168.0.197] (unknown [208.100.138.231])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by smtp.mxes.net (Postfix) with ESMTPSA id 9E0D1509DB;
	Mon,  3 Aug 2009 19:14:48 -0400 (EDT)
Message-Id: <4936BB88-7FD2-4186-B806-6EC372F99E05@wensel.net>
From: Chris K Wensel <chris@wensel.net>
To: common-user@hadoop.apache.org,
 hbase-user@hadoop.apache.org,
 Hadoop Core User List <core-user@hadoop.apache.org>,
 katta-developer@lists.sourceforge.net,
 cascading-user <cascading-user@googlegroups.com>,
 zookeeper-user@hadoop.apache.org
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v935.3)
Subject: Hadoop BootCamp in Berlin Aug 27, 28th (reminder)
Date: Mon, 3 Aug 2009 16:14:26 -0700
X-Mailer: Apple Mail (2.935.3)
X-Virus-Checked: Checked by ClamAV on apache.org


Hi all,

A quick reminder that Scale Unlimited will run a 2 day Hadoop BootCamp  
in Berlin on August 27th and 28th.

This 2 day course is for managers and developers who want to quickly  
become experienced with Hadoop and related technologies.

The BootCamp provides training in MapReduce Theory, Hadoop  
Architecture, configuration, and API's through our hands-on labs.

All our courses are taught by practitioners with years of Hadoop and  
related experience in large data architectures.

** Professional independent consultants may take this course for free,  
please email info@scaleunlimited.com to inquire.
http://www.scaleunlimited.com/courses/programs

Detailed information and registration information is at:

   http://www.scaleunlimited.com/courses/berlin08 (german) or
   http://www.scaleunlimited.com/courses/hadoop-boot-camp-berlin-en  
(english)

cheers,
chris

P.S Apologies for the cross posting.
P.P.S. Please spread the word!

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Hadoop training and consulting
http://www.scaleunlimited.com

From common-user-return-16529-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 23:15:22 2009
Return-Path: <common-user-return-16529-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70768 invoked from network); 3 Aug 2009 23:15:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 23:15:21 -0000
Received: (qmail 56708 invoked by uid 500); 3 Aug 2009 23:15:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 56537 invoked by uid 500); 3 Aug 2009 23:15:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 56494 invoked by uid 500); 3 Aug 2009 23:15:21 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 56484 invoked by uid 99); 3 Aug 2009 23:15:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 23:15:20 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [216.86.168.183] (HELO mxout-08.mxes.net) (216.86.168.183)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 23:15:10 +0000
Received: from [192.168.0.197] (unknown [208.100.138.231])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by smtp.mxes.net (Postfix) with ESMTPSA id 9E0D1509DB;
	Mon,  3 Aug 2009 19:14:48 -0400 (EDT)
Message-Id: <4936BB88-7FD2-4186-B806-6EC372F99E05@wensel.net>
From: Chris K Wensel <chris@wensel.net>
To: common-user@hadoop.apache.org,
 hbase-user@hadoop.apache.org,
 Hadoop Core User List <core-user@hadoop.apache.org>,
 katta-developer@lists.sourceforge.net,
 cascading-user <cascading-user@googlegroups.com>,
 zookeeper-user@hadoop.apache.org
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v935.3)
Subject: Hadoop BootCamp in Berlin Aug 27, 28th (reminder)
Date: Mon, 3 Aug 2009 16:14:26 -0700
X-Mailer: Apple Mail (2.935.3)
X-Virus-Checked: Checked by ClamAV on apache.org


Hi all,

A quick reminder that Scale Unlimited will run a 2 day Hadoop BootCamp  
in Berlin on August 27th and 28th.

This 2 day course is for managers and developers who want to quickly  
become experienced with Hadoop and related technologies.

The BootCamp provides training in MapReduce Theory, Hadoop  
Architecture, configuration, and API's through our hands-on labs.

All our courses are taught by practitioners with years of Hadoop and  
related experience in large data architectures.

** Professional independent consultants may take this course for free,  
please email info@scaleunlimited.com to inquire.
http://www.scaleunlimited.com/courses/programs

Detailed information and registration information is at:

   http://www.scaleunlimited.com/courses/berlin08 (german) or
   http://www.scaleunlimited.com/courses/hadoop-boot-camp-berlin-en  
(english)

cheers,
chris

P.S Apologies for the cross posting.
P.P.S. Please spread the word!

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Hadoop training and consulting
http://www.scaleunlimited.com

From common-user-return-16530-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 03 23:57:55 2009
Return-Path: <common-user-return-16530-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 83112 invoked from network); 3 Aug 2009 23:57:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 3 Aug 2009 23:57:54 -0000
Received: (qmail 12653 invoked by uid 500); 3 Aug 2009 23:57:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 12593 invoked by uid 500); 3 Aug 2009 23:57:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 12583 invoked by uid 99); 3 Aug 2009 23:57:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 23:57:57 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of onur.aktas@live.com designates 65.54.246.221 as permitted sender)
Received: from [65.54.246.221] (HELO bay0-omc3-s21.bay0.hotmail.com) (65.54.246.221)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 03 Aug 2009 23:57:43 +0000
Received: from BAY107-W8 ([64.4.51.108]) by bay0-omc3-s21.bay0.hotmail.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Mon, 3 Aug 2009 16:57:21 -0700
Message-ID: <BAY107-W82FB176A70E2FBD18D043E70F0@phx.gbl>
Content-Type: multipart/alternative;
	boundary="_a1bdd0c6-b56a-4e9f-a20c-a88bee1df063_"
X-Originating-IP: [88.238.30.119]
From: Onur AKTAS <onur.aktas@live.com>
To: <common-user@hadoop.apache.org>
Subject: Problem with starting Hadoop in Pseudo Distributed Mode
Date: Tue, 4 Aug 2009 02:57:23 +0300
Importance: Normal
MIME-Version: 1.0
X-OriginalArrivalTime: 03 Aug 2009 23:57:21.0723 (UTC) FILETIME=[242058B0:01CA1496]
X-Virus-Checked: Checked by ClamAV on apache.org

--_a1bdd0c6-b56a-4e9f-a20c-a88bee1df063_
Content-Type: text/plain; charset="windows-1254"
Content-Transfer-Encoding: 8bit


Hi,

I'm having troubles with running Hadoop in RHEL 5, I did everything as documented in: 
http://hadoop.apache.org/common/docs/r0.20.0/quickstart.html

And configured:
conf/core-site.xml, conf/hdfs-site.xml, 
conf/mapred-site.xml.

Connected to "localhost" with ssh (did passphrase stuff etc.), then I did the following:

$ bin/hadoop namenode -format
$ bin/start-all.sh 
starting namenode, logging to /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-namenode-localhost.localdomain.out
localhost: starting datanode, logging to /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-datanode-localhost.localdomain.out
localhost: starting secondarynamenode, logging to /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-secondarynamenode-localhost.localdomain.out
starting jobtracker, logging to /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-jobtracker-localhost.localdomain.out
localhost: starting tasktracker, logging to /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-tasktracker-localhost.localdomain.out

Everything seems ok, but when I check the Hadoop Logs I see many errors. (and they all cause HBase connection problems.)
How can I solve this problem? Here are the Logs

 hadoop-oracle-datanode-localhost.localdomain.log:
2009-08-04 02:54:28,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = localhost.localdomain/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.0
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
************************************************************/
2009-08-04 02:54:29,562 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Incompatible namespaceIDs in /tmp/hadoop-oracle/dfs/data: namenode namespaceID = 36527197; datanode namespaceID = 2138759529
    at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:233)
    at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:148)
    at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:298)
    at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:216)
    at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1283)
    at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1238)
    at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1246)
    at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1368)

2009-08-04 02:54:29,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at localhost.localdomain/127.0.0.1
************************************************************/
------------------------------------------------------------------------------------------
hadoop-oracle-namenode-localhost.localdomain.log
2009-08-04 02:54:26,987 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = localhost.localdomain/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.0
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
************************************************************/
2009-08-04 02:54:27,116 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=9000
2009-08-04 02:54:27,174 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost.localdomain/127.0.0.1:9000
2009-08-04 02:54:27,179 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2009-08-04 02:54:27,180 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2009-08-04 02:54:27,278 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=oracle,oinstall,root,dba,oper,asmadmin
2009-08-04 02:54:27,278 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2009-08-04 02:54:27,278 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2009-08-04 02:54:27,294 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2009-08-04 02:54:27,297 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2009-08-04 02:54:27,341 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 8
2009-08-04 02:54:27,348 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 2
2009-08-04 02:54:27,351 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 923 loaded in 0 seconds.
2009-08-04 02:54:27,351 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-oracle/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2009-08-04 02:54:27,435 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 923 saved in 0 seconds.
2009-08-04 02:54:27,495 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 262 msecs
2009-08-04 02:54:27,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2009-08-04 02:54:27,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2009-08-04 02:54:27,696 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2009-08-04 02:54:27,775 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2009-08-04 02:54:27,775 INFO org.mortbay.log: jetty-6.1.14
2009-08-04 02:54:28,277 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2009-08-04 02:54:28,278 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2009-08-04 02:54:28,278 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2009-08-04 02:54:28,279 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000: starting
2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000: starting
2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000: starting
2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000: starting
2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000: starting
2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000: starting
2009-08-04 02:54:28,328 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000: starting
2009-08-04 02:54:28,361 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000: starting
2009-08-04 02:54:28,362 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000: starting
2009-08-04 02:54:28,366 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000: starting
2009-08-04 02:54:38,433 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1    cmd=listStatus    src=/tmp/hadoop-oracle/mapred/system    dst=null    perm=null
2009-08-04 02:54:38,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1    cmd=delete    src=/tmp/hadoop-oracle/mapred/system    dst=null    perm=null
2009-08-04 02:54:38,773 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1    cmd=mkdirs    src=/tmp/hadoop-oracle/mapred/system    dst=null    perm=oracle:supergroup:rwxr-xr-x
2009-08-04 02:54:38,785 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1    cmd=setPermission    src=/tmp/hadoop-oracle/mapred/system    dst=null    perm=oracle:supergroup:rwx-wx-wx
2009-08-04 02:54:38,862 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1    cmd=create    src=/tmp/hadoop-oracle/mapred/system/jobtracker.info    dst=null    perm=oracle:supergroup:rw-r--r--
2009-08-04 02:54:38,900 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1    cmd=setPermission    src=/tmp/hadoop-oracle/mapred/system/jobtracker.info    dst=null    perm=oracle:supergroup:rw-------
2009-08-04 02:54:38,955 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error: java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
    at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:396)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
2009-08-04 02:54:39,548 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error: java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
    at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:396)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
2009-08-04 02:54:40,359 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error: java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
    at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:396)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
2009-08-04 02:54:41,969 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error: java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
    at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:396)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
2009-08-04 02:54:45,180 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error: java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
    at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:396)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)



_________________________________________________________________
Windows Live ile fotoraflarnz organize edebilir, dzenleyebilir ve paylaabilirsiniz.
http://www.microsoft.com/turkiye/windows/windowslive/products/photo-gallery-edit.aspx
--_a1bdd0c6-b56a-4e9f-a20c-a88bee1df063_--

From common-user-return-16531-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 00:03:43 2009
Return-Path: <common-user-return-16531-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 84691 invoked from network); 4 Aug 2009 00:03:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 00:03:43 -0000
Received: (qmail 17503 invoked by uid 500); 4 Aug 2009 00:03:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 17393 invoked by uid 500); 4 Aug 2009 00:03:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 17383 invoked by uid 99); 4 Aug 2009 00:03:45 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 00:03:45 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of amansk@gmail.com designates 209.85.211.202 as permitted sender)
Received: from [209.85.211.202] (HELO mail-yw0-f202.google.com) (209.85.211.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 00:03:32 +0000
Received: by ywh40 with SMTP id 40so4384137ywh.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 17:03:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=2z5fcG4wmmrhBsz13R+pnk2IkwGiCK3rT8Qx+wEx2/U=;
        b=cJqzAMPLr/Lsuo6Ov0OoKqLaqLC50HEBbhUxr18mYsS6t9HU2Z9OJMdayL36jbCHuN
         /EbsentDem1G3tW16xPBYikCEIQpuGoVJEyneBRpk18fD6am5Hd3QOcVSvPWYfi7Uf9F
         m6i6WFeIs1axahj5iOFGuxJX56MqzNy9a3a7I=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=W1ps/Qhyf6003qrvYqrjnOdy2iMepVmIH1HjkvxrtY60BYSg1IGCF7Pm/njj1sC5xE
         Y+QjmYK4L8JeATtQmjitB+nqDnkFEU5XRvKbMmGYfIZKqWKlcy05KCvMisCJ550QbFn5
         zPChNTEHK22uYtZeZfynF0O74ypvWgd8vv94A=
MIME-Version: 1.0
Received: by 10.100.151.5 with SMTP id y5mr7898616and.176.1249344190177; Mon, 
	03 Aug 2009 17:03:10 -0700 (PDT)
In-Reply-To: <BAY107-W82FB176A70E2FBD18D043E70F0@phx.gbl>
References: <BAY107-W82FB176A70E2FBD18D043E70F0@phx.gbl>
From: Amandeep Khurana <amansk@gmail.com>
Date: Mon, 3 Aug 2009 17:02:50 -0700
Message-ID: <35a22e220908031702n629c3ac0l22a25bd140d571ff@mail.gmail.com>
Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e644cf72a861d80470459cc3
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e644cf72a861d80470459cc3
Content-Type: text/plain; charset=ISO-8859-9
Content-Transfer-Encoding: quoted-printable

I'm assuming that you have no data in HDFS since it never came up... So, go
ahead and clean up the directory where you are storing the datanode's data
and the namenode's metadata. After that format the namenode and restart
hadoop.


2009/8/3 Onur AKTAS <onur.aktas@live.com>

>
> Hi,
>
> I'm having troubles with running Hadoop in RHEL 5, I did everything as
> documented in:
> http://hadoop.apache.org/common/docs/r0.20.0/quickstart.html
>
> And configured:
> conf/core-site.xml, conf/hdfs-site.xml,
> conf/mapred-site.xml.
>
> Connected to "localhost" with ssh (did passphrase stuff etc.), then I did
> the following:
>
> $ bin/hadoop namenode -format
> $ bin/start-all.sh
> starting namenode, logging to
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-namenode-localhost.local=
domain.out
> localhost: starting datanode, logging to
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-datanode-localhost.local=
domain.out
> localhost: starting secondarynamenode, logging to
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-secondarynamenode-localh=
ost.localdomain.out
> starting jobtracker, logging to
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-jobtracker-localhost.loc=
aldomain.out
> localhost: starting tasktracker, logging to
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-tasktracker-localhost.lo=
caldomain.out
>
> Everything seems ok, but when I check the Hadoop Logs I see many errors.
> (and they all cause HBase connection problems.)
> How can I solve this problem? Here are the Logs
>
>  hadoop-oracle-datanode-localhost.localdomain.log:
> 2009-08-04 02:54:28,971 INFO
> org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
> /************************************************************
> STARTUP_MSG: Starting DataNode
> STARTUP_MSG:   host =3D localhost.localdomain/127.0.0.1
> STARTUP_MSG:   args =3D []
> STARTUP_MSG:   version =3D 0.20.0
> STARTUP_MSG:   build =3D
> https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r
> 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> ************************************************************/
> 2009-08-04 02:54:29,562 ERROR
> org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException:
> Incompatible namespaceIDs in /tmp/hadoop-oracle/dfs/data: namenode
> namespaceID =3D 36527197; datanode namespaceID =3D 2138759529
>    at
> org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStora=
ge.java:233)
>    at
> org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(=
DataStorage.java:148)
>    at
> org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.ja=
va:298)
>    at
> org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:216)
>    at
> org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.jav=
a:1283)
>    at
> org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataN=
ode.java:1238)
>    at
> org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.j=
ava:1246)
>    at
> org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1368)
>
> 2009-08-04 02:54:29,563 INFO
> org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
> /************************************************************
> SHUTDOWN_MSG: Shutting down DataNode at localhost.localdomain/127.0.0.1
> ************************************************************/
>
> -------------------------------------------------------------------------=
-----------------
> hadoop-oracle-namenode-localhost.localdomain.log
> 2009-08-04 02:54:26,987 INFO
> org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG:
> /************************************************************
> STARTUP_MSG: Starting NameNode
> STARTUP_MSG:   host =3D localhost.localdomain/127.0.0.1
> STARTUP_MSG:   args =3D []
> STARTUP_MSG:   version =3D 0.20.0
> STARTUP_MSG:   build =3D
> https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r
> 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> ************************************************************/
> 2009-08-04 02:54:27,116 INFO org.apache.hadoop.ipc.metrics.RpcMetrics:
> Initializing RPC Metrics with hostName=3DNameNode, port=3D9000
> 2009-08-04 02:54:27,174 INFO
> org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at:
> localhost.localdomain/127.0.0.1:9000
> 2009-08-04 02:54:27,179 INFO org.apache.hadoop.metrics.jvm.JvmMetrics:
> Initializing JVM Metrics with processName=3DNameNode, sessionId=3Dnull
> 2009-08-04 02:54:27,180 INFO
> org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializ=
ing
> NameNodeMeterics using context
> object:org.apache.hadoop.metrics.spi.NullContext
> 2009-08-04 02:54:27,278 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> fsOwner=3Doracle,oinstall,root,dba,oper,asmadmin
> 2009-08-04 02:54:27,278 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=3Dsupergr=
oup
> 2009-08-04 02:54:27,278 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> isPermissionEnabled=3Dtrue
> 2009-08-04 02:54:27,294 INFO
> org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics:
> Initializing FSNamesystemMetrics using context
> object:org.apache.hadoop.metrics.spi.NullContext
> 2009-08-04 02:54:27,297 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered
> FSNamesystemStatusMBean
> 2009-08-04 02:54:27,341 INFO org.apache.hadoop.hdfs.server.common.Storage=
:
> Number of files =3D 8
> 2009-08-04 02:54:27,348 INFO org.apache.hadoop.hdfs.server.common.Storage=
:
> Number of files under construction =3D 2
> 2009-08-04 02:54:27,351 INFO org.apache.hadoop.hdfs.server.common.Storage=
:
> Image file of size 923 loaded in 0 seconds.
> 2009-08-04 02:54:27,351 INFO org.apache.hadoop.hdfs.server.common.Storage=
:
> Edits file /tmp/hadoop-oracle/dfs/name/current/edits of size 4 edits # 0
> loaded in 0 seconds.
> 2009-08-04 02:54:27,435 INFO org.apache.hadoop.hdfs.server.common.Storage=
:
> Image file of size 923 saved in 0 seconds.
> 2009-08-04 02:54:27,495 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading
> FSImage in 262 msecs
> 2009-08-04 02:54:27,496 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of bloc=
ks
> =3D 0
> 2009-08-04 02:54:27,496 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid
> blocks =3D 0
> 2009-08-04 02:54:27,497 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> under-replicated blocks =3D 0
> 2009-08-04 02:54:27,497 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
>  over-replicated blocks =3D 0
> 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE*
> Leaving safe mode after 0 secs.
> 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE*
> Network topology has 0 racks and 0 datanodes
> 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE*
> UnderReplicatedBlocks has 0 blocks
> 2009-08-04 02:54:27,696 INFO org.mortbay.log: Logging to
> org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via
> org.mortbay.log.Slf4jLog
> 2009-08-04 02:54:27,775 INFO org.apache.hadoop.http.HttpServer: Jetty bou=
nd
> to port 50070
> 2009-08-04 02:54:27,775 INFO org.mortbay.log: jetty-6.1.14
> 2009-08-04 02:54:28,277 INFO org.mortbay.log: Started
> SelectChannelConnector@0.0.0.0:50070
> 2009-08-04 02:54:28,278 INFO
> org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at:
> 0.0.0.0:50070
> 2009-08-04 02:54:28,278 INFO org.apache.hadoop.ipc.Server: IPC Server
> Responder: starting
> 2009-08-04 02:54:28,279 INFO org.apache.hadoop.ipc.Server: IPC Server
> listener on 9000: starting
> 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 0 on 9000: starting
> 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 1 on 9000: starting
> 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 2 on 9000: starting
> 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 3 on 9000: starting
> 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 4 on 9000: starting
> 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 5 on 9000: starting
> 2009-08-04 02:54:28,328 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 6 on 9000: starting
> 2009-08-04 02:54:28,361 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 7 on 9000: starting
> 2009-08-04 02:54:28,362 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 8 on 9000: starting
> 2009-08-04 02:54:28,366 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 9 on 9000: starting
> 2009-08-04 02:54:38,433 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
>  cmd=3DlistStatus    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dnull
>  perm=3Dnull
> 2009-08-04 02:54:38,755 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1    cmd=3D=
delete
>    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dnull    perm=3Dnull
> 2009-08-04 02:54:38,773 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1    cmd=3D=
mkdirs
>    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dnull
>  perm=3Doracle:supergroup:rwxr-xr-x
> 2009-08-04 02:54:38,785 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
>  cmd=3DsetPermission    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dn=
ull
>  perm=3Doracle:supergroup:rwx-wx-wx
> 2009-08-04 02:54:38,862 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1    cmd=3D=
create
>    src=3D/tmp/hadoop-oracle/mapred/system/jobtracker.info    dst=3Dnull
>  perm=3Doracle:supergroup:rw-r--r--
> 2009-08-04 02:54:38,900 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
>  cmd=3DsetPermission    src=3D/tmp/hadoop-oracle/mapred/system/jobtracker=
.info   dst=3Dnull    perm=3Doracle:supergroup:rw-------
> 2009-08-04 02:54:38,955 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 4 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.inf=
ocould only be replicated to 0 nodes, instead of 1
> java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.inf=
ocould only be replicated to 0 nodes, instead of 1
>    at
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
>    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>    at
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
>    at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
>    at java.lang.reflect.Method.invoke(Method.java:597)
>    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
>    at java.security.AccessController.doPrivileged(Native Method)
>    at javax.security.auth.Subject.doAs(Subject.java:396)
>    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> 2009-08-04 02:54:39,548 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 5 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.inf=
ocould only be replicated to 0 nodes, instead of 1
> java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.inf=
ocould only be replicated to 0 nodes, instead of 1
>    at
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
>    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>    at
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
>    at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
>    at java.lang.reflect.Method.invoke(Method.java:597)
>    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
>    at java.security.AccessController.doPrivileged(Native Method)
>    at javax.security.auth.Subject.doAs(Subject.java:396)
>    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> 2009-08-04 02:54:40,359 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 6 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.inf=
ocould only be replicated to 0 nodes, instead of 1
> java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.inf=
ocould only be replicated to 0 nodes, instead of 1
>    at
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
>    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>    at
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
>    at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
>    at java.lang.reflect.Method.invoke(Method.java:597)
>    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
>    at java.security.AccessController.doPrivileged(Native Method)
>    at javax.security.auth.Subject.doAs(Subject.java:396)
>    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> 2009-08-04 02:54:41,969 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 7 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.inf=
ocould only be replicated to 0 nodes, instead of 1
> java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.inf=
ocould only be replicated to 0 nodes, instead of 1
>    at
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
>    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>    at
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
>    at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
>    at java.lang.reflect.Method.invoke(Method.java:597)
>    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
>    at java.security.AccessController.doPrivileged(Native Method)
>    at javax.security.auth.Subject.doAs(Subject.java:396)
>    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> 2009-08-04 02:54:45,180 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 8 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.inf=
ocould only be replicated to 0 nodes, instead of 1
> java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.inf=
ocould only be replicated to 0 nodes, instead of 1
>    at
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
>    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>    at
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
>    at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
>    at java.lang.reflect.Method.invoke(Method.java:597)
>    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
>    at java.security.AccessController.doPrivileged(Native Method)
>    at javax.security.auth.Subject.doAs(Subject.java:396)
>    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
>
>
>
> _________________________________________________________________
> Windows Live ile foto=F0raflar=FDn=FDz=FD organize edebilir, d=FCzenleyeb=
ilir ve
> payla=FEabilirsiniz.
>
> http://www.microsoft.com/turkiye/windows/windowslive/products/photo-galle=
ry-edit.aspx

--0016e644cf72a861d80470459cc3--

From common-user-return-16532-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 00:27:43 2009
Return-Path: <common-user-return-16532-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 97731 invoked from network); 4 Aug 2009 00:27:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 00:27:43 -0000
Received: (qmail 47948 invoked by uid 500); 4 Aug 2009 00:27:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 47864 invoked by uid 500); 4 Aug 2009 00:27:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 47854 invoked by uid 99); 4 Aug 2009 00:27:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 00:27:46 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of onur.aktas@live.com designates 65.54.246.211 as permitted sender)
Received: from [65.54.246.211] (HELO bay0-omc3-s11.bay0.hotmail.com) (65.54.246.211)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 00:27:32 +0000
Received: from BAY107-W54 ([64.4.51.154]) by bay0-omc3-s11.bay0.hotmail.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Mon, 3 Aug 2009 17:27:10 -0700
Message-ID: <BAY107-W5420D81B2F5CFD1AE5D9F6E70C0@phx.gbl>
Content-Type: multipart/alternative;
	boundary="_6cf336b5-6242-40a9-8849-95254ea6d7e2_"
X-Originating-IP: [88.238.30.119]
From: Onur AKTAS <onur.aktas@live.com>
To: <common-user@hadoop.apache.org>
Subject: RE: Problem with starting Hadoop in Pseudo Distributed Mode
Date: Tue, 4 Aug 2009 03:27:10 +0300
Importance: Normal
In-Reply-To: <35a22e220908031702n629c3ac0l22a25bd140d571ff@mail.gmail.com>
References: <BAY107-W82FB176A70E2FBD18D043E70F0@phx.gbl>
 <35a22e220908031702n629c3ac0l22a25bd140d571ff@mail.gmail.com>
MIME-Version: 1.0
X-OriginalArrivalTime: 04 Aug 2009 00:27:10.0582 (UTC) FILETIME=[4E5E9160:01CA149A]
X-Virus-Checked: Checked by ClamAV on apache.org

--_6cf336b5-6242-40a9-8849-95254ea6d7e2_
Content-Type: text/plain; charset="windows-1254"
Content-Transfer-Encoding: 8bit


Is it the directory that Hadoop uses?

/tmp/hadoop-oracle
/tmp/hadoop-oracle/dfs/ 
/tmp/hadoop-oracle/mapred/

If yes, how can I change the directory to anywhere else? I do not want it to be kept in /tmp folder.

> From: amansk@gmail.com
> Date: Mon, 3 Aug 2009 17:02:50 -0700
> Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
> To: common-user@hadoop.apache.org
> 
> I'm assuming that you have no data in HDFS since it never came up... So, go
> ahead and clean up the directory where you are storing the datanode's data
> and the namenode's metadata. After that format the namenode and restart
> hadoop.
> 
> 
> 2009/8/3 Onur AKTAS <onur.aktas@live.com>
> 
> >
> > Hi,
> >
> > I'm having troubles with running Hadoop in RHEL 5, I did everything as
> > documented in:
> > http://hadoop.apache.org/common/docs/r0.20.0/quickstart.html
> >
> > And configured:
> > conf/core-site.xml, conf/hdfs-site.xml,
> > conf/mapred-site.xml.
> >
> > Connected to "localhost" with ssh (did passphrase stuff etc.), then I did
> > the following:
> >
> > $ bin/hadoop namenode -format
> > $ bin/start-all.sh
> > starting namenode, logging to
> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-namenode-localhost.localdomain.out
> > localhost: starting datanode, logging to
> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-datanode-localhost.localdomain.out
> > localhost: starting secondarynamenode, logging to
> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-secondarynamenode-localhost.localdomain.out
> > starting jobtracker, logging to
> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-jobtracker-localhost.localdomain.out
> > localhost: starting tasktracker, logging to
> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-tasktracker-localhost.localdomain.out
> >
> > Everything seems ok, but when I check the Hadoop Logs I see many errors.
> > (and they all cause HBase connection problems.)
> > How can I solve this problem? Here are the Logs
> >
> >  hadoop-oracle-datanode-localhost.localdomain.log:
> > 2009-08-04 02:54:28,971 INFO
> > org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
> > /************************************************************
> > STARTUP_MSG: Starting DataNode
> > STARTUP_MSG:   host = localhost.localdomain/127.0.0.1
> > STARTUP_MSG:   args = []
> > STARTUP_MSG:   version = 0.20.0
> > STARTUP_MSG:   build =
> > https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r
> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> > ************************************************************/
> > 2009-08-04 02:54:29,562 ERROR
> > org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException:
> > Incompatible namespaceIDs in /tmp/hadoop-oracle/dfs/data: namenode
> > namespaceID = 36527197; datanode namespaceID = 2138759529
> >    at
> > org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:233)
> >    at
> > org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:148)
> >    at
> > org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:298)
> >    at
> > org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:216)
> >    at
> > org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1283)
> >    at
> > org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1238)
> >    at
> > org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1246)
> >    at
> > org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1368)
> >
> > 2009-08-04 02:54:29,563 INFO
> > org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
> > /************************************************************
> > SHUTDOWN_MSG: Shutting down DataNode at localhost.localdomain/127.0.0.1
> > ************************************************************/
> >
> > ------------------------------------------------------------------------------------------
> > hadoop-oracle-namenode-localhost.localdomain.log
> > 2009-08-04 02:54:26,987 INFO
> > org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG:
> > /************************************************************
> > STARTUP_MSG: Starting NameNode
> > STARTUP_MSG:   host = localhost.localdomain/127.0.0.1
> > STARTUP_MSG:   args = []
> > STARTUP_MSG:   version = 0.20.0
> > STARTUP_MSG:   build =
> > https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r
> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> > ************************************************************/
> > 2009-08-04 02:54:27,116 INFO org.apache.hadoop.ipc.metrics.RpcMetrics:
> > Initializing RPC Metrics with hostName=NameNode, port=9000
> > 2009-08-04 02:54:27,174 INFO
> > org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at:
> > localhost.localdomain/127.0.0.1:9000
> > 2009-08-04 02:54:27,179 INFO org.apache.hadoop.metrics.jvm.JvmMetrics:
> > Initializing JVM Metrics with processName=NameNode, sessionId=null
> > 2009-08-04 02:54:27,180 INFO
> > org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing
> > NameNodeMeterics using context
> > object:org.apache.hadoop.metrics.spi.NullContext
> > 2009-08-04 02:54:27,278 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > fsOwner=oracle,oinstall,root,dba,oper,asmadmin
> > 2009-08-04 02:54:27,278 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
> > 2009-08-04 02:54:27,278 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > isPermissionEnabled=true
> > 2009-08-04 02:54:27,294 INFO
> > org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics:
> > Initializing FSNamesystemMetrics using context
> > object:org.apache.hadoop.metrics.spi.NullContext
> > 2009-08-04 02:54:27,297 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered
> > FSNamesystemStatusMBean
> > 2009-08-04 02:54:27,341 INFO org.apache.hadoop.hdfs.server.common.Storage:
> > Number of files = 8
> > 2009-08-04 02:54:27,348 INFO org.apache.hadoop.hdfs.server.common.Storage:
> > Number of files under construction = 2
> > 2009-08-04 02:54:27,351 INFO org.apache.hadoop.hdfs.server.common.Storage:
> > Image file of size 923 loaded in 0 seconds.
> > 2009-08-04 02:54:27,351 INFO org.apache.hadoop.hdfs.server.common.Storage:
> > Edits file /tmp/hadoop-oracle/dfs/name/current/edits of size 4 edits # 0
> > loaded in 0 seconds.
> > 2009-08-04 02:54:27,435 INFO org.apache.hadoop.hdfs.server.common.Storage:
> > Image file of size 923 saved in 0 seconds.
> > 2009-08-04 02:54:27,495 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading
> > FSImage in 262 msecs
> > 2009-08-04 02:54:27,496 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks
> > = 0
> > 2009-08-04 02:54:27,496 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid
> > blocks = 0
> > 2009-08-04 02:54:27,497 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> > under-replicated blocks = 0
> > 2009-08-04 02:54:27,497 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> >  over-replicated blocks = 0
> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE*
> > Leaving safe mode after 0 secs.
> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE*
> > Network topology has 0 racks and 0 datanodes
> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE*
> > UnderReplicatedBlocks has 0 blocks
> > 2009-08-04 02:54:27,696 INFO org.mortbay.log: Logging to
> > org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via
> > org.mortbay.log.Slf4jLog
> > 2009-08-04 02:54:27,775 INFO org.apache.hadoop.http.HttpServer: Jetty bound
> > to port 50070
> > 2009-08-04 02:54:27,775 INFO org.mortbay.log: jetty-6.1.14
> > 2009-08-04 02:54:28,277 INFO org.mortbay.log: Started
> > SelectChannelConnector@0.0.0.0:50070
> > 2009-08-04 02:54:28,278 INFO
> > org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at:
> > 0.0.0.0:50070
> > 2009-08-04 02:54:28,278 INFO org.apache.hadoop.ipc.Server: IPC Server
> > Responder: starting
> > 2009-08-04 02:54:28,279 INFO org.apache.hadoop.ipc.Server: IPC Server
> > listener on 9000: starting
> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 0 on 9000: starting
> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 1 on 9000: starting
> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 2 on 9000: starting
> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 3 on 9000: starting
> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 4 on 9000: starting
> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 5 on 9000: starting
> > 2009-08-04 02:54:28,328 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 6 on 9000: starting
> > 2009-08-04 02:54:28,361 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 7 on 9000: starting
> > 2009-08-04 02:54:28,362 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 8 on 9000: starting
> > 2009-08-04 02:54:28,366 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 9 on 9000: starting
> > 2009-08-04 02:54:38,433 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> >  cmd=listStatus    src=/tmp/hadoop-oracle/mapred/system    dst=null
> >  perm=null
> > 2009-08-04 02:54:38,755 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1    cmd=delete
> >    src=/tmp/hadoop-oracle/mapred/system    dst=null    perm=null
> > 2009-08-04 02:54:38,773 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1    cmd=mkdirs
> >    src=/tmp/hadoop-oracle/mapred/system    dst=null
> >  perm=oracle:supergroup:rwxr-xr-x
> > 2009-08-04 02:54:38,785 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> >  cmd=setPermission    src=/tmp/hadoop-oracle/mapred/system    dst=null
> >  perm=oracle:supergroup:rwx-wx-wx
> > 2009-08-04 02:54:38,862 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1    cmd=create
> >    src=/tmp/hadoop-oracle/mapred/system/jobtracker.info    dst=null
> >  perm=oracle:supergroup:rw-r--r--
> > 2009-08-04 02:54:38,900 INFO
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> >  cmd=setPermission    src=/tmp/hadoop-oracle/mapred/system/jobtracker.info   dst=null    perm=oracle:supergroup:rw-------
> > 2009-08-04 02:54:38,955 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 4 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> > java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated to 0 nodes, instead of 1
> > java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated to 0 nodes, instead of 1
> >    at
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >    at
> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >    at
> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >    at java.lang.reflect.Method.invoke(Method.java:597)
> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> >    at java.security.AccessController.doPrivileged(Native Method)
> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > 2009-08-04 02:54:39,548 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 5 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> > java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated to 0 nodes, instead of 1
> > java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated to 0 nodes, instead of 1
> >    at
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >    at
> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >    at
> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >    at java.lang.reflect.Method.invoke(Method.java:597)
> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> >    at java.security.AccessController.doPrivileged(Native Method)
> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > 2009-08-04 02:54:40,359 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 6 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> > java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated to 0 nodes, instead of 1
> > java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated to 0 nodes, instead of 1
> >    at
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >    at
> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >    at
> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >    at java.lang.reflect.Method.invoke(Method.java:597)
> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> >    at java.security.AccessController.doPrivileged(Native Method)
> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > 2009-08-04 02:54:41,969 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 7 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> > java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated to 0 nodes, instead of 1
> > java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated to 0 nodes, instead of 1
> >    at
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >    at
> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >    at
> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >    at java.lang.reflect.Method.invoke(Method.java:597)
> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> >    at java.security.AccessController.doPrivileged(Native Method)
> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > 2009-08-04 02:54:45,180 INFO org.apache.hadoop.ipc.Server: IPC Server
> > handler 8 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> > java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated to 0 nodes, instead of 1
> > java.io.IOException: File /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated to 0 nodes, instead of 1
> >    at
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >    at
> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >    at
> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >    at java.lang.reflect.Method.invoke(Method.java:597)
> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> >    at java.security.AccessController.doPrivileged(Native Method)
> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> >
> >
> >
> > _________________________________________________________________
> > Windows Live ile fotoraflarnz organize edebilir, dzenleyebilir ve
> > paylaabilirsiniz.
> >
> > http://www.microsoft.com/turkiye/windows/windowslive/products/photo-gallery-edit.aspx

_________________________________________________________________
Windows Live tm arkadalarnzla tek bir yerden iletiim kurmanza yardmc olur.
http://www.microsoft.com/turkiye/windows/windowslive/products/social-network-connector.aspx
--_6cf336b5-6242-40a9-8849-95254ea6d7e2_--

From common-user-return-16533-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 00:30:21 2009
Return-Path: <common-user-return-16533-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 98329 invoked from network); 4 Aug 2009 00:30:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 00:30:21 -0000
Received: (qmail 52683 invoked by uid 500); 4 Aug 2009 00:30:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52586 invoked by uid 500); 4 Aug 2009 00:30:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52576 invoked by uid 99); 4 Aug 2009 00:30:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 00:30:23 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of amansk@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 00:30:13 +0000
Received: by yxe15 with SMTP id 15so6126476yxe.5
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 17:29:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=O1KdGXtwydHk3WdgnqvUWgTwczAJWaSNXxUxw5U/odY=;
        b=e7eZk1POr20yOilavgxXklX5hs6Xc/5OdhSL7fMXEoQ9CcAuG/+ptu/5nA+4iSaYTs
         T+FxJ/ZqEq7Xe+SXl5gQuOtwtOU3GCSFtvYei73c9Vm0bE2FwX0Br6Q5YJMVGV9fXvvp
         /SQfcgikoa7xwhw7BqqZn7L1p6LsKK/uKv34Y=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=J/tN1oTdSq9pO7ofEfIIObJ9rha8PilWKAvIn9qXCUTpZ/k14C3GqTUPw7OH/ReD+d
         hOFgCpCX1XFMuYJbXs1E6Fen6aK4kLFQ4k5tCVn0GONku29vGdpSgEdj/Tk1n48fBInP
         537fxxrbvPm11isMO4r8PtDLFnodSrwdHWJlc=
MIME-Version: 1.0
Received: by 10.100.48.8 with SMTP id v8mr7861251anv.84.1249345792858; Mon, 03 
	Aug 2009 17:29:52 -0700 (PDT)
In-Reply-To: <BAY107-W5420D81B2F5CFD1AE5D9F6E70C0@phx.gbl>
References: <BAY107-W82FB176A70E2FBD18D043E70F0@phx.gbl>
	 <35a22e220908031702n629c3ac0l22a25bd140d571ff@mail.gmail.com>
	 <BAY107-W5420D81B2F5CFD1AE5D9F6E70C0@phx.gbl>
Date: Mon, 3 Aug 2009 17:29:52 -0700
Message-ID: <35a22e220908031729k3ffbab3ftf51dfe979bc147cb@mail.gmail.com>
Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
From: Amandeep Khurana <amansk@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-9
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Yes, you need to change these directories. The config is put in the
hadoop-site.xml. Or in this case, separately in the 3 xmls. See the
default xml for syntax and property name.

On 8/3/09, Onur AKTAS <onur.aktas@live.com> wrote:
>
> Is it the directory that Hadoop uses?
>
> /tmp/hadoop-oracle
> /tmp/hadoop-oracle/dfs/
> /tmp/hadoop-oracle/mapred/
>
> If yes, how can I change the directory to anywhere else? I do not want it=
 to
> be kept in /tmp folder.
>
>> From: amansk@gmail.com
>> Date: Mon, 3 Aug 2009 17:02:50 -0700
>> Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
>> To: common-user@hadoop.apache.org
>>
>> I'm assuming that you have no data in HDFS since it never came up... So,
>> go
>> ahead and clean up the directory where you are storing the datanode's da=
ta
>> and the namenode's metadata. After that format the namenode and restart
>> hadoop.
>>
>>
>> 2009/8/3 Onur AKTAS <onur.aktas@live.com>
>>
>> >
>> > Hi,
>> >
>> > I'm having troubles with running Hadoop in RHEL 5, I did everything as
>> > documented in:
>> > http://hadoop.apache.org/common/docs/r0.20.0/quickstart.html
>> >
>> > And configured:
>> > conf/core-site.xml, conf/hdfs-site.xml,
>> > conf/mapred-site.xml.
>> >
>> > Connected to "localhost" with ssh (did passphrase stuff etc.), then I
>> > did
>> > the following:
>> >
>> > $ bin/hadoop namenode -format
>> > $ bin/start-all.sh
>> > starting namenode, logging to
>> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-namenode-localhost.lo=
caldomain.out
>> > localhost: starting datanode, logging to
>> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-datanode-localhost.lo=
caldomain.out
>> > localhost: starting secondarynamenode, logging to
>> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-secondarynamenode-loc=
alhost.localdomain.out
>> > starting jobtracker, logging to
>> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-jobtracker-localhost.=
localdomain.out
>> > localhost: starting tasktracker, logging to
>> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-tasktracker-localhost=
.localdomain.out
>> >
>> > Everything seems ok, but when I check the Hadoop Logs I see many error=
s.
>> > (and they all cause HBase connection problems.)
>> > How can I solve this problem? Here are the Logs
>> >
>> >  hadoop-oracle-datanode-localhost.localdomain.log:
>> > 2009-08-04 02:54:28,971 INFO
>> > org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
>> > /************************************************************
>> > STARTUP_MSG: Starting DataNode
>> > STARTUP_MSG:   host =3D localhost.localdomain/127.0.0.1
>> > STARTUP_MSG:   args =3D []
>> > STARTUP_MSG:   version =3D 0.20.0
>> > STARTUP_MSG:   build =3D
>> > https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r
>> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
>> > ************************************************************/
>> > 2009-08-04 02:54:29,562 ERROR
>> > org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException:
>> > Incompatible namespaceIDs in /tmp/hadoop-oracle/dfs/data: namenode
>> > namespaceID =3D 36527197; datanode namespaceID =3D 2138759529
>> >    at
>> > org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataSt=
orage.java:233)
>> >    at
>> > org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRe=
ad(DataStorage.java:148)
>> >    at
>> > org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode=
.java:298)
>> >    at
>> > org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:2=
16)
>> >    at
>> > org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.=
java:1283)
>> >    at
>> > org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(Da=
taNode.java:1238)
>> >    at
>> > org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNod=
e.java:1246)
>> >    at
>> > org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:136=
8)
>> >
>> > 2009-08-04 02:54:29,563 INFO
>> > org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
>> > /************************************************************
>> > SHUTDOWN_MSG: Shutting down DataNode at localhost.localdomain/127.0.0.=
1
>> > ************************************************************/
>> >
>> > ----------------------------------------------------------------------=
--------------------
>> > hadoop-oracle-namenode-localhost.localdomain.log
>> > 2009-08-04 02:54:26,987 INFO
>> > org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG:
>> > /************************************************************
>> > STARTUP_MSG: Starting NameNode
>> > STARTUP_MSG:   host =3D localhost.localdomain/127.0.0.1
>> > STARTUP_MSG:   args =3D []
>> > STARTUP_MSG:   version =3D 0.20.0
>> > STARTUP_MSG:   build =3D
>> > https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r
>> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
>> > ************************************************************/
>> > 2009-08-04 02:54:27,116 INFO org.apache.hadoop.ipc.metrics.RpcMetrics:
>> > Initializing RPC Metrics with hostName=3DNameNode, port=3D9000
>> > 2009-08-04 02:54:27,174 INFO
>> > org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at:
>> > localhost.localdomain/127.0.0.1:9000
>> > 2009-08-04 02:54:27,179 INFO org.apache.hadoop.metrics.jvm.JvmMetrics:
>> > Initializing JVM Metrics with processName=3DNameNode, sessionId=3Dnull
>> > 2009-08-04 02:54:27,180 INFO
>> > org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics:
>> > Initializing
>> > NameNodeMeterics using context
>> > object:org.apache.hadoop.metrics.spi.NullContext
>> > 2009-08-04 02:54:27,278 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
>> > fsOwner=3Doracle,oinstall,root,dba,oper,asmadmin
>> > 2009-08-04 02:54:27,278 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
>> > supergroup=3Dsupergroup
>> > 2009-08-04 02:54:27,278 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
>> > isPermissionEnabled=3Dtrue
>> > 2009-08-04 02:54:27,294 INFO
>> > org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics:
>> > Initializing FSNamesystemMetrics using context
>> > object:org.apache.hadoop.metrics.spi.NullContext
>> > 2009-08-04 02:54:27,297 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered
>> > FSNamesystemStatusMBean
>> > 2009-08-04 02:54:27,341 INFO
>> > org.apache.hadoop.hdfs.server.common.Storage:
>> > Number of files =3D 8
>> > 2009-08-04 02:54:27,348 INFO
>> > org.apache.hadoop.hdfs.server.common.Storage:
>> > Number of files under construction =3D 2
>> > 2009-08-04 02:54:27,351 INFO
>> > org.apache.hadoop.hdfs.server.common.Storage:
>> > Image file of size 923 loaded in 0 seconds.
>> > 2009-08-04 02:54:27,351 INFO
>> > org.apache.hadoop.hdfs.server.common.Storage:
>> > Edits file /tmp/hadoop-oracle/dfs/name/current/edits of size 4 edits #=
 0
>> > loaded in 0 seconds.
>> > 2009-08-04 02:54:27,435 INFO
>> > org.apache.hadoop.hdfs.server.common.Storage:
>> > Image file of size 923 saved in 0 seconds.
>> > 2009-08-04 02:54:27,495 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading
>> > FSImage in 262 msecs
>> > 2009-08-04 02:54:27,496 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of
>> > blocks
>> > =3D 0
>> > 2009-08-04 02:54:27,496 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid
>> > blocks =3D 0
>> > 2009-08-04 02:54:27,497 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
>> > under-replicated blocks =3D 0
>> > 2009-08-04 02:54:27,497 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
>> >  over-replicated blocks =3D 0
>> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE=
*
>> > Leaving safe mode after 0 secs.
>> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE=
*
>> > Network topology has 0 racks and 0 datanodes
>> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE=
*
>> > UnderReplicatedBlocks has 0 blocks
>> > 2009-08-04 02:54:27,696 INFO org.mortbay.log: Logging to
>> > org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via
>> > org.mortbay.log.Slf4jLog
>> > 2009-08-04 02:54:27,775 INFO org.apache.hadoop.http.HttpServer: Jetty
>> > bound
>> > to port 50070
>> > 2009-08-04 02:54:27,775 INFO org.mortbay.log: jetty-6.1.14
>> > 2009-08-04 02:54:28,277 INFO org.mortbay.log: Started
>> > SelectChannelConnector@0.0.0.0:50070
>> > 2009-08-04 02:54:28,278 INFO
>> > org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at:
>> > 0.0.0.0:50070
>> > 2009-08-04 02:54:28,278 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > Responder: starting
>> > 2009-08-04 02:54:28,279 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > listener on 9000: starting
>> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 0 on 9000: starting
>> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 1 on 9000: starting
>> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 2 on 9000: starting
>> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 3 on 9000: starting
>> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 4 on 9000: starting
>> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 5 on 9000: starting
>> > 2009-08-04 02:54:28,328 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 6 on 9000: starting
>> > 2009-08-04 02:54:28,361 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 7 on 9000: starting
>> > 2009-08-04 02:54:28,362 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 8 on 9000: starting
>> > 2009-08-04 02:54:28,366 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 9 on 9000: starting
>> > 2009-08-04 02:54:38,433 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
>> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
>> >  cmd=3DlistStatus    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dn=
ull
>> >  perm=3Dnull
>> > 2009-08-04 02:54:38,755 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
>> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
>> > cmd=3Ddelete
>> >    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dnull    perm=3Dnull
>> > 2009-08-04 02:54:38,773 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
>> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
>> > cmd=3Dmkdirs
>> >    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dnull
>> >  perm=3Doracle:supergroup:rwxr-xr-x
>> > 2009-08-04 02:54:38,785 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
>> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
>> >  cmd=3DsetPermission    src=3D/tmp/hadoop-oracle/mapred/system    dst=
=3Dnull
>> >  perm=3Doracle:supergroup:rwx-wx-wx
>> > 2009-08-04 02:54:38,862 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
>> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
>> > cmd=3Dcreate
>> >    src=3D/tmp/hadoop-oracle/mapred/system/jobtracker.info    dst=3Dnul=
l
>> >  perm=3Doracle:supergroup:rw-r--r--
>> > 2009-08-04 02:54:38,900 INFO
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
>> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
>> >  cmd=3DsetPermission
>> > src=3D/tmp/hadoop-oracle/mapred/system/jobtracker.info   dst=3Dnull
>> > perm=3Doracle:supergroup:rw-------
>> > 2009-08-04 02:54:38,955 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 4 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
>> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
>> > java.io.IOException: File
>> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicat=
ed
>> > to 0 nodes, instead of 1
>> > java.io.IOException: File
>> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicat=
ed
>> > to 0 nodes, instead of 1
>> >    at
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock=
(FSNamesystem.java:1256)
>> >    at
>> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java=
:422)
>> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>> >    at
>> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.j=
ava:39)
>> >    at
>> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccess=
orImpl.java:25)
>> >    at java.lang.reflect.Method.invoke(Method.java:597)
>> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
>> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
>> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
>> >    at java.security.AccessController.doPrivileged(Native Method)
>> >    at javax.security.auth.Subject.doAs(Subject.java:396)
>> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
>> > 2009-08-04 02:54:39,548 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 5 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
>> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
>> > java.io.IOException: File
>> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicat=
ed
>> > to 0 nodes, instead of 1
>> > java.io.IOException: File
>> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicat=
ed
>> > to 0 nodes, instead of 1
>> >    at
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock=
(FSNamesystem.java:1256)
>> >    at
>> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java=
:422)
>> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>> >    at
>> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.j=
ava:39)
>> >    at
>> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccess=
orImpl.java:25)
>> >    at java.lang.reflect.Method.invoke(Method.java:597)
>> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
>> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
>> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
>> >    at java.security.AccessController.doPrivileged(Native Method)
>> >    at javax.security.auth.Subject.doAs(Subject.java:396)
>> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
>> > 2009-08-04 02:54:40,359 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 6 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
>> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
>> > java.io.IOException: File
>> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicat=
ed
>> > to 0 nodes, instead of 1
>> > java.io.IOException: File
>> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicat=
ed
>> > to 0 nodes, instead of 1
>> >    at
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock=
(FSNamesystem.java:1256)
>> >    at
>> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java=
:422)
>> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>> >    at
>> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.j=
ava:39)
>> >    at
>> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccess=
orImpl.java:25)
>> >    at java.lang.reflect.Method.invoke(Method.java:597)
>> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
>> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
>> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
>> >    at java.security.AccessController.doPrivileged(Native Method)
>> >    at javax.security.auth.Subject.doAs(Subject.java:396)
>> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
>> > 2009-08-04 02:54:41,969 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 7 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
>> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
>> > java.io.IOException: File
>> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicat=
ed
>> > to 0 nodes, instead of 1
>> > java.io.IOException: File
>> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicat=
ed
>> > to 0 nodes, instead of 1
>> >    at
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock=
(FSNamesystem.java:1256)
>> >    at
>> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java=
:422)
>> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>> >    at
>> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.j=
ava:39)
>> >    at
>> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccess=
orImpl.java:25)
>> >    at java.lang.reflect.Method.invoke(Method.java:597)
>> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
>> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
>> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
>> >    at java.security.AccessController.doPrivileged(Native Method)
>> >    at javax.security.auth.Subject.doAs(Subject.java:396)
>> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
>> > 2009-08-04 02:54:45,180 INFO org.apache.hadoop.ipc.Server: IPC Server
>> > handler 8 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
>> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
>> > java.io.IOException: File
>> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicat=
ed
>> > to 0 nodes, instead of 1
>> > java.io.IOException: File
>> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicat=
ed
>> > to 0 nodes, instead of 1
>> >    at
>> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock=
(FSNamesystem.java:1256)
>> >    at
>> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java=
:422)
>> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>> >    at
>> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.j=
ava:39)
>> >    at
>> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccess=
orImpl.java:25)
>> >    at java.lang.reflect.Method.invoke(Method.java:597)
>> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
>> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
>> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
>> >    at java.security.AccessController.doPrivileged(Native Method)
>> >    at javax.security.auth.Subject.doAs(Subject.java:396)
>> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
>> >
>> >
>> >
>> > _________________________________________________________________
>> > Windows Live ile foto=F0raflar=FDn=FDz=FD organize edebilir, d=FCzenle=
yebilir ve
>> > payla=FEabilirsiniz.
>> >
>> > http://www.microsoft.com/turkiye/windows/windowslive/products/photo-ga=
llery-edit.aspx
>
> _________________________________________________________________
> Windows Live t=FCm arkada=FElar=FDn=FDzla tek bir yerden ileti=FEim kurma=
n=FDza yard=FDmc=FD
> olur.
> http://www.microsoft.com/turkiye/windows/windowslive/products/social-netw=
ork-connector.aspx


--=20


Amandeep Khurana
Computer Science Graduate Student
University of California, Santa Cruz

From common-user-return-16534-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 00:42:56 2009
Return-Path: <common-user-return-16534-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 3258 invoked from network); 4 Aug 2009 00:42:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 00:42:56 -0000
Received: (qmail 73163 invoked by uid 500); 4 Aug 2009 00:42:58 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 73079 invoked by uid 500); 4 Aug 2009 00:42:58 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 73069 invoked by uid 99); 4 Aug 2009 00:42:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 00:42:58 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of onur.aktas@live.com designates 65.54.246.209 as permitted sender)
Received: from [65.54.246.209] (HELO bay0-omc3-s9.bay0.hotmail.com) (65.54.246.209)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 00:42:45 +0000
Received: from BAY107-W6 ([64.4.51.106]) by bay0-omc3-s9.bay0.hotmail.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Mon, 3 Aug 2009 17:42:23 -0700
Message-ID: <BAY107-W62282DAE8C264A7C186AFE70C0@phx.gbl>
Content-Type: multipart/alternative;
	boundary="_ca670b6c-0dc7-46b1-b500-5dfc60fb9fc7_"
X-Originating-IP: [88.238.30.119]
From: Onur AKTAS <onur.aktas@live.com>
To: <common-user@hadoop.apache.org>
Subject: RE: Problem with starting Hadoop in Pseudo Distributed Mode
Date: Tue, 4 Aug 2009 03:42:23 +0300
Importance: Normal
In-Reply-To: <35a22e220908031729k3ffbab3ftf51dfe979bc147cb@mail.gmail.com>
References: <BAY107-W82FB176A70E2FBD18D043E70F0@phx.gbl>
	 <35a22e220908031702n629c3ac0l22a25bd140d571ff@mail.gmail.com>
 	 <BAY107-W5420D81B2F5CFD1AE5D9F6E70C0@phx.gbl> 
 <35a22e220908031729k3ffbab3ftf51dfe979bc147cb@mail.gmail.com>
MIME-Version: 1.0
X-OriginalArrivalTime: 04 Aug 2009 00:42:23.0049 (UTC) FILETIME=[6E3DFB90:01CA149C]
X-Virus-Checked: Checked by ClamAV on apache.org

--_ca670b6c-0dc7-46b1-b500-5dfc60fb9fc7_
Content-Type: text/plain; charset="windows-1254"
Content-Transfer-Encoding: 8bit


There is no default.xml in Hadoop 0.20.0, but luckly I also have release 0.18.3 and found these..

<property>
  <name>hadoop.tmp.dir</name>
  <value>/tmp/hadoop-${user.name}</value>
  <description>A base for other temporary directories.</description>
</property>

It seems /tmp/hadoop-${user.name} is a temporary directory as description indicates, then where is the real directory?
I deleted whole tmp directory and formatted it again.. Started the server, checked the logs and still have same errors. 

> Date: Mon, 3 Aug 2009 17:29:52 -0700
> Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
> From: amansk@gmail.com
> To: common-user@hadoop.apache.org
> 
> Yes, you need to change these directories. The config is put in the
> hadoop-site.xml. Or in this case, separately in the 3 xmls. See the
> default xml for syntax and property name.
> 
> On 8/3/09, Onur AKTAS <onur.aktas@live.com> wrote:
> >
> > Is it the directory that Hadoop uses?
> >
> > /tmp/hadoop-oracle
> > /tmp/hadoop-oracle/dfs/
> > /tmp/hadoop-oracle/mapred/
> >
> > If yes, how can I change the directory to anywhere else? I do not want it to
> > be kept in /tmp folder.
> >
> >> From: amansk@gmail.com
> >> Date: Mon, 3 Aug 2009 17:02:50 -0700
> >> Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
> >> To: common-user@hadoop.apache.org
> >>
> >> I'm assuming that you have no data in HDFS since it never came up... So,
> >> go
> >> ahead and clean up the directory where you are storing the datanode's data
> >> and the namenode's metadata. After that format the namenode and restart
> >> hadoop.
> >>
> >>
> >> 2009/8/3 Onur AKTAS <onur.aktas@live.com>
> >>
> >> >
> >> > Hi,
> >> >
> >> > I'm having troubles with running Hadoop in RHEL 5, I did everything as
> >> > documented in:
> >> > http://hadoop.apache.org/common/docs/r0.20.0/quickstart.html
> >> >
> >> > And configured:
> >> > conf/core-site.xml, conf/hdfs-site.xml,
> >> > conf/mapred-site.xml.
> >> >
> >> > Connected to "localhost" with ssh (did passphrase stuff etc.), then I
> >> > did
> >> > the following:
> >> >
> >> > $ bin/hadoop namenode -format
> >> > $ bin/start-all.sh
> >> > starting namenode, logging to
> >> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-namenode-localhost.localdomain.out
> >> > localhost: starting datanode, logging to
> >> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-datanode-localhost.localdomain.out
> >> > localhost: starting secondarynamenode, logging to
> >> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-secondarynamenode-localhost.localdomain.out
> >> > starting jobtracker, logging to
> >> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-jobtracker-localhost.localdomain.out
> >> > localhost: starting tasktracker, logging to
> >> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-tasktracker-localhost.localdomain.out
> >> >
> >> > Everything seems ok, but when I check the Hadoop Logs I see many errors.
> >> > (and they all cause HBase connection problems.)
> >> > How can I solve this problem? Here are the Logs
> >> >
> >> >  hadoop-oracle-datanode-localhost.localdomain.log:
> >> > 2009-08-04 02:54:28,971 INFO
> >> > org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
> >> > /************************************************************
> >> > STARTUP_MSG: Starting DataNode
> >> > STARTUP_MSG:   host = localhost.localdomain/127.0.0.1
> >> > STARTUP_MSG:   args = []
> >> > STARTUP_MSG:   version = 0.20.0
> >> > STARTUP_MSG:   build =
> >> > https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r
> >> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> >> > ************************************************************/
> >> > 2009-08-04 02:54:29,562 ERROR
> >> > org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException:
> >> > Incompatible namespaceIDs in /tmp/hadoop-oracle/dfs/data: namenode
> >> > namespaceID = 36527197; datanode namespaceID = 2138759529
> >> >    at
> >> > org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:233)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:148)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:298)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:216)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1283)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1238)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1246)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1368)
> >> >
> >> > 2009-08-04 02:54:29,563 INFO
> >> > org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
> >> > /************************************************************
> >> > SHUTDOWN_MSG: Shutting down DataNode at localhost.localdomain/127.0.0.1
> >> > ************************************************************/
> >> >
> >> > ------------------------------------------------------------------------------------------
> >> > hadoop-oracle-namenode-localhost.localdomain.log
> >> > 2009-08-04 02:54:26,987 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG:
> >> > /************************************************************
> >> > STARTUP_MSG: Starting NameNode
> >> > STARTUP_MSG:   host = localhost.localdomain/127.0.0.1
> >> > STARTUP_MSG:   args = []
> >> > STARTUP_MSG:   version = 0.20.0
> >> > STARTUP_MSG:   build =
> >> > https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r
> >> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> >> > ************************************************************/
> >> > 2009-08-04 02:54:27,116 INFO org.apache.hadoop.ipc.metrics.RpcMetrics:
> >> > Initializing RPC Metrics with hostName=NameNode, port=9000
> >> > 2009-08-04 02:54:27,174 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at:
> >> > localhost.localdomain/127.0.0.1:9000
> >> > 2009-08-04 02:54:27,179 INFO org.apache.hadoop.metrics.jvm.JvmMetrics:
> >> > Initializing JVM Metrics with processName=NameNode, sessionId=null
> >> > 2009-08-04 02:54:27,180 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics:
> >> > Initializing
> >> > NameNodeMeterics using context
> >> > object:org.apache.hadoop.metrics.spi.NullContext
> >> > 2009-08-04 02:54:27,278 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> >> > fsOwner=oracle,oinstall,root,dba,oper,asmadmin
> >> > 2009-08-04 02:54:27,278 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> >> > supergroup=supergroup
> >> > 2009-08-04 02:54:27,278 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> >> > isPermissionEnabled=true
> >> > 2009-08-04 02:54:27,294 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics:
> >> > Initializing FSNamesystemMetrics using context
> >> > object:org.apache.hadoop.metrics.spi.NullContext
> >> > 2009-08-04 02:54:27,297 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered
> >> > FSNamesystemStatusMBean
> >> > 2009-08-04 02:54:27,341 INFO
> >> > org.apache.hadoop.hdfs.server.common.Storage:
> >> > Number of files = 8
> >> > 2009-08-04 02:54:27,348 INFO
> >> > org.apache.hadoop.hdfs.server.common.Storage:
> >> > Number of files under construction = 2
> >> > 2009-08-04 02:54:27,351 INFO
> >> > org.apache.hadoop.hdfs.server.common.Storage:
> >> > Image file of size 923 loaded in 0 seconds.
> >> > 2009-08-04 02:54:27,351 INFO
> >> > org.apache.hadoop.hdfs.server.common.Storage:
> >> > Edits file /tmp/hadoop-oracle/dfs/name/current/edits of size 4 edits # 0
> >> > loaded in 0 seconds.
> >> > 2009-08-04 02:54:27,435 INFO
> >> > org.apache.hadoop.hdfs.server.common.Storage:
> >> > Image file of size 923 saved in 0 seconds.
> >> > 2009-08-04 02:54:27,495 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading
> >> > FSImage in 262 msecs
> >> > 2009-08-04 02:54:27,496 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of
> >> > blocks
> >> > = 0
> >> > 2009-08-04 02:54:27,496 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid
> >> > blocks = 0
> >> > 2009-08-04 02:54:27,497 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> >> > under-replicated blocks = 0
> >> > 2009-08-04 02:54:27,497 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> >> >  over-replicated blocks = 0
> >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE*
> >> > Leaving safe mode after 0 secs.
> >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE*
> >> > Network topology has 0 racks and 0 datanodes
> >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange: STATE*
> >> > UnderReplicatedBlocks has 0 blocks
> >> > 2009-08-04 02:54:27,696 INFO org.mortbay.log: Logging to
> >> > org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via
> >> > org.mortbay.log.Slf4jLog
> >> > 2009-08-04 02:54:27,775 INFO org.apache.hadoop.http.HttpServer: Jetty
> >> > bound
> >> > to port 50070
> >> > 2009-08-04 02:54:27,775 INFO org.mortbay.log: jetty-6.1.14
> >> > 2009-08-04 02:54:28,277 INFO org.mortbay.log: Started
> >> > SelectChannelConnector@0.0.0.0:50070
> >> > 2009-08-04 02:54:28,278 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at:
> >> > 0.0.0.0:50070
> >> > 2009-08-04 02:54:28,278 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > Responder: starting
> >> > 2009-08-04 02:54:28,279 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > listener on 9000: starting
> >> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 0 on 9000: starting
> >> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 1 on 9000: starting
> >> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 2 on 9000: starting
> >> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 3 on 9000: starting
> >> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 4 on 9000: starting
> >> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 5 on 9000: starting
> >> > 2009-08-04 02:54:28,328 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 6 on 9000: starting
> >> > 2009-08-04 02:54:28,361 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 7 on 9000: starting
> >> > 2009-08-04 02:54:28,362 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 8 on 9000: starting
> >> > 2009-08-04 02:54:28,366 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 9 on 9000: starting
> >> > 2009-08-04 02:54:38,433 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> >> >  cmd=listStatus    src=/tmp/hadoop-oracle/mapred/system    dst=null
> >> >  perm=null
> >> > 2009-08-04 02:54:38,755 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> >> > cmd=delete
> >> >    src=/tmp/hadoop-oracle/mapred/system    dst=null    perm=null
> >> > 2009-08-04 02:54:38,773 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> >> > cmd=mkdirs
> >> >    src=/tmp/hadoop-oracle/mapred/system    dst=null
> >> >  perm=oracle:supergroup:rwxr-xr-x
> >> > 2009-08-04 02:54:38,785 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> >> >  cmd=setPermission    src=/tmp/hadoop-oracle/mapred/system    dst=null
> >> >  perm=oracle:supergroup:rwx-wx-wx
> >> > 2009-08-04 02:54:38,862 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> >> > cmd=create
> >> >    src=/tmp/hadoop-oracle/mapred/system/jobtracker.info    dst=null
> >> >  perm=oracle:supergroup:rw-r--r--
> >> > 2009-08-04 02:54:38,900 INFO
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> >> >  cmd=setPermission
> >> > src=/tmp/hadoop-oracle/mapred/system/jobtracker.info   dst=null
> >> > perm=oracle:supergroup:rw-------
> >> > 2009-08-04 02:54:38,955 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 4 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> >> > java.io.IOException: File
> >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated
> >> > to 0 nodes, instead of 1
> >> > java.io.IOException: File
> >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated
> >> > to 0 nodes, instead of 1
> >> >    at
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >> >    at
> >> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >> >    at
> >> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> >> >    at java.security.AccessController.doPrivileged(Native Method)
> >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> >> > 2009-08-04 02:54:39,548 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 5 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> >> > java.io.IOException: File
> >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated
> >> > to 0 nodes, instead of 1
> >> > java.io.IOException: File
> >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated
> >> > to 0 nodes, instead of 1
> >> >    at
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >> >    at
> >> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >> >    at
> >> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> >> >    at java.security.AccessController.doPrivileged(Native Method)
> >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> >> > 2009-08-04 02:54:40,359 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 6 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> >> > java.io.IOException: File
> >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated
> >> > to 0 nodes, instead of 1
> >> > java.io.IOException: File
> >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated
> >> > to 0 nodes, instead of 1
> >> >    at
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >> >    at
> >> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >> >    at
> >> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> >> >    at java.security.AccessController.doPrivileged(Native Method)
> >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> >> > 2009-08-04 02:54:41,969 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 7 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> >> > java.io.IOException: File
> >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated
> >> > to 0 nodes, instead of 1
> >> > java.io.IOException: File
> >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated
> >> > to 0 nodes, instead of 1
> >> >    at
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >> >    at
> >> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >> >    at
> >> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> >> >    at java.security.AccessController.doPrivileged(Native Method)
> >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> >> > 2009-08-04 02:54:45,180 INFO org.apache.hadoop.ipc.Server: IPC Server
> >> > handler 8 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> >> > java.io.IOException: File
> >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated
> >> > to 0 nodes, instead of 1
> >> > java.io.IOException: File
> >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be replicated
> >> > to 0 nodes, instead of 1
> >> >    at
> >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> >> >    at
> >> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >> >    at
> >> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >> >    at
> >> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> >> >    at java.security.AccessController.doPrivileged(Native Method)
> >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> >> >
> >> >
> >> >
> >> > _________________________________________________________________
> >> > Windows Live ile fotoraflarnz organize edebilir, dzenleyebilir ve
> >> > paylaabilirsiniz.
> >> >
> >> > http://www.microsoft.com/turkiye/windows/windowslive/products/photo-gallery-edit.aspx
> >
> > _________________________________________________________________
> > Windows Live tm arkadalarnzla tek bir yerden iletiim kurmanza yardmc
> > olur.
> > http://www.microsoft.com/turkiye/windows/windowslive/products/social-network-connector.aspx
> 
> 
> -- 
> 
> 
> Amandeep Khurana
> Computer Science Graduate Student
> University of California, Santa Cruz

_________________________________________________________________
Sadece e-posta iletilerinden daha fazlas: Dier Windows Live zelliklerine gz atn.
http://www.microsoft.com/turkiye/windows/windowslive/
--_ca670b6c-0dc7-46b1-b500-5dfc60fb9fc7_--

From common-user-return-16535-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 00:49:17 2009
Return-Path: <common-user-return-16535-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 4559 invoked from network); 4 Aug 2009 00:49:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 00:49:17 -0000
Received: (qmail 81270 invoked by uid 500); 4 Aug 2009 00:49:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 81193 invoked by uid 500); 4 Aug 2009 00:49:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 81183 invoked by uid 99); 4 Aug 2009 00:49:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 00:49:20 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of amansk@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 00:49:05 +0000
Received: by yxe15 with SMTP id 15so6138876yxe.5
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 17:48:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=Gv2+R3ipLRWAgfAf8mHs72u+oaA10UKtfiRliMjg7D0=;
        b=WyQ6ULMYPLVJoR2CFjXOyGNV0OU1p9AmwD/Qxitv3wXoWzgSpctXtOU4J+Mo3sVD21
         tuSbeldqg4E9cFOMFu5zy6ZpKwajT9F5NcSx0YJe+J2j8LWP2i2bYpkTC5beSToG9fsS
         RFsUUN78fHbRuSAbIo+8w3TDeo6tAxt2tVQ6g=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=olsvSW9HFtK5UMjTX+fRpkDxxHqp974Z+tN/wpcM4krqHeMQDRr5Sh+c6J73edYrlX
         qavMoxgV4cEPp4uM9CGbMKuIEtqonnQ5xBwgSBvfMeI3zRT0dKWgJ1ynZqx5XV1FSyD8
         Fkggz6SnQ4Kn4wXh/uv1Slf6UPOY0R3TqTU0Y=
MIME-Version: 1.0
Received: by 10.100.167.20 with SMTP id p20mr7921388ane.80.1249346924167; Mon, 
	03 Aug 2009 17:48:44 -0700 (PDT)
In-Reply-To: <BAY107-W62282DAE8C264A7C186AFE70C0@phx.gbl>
References: <BAY107-W82FB176A70E2FBD18D043E70F0@phx.gbl> <35a22e220908031702n629c3ac0l22a25bd140d571ff@mail.gmail.com> 
	<BAY107-W5420D81B2F5CFD1AE5D9F6E70C0@phx.gbl> <35a22e220908031729k3ffbab3ftf51dfe979bc147cb@mail.gmail.com> 
	<BAY107-W62282DAE8C264A7C186AFE70C0@phx.gbl>
From: Amandeep Khurana <amansk@gmail.com>
Date: Mon, 3 Aug 2009 17:48:24 -0700
Message-ID: <35a22e220908031748h67cd3601he117f66d223e363@mail.gmail.com>
Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e644d0a29dc1b50470463fc5
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e644d0a29dc1b50470463fc5
Content-Type: text/plain; charset=ISO-8859-9
Content-Transfer-Encoding: quoted-printable

1. The default xmls are in $HADOOP_HOME/build/classes
2. You have to ovverride the parameters and put them in the site.xml's so
you can have it in some other directory and not /tmp

Do that and try starting hadoop.


Amandeep Khurana
Computer Science Graduate Student
University of California, Santa Cruz


2009/8/3 Onur AKTAS <onur.aktas@live.com>

>
> There is no default.xml in Hadoop 0.20.0, but luckly I also have release
> 0.18.3 and found these..
>
> <property>
>  <name>hadoop.tmp.dir</name>
>  <value>/tmp/hadoop-${user.name}</value>
>  <description>A base for other temporary directories.</description>
> </property>
>
> It seems /tmp/hadoop-${user.name} is a temporary directory as description
> indicates, then where is the real directory?
> I deleted whole tmp directory and formatted it again.. Started the server=
,
> checked the logs and still have same errors.
>
> > Date: Mon, 3 Aug 2009 17:29:52 -0700
> > Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
> > From: amansk@gmail.com
> > To: common-user@hadoop.apache.org
> >
> > Yes, you need to change these directories. The config is put in the
> > hadoop-site.xml. Or in this case, separately in the 3 xmls. See the
> > default xml for syntax and property name.
> >
> > On 8/3/09, Onur AKTAS <onur.aktas@live.com> wrote:
> > >
> > > Is it the directory that Hadoop uses?
> > >
> > > /tmp/hadoop-oracle
> > > /tmp/hadoop-oracle/dfs/
> > > /tmp/hadoop-oracle/mapred/
> > >
> > > If yes, how can I change the directory to anywhere else? I do not wan=
t
> it to
> > > be kept in /tmp folder.
> > >
> > >> From: amansk@gmail.com
> > >> Date: Mon, 3 Aug 2009 17:02:50 -0700
> > >> Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
> > >> To: common-user@hadoop.apache.org
> > >>
> > >> I'm assuming that you have no data in HDFS since it never came up...
> So,
> > >> go
> > >> ahead and clean up the directory where you are storing the datanode'=
s
> data
> > >> and the namenode's metadata. After that format the namenode and
> restart
> > >> hadoop.
> > >>
> > >>
> > >> 2009/8/3 Onur AKTAS <onur.aktas@live.com>
> > >>
> > >> >
> > >> > Hi,
> > >> >
> > >> > I'm having troubles with running Hadoop in RHEL 5, I did everythin=
g
> as
> > >> > documented in:
> > >> > http://hadoop.apache.org/common/docs/r0.20.0/quickstart.html
> > >> >
> > >> > And configured:
> > >> > conf/core-site.xml, conf/hdfs-site.xml,
> > >> > conf/mapred-site.xml.
> > >> >
> > >> > Connected to "localhost" with ssh (did passphrase stuff etc.), the=
n
> I
> > >> > did
> > >> > the following:
> > >> >
> > >> > $ bin/hadoop namenode -format
> > >> > $ bin/start-all.sh
> > >> > starting namenode, logging to
> > >> >
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-namenode-localhost.local=
domain.out
> > >> > localhost: starting datanode, logging to
> > >> >
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-datanode-localhost.local=
domain.out
> > >> > localhost: starting secondarynamenode, logging to
> > >> >
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-secondarynamenode-localh=
ost.localdomain.out
> > >> > starting jobtracker, logging to
> > >> >
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-jobtracker-localhost.loc=
aldomain.out
> > >> > localhost: starting tasktracker, logging to
> > >> >
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-tasktracker-localhost.lo=
caldomain.out
> > >> >
> > >> > Everything seems ok, but when I check the Hadoop Logs I see many
> errors.
> > >> > (and they all cause HBase connection problems.)
> > >> > How can I solve this problem? Here are the Logs
> > >> >
> > >> >  hadoop-oracle-datanode-localhost.localdomain.log:
> > >> > 2009-08-04 02:54:28,971 INFO
> > >> > org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
> > >> > /************************************************************
> > >> > STARTUP_MSG: Starting DataNode
> > >> > STARTUP_MSG:   host =3D localhost.localdomain/127.0.0.1
> > >> > STARTUP_MSG:   args =3D []
> > >> > STARTUP_MSG:   version =3D 0.20.0
> > >> > STARTUP_MSG:   build =3D
> > >> > https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20-=
r
> > >> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> > >> > ************************************************************/
> > >> > 2009-08-04 02:54:29,562 ERROR
> > >> > org.apache.hadoop.hdfs.server.datanode.DataNode:
> java.io.IOException:
> > >> > Incompatible namespaceIDs in /tmp/hadoop-oracle/dfs/data: namenode
> > >> > namespaceID =3D 36527197; datanode namespaceID =3D 2138759529
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStora=
ge.java:233)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(=
DataStorage.java:148)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.ja=
va:298)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:216)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.jav=
a:1283)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataN=
ode.java:1238)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.j=
ava:1246)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1368)
> > >> >
> > >> > 2009-08-04 02:54:29,563 INFO
> > >> > org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
> > >> > /************************************************************
> > >> > SHUTDOWN_MSG: Shutting down DataNode at localhost.localdomain/
> 127.0.0.1
> > >> > ************************************************************/
> > >> >
> > >> >
> -------------------------------------------------------------------------=
-----------------
> > >> > hadoop-oracle-namenode-localhost.localdomain.log
> > >> > 2009-08-04 02:54:26,987 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG:
> > >> > /************************************************************
> > >> > STARTUP_MSG: Starting NameNode
> > >> > STARTUP_MSG:   host =3D localhost.localdomain/127.0.0.1
> > >> > STARTUP_MSG:   args =3D []
> > >> > STARTUP_MSG:   version =3D 0.20.0
> > >> > STARTUP_MSG:   build =3D
> > >> > https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20-=
r
> > >> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> > >> > ************************************************************/
> > >> > 2009-08-04 02:54:27,116 INFO
> org.apache.hadoop.ipc.metrics.RpcMetrics:
> > >> > Initializing RPC Metrics with hostName=3DNameNode, port=3D9000
> > >> > 2009-08-04 02:54:27,174 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at:
> > >> > localhost.localdomain/127.0.0.1:9000
> > >> > 2009-08-04 02:54:27,179 INFO
> org.apache.hadoop.metrics.jvm.JvmMetrics:
> > >> > Initializing JVM Metrics with processName=3DNameNode, sessionId=3D=
null
> > >> > 2009-08-04 02:54:27,180 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics:
> > >> > Initializing
> > >> > NameNodeMeterics using context
> > >> > object:org.apache.hadoop.metrics.spi.NullContext
> > >> > 2009-08-04 02:54:27,278 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > >> > fsOwner=3Doracle,oinstall,root,dba,oper,asmadmin
> > >> > 2009-08-04 02:54:27,278 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > >> > supergroup=3Dsupergroup
> > >> > 2009-08-04 02:54:27,278 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > >> > isPermissionEnabled=3Dtrue
> > >> > 2009-08-04 02:54:27,294 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics=
:
> > >> > Initializing FSNamesystemMetrics using context
> > >> > object:org.apache.hadoop.metrics.spi.NullContext
> > >> > 2009-08-04 02:54:27,297 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered
> > >> > FSNamesystemStatusMBean
> > >> > 2009-08-04 02:54:27,341 INFO
> > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > >> > Number of files =3D 8
> > >> > 2009-08-04 02:54:27,348 INFO
> > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > >> > Number of files under construction =3D 2
> > >> > 2009-08-04 02:54:27,351 INFO
> > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > >> > Image file of size 923 loaded in 0 seconds.
> > >> > 2009-08-04 02:54:27,351 INFO
> > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > >> > Edits file /tmp/hadoop-oracle/dfs/name/current/edits of size 4 edi=
ts
> # 0
> > >> > loaded in 0 seconds.
> > >> > 2009-08-04 02:54:27,435 INFO
> > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > >> > Image file of size 923 saved in 0 seconds.
> > >> > 2009-08-04 02:54:27,495 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished
> loading
> > >> > FSImage in 262 msecs
> > >> > 2009-08-04 02:54:27,496 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number =
of
> > >> > blocks
> > >> > =3D 0
> > >> > 2009-08-04 02:54:27,496 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> invalid
> > >> > blocks =3D 0
> > >> > 2009-08-04 02:54:27,497 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> > >> > under-replicated blocks =3D 0
> > >> > 2009-08-04 02:54:27,497 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> > >> >  over-replicated blocks =3D 0
> > >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange:
> STATE*
> > >> > Leaving safe mode after 0 secs.
> > >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange:
> STATE*
> > >> > Network topology has 0 racks and 0 datanodes
> > >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange:
> STATE*
> > >> > UnderReplicatedBlocks has 0 blocks
> > >> > 2009-08-04 02:54:27,696 INFO org.mortbay.log: Logging to
> > >> > org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via
> > >> > org.mortbay.log.Slf4jLog
> > >> > 2009-08-04 02:54:27,775 INFO org.apache.hadoop.http.HttpServer:
> Jetty
> > >> > bound
> > >> > to port 50070
> > >> > 2009-08-04 02:54:27,775 INFO org.mortbay.log: jetty-6.1.14
> > >> > 2009-08-04 02:54:28,277 INFO org.mortbay.log: Started
> > >> > SelectChannelConnector@0.0.0.0:50070
> > >> > 2009-08-04 02:54:28,278 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at:
> > >> > 0.0.0.0:50070
> > >> > 2009-08-04 02:54:28,278 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > Responder: starting
> > >> > 2009-08-04 02:54:28,279 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > listener on 9000: starting
> > >> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 0 on 9000: starting
> > >> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 1 on 9000: starting
> > >> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 2 on 9000: starting
> > >> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 3 on 9000: starting
> > >> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 4 on 9000: starting
> > >> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 5 on 9000: starting
> > >> > 2009-08-04 02:54:28,328 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 6 on 9000: starting
> > >> > 2009-08-04 02:54:28,361 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 7 on 9000: starting
> > >> > 2009-08-04 02:54:28,362 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 8 on 9000: starting
> > >> > 2009-08-04 02:54:28,366 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 9 on 9000: starting
> > >> > 2009-08-04 02:54:38,433 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
> > >> >  cmd=3DlistStatus    src=3D/tmp/hadoop-oracle/mapred/system    dst=
=3Dnull
> > >> >  perm=3Dnull
> > >> > 2009-08-04 02:54:38,755 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
> > >> > cmd=3Ddelete
> > >> >    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dnull    perm=3D=
null
> > >> > 2009-08-04 02:54:38,773 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
> > >> > cmd=3Dmkdirs
> > >> >    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dnull
> > >> >  perm=3Doracle:supergroup:rwxr-xr-x
> > >> > 2009-08-04 02:54:38,785 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
> > >> >  cmd=3DsetPermission    src=3D/tmp/hadoop-oracle/mapred/system
>  dst=3Dnull
> > >> >  perm=3Doracle:supergroup:rwx-wx-wx
> > >> > 2009-08-04 02:54:38,862 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
> > >> > cmd=3Dcreate
> > >> >    src=3D/tmp/hadoop-oracle/mapred/system/jobtracker.info    dst=
=3Dnull
> > >> >  perm=3Doracle:supergroup:rw-r--r--
> > >> > 2009-08-04 02:54:38,900 INFO
> > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.1
> > >> >  cmd=3DsetPermission
> > >> > src=3D/tmp/hadoop-oracle/mapred/system/jobtracker.info   dst=3Dnul=
l
> > >> > perm=3Doracle:supergroup:rw-------
> > >> > 2009-08-04 02:54:38,955 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 4 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error=
:
> > >> > java.io.IOException: File
> > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> replicated
> > >> > to 0 nodes, instead of 1
> > >> > java.io.IOException: File
> > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> replicated
> > >> > to 0 nodes, instead of 1
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
> > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > >> >    at
> > >> >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> > >> >    at
> > >> >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > >> >    at java.security.AccessController.doPrivileged(Native Method)
> > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > >> > 2009-08-04 02:54:39,548 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 5 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error=
:
> > >> > java.io.IOException: File
> > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> replicated
> > >> > to 0 nodes, instead of 1
> > >> > java.io.IOException: File
> > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> replicated
> > >> > to 0 nodes, instead of 1
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
> > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > >> >    at
> > >> >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> > >> >    at
> > >> >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > >> >    at java.security.AccessController.doPrivileged(Native Method)
> > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > >> > 2009-08-04 02:54:40,359 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 6 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error=
:
> > >> > java.io.IOException: File
> > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> replicated
> > >> > to 0 nodes, instead of 1
> > >> > java.io.IOException: File
> > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> replicated
> > >> > to 0 nodes, instead of 1
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
> > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > >> >    at
> > >> >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> > >> >    at
> > >> >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > >> >    at java.security.AccessController.doPrivileged(Native Method)
> > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > >> > 2009-08-04 02:54:41,969 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 7 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error=
:
> > >> > java.io.IOException: File
> > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> replicated
> > >> > to 0 nodes, instead of 1
> > >> > java.io.IOException: File
> > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> replicated
> > >> > to 0 nodes, instead of 1
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
> > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > >> >    at
> > >> >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> > >> >    at
> > >> >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > >> >    at java.security.AccessController.doPrivileged(Native Method)
> > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > >> > 2009-08-04 02:54:45,180 INFO org.apache.hadoop.ipc.Server: IPC
> Server
> > >> > handler 8 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error=
:
> > >> > java.io.IOException: File
> > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> replicated
> > >> > to 0 nodes, instead of 1
> > >> > java.io.IOException: File
> > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> replicated
> > >> > to 0 nodes, instead of 1
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
> > >> >    at
> > >> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
> > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > >> >    at
> > >> >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> > >> >    at
> > >> >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > >> >    at java.security.AccessController.doPrivileged(Native Method)
> > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > >> >
> > >> >
> > >> >
> > >> > _________________________________________________________________
> > >> > Windows Live ile foto=F0raflar=FDn=FDz=FD organize edebilir, d=FCz=
enleyebilir
> ve
> > >> > payla=FEabilirsiniz.
> > >> >
> > >> >
> http://www.microsoft.com/turkiye/windows/windowslive/products/photo-galle=
ry-edit.aspx
> > >
> > > _________________________________________________________________
> > > Windows Live t=FCm arkada=FElar=FDn=FDzla tek bir yerden ileti=FEim k=
urman=FDza
> yard=FDmc=FD
> > > olur.
> > >
> http://www.microsoft.com/turkiye/windows/windowslive/products/social-netw=
ork-connector.aspx
> >
> >
> > --
> >
> >
> > Amandeep Khurana
> > Computer Science Graduate Student
> > University of California, Santa Cruz
>
> _________________________________________________________________
> Sadece e-posta iletilerinden daha fazlas=FD: Di=F0er Windows Live(tm)
> =F6zelliklerine g=F6z at=FDn.
> http://www.microsoft.com/turkiye/windows/windowslive/
>

--0016e644d0a29dc1b50470463fc5--

From common-user-return-16536-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 01:06:20 2009
Return-Path: <common-user-return-16536-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7368 invoked from network); 4 Aug 2009 01:06:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 01:06:20 -0000
Received: (qmail 93251 invoked by uid 500); 4 Aug 2009 01:06:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 93179 invoked by uid 500); 4 Aug 2009 01:06:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 93169 invoked by uid 99); 4 Aug 2009 01:06:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 01:06:22 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of onur.aktas@live.com designates 65.54.246.239 as permitted sender)
Received: from [65.54.246.239] (HELO bay0-omc3-s39.bay0.hotmail.com) (65.54.246.239)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 01:06:11 +0000
Received: from BAY107-W22 ([64.4.51.122]) by bay0-omc3-s39.bay0.hotmail.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Mon, 3 Aug 2009 18:05:50 -0700
Message-ID: <BAY107-W229FBBE97806C8113310A8E70C0@phx.gbl>
Content-Type: multipart/alternative;
	boundary="_1a3807fd-d618-4c58-8e0a-a796fc047452_"
X-Originating-IP: [88.238.30.119]
From: Onur AKTAS <onur.aktas@live.com>
To: <common-user@hadoop.apache.org>
Subject: RE: Problem with starting Hadoop in Pseudo Distributed Mode
Date: Tue, 4 Aug 2009 04:05:50 +0300
Importance: Normal
In-Reply-To: <35a22e220908031748h67cd3601he117f66d223e363@mail.gmail.com>
References: <BAY107-W82FB176A70E2FBD18D043E70F0@phx.gbl>
 <35a22e220908031702n629c3ac0l22a25bd140d571ff@mail.gmail.com>
 	<BAY107-W5420D81B2F5CFD1AE5D9F6E70C0@phx.gbl>
 <35a22e220908031729k3ffbab3ftf51dfe979bc147cb@mail.gmail.com> 
 	<BAY107-W62282DAE8C264A7C186AFE70C0@phx.gbl> 
 <35a22e220908031748h67cd3601he117f66d223e363@mail.gmail.com>
MIME-Version: 1.0
X-OriginalArrivalTime: 04 Aug 2009 01:05:50.0940 (UTC) FILETIME=[B56919C0:01CA149F]
X-Virus-Checked: Checked by ClamAV on apache.org

--_1a3807fd-d618-4c58-8e0a-a796fc047452_
Content-Type: text/plain; charset="windows-1254"
Content-Transfer-Encoding: 8bit


Thank you very much!

I added tags below to conf/core-site.xml and reformatted it again.. 
it started without any problems and I also started HBase and connected it with a client! 

<property>
    <name>hadoop.tmp.dir</name>
    <value>/tmp/hadoop-onur</value>
    <description>A base for other temporary directories.</description>
   </property>

Thank you again..

> From: amansk@gmail.com
> Date: Mon, 3 Aug 2009 17:48:24 -0700
> Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
> To: common-user@hadoop.apache.org
> 
> 1. The default xmls are in $HADOOP_HOME/build/classes
> 2. You have to ovverride the parameters and put them in the site.xml's so
> you can have it in some other directory and not /tmp
> 
> Do that and try starting hadoop.
> 
> 
> Amandeep Khurana
> Computer Science Graduate Student
> University of California, Santa Cruz
> 
> 
> 2009/8/3 Onur AKTAS <onur.aktas@live.com>
> 
> >
> > There is no default.xml in Hadoop 0.20.0, but luckly I also have release
> > 0.18.3 and found these..
> >
> > <property>
> >  <name>hadoop.tmp.dir</name>
> >  <value>/tmp/hadoop-${user.name}</value>
> >  <description>A base for other temporary directories.</description>
> > </property>
> >
> > It seems /tmp/hadoop-${user.name} is a temporary directory as description
> > indicates, then where is the real directory?
> > I deleted whole tmp directory and formatted it again.. Started the server,
> > checked the logs and still have same errors.
> >
> > > Date: Mon, 3 Aug 2009 17:29:52 -0700
> > > Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
> > > From: amansk@gmail.com
> > > To: common-user@hadoop.apache.org
> > >
> > > Yes, you need to change these directories. The config is put in the
> > > hadoop-site.xml. Or in this case, separately in the 3 xmls. See the
> > > default xml for syntax and property name.
> > >
> > > On 8/3/09, Onur AKTAS <onur.aktas@live.com> wrote:
> > > >
> > > > Is it the directory that Hadoop uses?
> > > >
> > > > /tmp/hadoop-oracle
> > > > /tmp/hadoop-oracle/dfs/
> > > > /tmp/hadoop-oracle/mapred/
> > > >
> > > > If yes, how can I change the directory to anywhere else? I do not want
> > it to
> > > > be kept in /tmp folder.
> > > >
> > > >> From: amansk@gmail.com
> > > >> Date: Mon, 3 Aug 2009 17:02:50 -0700
> > > >> Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
> > > >> To: common-user@hadoop.apache.org
> > > >>
> > > >> I'm assuming that you have no data in HDFS since it never came up...
> > So,
> > > >> go
> > > >> ahead and clean up the directory where you are storing the datanode's
> > data
> > > >> and the namenode's metadata. After that format the namenode and
> > restart
> > > >> hadoop.
> > > >>
> > > >>
> > > >> 2009/8/3 Onur AKTAS <onur.aktas@live.com>
> > > >>
> > > >> >
> > > >> > Hi,
> > > >> >
> > > >> > I'm having troubles with running Hadoop in RHEL 5, I did everything
> > as
> > > >> > documented in:
> > > >> > http://hadoop.apache.org/common/docs/r0.20.0/quickstart.html
> > > >> >
> > > >> > And configured:
> > > >> > conf/core-site.xml, conf/hdfs-site.xml,
> > > >> > conf/mapred-site.xml.
> > > >> >
> > > >> > Connected to "localhost" with ssh (did passphrase stuff etc.), then
> > I
> > > >> > did
> > > >> > the following:
> > > >> >
> > > >> > $ bin/hadoop namenode -format
> > > >> > $ bin/start-all.sh
> > > >> > starting namenode, logging to
> > > >> >
> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-namenode-localhost.localdomain.out
> > > >> > localhost: starting datanode, logging to
> > > >> >
> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-datanode-localhost.localdomain.out
> > > >> > localhost: starting secondarynamenode, logging to
> > > >> >
> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-secondarynamenode-localhost.localdomain.out
> > > >> > starting jobtracker, logging to
> > > >> >
> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-jobtracker-localhost.localdomain.out
> > > >> > localhost: starting tasktracker, logging to
> > > >> >
> > /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-tasktracker-localhost.localdomain.out
> > > >> >
> > > >> > Everything seems ok, but when I check the Hadoop Logs I see many
> > errors.
> > > >> > (and they all cause HBase connection problems.)
> > > >> > How can I solve this problem? Here are the Logs
> > > >> >
> > > >> >  hadoop-oracle-datanode-localhost.localdomain.log:
> > > >> > 2009-08-04 02:54:28,971 INFO
> > > >> > org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
> > > >> > /************************************************************
> > > >> > STARTUP_MSG: Starting DataNode
> > > >> > STARTUP_MSG:   host = localhost.localdomain/127.0.0.1
> > > >> > STARTUP_MSG:   args = []
> > > >> > STARTUP_MSG:   version = 0.20.0
> > > >> > STARTUP_MSG:   build =
> > > >> > https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20-r
> > > >> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> > > >> > ************************************************************/
> > > >> > 2009-08-04 02:54:29,562 ERROR
> > > >> > org.apache.hadoop.hdfs.server.datanode.DataNode:
> > java.io.IOException:
> > > >> > Incompatible namespaceIDs in /tmp/hadoop-oracle/dfs/data: namenode
> > > >> > namespaceID = 36527197; datanode namespaceID = 2138759529
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:233)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:148)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:298)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:216)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1283)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1238)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1246)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1368)
> > > >> >
> > > >> > 2009-08-04 02:54:29,563 INFO
> > > >> > org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
> > > >> > /************************************************************
> > > >> > SHUTDOWN_MSG: Shutting down DataNode at localhost.localdomain/
> > 127.0.0.1
> > > >> > ************************************************************/
> > > >> >
> > > >> >
> > ------------------------------------------------------------------------------------------
> > > >> > hadoop-oracle-namenode-localhost.localdomain.log
> > > >> > 2009-08-04 02:54:26,987 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG:
> > > >> > /************************************************************
> > > >> > STARTUP_MSG: Starting NameNode
> > > >> > STARTUP_MSG:   host = localhost.localdomain/127.0.0.1
> > > >> > STARTUP_MSG:   args = []
> > > >> > STARTUP_MSG:   version = 0.20.0
> > > >> > STARTUP_MSG:   build =
> > > >> > https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20-r
> > > >> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> > > >> > ************************************************************/
> > > >> > 2009-08-04 02:54:27,116 INFO
> > org.apache.hadoop.ipc.metrics.RpcMetrics:
> > > >> > Initializing RPC Metrics with hostName=NameNode, port=9000
> > > >> > 2009-08-04 02:54:27,174 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at:
> > > >> > localhost.localdomain/127.0.0.1:9000
> > > >> > 2009-08-04 02:54:27,179 INFO
> > org.apache.hadoop.metrics.jvm.JvmMetrics:
> > > >> > Initializing JVM Metrics with processName=NameNode, sessionId=null
> > > >> > 2009-08-04 02:54:27,180 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics:
> > > >> > Initializing
> > > >> > NameNodeMeterics using context
> > > >> > object:org.apache.hadoop.metrics.spi.NullContext
> > > >> > 2009-08-04 02:54:27,278 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > > >> > fsOwner=oracle,oinstall,root,dba,oper,asmadmin
> > > >> > 2009-08-04 02:54:27,278 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > > >> > supergroup=supergroup
> > > >> > 2009-08-04 02:54:27,278 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > > >> > isPermissionEnabled=true
> > > >> > 2009-08-04 02:54:27,294 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics:
> > > >> > Initializing FSNamesystemMetrics using context
> > > >> > object:org.apache.hadoop.metrics.spi.NullContext
> > > >> > 2009-08-04 02:54:27,297 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered
> > > >> > FSNamesystemStatusMBean
> > > >> > 2009-08-04 02:54:27,341 INFO
> > > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > > >> > Number of files = 8
> > > >> > 2009-08-04 02:54:27,348 INFO
> > > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > > >> > Number of files under construction = 2
> > > >> > 2009-08-04 02:54:27,351 INFO
> > > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > > >> > Image file of size 923 loaded in 0 seconds.
> > > >> > 2009-08-04 02:54:27,351 INFO
> > > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > > >> > Edits file /tmp/hadoop-oracle/dfs/name/current/edits of size 4 edits
> > # 0
> > > >> > loaded in 0 seconds.
> > > >> > 2009-08-04 02:54:27,435 INFO
> > > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > > >> > Image file of size 923 saved in 0 seconds.
> > > >> > 2009-08-04 02:54:27,495 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished
> > loading
> > > >> > FSImage in 262 msecs
> > > >> > 2009-08-04 02:54:27,496 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of
> > > >> > blocks
> > > >> > = 0
> > > >> > 2009-08-04 02:54:27,496 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> > invalid
> > > >> > blocks = 0
> > > >> > 2009-08-04 02:54:27,497 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> > > >> > under-replicated blocks = 0
> > > >> > 2009-08-04 02:54:27,497 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> > > >> >  over-replicated blocks = 0
> > > >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange:
> > STATE*
> > > >> > Leaving safe mode after 0 secs.
> > > >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange:
> > STATE*
> > > >> > Network topology has 0 racks and 0 datanodes
> > > >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChange:
> > STATE*
> > > >> > UnderReplicatedBlocks has 0 blocks
> > > >> > 2009-08-04 02:54:27,696 INFO org.mortbay.log: Logging to
> > > >> > org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via
> > > >> > org.mortbay.log.Slf4jLog
> > > >> > 2009-08-04 02:54:27,775 INFO org.apache.hadoop.http.HttpServer:
> > Jetty
> > > >> > bound
> > > >> > to port 50070
> > > >> > 2009-08-04 02:54:27,775 INFO org.mortbay.log: jetty-6.1.14
> > > >> > 2009-08-04 02:54:28,277 INFO org.mortbay.log: Started
> > > >> > SelectChannelConnector@0.0.0.0:50070
> > > >> > 2009-08-04 02:54:28,278 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at:
> > > >> > 0.0.0.0:50070
> > > >> > 2009-08-04 02:54:28,278 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > Responder: starting
> > > >> > 2009-08-04 02:54:28,279 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > listener on 9000: starting
> > > >> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 0 on 9000: starting
> > > >> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 1 on 9000: starting
> > > >> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 2 on 9000: starting
> > > >> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 3 on 9000: starting
> > > >> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 4 on 9000: starting
> > > >> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 5 on 9000: starting
> > > >> > 2009-08-04 02:54:28,328 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 6 on 9000: starting
> > > >> > 2009-08-04 02:54:28,361 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 7 on 9000: starting
> > > >> > 2009-08-04 02:54:28,362 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 8 on 9000: starting
> > > >> > 2009-08-04 02:54:28,366 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 9 on 9000: starting
> > > >> > 2009-08-04 02:54:38,433 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> > > >> >  cmd=listStatus    src=/tmp/hadoop-oracle/mapred/system    dst=null
> > > >> >  perm=null
> > > >> > 2009-08-04 02:54:38,755 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> > > >> > cmd=delete
> > > >> >    src=/tmp/hadoop-oracle/mapred/system    dst=null    perm=null
> > > >> > 2009-08-04 02:54:38,773 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> > > >> > cmd=mkdirs
> > > >> >    src=/tmp/hadoop-oracle/mapred/system    dst=null
> > > >> >  perm=oracle:supergroup:rwxr-xr-x
> > > >> > 2009-08-04 02:54:38,785 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> > > >> >  cmd=setPermission    src=/tmp/hadoop-oracle/mapred/system
> >  dst=null
> > > >> >  perm=oracle:supergroup:rwx-wx-wx
> > > >> > 2009-08-04 02:54:38,862 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> > > >> > cmd=create
> > > >> >    src=/tmp/hadoop-oracle/mapred/system/jobtracker.info    dst=null
> > > >> >  perm=oracle:supergroup:rw-r--r--
> > > >> > 2009-08-04 02:54:38,900 INFO
> > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > >> > ugi=oracle,oinstall,root,dba,oper,asmadmin    ip=/127.0.0.1
> > > >> >  cmd=setPermission
> > > >> > src=/tmp/hadoop-oracle/mapred/system/jobtracker.info   dst=null
> > > >> > perm=oracle:supergroup:rw-------
> > > >> > 2009-08-04 02:54:38,955 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 4 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> > > >> > java.io.IOException: File
> > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > replicated
> > > >> > to 0 nodes, instead of 1
> > > >> > java.io.IOException: File
> > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > replicated
> > > >> > to 0 nodes, instead of 1
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> > > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > > >> >    at
> > > >> >
> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> > > >> >    at
> > > >> >
> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> > > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > > >> >    at java.security.AccessController.doPrivileged(Native Method)
> > > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > > >> > 2009-08-04 02:54:39,548 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 5 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> > > >> > java.io.IOException: File
> > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > replicated
> > > >> > to 0 nodes, instead of 1
> > > >> > java.io.IOException: File
> > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > replicated
> > > >> > to 0 nodes, instead of 1
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> > > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > > >> >    at
> > > >> >
> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> > > >> >    at
> > > >> >
> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> > > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > > >> >    at java.security.AccessController.doPrivileged(Native Method)
> > > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > > >> > 2009-08-04 02:54:40,359 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 6 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> > > >> > java.io.IOException: File
> > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > replicated
> > > >> > to 0 nodes, instead of 1
> > > >> > java.io.IOException: File
> > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > replicated
> > > >> > to 0 nodes, instead of 1
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> > > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > > >> >    at
> > > >> >
> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> > > >> >    at
> > > >> >
> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> > > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > > >> >    at java.security.AccessController.doPrivileged(Native Method)
> > > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > > >> > 2009-08-04 02:54:41,969 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 7 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> > > >> > java.io.IOException: File
> > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > replicated
> > > >> > to 0 nodes, instead of 1
> > > >> > java.io.IOException: File
> > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > replicated
> > > >> > to 0 nodes, instead of 1
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> > > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > > >> >    at
> > > >> >
> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> > > >> >    at
> > > >> >
> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> > > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > > >> >    at java.security.AccessController.doPrivileged(Native Method)
> > > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > > >> > 2009-08-04 02:54:45,180 INFO org.apache.hadoop.ipc.Server: IPC
> > Server
> > > >> > handler 8 on 9000, call addBlock(/tmp/hadoop-oracle/mapred/system/
> > > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803: error:
> > > >> > java.io.IOException: File
> > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > replicated
> > > >> > to 0 nodes, instead of 1
> > > >> > java.io.IOException: File
> > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > replicated
> > > >> > to 0 nodes, instead of 1
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1256)
> > > >> >    at
> > > >> >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:422)
> > > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > > >> >    at
> > > >> >
> > sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> > > >> >    at
> > > >> >
> > sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> > > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > > >> >    at java.security.AccessController.doPrivileged(Native Method)
> > > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
> > > >> >
> > > >> >
> > > >> >
> > > >> > _________________________________________________________________
> > > >> > Windows Live ile fotoraflarnz organize edebilir, dzenleyebilir
> > ve
> > > >> > paylaabilirsiniz.
> > > >> >
> > > >> >
> > http://www.microsoft.com/turkiye/windows/windowslive/products/photo-gallery-edit.aspx
> > > >
> > > > _________________________________________________________________
> > > > Windows Live tm arkadalarnzla tek bir yerden iletiim kurmanza
> > yardmc
> > > > olur.
> > > >
> > http://www.microsoft.com/turkiye/windows/windowslive/products/social-network-connector.aspx
> > >
> > >
> > > --
> > >
> > >
> > > Amandeep Khurana
> > > Computer Science Graduate Student
> > > University of California, Santa Cruz
> >
> > _________________________________________________________________
> > Sadece e-posta iletilerinden daha fazlas: Dier Windows Live(tm)
> > zelliklerine gz atn.
> > http://www.microsoft.com/turkiye/windows/windowslive/
> >

_________________________________________________________________
Windows Live ile fotoraflarnz organize edebilir, dzenleyebilir ve paylaabilirsiniz.
http://www.microsoft.com/turkiye/windows/windowslive/products/photo-gallery-edit.aspx
--_1a3807fd-d618-4c58-8e0a-a796fc047452_--

From common-user-return-16537-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 01:25:57 2009
Return-Path: <common-user-return-16537-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 12173 invoked from network); 4 Aug 2009 01:25:57 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 01:25:57 -0000
Received: (qmail 9446 invoked by uid 500); 4 Aug 2009 01:25:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 9366 invoked by uid 500); 4 Aug 2009 01:25:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 9356 invoked by uid 99); 4 Aug 2009 01:25:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 01:25:59 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of amansk@gmail.com designates 209.85.211.202 as permitted sender)
Received: from [209.85.211.202] (HELO mail-yw0-f202.google.com) (209.85.211.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 01:25:49 +0000
Received: by ywh40 with SMTP id 40so4442589ywh.29
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 18:25:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=O4XMihLk5lmGn7mAhFJN3ac8JfmPKyMV45A350uMHl4=;
        b=P6CcxAVpgA+8at7ASGXTMrzb/ZDY9P1CJNkwn/gXcTHPHXDCe41XrUEAd4uNDxu2Eb
         86mmmuYr/qWaKnOA/4clFJnHJVFbDLCEvCO56wcJ3ZR5HzO5HxIkf+1pNJSi7lTwGTng
         QLgI0JWljypNzcty7953podlSyjIgVv73ike0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=eQGfgD41nMrfGpllo/GXj5q1lLEYmxqjSf9IqXfoLg2KRUluJWOw5qbaWlGTqAP2YU
         PZW9qyH0vV4wfLT5ImXkveHA9UblQdYWhE/pJwTbwXCbhtiLhzhcX84Js3LW21xolRSW
         X22IeRSiTBQx3cNP5ULJn3i8QUVWenQbUd4Og=
MIME-Version: 1.0
Received: by 10.100.151.5 with SMTP id y5mr8002865and.176.1249349128169; Mon, 
	03 Aug 2009 18:25:28 -0700 (PDT)
In-Reply-To: <BAY107-W229FBBE97806C8113310A8E70C0@phx.gbl>
References: <BAY107-W82FB176A70E2FBD18D043E70F0@phx.gbl> <35a22e220908031702n629c3ac0l22a25bd140d571ff@mail.gmail.com> 
	<BAY107-W5420D81B2F5CFD1AE5D9F6E70C0@phx.gbl> <35a22e220908031729k3ffbab3ftf51dfe979bc147cb@mail.gmail.com> 
	<BAY107-W62282DAE8C264A7C186AFE70C0@phx.gbl> <35a22e220908031748h67cd3601he117f66d223e363@mail.gmail.com> 
	<BAY107-W229FBBE97806C8113310A8E70C0@phx.gbl>
From: Amandeep Khurana <amansk@gmail.com>
Date: Mon, 3 Aug 2009 18:25:08 -0700
Message-ID: <35a22e220908031825m7ea50243x81cc3edcb6d57e51@mail.gmail.com>
Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e644cf72fc285e047046c2f9
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e644cf72fc285e047046c2f9
Content-Type: text/plain; charset=ISO-8859-9
Content-Transfer-Encoding: quoted-printable

No probs.

I hope you got the data directory to point out of /tmp as well... If not, d=
o
that as well. Otherwise, when the /tmp gets cleaned up, you'll lose your
data.



Amandeep Khurana
Computer Science Graduate Student
University of California, Santa Cruz


2009/8/3 Onur AKTAS <onur.aktas@live.com>

>
> Thank you very much!
>
> I added tags below to conf/core-site.xml and reformatted it again..
> it started without any problems and I also started HBase and connected it
> with a client!
>
> <property>
>    <name>hadoop.tmp.dir</name>
>     <value>/tmp/hadoop-onur</value>
>     <description>A base for other temporary directories.</description>
>   </property>
>
> Thank you again..
>
> > From: amansk@gmail.com
> > Date: Mon, 3 Aug 2009 17:48:24 -0700
> > Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mode
> > To: common-user@hadoop.apache.org
> >
> > 1. The default xmls are in $HADOOP_HOME/build/classes
> > 2. You have to ovverride the parameters and put them in the site.xml's =
so
> > you can have it in some other directory and not /tmp
> >
> > Do that and try starting hadoop.
> >
> >
> > Amandeep Khurana
> > Computer Science Graduate Student
> > University of California, Santa Cruz
> >
> >
> > 2009/8/3 Onur AKTAS <onur.aktas@live.com>
> >
> > >
> > > There is no default.xml in Hadoop 0.20.0, but luckly I also have
> release
> > > 0.18.3 and found these..
> > >
> > > <property>
> > >  <name>hadoop.tmp.dir</name>
> > >  <value>/tmp/hadoop-${user.name}</value>
> > >  <description>A base for other temporary directories.</description>
> > > </property>
> > >
> > > It seems /tmp/hadoop-${user.name} is a temporary directory as
> description
> > > indicates, then where is the real directory?
> > > I deleted whole tmp directory and formatted it again.. Started the
> server,
> > > checked the logs and still have same errors.
> > >
> > > > Date: Mon, 3 Aug 2009 17:29:52 -0700
> > > > Subject: Re: Problem with starting Hadoop in Pseudo Distributed Mod=
e
> > > > From: amansk@gmail.com
> > > > To: common-user@hadoop.apache.org
> > > >
> > > > Yes, you need to change these directories. The config is put in the
> > > > hadoop-site.xml. Or in this case, separately in the 3 xmls. See the
> > > > default xml for syntax and property name.
> > > >
> > > > On 8/3/09, Onur AKTAS <onur.aktas@live.com> wrote:
> > > > >
> > > > > Is it the directory that Hadoop uses?
> > > > >
> > > > > /tmp/hadoop-oracle
> > > > > /tmp/hadoop-oracle/dfs/
> > > > > /tmp/hadoop-oracle/mapred/
> > > > >
> > > > > If yes, how can I change the directory to anywhere else? I do not
> want
> > > it to
> > > > > be kept in /tmp folder.
> > > > >
> > > > >> From: amansk@gmail.com
> > > > >> Date: Mon, 3 Aug 2009 17:02:50 -0700
> > > > >> Subject: Re: Problem with starting Hadoop in Pseudo Distributed
> Mode
> > > > >> To: common-user@hadoop.apache.org
> > > > >>
> > > > >> I'm assuming that you have no data in HDFS since it never came
> up...
> > > So,
> > > > >> go
> > > > >> ahead and clean up the directory where you are storing the
> datanode's
> > > data
> > > > >> and the namenode's metadata. After that format the namenode and
> > > restart
> > > > >> hadoop.
> > > > >>
> > > > >>
> > > > >> 2009/8/3 Onur AKTAS <onur.aktas@live.com>
> > > > >>
> > > > >> >
> > > > >> > Hi,
> > > > >> >
> > > > >> > I'm having troubles with running Hadoop in RHEL 5, I did
> everything
> > > as
> > > > >> > documented in:
> > > > >> > http://hadoop.apache.org/common/docs/r0.20.0/quickstart.html
> > > > >> >
> > > > >> > And configured:
> > > > >> > conf/core-site.xml, conf/hdfs-site.xml,
> > > > >> > conf/mapred-site.xml.
> > > > >> >
> > > > >> > Connected to "localhost" with ssh (did passphrase stuff etc.),
> then
> > > I
> > > > >> > did
> > > > >> > the following:
> > > > >> >
> > > > >> > $ bin/hadoop namenode -format
> > > > >> > $ bin/start-all.sh
> > > > >> > starting namenode, logging to
> > > > >> >
> > >
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-namenode-localhost.local=
domain.out
> > > > >> > localhost: starting datanode, logging to
> > > > >> >
> > >
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-datanode-localhost.local=
domain.out
> > > > >> > localhost: starting secondarynamenode, logging to
> > > > >> >
> > >
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-secondarynamenode-localh=
ost.localdomain.out
> > > > >> > starting jobtracker, logging to
> > > > >> >
> > >
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-jobtracker-localhost.loc=
aldomain.out
> > > > >> > localhost: starting tasktracker, logging to
> > > > >> >
> > >
> /hda3/ps/hadoop-0.20.0/bin/../logs/hadoop-oracle-tasktracker-localhost.lo=
caldomain.out
> > > > >> >
> > > > >> > Everything seems ok, but when I check the Hadoop Logs I see ma=
ny
> > > errors.
> > > > >> > (and they all cause HBase connection problems.)
> > > > >> > How can I solve this problem? Here are the Logs
> > > > >> >
> > > > >> >  hadoop-oracle-datanode-localhost.localdomain.log:
> > > > >> > 2009-08-04 02:54:28,971 INFO
> > > > >> > org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
> > > > >> > /************************************************************
> > > > >> > STARTUP_MSG: Starting DataNode
> > > > >> > STARTUP_MSG:   host =3D localhost.localdomain/127.0.0.1
> > > > >> > STARTUP_MSG:   args =3D []
> > > > >> > STARTUP_MSG:   version =3D 0.20.0
> > > > >> > STARTUP_MSG:   build =3D
> > > > >> >
> https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20-r
> > > > >> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> > > > >> > ************************************************************/
> > > > >> > 2009-08-04 02:54:29,562 ERROR
> > > > >> > org.apache.hadoop.hdfs.server.datanode.DataNode:
> > > java.io.IOException:
> > > > >> > Incompatible namespaceIDs in /tmp/hadoop-oracle/dfs/data:
> namenode
> > > > >> > namespaceID =3D 36527197; datanode namespaceID =3D 2138759529
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStora=
ge.java:233)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(=
DataStorage.java:148)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.ja=
va:298)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:216)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.jav=
a:1283)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataN=
ode.java:1238)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.j=
ava:1246)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1368)
> > > > >> >
> > > > >> > 2009-08-04 02:54:29,563 INFO
> > > > >> > org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
> > > > >> > /************************************************************
> > > > >> > SHUTDOWN_MSG: Shutting down DataNode at localhost.localdomain/
> > > 127.0.0.1
> > > > >> > ************************************************************/
> > > > >> >
> > > > >> >
> > >
> -------------------------------------------------------------------------=
-----------------
> > > > >> > hadoop-oracle-namenode-localhost.localdomain.log
> > > > >> > 2009-08-04 02:54:26,987 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG:
> > > > >> > /************************************************************
> > > > >> > STARTUP_MSG: Starting NameNode
> > > > >> > STARTUP_MSG:   host =3D localhost.localdomain/127.0.0.1
> > > > >> > STARTUP_MSG:   args =3D []
> > > > >> > STARTUP_MSG:   version =3D 0.20.0
> > > > >> > STARTUP_MSG:   build =3D
> > > > >> >
> https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20-r
> > > > >> > 763504; compiled by 'ndaley' on Thu Apr  9 05:18:40 UTC 2009
> > > > >> > ************************************************************/
> > > > >> > 2009-08-04 02:54:27,116 INFO
> > > org.apache.hadoop.ipc.metrics.RpcMetrics:
> > > > >> > Initializing RPC Metrics with hostName=3DNameNode, port=3D9000
> > > > >> > 2009-08-04 02:54:27,174 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up a=
t:
> > > > >> > localhost.localdomain/127.0.0.1:9000
> > > > >> > 2009-08-04 02:54:27,179 INFO
> > > org.apache.hadoop.metrics.jvm.JvmMetrics:
> > > > >> > Initializing JVM Metrics with processName=3DNameNode,
> sessionId=3Dnull
> > > > >> > 2009-08-04 02:54:27,180 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics=
:
> > > > >> > Initializing
> > > > >> > NameNodeMeterics using context
> > > > >> > object:org.apache.hadoop.metrics.spi.NullContext
> > > > >> > 2009-08-04 02:54:27,278 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > > > >> > fsOwner=3Doracle,oinstall,root,dba,oper,asmadmin
> > > > >> > 2009-08-04 02:54:27,278 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > > > >> > supergroup=3Dsupergroup
> > > > >> > 2009-08-04 02:54:27,278 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem:
> > > > >> > isPermissionEnabled=3Dtrue
> > > > >> > 2009-08-04 02:54:27,294 INFO
> > > > >> >
> org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics:
> > > > >> > Initializing FSNamesystemMetrics using context
> > > > >> > object:org.apache.hadoop.metrics.spi.NullContext
> > > > >> > 2009-08-04 02:54:27,297 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registere=
d
> > > > >> > FSNamesystemStatusMBean
> > > > >> > 2009-08-04 02:54:27,341 INFO
> > > > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > > > >> > Number of files =3D 8
> > > > >> > 2009-08-04 02:54:27,348 INFO
> > > > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > > > >> > Number of files under construction =3D 2
> > > > >> > 2009-08-04 02:54:27,351 INFO
> > > > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > > > >> > Image file of size 923 loaded in 0 seconds.
> > > > >> > 2009-08-04 02:54:27,351 INFO
> > > > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > > > >> > Edits file /tmp/hadoop-oracle/dfs/name/current/edits of size 4
> edits
> > > # 0
> > > > >> > loaded in 0 seconds.
> > > > >> > 2009-08-04 02:54:27,435 INFO
> > > > >> > org.apache.hadoop.hdfs.server.common.Storage:
> > > > >> > Image file of size 923 saved in 0 seconds.
> > > > >> > 2009-08-04 02:54:27,495 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished
> > > loading
> > > > >> > FSImage in 262 msecs
> > > > >> > 2009-08-04 02:54:27,496 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total
> number of
> > > > >> > blocks
> > > > >> > =3D 0
> > > > >> > 2009-08-04 02:54:27,496 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> > > invalid
> > > > >> > blocks =3D 0
> > > > >> > 2009-08-04 02:54:27,497 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> > > > >> > under-replicated blocks =3D 0
> > > > >> > 2009-08-04 02:54:27,497 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of
> > > > >> >  over-replicated blocks =3D 0
> > > > >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChang=
e:
> > > STATE*
> > > > >> > Leaving safe mode after 0 secs.
> > > > >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChang=
e:
> > > STATE*
> > > > >> > Network topology has 0 racks and 0 datanodes
> > > > >> > 2009-08-04 02:54:27,497 INFO org.apache.hadoop.hdfs.StateChang=
e:
> > > STATE*
> > > > >> > UnderReplicatedBlocks has 0 blocks
> > > > >> > 2009-08-04 02:54:27,696 INFO org.mortbay.log: Logging to
> > > > >> > org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via
> > > > >> > org.mortbay.log.Slf4jLog
> > > > >> > 2009-08-04 02:54:27,775 INFO org.apache.hadoop.http.HttpServer=
:
> > > Jetty
> > > > >> > bound
> > > > >> > to port 50070
> > > > >> > 2009-08-04 02:54:27,775 INFO org.mortbay.log: jetty-6.1.14
> > > > >> > 2009-08-04 02:54:28,277 INFO org.mortbay.log: Started
> > > > >> > SelectChannelConnector@0.0.0.0:50070
> > > > >> > 2009-08-04 02:54:28,278 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up
> at:
> > > > >> > 0.0.0.0:50070
> > > > >> > 2009-08-04 02:54:28,278 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > Responder: starting
> > > > >> > 2009-08-04 02:54:28,279 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > listener on 9000: starting
> > > > >> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 0 on 9000: starting
> > > > >> > 2009-08-04 02:54:28,280 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 1 on 9000: starting
> > > > >> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 2 on 9000: starting
> > > > >> > 2009-08-04 02:54:28,316 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 3 on 9000: starting
> > > > >> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 4 on 9000: starting
> > > > >> > 2009-08-04 02:54:28,321 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 5 on 9000: starting
> > > > >> > 2009-08-04 02:54:28,328 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 6 on 9000: starting
> > > > >> > 2009-08-04 02:54:28,361 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 7 on 9000: starting
> > > > >> > 2009-08-04 02:54:28,362 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 8 on 9000: starting
> > > > >> > 2009-08-04 02:54:28,366 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 9 on 9000: starting
> > > > >> > 2009-08-04 02:54:38,433 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.=
1
> > > > >> >  cmd=3DlistStatus    src=3D/tmp/hadoop-oracle/mapred/system
>  dst=3Dnull
> > > > >> >  perm=3Dnull
> > > > >> > 2009-08-04 02:54:38,755 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.=
1
> > > > >> > cmd=3Ddelete
> > > > >> >    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dnull    per=
m=3Dnull
> > > > >> > 2009-08-04 02:54:38,773 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.=
1
> > > > >> > cmd=3Dmkdirs
> > > > >> >    src=3D/tmp/hadoop-oracle/mapred/system    dst=3Dnull
> > > > >> >  perm=3Doracle:supergroup:rwxr-xr-x
> > > > >> > 2009-08-04 02:54:38,785 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.=
1
> > > > >> >  cmd=3DsetPermission    src=3D/tmp/hadoop-oracle/mapred/system
> > >  dst=3Dnull
> > > > >> >  perm=3Doracle:supergroup:rwx-wx-wx
> > > > >> > 2009-08-04 02:54:38,862 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.=
1
> > > > >> > cmd=3Dcreate
> > > > >> >    src=3D/tmp/hadoop-oracle/mapred/system/jobtracker.info
>  dst=3Dnull
> > > > >> >  perm=3Doracle:supergroup:rw-r--r--
> > > > >> > 2009-08-04 02:54:38,900 INFO
> > > > >> > org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit:
> > > > >> > ugi=3Doracle,oinstall,root,dba,oper,asmadmin    ip=3D/127.0.0.=
1
> > > > >> >  cmd=3DsetPermission
> > > > >> > src=3D/tmp/hadoop-oracle/mapred/system/jobtracker.info   dst=
=3Dnull
> > > > >> > perm=3Doracle:supergroup:rw-------
> > > > >> > 2009-08-04 02:54:38,955 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 4 on 9000, call
> addBlock(/tmp/hadoop-oracle/mapred/system/
> > > > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803:
> error:
> > > > >> > java.io.IOException: File
> > > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > > replicated
> > > > >> > to 0 nodes, instead of 1
> > > > >> > java.io.IOException: File
> > > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > > replicated
> > > > >> > to 0 nodes, instead of 1
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
> > > > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native
> Method)
> > > > >> >    at
> > > > >> >
> > >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> > > > >> >    at
> > > > >> >
> > >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> > > > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > > > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > > > >> >    at
> org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > > > >> >    at
> org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > > > >> >    at java.security.AccessController.doPrivileged(Native Metho=
d)
> > > > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > > > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953=
)
> > > > >> > 2009-08-04 02:54:39,548 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 5 on 9000, call
> addBlock(/tmp/hadoop-oracle/mapred/system/
> > > > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803:
> error:
> > > > >> > java.io.IOException: File
> > > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > > replicated
> > > > >> > to 0 nodes, instead of 1
> > > > >> > java.io.IOException: File
> > > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > > replicated
> > > > >> > to 0 nodes, instead of 1
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
> > > > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native
> Method)
> > > > >> >    at
> > > > >> >
> > >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> > > > >> >    at
> > > > >> >
> > >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> > > > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > > > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > > > >> >    at
> org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > > > >> >    at
> org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > > > >> >    at java.security.AccessController.doPrivileged(Native Metho=
d)
> > > > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > > > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953=
)
> > > > >> > 2009-08-04 02:54:40,359 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 6 on 9000, call
> addBlock(/tmp/hadoop-oracle/mapred/system/
> > > > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803:
> error:
> > > > >> > java.io.IOException: File
> > > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > > replicated
> > > > >> > to 0 nodes, instead of 1
> > > > >> > java.io.IOException: File
> > > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > > replicated
> > > > >> > to 0 nodes, instead of 1
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
> > > > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native
> Method)
> > > > >> >    at
> > > > >> >
> > >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> > > > >> >    at
> > > > >> >
> > >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> > > > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > > > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > > > >> >    at
> org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > > > >> >    at
> org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > > > >> >    at java.security.AccessController.doPrivileged(Native Metho=
d)
> > > > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > > > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953=
)
> > > > >> > 2009-08-04 02:54:41,969 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 7 on 9000, call
> addBlock(/tmp/hadoop-oracle/mapred/system/
> > > > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803:
> error:
> > > > >> > java.io.IOException: File
> > > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > > replicated
> > > > >> > to 0 nodes, instead of 1
> > > > >> > java.io.IOException: File
> > > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > > replicated
> > > > >> > to 0 nodes, instead of 1
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
> > > > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native
> Method)
> > > > >> >    at
> > > > >> >
> > >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> > > > >> >    at
> > > > >> >
> > >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> > > > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > > > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > > > >> >    at
> org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > > > >> >    at
> org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > > > >> >    at java.security.AccessController.doPrivileged(Native Metho=
d)
> > > > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > > > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953=
)
> > > > >> > 2009-08-04 02:54:45,180 INFO org.apache.hadoop.ipc.Server: IPC
> > > Server
> > > > >> > handler 8 on 9000, call
> addBlock(/tmp/hadoop-oracle/mapred/system/
> > > > >> > jobtracker.info, DFSClient_-603868025) from 127.0.0.1:51803:
> error:
> > > > >> > java.io.IOException: File
> > > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > > replicated
> > > > >> > to 0 nodes, instead of 1
> > > > >> > java.io.IOException: File
> > > > >> > /tmp/hadoop-oracle/mapred/system/jobtracker.infocould only be
> > > replicated
> > > > >> > to 0 nodes, instead of 1
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FS=
Namesystem.java:1256)
> > > > >> >    at
> > > > >> >
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:42=
2)
> > > > >> >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native
> Method)
> > > > >> >    at
> > > > >> >
> > >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> > > > >> >    at
> > > > >> >
> > >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> > > > >> >    at java.lang.reflect.Method.invoke(Method.java:597)
> > > > >> >    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
> > > > >> >    at
> org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
> > > > >> >    at
> org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
> > > > >> >    at java.security.AccessController.doPrivileged(Native Metho=
d)
> > > > >> >    at javax.security.auth.Subject.doAs(Subject.java:396)
> > > > >> >    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953=
)
> > > > >> >
> > > > >> >
> > > > >> >
> > > > >> >
> _________________________________________________________________
> > > > >> > Windows Live ile foto=F0raflar=FDn=FDz=FD organize edebilir,
> d=FCzenleyebilir
> > > ve
> > > > >> > payla=FEabilirsiniz.
> > > > >> >
> > > > >> >
> > >
> http://www.microsoft.com/turkiye/windows/windowslive/products/photo-galle=
ry-edit.aspx
> > > > >
> > > > > _________________________________________________________________
> > > > > Windows Live t=FCm arkada=FElar=FDn=FDzla tek bir yerden ileti=FE=
im kurman=FDza
> > > yard=FDmc=FD
> > > > > olur.
> > > > >
> > >
> http://www.microsoft.com/turkiye/windows/windowslive/products/social-netw=
ork-connector.aspx
> > > >
> > > >
> > > > --
> > > >
> > > >
> > > > Amandeep Khurana
> > > > Computer Science Graduate Student
> > > > University of California, Santa Cruz
> > >
> > > _________________________________________________________________
> > > Sadece e-posta iletilerinden daha fazlas=FD: Di=F0er Windows Live(tm)
> > > =F6zelliklerine g=F6z at=FDn.
> > > http://www.microsoft.com/turkiye/windows/windowslive/
> > >
>
> _________________________________________________________________
> Windows Live ile foto=F0raflar=FDn=FDz=FD organize edebilir, d=FCzenleyeb=
ilir ve
> payla=FEabilirsiniz.
>
> http://www.microsoft.com/turkiye/windows/windowslive/products/photo-galle=
ry-edit.aspx
>

--0016e644cf72fc285e047046c2f9--

From common-user-return-16538-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 02:27:44 2009
Return-Path: <common-user-return-16538-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 40929 invoked from network); 4 Aug 2009 02:27:44 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 02:27:44 -0000
Received: (qmail 65291 invoked by uid 500); 4 Aug 2009 02:27:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 65199 invoked by uid 500); 4 Aug 2009 02:27:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 65189 invoked by uid 99); 4 Aug 2009 02:27:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 02:27:47 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bharathvissapragada1990@gmail.com designates 209.85.221.188 as permitted sender)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 02:27:36 +0000
Received: by qyk26 with SMTP id 26so4661310qyk.5
        for <common-user@hadoop.apache.org>; Mon, 03 Aug 2009 19:27:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=heMOqHRyMyF4IzvzJ3M8z1D2nPy64SF8tVa3XLi9HwU=;
        b=ACoAGAkoHx330o9ar49Y0JZkYSCWidLfpeAL/QC2SAVLwQlNsEfaZX1Xr1OADT0bAh
         87fLaOVHXqD+lYVHORGD16lDDhW7XeYxe2rj/9eJ+zMWjoG02qZ69JlXqdxsea4T7FF2
         O1IhhZiNeZHGAAGRT7kX2wiRvVtuwGjA4mNm4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=oIHxMD5Aa4zBPv7UptqEYFGVAPfd31bR+v5XPmiMcLiYgD8dKq1E9s2cADlU4ZKjv7
         dKUEJPAZQmL5RO8+d/AzXz/rZ7WHLK7hTsSDavmqwgZKvVPtytflYS36PXlRUbLmvNl7
         KavYqt0wlp/JOy/YCrPN+S2YzQxZETkGBssK0=
MIME-Version: 1.0
Received: by 10.229.100.9 with SMTP id w9mr1495187qcn.31.1249352835684; Mon, 
	03 Aug 2009 19:27:15 -0700 (PDT)
In-Reply-To: <45f85f70908031221h256cd12bq10316f7a96ec6170@mail.gmail.com>
References: <73d592f60908031208p41a4fcb0ob90523eddfedd01e@mail.gmail.com> 
	<45f85f70908031221h256cd12bq10316f7a96ec6170@mail.gmail.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Tue, 4 Aug 2009 07:56:55 +0530
Message-ID: <73d592f60908031926x47775532j7debd2deed07aef9@mail.gmail.com>
Subject: Re: namenode -upgrade problem
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016364ed258f85a8a0470479fc0
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364ed258f85a8a0470479fc0
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Todd thanks for replying ..

I stopped the cluster and issued the command

"bin/hadoop namenode -upgrade" and iam getting this exception

09/08/04 07:52:39 ERROR namenode.NameNode: java.net.BindException: Problem
binding to master/10.2.24.21:54310 : Address already in use
    at org.apache.hadoop.ipc.Server.bind(Server.java:171)
    at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:234)
    at org.apache.hadoop.ipc.Server.<init>(Server.java:960)
    at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:465)
    at org.apache.hadoop.ipc.RPC.getServer(RPC.java:427)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:153)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
Caused by: java.net.BindException: Address already in use
    at sun.nio.ch.Net.bind(Native Method)
    at
sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:119)
    at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
    at org.apache.hadoop.ipc.Server.bind(Server.java:169)
    ... 9 more

any clue?

On Tue, Aug 4, 2009 at 12:51 AM, Todd Lipcon <todd@cloudera.com> wrote:

> On Mon, Aug 3, 2009 at 12:08 PM, bharath vissapragada <
> bharathvissapragada1990@gmail.com> wrote:
>
> > Hi all ,
> >
> > I have noticed some problem in my cluster when i changed the hadoop
> version
> > on the same DFS directory .. The namenode log on the master says the
> > following ..
> >
> >
> > ile system image contains an old layout version -16.
> > *An upgrade to version -18 is required.
> > Please restart NameNode with -upgrade option.
> > *
>
>
> See bolded text above -- you need to run namenode -upgrade to upgrade your
> metadata format to the current version.
>
> -Todd
>
>   at
> >
>
> >
> >
> org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> > 2009-08-04 00:27:51,498 INFO org.apache.hadoop.ipc.Server: Stopping
> server
> > on 54310
> > 2009-08-04 00:27:51,498 ERROR
> > org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException:
> > File system image contains an old layout version -16.
> > An upgrade to version -18 is required.
> > Please restart NameNode with -upgrade option.
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> >
> > 2009-08-04 00:27:51,499 INFO
> > org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG
> >
> > Can anyone explain me the reason ... i googled it .. but those
> explanations
> > weren't quite useful
> >
> > Thanks
> >
>

--0016364ed258f85a8a0470479fc0--

From common-user-return-16539-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 03:16:04 2009
Return-Path: <common-user-return-16539-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 55103 invoked from network); 4 Aug 2009 03:16:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 03:16:03 -0000
Received: (qmail 95459 invoked by uid 500); 4 Aug 2009 03:16:06 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95381 invoked by uid 500); 4 Aug 2009 03:16:05 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95371 invoked by uid 500); 4 Aug 2009 03:16:05 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 95368 invoked by uid 99); 4 Aug 2009 03:16:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 03:16:01 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of coderplay@gmail.com designates 72.14.220.155 as permitted sender)
Received: from [72.14.220.155] (HELO fg-out-1718.google.com) (72.14.220.155)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 03:15:51 +0000
Received: by fg-out-1718.google.com with SMTP id l26so585871fgb.12
        for <core-user@hadoop.apache.org>; Mon, 03 Aug 2009 20:15:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=l528vVhqD+szaV3i30fTErr5AdfmSpZzTsov1Enqi9Q=;
        b=YV33lfg49ybMANqljgyIx20rtWNVPNsQYWnfSSqNC9wnxH0HlDyjSpz6dzmfE9ayKO
         SID7YyB9bDnBy5reIOdy4Kc/XWlusT51tRjt8u1+WTxRpVMIl2DVQVfwbdHxQsQAkDWJ
         YjIcupAcNf9kAO586Hzr2XLPcblxojvl561xE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=aM2H4idaICaRR3wln8a8xjJ8xixG+bZoDuDMITzfbtEzRcGBubOToq/Ql5dCx6fte4
         0XSXwZvPkvOYCqF90AcKa+y+vqYfGtBSKZxDTBWNL5TBeGTNuHuhimwpZPG8erdvQIvu
         grHhAnygStBUlwNxf8FVQ7QaQ6LX1SwI2RAI8=
MIME-Version: 1.0
Received: by 10.239.132.205 with SMTP id 13mr628472hbs.168.1249355729882; Mon, 
	03 Aug 2009 20:15:29 -0700 (PDT)
Date: Tue, 4 Aug 2009 11:15:29 +0800
Message-ID: <bcaf338a0908032015h41cff744l1b0f74ea60cc32df@mail.gmail.com>
Subject: how to dump data from a mysql cluster to hdfs?
From: Min Zhou <coderplay@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f44bfe7a4ed10470484c93
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f44bfe7a4ed10470484c93
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

hi all,

We need to dump data from a mysql cluster with about 50 nodes to a hdfs
file. Considered about the issues on security , we can't use tools like
sqoop, where all datanodes must hold a connection to mysql. any suggestions?


Thanks,
Min
-- 
My research interests are distributed systems, parallel computing and
bytecode based virtual machine.

My profile:
http://www.linkedin.com/in/coderplay
My blog:
http://coderplay.javaeye.com

--001485f44bfe7a4ed10470484c93--

From common-user-return-16540-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 05:40:47 2009
Return-Path: <common-user-return-16540-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 83796 invoked from network); 4 Aug 2009 05:40:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 05:40:46 -0000
Received: (qmail 98386 invoked by uid 500); 4 Aug 2009 05:40:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 98304 invoked by uid 500); 4 Aug 2009 05:40:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 98294 invoked by uid 99); 4 Aug 2009 05:40:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 05:40:49 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 05:40:36 +0000
Received: from EGL-EX07CAS02.ds.corp.yahoo.com (egl-ex07cas02.eglbp.corp.yahoo.com [203.83.248.209])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n745dAhx015989
	for <common-user@hadoop.apache.org>; Mon, 3 Aug 2009 22:39:10 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=ZxSHRdoZJuPSqqwXlEaCqase8Lft13SoH48vGbIMdnnTzL1HPMn+q+yrpFpvB/4J
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.205]) by
 EGL-EX07CAS02.ds.corp.yahoo.com ([203.83.248.216]) with mapi; Tue, 4 Aug 2009
 11:09:09 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Tue, 4 Aug 2009 11:08:12 +0530
Subject: RE: Counting no. of keys.
Thread-Topic: Counting no. of keys.
Thread-Index: AcoUOqM2yXpWDu98RJ2MzKupqkEyFQAivyzw
Message-ID: <616DA47B2EF5B944B91846785B512FF4AAC0D53503@EGL-EX07VS01.ds.corp.yahoo.com>
References: <ac6e61fc0908012153o5f6f5ee9ocbcdef8b21dda20b@mail.gmail.com>
	 <c7d45fc70908012308i2764a7f4g1c86dfe90880194e@mail.gmail.com>
 <de9d20b80908030601y7dc91ce5m34e6e913a65ec149@mail.gmail.com>
In-Reply-To: <de9d20b80908030601y7dc91ce5m34e6e913a65ec149@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Have you had a look at the reporter.counter hadoop provides? I think it mig=
ht be helpful in your case, where in you can locally aggregate for each map=
 task and then push it to global counter.

-----Original Message-----
From: Zhong Wang [mailto:wangzhong.neu@gmail.com]=20
Sent: Monday, August 03, 2009 6:31 PM
To: common-user@hadoop.apache.org
Subject: Re: Counting no. of keys.

I have the same question, but i want to use map records number in
reduce phase exactly after the map. This is very useful in solving
problems like TF-IDF. In reduce (IDF calculating) phase, you must know
the total number of all documents. Is there any method to solve the
problem without running two Map-Reduce jobs?

On Sun, Aug 2, 2009 at 2:08 PM, Ted Dunning<ted.dunning@gmail.com> wrote:
> Sure. =A0Write a word count map-reduce program. =A0The mapper outputs the=
 key
> from the sequence file as the output key and includes a count. =A0Then yo=
u do
> the normal combiner and reducer from a normal word count program.
>
> On Sat, Aug 1, 2009 at 9:53 PM, prashant ullegaddi <prashullegaddi@gmail.=
com
>> wrote:
>
>> Hi,
>>
>> I've say 800 sequence files written using SequenceFileOutputFormat. Is
>> there
>> any way to know
>> no. of unique keys in those sequence files?
>>
>> Thanks,
>> Prashant.
>>
>
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>



--=20
Zhong Wang

From common-user-return-16541-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 07:20:48 2009
Return-Path: <common-user-return-16541-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 17494 invoked from network); 4 Aug 2009 07:20:47 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 07:20:47 -0000
Received: (qmail 82229 invoked by uid 500); 4 Aug 2009 07:20:50 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82159 invoked by uid 500); 4 Aug 2009 07:20:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82149 invoked by uid 99); 4 Aug 2009 07:20:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 07:20:50 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of prashullegaddi@gmail.com designates 209.85.216.198 as permitted sender)
Received: from [209.85.216.198] (HELO mail-px0-f198.google.com) (209.85.216.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 07:20:40 +0000
Received: by pxi36 with SMTP id 36so2918006pxi.2
        for <common-user@hadoop.apache.org>; Tue, 04 Aug 2009 00:20:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=uu3BJCo39GWjg7183heOh3Pr9k8wg16jQxaGDCnkfpU=;
        b=jcz2f75OyNzJz3YOzMBK1lIAUa0cn17kVy+9uz1/Ro2AzChrhhzifL7ttSJ12FPErl
         LMeYhv+3N7EveVLRC2ZQvBJIwLNLzTF1eKU6lMnTT3QHdYIptH8FBx5fGq6v0UDXUAFj
         WFvKQFZEWozHFYMFgw+cb5ExdLV+m2wHhcpC4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=i95jJKUkuFlmNm6eAlnBH0neyFLO8n3xwObakrdjHKoODmGC3UHhOz9aPDJvWuMGpH
         Jv7d1OwqdnUGw+vWMHROiuywuxvorTVae9zx44FvE8nUJtJNLJkq3VFcgarZEUPQHMO+
         DR/LvECcdu/hJ6nIcyemXp5ZxRLOczA36407M=
MIME-Version: 1.0
Received: by 10.141.29.16 with SMTP id g16mr4820743rvj.18.1249370419340; Tue, 
	04 Aug 2009 00:20:19 -0700 (PDT)
In-Reply-To: <616DA47B2EF5B944B91846785B512FF4AAC0D53503@EGL-EX07VS01.ds.corp.yahoo.com>
References: <ac6e61fc0908012153o5f6f5ee9ocbcdef8b21dda20b@mail.gmail.com>
	 <c7d45fc70908012308i2764a7f4g1c86dfe90880194e@mail.gmail.com>
	 <de9d20b80908030601y7dc91ce5m34e6e913a65ec149@mail.gmail.com>
	 <616DA47B2EF5B944B91846785B512FF4AAC0D53503@EGL-EX07VS01.ds.corp.yahoo.com>
Date: Tue, 4 Aug 2009 12:50:18 +0530
Message-ID: <ac6e61fc0908040020s7f87750ds4af225c7bb2cddc0@mail.gmail.com>
Subject: Re: Counting no. of keys.
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd1754809dec104704bb8cb
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd1754809dec104704bb8cb
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thank you all guys. In fact all methods worked :)

On Tue, Aug 4, 2009 at 11:08 AM, Amogh Vasekar <amogh@yahoo-inc.com> wrote:

> Have you had a look at the reporter.counter hadoop provides? I think it
> might be helpful in your case, where in you can locally aggregate for each
> map task and then push it to global counter.
>
> -----Original Message-----
> From: Zhong Wang [mailto:wangzhong.neu@gmail.com]
> Sent: Monday, August 03, 2009 6:31 PM
> To: common-user@hadoop.apache.org
> Subject: Re: Counting no. of keys.
>
> I have the same question, but i want to use map records number in
> reduce phase exactly after the map. This is very useful in solving
> problems like TF-IDF. In reduce (IDF calculating) phase, you must know
> the total number of all documents. Is there any method to solve the
> problem without running two Map-Reduce jobs?
>
> On Sun, Aug 2, 2009 at 2:08 PM, Ted Dunning<ted.dunning@gmail.com> wrote:
> > Sure.  Write a word count map-reduce program.  The mapper outputs the key
> > from the sequence file as the output key and includes a count.  Then you
> do
> > the normal combiner and reducer from a normal word count program.
> >
> > On Sat, Aug 1, 2009 at 9:53 PM, prashant ullegaddi <
> prashullegaddi@gmail.com
> >> wrote:
> >
> >> Hi,
> >>
> >> I've say 800 sequence files written using SequenceFileOutputFormat. Is
> >> there
> >> any way to know
> >> no. of unique keys in those sequence files?
> >>
> >> Thanks,
> >> Prashant.
> >>
> >
> >
> >
> > --
> > Ted Dunning, CTO
> > DeepDyve
> >
>
>
>
> --
> Zhong Wang
>

--000e0cd1754809dec104704bb8cb--

From common-user-return-16542-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 14:26:02 2009
Return-Path: <common-user-return-16542-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 92125 invoked from network); 4 Aug 2009 14:26:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 14:26:02 -0000
Received: (qmail 35630 invoked by uid 500); 4 Aug 2009 14:26:05 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35572 invoked by uid 500); 4 Aug 2009 14:26:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35562 invoked by uid 99); 4 Aug 2009 14:26:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 14:26:04 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.211.202 as permitted sender)
Received: from [209.85.211.202] (HELO mail-yw0-f202.google.com) (209.85.211.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 14:25:55 +0000
Received: by ywh40 with SMTP id 40so4942903ywh.29
        for <common-user@hadoop.apache.org>; Tue, 04 Aug 2009 07:25:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=g24egLgcG8ygW0k7fgTIjuCeMIicItEIMwfgQ6BIax4=;
        b=wacnA+bTsjbxyxsEi0UF1hmQ7fR3MzT+qytE7Tv6tcfGmmo+t5MSgKiINk8wwYsR5H
         dQD8MboPYFmvaH5LD7OcdWiOSu8a4HTtEKaXTByKqUFllsxU6ZFaEDIK9owAV50mbD+R
         XsBYkKQOUpiRH95b4TAhovvjQaixYi3bAhJVE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=A7PYm2ppwZzu9uX7sXnV/tyUiPMwMIkz07VpG3rwj0oYxtqsxgILjh4CsomsslcRrq
         C4x6JmDopDMD9mNqGO25gB7J9ns0rP0CEZmIcwuAbVX/hjLRxtBFtnODpIOJ0HWYMkZz
         IlQMohg5Jb9+V/0y35Pij4yFnjnx1CcYnrVWM=
MIME-Version: 1.0
Received: by 10.150.149.4 with SMTP id w4mr591907ybd.247.1249395934139; Tue, 
	04 Aug 2009 07:25:34 -0700 (PDT)
In-Reply-To: <de9d20b80908030601y7dc91ce5m34e6e913a65ec149@mail.gmail.com>
References: <ac6e61fc0908012153o5f6f5ee9ocbcdef8b21dda20b@mail.gmail.com> 
	<c7d45fc70908012308i2764a7f4g1c86dfe90880194e@mail.gmail.com> 
	<de9d20b80908030601y7dc91ce5m34e6e913a65ec149@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Tue, 4 Aug 2009 07:25:14 -0700
Message-ID: <c7d45fc70908040725l4c78582ev2384ed0cdeb58fb6@mail.gmail.com>
Subject: Re: Counting no. of keys.
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd4d64ad6978c047051a8a5
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd4d64ad6978c047051a8a5
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

If you need the number of token occurrences, then counters work well.

If you need the number unique tokens, then you need a separate map reduce.


On Mon, Aug 3, 2009 at 6:01 AM, Zhong Wang <wangzhong.neu@gmail.com> wrote:

> I have the same question, but i want to use map records number in
> reduce phase exactly after the map. This is very useful in solving
> problems like TF-IDF. In reduce (IDF calculating) phase, you must know
> the total number of all documents. Is there any method to solve the
> problem without running two Map-Reduce jobs?
>
> On Sun, Aug 2, 2009 at 2:08 PM, Ted Dunning<ted.dunning@gmail.com> wrote:
> > Sure.  Write a word count map-reduce program.  The mapper outputs the key
> > from the sequence file as the output key and includes a count.  Then you
> do
> > the normal combiner and reducer from a normal word count program.
> >
> > On Sat, Aug 1, 2009 at 9:53 PM, prashant ullegaddi <
> prashullegaddi@gmail.com
> >> wrote:
> >
> >> Hi,
> >>
> >> I've say 800 sequence files written using SequenceFileOutputFormat. Is
> >> there
> >> any way to know
> >> no. of unique keys in those sequence files?
> >>
> >> Thanks,
> >> Prashant.
> >>
> >
> >
> >
> > --
> > Ted Dunning, CTO
> > DeepDyve
> >
>
>
>
> --
> Zhong Wang
>



-- 
Ted Dunning, CTO
DeepDyve

--000e0cd4d64ad6978c047051a8a5--

From common-user-return-16543-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 04 21:30:44 2009
Return-Path: <common-user-return-16543-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 76550 invoked from network); 4 Aug 2009 21:30:44 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 4 Aug 2009 21:30:44 -0000
Received: (qmail 45759 invoked by uid 500); 4 Aug 2009 21:30:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 45666 invoked by uid 500); 4 Aug 2009 21:30:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 45656 invoked by uid 99); 4 Aug 2009 21:30:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 21:30:47 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of erikholstad@gmail.com designates 209.85.132.242 as permitted sender)
Received: from [209.85.132.242] (HELO an-out-0708.google.com) (209.85.132.242)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 04 Aug 2009 21:30:37 +0000
Received: by an-out-0708.google.com with SMTP id c38so2490148ana.29
        for <common-user@hadoop.apache.org>; Tue, 04 Aug 2009 14:30:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=w3I3uXcrUY2hLjNm/4cgn/Z9VpJOgfKZ7haL88qEu6A=;
        b=q+uam1uCP0wzY1HUStX5L9fNMpSsI5jvAHYZs6vPkU4BGwMrF21n1FwfqFRQwgyZxg
         sapLpHO7MK7Lyp4gDSK0obtjzHQ7EAwGfxCP6QsKuiJOsG1idWVtOSNOUYpBU91VfyhW
         D3PovVH10e5EKcrDLPKWFftpSt0UejVtJ0TkQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=MYLzbciiwkAg0FwIPHpBV/TSVBqPdyAHbtUcQ8wOoCSZwOHer/a/r59PA/kmmEoLKJ
         5O3IHnkA7abu7rzUDABSBhAZC7OvU1eCaLETTPqExGul3CheWhESX9KvclHgDleFDVJq
         Ey39bAVxlAFJb4bH6Yoj2/A63NeBvTp2DQNKA=
MIME-Version: 1.0
Received: by 10.101.70.14 with SMTP id x14mr9449820ank.78.1249421415689; Tue, 
	04 Aug 2009 14:30:15 -0700 (PDT)
In-Reply-To: <74f4d40b0908031327w10c0e90es957bee0a84e0047a@mail.gmail.com>
References: <74f4d40b0908031327w10c0e90es957bee0a84e0047a@mail.gmail.com>
Date: Tue, 4 Aug 2009 14:30:15 -0700
Message-ID: <74f4d40b0908041430s46203a9cp9ef5b7db8d01dd18@mail.gmail.com>
Subject: Re: Problem getting scheduler to work.
From: Erik Holstad <erikholstad@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016369fa251a855f40470579731
X-Virus-Checked: Checked by ClamAV on apache.org

--0016369fa251a855f40470579731
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Just to let people know that encounters this in the future what to do.

After recommendations from Matei I changed the

<name>mapred.fairscheduler.poolnameproperty</name>
from
<value>mapred.job.queue.name</value>
to
<property>
    <name>mapred.fairscheduler.poolnameproperty</name>
    <value>pool.name</value>
</property>

and set the conf accordingly and now it works fine.

Thanks Matei for the help!

Erik

--0016369fa251a855f40470579731--

From common-user-return-16544-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 02:31:32 2009
Return-Path: <common-user-return-16544-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 77500 invoked from network); 5 Aug 2009 02:31:32 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 02:31:32 -0000
Received: (qmail 73332 invoked by uid 500); 5 Aug 2009 02:31:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 73209 invoked by uid 500); 5 Aug 2009 02:31:34 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 73164 invoked by uid 99); 5 Aug 2009 02:31:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 02:31:34 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 02:31:23 +0000
Received: by gxk18 with SMTP id 18so6886618gxk.5
        for <multiple recipients>; Tue, 04 Aug 2009 19:31:01 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.67.20 with SMTP id p20mr3481135aga.5.1249439461411; Tue, 04 
	Aug 2009 19:31:01 -0700 (PDT)
From: Christophe Bisciglia <christophe@cloudera.com>
Date: Tue, 4 Aug 2009 19:30:41 -0700
Message-ID: <69035570908041930g33c24676x5768dbfef9564692@mail.gmail.com>
Subject: Hadoop Meetup at ApacheCon US
To: common-user@hadoop.apache.org, hive-user@hadoop.apache.org, 
	pig-user@hadoop.apache.org, hbase-user <hbase-user@hadoop.apache.org>, 
	zookeeper-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hadoop Fans, it looks like most of you prefer to have this on Thursday
(November 5th), so that's what we'll plan for.

Anyone is welcome to come to this meetup, even if you don't attend
ApacheCon. We'd love to hear more about various sub-projects and cool
Hadoop applications, tips, tricks, etc.

If you'd like to grab a 10 minute speaking slot, just drop me a note
(and if you need more time, just let me know).

More details and RSVP here: http://www.meetup.com/hadoop/calendar/11038623/

Cheers,
Christophe

On Wed, Jul 29, 2009 at 5:01 PM, Christophe
Bisciglia<christophe@cloudera.com> wrote:
> Hey Hadoop Fans, after working with the ApacheCon organizers, it's
> clear there is way more interest in Hadoop than can fit into a single
> day - even with it's own track. Specifically, there were a lot of
> great talks from sub projects that didn't make the final schedule, and
> it's clear there are all kinds of great ideas to convey with some
> shorter format talks.
>
> To that end, we're putting together a meet up =A0at ApacheCon US to
> enable more information exchange amongst the growing Hadoop community.
>
> The first thing we'd like to do is choose a date that works well for
> participants. Monday and Thursday are both viable options, and one
> falls before the Hadoop track (Wednesday) and one after. We can see
> advantages to both... If you have a preference, please let us know by
> next Wednesday.
>
> So, if you are going to be around, please let us know which date you'd
> prefer by filling out this very short form:
> https://spreadsheets.google.com/a/cloudera.com/viewform?hl=3Den&formkey=
=3DdDczc251N1ZLVUlfMS05d3RDRDFxemc6MA..
>
> Cheers,
> Christophe
>
> P.S. Please notice there are two periods (..) at the end of the form
> URL. This confuses some mail readers, so if the form acts funny, you
> may need to copy/paste the URL directly. Sorry :-/
>
> --
> get hadoop: cloudera.com/hadoop
> online training: cloudera.com/hadoop-training
> blog: cloudera.com/blog
> twitter: twitter.com/cloudera
>



--=20
get hadoop: cloudera.com/hadoop
online training: cloudera.com/hadoop-training
blog: cloudera.com/blog
twitter: twitter.com/cloudera

From common-user-return-16545-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 03:51:05 2009
Return-Path: <common-user-return-16545-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 99465 invoked from network); 5 Aug 2009 03:51:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 03:51:04 -0000
Received: (qmail 33095 invoked by uid 500); 5 Aug 2009 03:51:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 32946 invoked by uid 500); 5 Aug 2009 03:51:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 32806 invoked by uid 500); 5 Aug 2009 03:51:02 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 32784 invoked by uid 99); 5 Aug 2009 03:51:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 03:51:02 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bradfordstephens@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 03:50:52 +0000
Received: by yxe15 with SMTP id 15so7330540yxe.5
        for <multiple recipients>; Tue, 04 Aug 2009 20:50:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=5VumxwmL9CISoyCAW1XdISB4hHrSRxtULEC+y1XcYO0=;
        b=Z/3eLeeCZ7xuQL3iFkCCX3NPRyGofEg5VlT0QgCA5dGU4Q1oDNeqjFqX4hVVZ9fn+y
         Uuw9fnfm4wj5fZv9fb6xRtmiawx2SKbQ3QXSt4yJ5xuAciB8dQfz/Kybtyu5VMiyaGq+
         f/hf825LkEkslQwJYVf2SlQ3BpWsbCWapVxog=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=WvBaVpis4t+1bh2P41SDeubuRj8p+rjAhRJbvCfK6ErSEGeGPecvGb7/lNFNgWL4wJ
         1eTxxudpCsPaUg/1F2xeGpBMwP8k313chWoHkR++p8TZ2+1DcUAzHLKlTn69XkZIDptX
         yiif/yoP2QvgzqtZY6Vrp9LQAZvBzdUiYudEU=
MIME-Version: 1.0
Received: by 10.90.101.17 with SMTP id y17mr3435601agb.116.1249444231427; Tue, 
	04 Aug 2009 20:50:31 -0700 (PDT)
Date: Tue, 4 Aug 2009 20:50:31 -0700
Message-ID: <860544ed0908042050ucb88f87w590ad4014a7ab3f1@mail.gmail.com>
Subject: A Presentation on Building a Hadoop + Lucene System Architecture
From: Bradford Stephens <bradfordstephens@gmail.com>
To: core-user@hadoop.apache.org, hbase-user@hadoop.apache.org, 
	pig-user@hadoop.apache.org, solr-user@lucene.apache.org, 
	java-user@lucene.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hey all,

I just wanted to send a link to a presentation I made on how my
company is building its entire core BI infrastructure around Hadoop,
HBase, Lucene, and more. It features a decent amount of practical
advice: from rules for approaching scalability problems, to why we
chose certain aspects of the Hadoop Ecosystem. Perhaps you can use it
as justification for their decisions, or as a jumping-off point to
utilizing it in the real world.

I hope you find it helpful! You can catch it at my blog:
http://www.roadtofailure.com . There's also a few inflammatory
articles, such as "Social Media Kills the RDBMS".

Ask me if you have any questions :)

-- 
http://www.hadoopconsulting.com -- Making Hadoop and your web apps
that use it scale
http://www.roadtofailure.com -- The Fringes of Scalability, Social
Media, and Computer Science

From common-user-return-16546-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 07:03:47 2009
Return-Path: <common-user-return-16546-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63315 invoked from network); 5 Aug 2009 07:03:47 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 07:03:47 -0000
Received: (qmail 48223 invoked by uid 500); 5 Aug 2009 07:03:52 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 48144 invoked by uid 500); 5 Aug 2009 07:03:52 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 48134 invoked by uid 99); 5 Aug 2009 07:03:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 07:03:52 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mathias.demare@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 07:03:39 +0000
Received: by fxm25 with SMTP id 25so3739018fxm.29
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 00:03:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:from:date
         :message-id:subject:to:content-type;
        bh=fV/6OG3nLsBkOni0L23Qnft7u7aUeeEYoJv4jLPIwqQ=;
        b=T+dFiY0srDwn+Af4zj0DH3Oj48DPMC7kYzicDKnleTPS1WTqhZwAAt8WxwGHgL9EXC
         mnO0hRi7i4sQPtHrTWQy9cAgON9+X2ZpPTsKT4cGqMyPD5aZtZaPgTU2Xvn41fs/DJNM
         RLE3IZXaVflQCZsVxJV3xPYaQf1N1EyVRBO3g=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:from:date:message-id:subject:to:content-type;
        b=qFUBWkoU2h5piEa/pbS9A0bUC+y6lOIrau2BOr8uPBLGoVkypIEFNiySLO2rw0JXhA
         GGtNIKquuAGHuwip3GxyA/LPwXz8f0GeY3bh6q0TN66BGjhp08s4nUy5qfNU95geFxGx
         HtH307OY2MLF61hqlV2/w7LFdhFvZiVFvoZdg=
MIME-Version: 1.0
Received: by 10.223.104.140 with SMTP id p12mr3517316fao.7.1249455799146; Wed, 
	05 Aug 2009 00:03:19 -0700 (PDT)
Reply-To: mathias.demare@gmail.com
From: =?UTF-8?Q?Mathias_De_Mar=C3=A9?= <mathias.demare@gmail.com>
Date: Wed, 5 Aug 2009 09:02:59 +0200
Message-ID: <375c60f40908050002n3a110d66ua2672a40bb8ad866@mail.gmail.com>
Subject: Some tasks fail to report status between the end of the map and the 
	beginning of the merge
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c5b0d4121a3104705f9979
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5b0d4121a3104705f9979
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hi,

I'm having some problems (Hadoop 0.20.0) where map tasks fail to report
status for 10 minutes and get killed eventually. All of the tasks output
around the same amount of data, some only take a few seconds before starting
the 'merge' on the segments, but some seem to fail by just stopping to work
for about 10 minutes.

Several of these failed tasks eventually do succeed, on their 2nd or 3rd
task attempt. It's nice to see them succeed eventually, but each of those
tasks crawls a few thousand websites, and it seems like a terrible waste to
let them retry a few times, in the meantime downloading all of those
websites again, after 10 minutes of doing nothing.

Even more annoyingly, eventually, one of the tasks fails completely, which
then kills the entire job.

I could probably increase the amount of task attempts and simply hope the
tasks will succeed eventually, but that doesn't solve the huge slowdowns and
the recrawling required.

Here's an example of a successful task attempt (this is attempt 3 of a
specific task -- note that it takes around 8 seconds between spill 133 and
spill 134):

2009-08-04 18:38:48,059 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 129

2009-08-04 18:39:00,626 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full = true
2009-08-04 18:39:00,626 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 2492163; bufend = 628913; bufvoid = 2988446

2009-08-04 18:39:00,626 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 9727; kvend = 7760; length = 9830
2009-08-04 18:39:01,467 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 130
2009-08-04 18:39:08,136 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full = true

2009-08-04 18:39:08,136 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 628913; bufend = 1880222; bufvoid = 2988448
2009-08-04 18:39:08,136 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 7760; kvend = 5793; length = 9830

2009-08-04 18:39:08,463 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 131
2009-08-04 18:39:12,456 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full = true
2009-08-04 18:39:12,459 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 1880222; bufend = 136018; bufvoid = 2988448

2009-08-04 18:39:12,459 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 5793; kvend = 3826; length = 9830
2009-08-04 18:39:12,697 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 132
2009-08-04 18:39:23,138 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full = true

2009-08-04 18:39:23,138 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 136018; bufend = 1347353; bufvoid = 2988448
2009-08-04 18:39:23,138 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 3826; kvend = 1859; length = 9830

2009-08-04 18:39:25,747 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 133
2009-08-04 18:47:49,823 INFO org.apache.hadoop.mapred.MapTask:
Starting flush of map output
2009-08-04 18:47:50,132 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 134

2009-08-04 18:47:50,525 INFO org.apache.hadoop.mapred.Merger: Merging
135 sorted segments
2009-08-04 18:47:50,528 INFO org.apache.hadoop.mapred.Merger: Merging
9 intermediate segments out of a total of 135
2009-08-04 18:47:52,224 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 127

2009-08-04 18:47:53,837 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 118
2009-08-04 18:47:55,417 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 109

2009-08-04 18:47:56,990 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 100
2009-08-04 18:47:58,492 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 91

2009-08-04 18:48:00,191 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 82
2009-08-04 18:48:02,315 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 73

2009-08-04 18:48:04,184 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 64
2009-08-04 18:48:06,162 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 55

2009-08-04 18:48:08,149 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 46
2009-08-04 18:48:09,888 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 37

2009-08-04 18:48:11,744 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 28
2009-08-04 18:48:13,544 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 19

2009-08-04 18:48:21,177 INFO org.apache.hadoop.mapred.Merger: Down to
the last merge-pass, with 10 segments left of total size: 153426836
bytes
2009-08-04 18:48:46,226 INFO org.apache.hadoop.mapred.TaskRunner:
Task:attempt_200908041626_0001_m_000133_2 is done. And is in the
process of commiting

2009-08-04 18:48:46,373 INFO org.apache.hadoop.mapred.TaskRunner: Task
'attempt_200908041626_0001_m_000133_2' done.

And here the same task, but an earlier attempt (it only goes up to spill
132, but those do vary slightly in size, right?):

2009-08-04 17:15:49,112 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 321905; bufend = 1464691; bufvoid = 2988448
2009-08-04 17:15:49,112 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 7764; kvend = 5797; length = 9830

2009-08-04 17:15:49,910 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 126
2009-08-04 17:16:00,785 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full = true
2009-08-04 17:16:00,785 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 1464691; bufend = 2580856; bufvoid = 2988448

2009-08-04 17:16:00,785 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 5797; kvend = 3830; length = 9830
2009-08-04 17:16:05,728 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 127
2009-08-04 17:16:20,883 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full = true

2009-08-04 17:16:20,883 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 2580856; bufend = 1000978; bufvoid = 2988448
2009-08-04 17:16:20,883 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 3830; kvend = 1863; length = 9830

2009-08-04 17:16:21,709 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 128
2009-08-04 17:16:24,461 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full = true
2009-08-04 17:16:24,461 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 1000978; bufend = 2246166; bufvoid = 2988448

2009-08-04 17:16:24,461 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 1863; kvend = 9727; length = 9830
2009-08-04 17:16:24,934 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 129
2009-08-04 17:16:40,853 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full = true

2009-08-04 17:16:40,853 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 2246166; bufend = 374750; bufvoid = 2988435
2009-08-04 17:16:40,853 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 9727; kvend = 7760; length = 9830

2009-08-04 17:16:43,740 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 130
2009-08-04 17:16:49,141 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full = true
2009-08-04 17:16:49,141 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 374750; bufend = 1653302; bufvoid = 2988448

2009-08-04 17:16:49,141 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 7760; kvend = 5793; length = 9830
2009-08-04 17:16:49,868 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 131
2009-08-04 17:17:04,902 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full = true

2009-08-04 17:17:04,902 INFO org.apache.hadoop.mapred.MapTask:
bufstart = 1653302; bufend = 2882491; bufvoid = 2988448
2009-08-04 17:17:04,902 INFO org.apache.hadoop.mapred.MapTask: kvstart
= 5793; kvend = 3826; length = 9830

2009-08-04 17:17:05,355 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 132

There's no more output after that last spill, since the task eventually got
killed after 10 minutes of nothing.

And in case it can help, here's a thread dump for one of those failed tasks:
2009-08-04 18:53:23,460 INFO org.apache.hadoop.mapred.TaskTracker:
attempt_200908041626_0001_m_000135_3: Task
attempt_200908041626_0001_m_000135_3 failed to report status for 602
seconds. Killing!
2009-08-04 18:53:23,470 INFO org.apache.hadoop.mapred.TaskTracker: Process
Thread Dump: lost task
31 active threads
Thread 1673 (process reaper):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    java.lang.UNIXProcess.waitForProcessExit(Native Method)
    java.lang.UNIXProcess.access$900(UNIXProcess.java:20)
    java.lang.UNIXProcess$1$1.run(UNIXProcess.java:132)
Thread 1672 (JVM Runner jvm_200908041626_0001_m_1938204689 spawned.):
  State: WAITING
  Blocked count: 1
  Waited count: 2
  Waiting on java.lang.UNIXProcess@155d434
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    java.lang.UNIXProcess.waitFor(UNIXProcess.java:165)
    org.apache.hadoop.util.Shell.runCommand(Shell.java:186)
    org.apache.hadoop.util.Shell.run(Shell.java:134)

org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.runChild(JvmManager.java:335)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.run(JvmManager.java:324)
Thread 1671 (Thread-1040):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.lang.Object@1ba4552
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:409)
Thread 1646 (process reaper):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    java.lang.UNIXProcess.waitForProcessExit(Native Method)
    java.lang.UNIXProcess.access$900(UNIXProcess.java:20)
    java.lang.UNIXProcess$1$1.run(UNIXProcess.java:132)
Thread 1645 (JVM Runner jvm_200908041626_0001_m_2100332869 spawned.):
  State: WAITING
  Blocked count: 1
  Waited count: 2
  Waiting on java.lang.UNIXProcess@5e34ce
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    java.lang.UNIXProcess.waitFor(UNIXProcess.java:165)
    org.apache.hadoop.util.Shell.runCommand(Shell.java:186)
    org.apache.hadoop.util.Shell.run(Shell.java:134)

org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.runChild(JvmManager.java:335)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.run(JvmManager.java:324)
Thread 1644 (Thread-1023):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.lang.Object@1bee6f
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:409)
Thread 143 (process reaper):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    java.lang.UNIXProcess.waitForProcessExit(Native Method)
    java.lang.UNIXProcess.access$900(UNIXProcess.java:20)
    java.lang.UNIXProcess$1$1.run(UNIXProcess.java:132)
Thread 141 (JVM Runner jvm_200908041626_0001_r_-836397802 spawned.):
  State: WAITING
  Blocked count: 1
  Waited count: 2
  Waiting on java.lang.UNIXProcess@11fceed
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    java.lang.UNIXProcess.waitFor(UNIXProcess.java:165)
    org.apache.hadoop.util.Shell.runCommand(Shell.java:186)
    org.apache.hadoop.util.Shell.run(Shell.java:134)

org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.runChild(JvmManager.java:335)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.run(JvmManager.java:324)
Thread 140 (Thread-89):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.lang.Object@1c63791
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:409)
Thread 33 (IPC Client (47) connection to localhost/127.0.0.1:9001 from
root):
  State: TIMED_WAITING
  Blocked count: 5563
  Waited count: 5552
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:403)
    org.apache.hadoop.ipc.Client$Connection.run(Client.java:445)
Thread 32 (Directory/File cleanup thread):
  State: WAITING
  Blocked count: 0
  Waited count: 165
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@fdffb1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)

org.apache.hadoop.mapred.CleanupQueue$PathCleanupThread.run(CleanupQueue.java:89)
Thread 8 (taskCleanup):
  State: WAITING
  Blocked count: 0
  Waited count: 2
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@19c205b
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.mapred.TaskTracker$1.run(TaskTracker.java:352)
    java.lang.Thread.run(Thread.java:619)
Thread 31 (TaskLauncher for task):
  State: WAITING
  Blocked count: 4
  Waited count: 5
  Waiting on java.util.LinkedList@1d9d565
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)

org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:1662)
Thread 30 (TaskLauncher for task):
  State: WAITING
  Blocked count: 783
  Waited count: 781
  Waiting on java.util.LinkedList@1fbebee
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)

org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:1662)
Thread 29 (Map-events fetcher for all reduce tasks on
tracker_ip-10-244-145-237.ec2.internal:localhost/127.0.0.1:40135):
  State: TIMED_WAITING
  Blocked count: 10965
  Waited count: 10957
  Stack:
    java.lang.Object.wait(Native Method)

org.apache.hadoop.mapred.TaskTracker$MapEventsFetcherThread.run(TaskTracker.java:671)
Thread 27 (IPC Server handler 7 on 40135):
  State: WAITING
  Blocked count: 5
  Waited count: 2565
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da690
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 26 (IPC Server handler 6 on 40135):
  State: WAITING
  Blocked count: 11
  Waited count: 2565
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da690
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 25 (IPC Server handler 5 on 40135):
  State: WAITING
  Blocked count: 11
  Waited count: 2566
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da690
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 24 (IPC Server handler 4 on 40135):
  State: WAITING
  Blocked count: 7
  Waited count: 2565
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da690
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 23 (IPC Server handler 3 on 40135):
  State: WAITING
  Blocked count: 10
  Waited count: 2565
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da690
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 22 (IPC Server handler 2 on 40135):
  State: WAITING
  Blocked count: 11
  Waited count: 2566
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da690
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 21 (IPC Server handler 1 on 40135):
  State: WAITING
  Blocked count: 15
  Waited count: 2567
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da690
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 20 (IPC Server handler 0 on 40135):
  State: WAITING
  Blocked count: 12
  Waited count: 2565
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da690
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 17 (IPC Server listener on 40135):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:84)
    org.apache.hadoop.ipc.Server$Listener.run(Server.java:318)
Thread 19 (IPC Server Responder):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)
    org.apache.hadoop.ipc.Server$Responder.run(Server.java:478)
Thread 16 (Timer-0):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 298
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:509)
    java.util.TimerThread.run(Timer.java:462)
Thread 15 (11502424@qtp0-0 - Acceptor0 SelectChannelConnector@0.0.0.0:50060
):
  State: RUNNABLE
  Blocked count: 50
  Waited count: 1
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)

org.mortbay.io.nio.SelectorManager$SelectSet.doSelect(SelectorManager.java:429)
    org.mortbay.io.nio.SelectorManager.doSelect(SelectorManager.java:185)

org.mortbay.jetty.nio.SelectChannelConnector.accept(SelectChannelConnector.java:124)

org.mortbay.jetty.AbstractConnector$Acceptor.run(AbstractConnector.java:707)

org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)
Thread 4 (Signal Dispatcher):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
Thread 3 (Finalizer):
  State: WAITING
  Blocked count: 424
  Waited count: 425
  Waiting on java.lang.ref.ReferenceQueue$Lock@7b6d1c
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:134)
    java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)
Thread 2 (Reference Handler):
  State: WAITING
  Blocked count: 445
  Waited count: 446
  Waiting on java.lang.ref.Reference$Lock@16ee240
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)
Thread 1 (main):
  State: RUNNABLE
  Blocked count: 2973
  Waited count: 5789
  Stack:
    sun.management.ThreadImpl.getThreadInfo0(Native Method)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:147)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:123)

org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:149)

org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:203)

org.apache.hadoop.mapred.TaskTracker.markUnresponsiveTasks(TaskTracker.java:1383)
    org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:1129)
    org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:1779)
    org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:2881)

2009-08-04 18:53:23,471 INFO org.apache.hadoop.mapred.TaskTracker: About to
purge task: attempt_200908041626_0001_m_000135_3
2009-08-04 18:53:23,471 INFO org.apache.hadoop.mapred.TaskTracker:
addFreeSlot : current free slots : 3
2009-08-04 18:53:23,471 INFO org.apache.hadoop.mapred.TaskRunner:
attempt_200908041626_0001_m_000135_3 done; removing files.
2009-08-04 18:53:23,550 INFO org.apache.hadoop.mapred.IndexCache: Map ID
attempt_200908041626_0001_m_000135_3 not found in cache


Thanks in advance for any response!
I'm afraid I'm somewhat clueless about this.

Mathias

--001636c5b0d4121a3104705f9979--

From common-user-return-16547-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 07:32:14 2009
Return-Path: <common-user-return-16547-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 67023 invoked from network); 5 Aug 2009 07:32:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 07:32:14 -0000
Received: (qmail 68729 invoked by uid 500); 5 Aug 2009 07:32:18 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 68642 invoked by uid 500); 5 Aug 2009 07:32:18 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 73345 invoked by uid 99); 4 Aug 2009 23:11:29 -0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of phil123@gmail.com designates 209.85.132.241 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=/B+4ulqc/OuhraKLMtBEBhbQiJEKstj3ti75lB+Lw+A=;
        b=cPF63OcgtvHhFISvPDUj9wnd91piOdBFAVa9K29m3h+T4DBAg00DjU8jXchAgf04Zg
         YjkAN/QLejbmCaj7hzXuLlZ9M6K/wPYBlmpcw8QoREyqsCAeA9Atwxm57UcRibtfLLN8
         w97GqbtE4jkMW2PffSM1Z6NSFQsYO+VWRS5BY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=Q/CrgJf9HaOpCsIc7vGx814XJIu3royyZubzso7W3fhFdRM4Pryx0WCEG3XXClNn2u
         tFxXYEoeEJYX/huvl+rVIEaauEnXCpkmCe9RH4hG9asoEc6xGQubCeg553FK5iWBXLwt
         4LSRr8u9KzNXq6w7UlkdBJu2yLv7BZI2ITYdU=
MIME-Version: 1.0
Date: Tue, 4 Aug 2009 16:10:59 -0700
Message-ID: <9cafbc680908041610n683a7868ua85ebe6518fc476b@mail.gmail.com>
Subject: how to get out of Safe Mode?
From: Phil Whelan <phil123@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

In setting up my cluster and brought a few machines up and down. I did
have some data in which I moved to Trash. Now that data is not 100%
available, which is fine, because I didn't want it.
But now I'm stuck in "Safe Mode", because it cannot find the data. I
cannot purge the Trash because it's in read-only due to Safe Mode.

   Safe mode is ON.
   The ratio of reported blocks 0.9931 has not reached the threshold 0.9990.
   Safe mode will be turned off automatically.
   459 files and directories, 583 blocks = 1042 total. Heap Size is
7.8 MB / 992.31 MB (0%)

I want to just want format the entire HDFS filesystem. I have nothing
I need in there. How can I do this?

Phil

From common-user-return-16548-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 07:33:33 2009
Return-Path: <common-user-return-16548-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 67413 invoked from network); 5 Aug 2009 07:33:32 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 07:33:32 -0000
Received: (qmail 70910 invoked by uid 500); 5 Aug 2009 07:33:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 70826 invoked by uid 500); 5 Aug 2009 07:33:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 4545 invoked by uid 99); 5 Aug 2009 03:05:15 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of caibinbupt@gmail.com designates 209.85.211.202 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :x-goomoji-body:date:message-id:subject:from:to:cc:content-type;
        bh=PewwjDCsBpqw5PU8zQLDa+otG4S4X/KkibcewhiVLNM=;
        b=JlDU2qBPMYjr1jG/wd3UqtMFGP0SVVCLty1Lxf3OQMe8461aUxz9G6XusypOr2adBh
         9hxwCZGcqswki4lhqchKrTgBIhepEiQ2OUwCAJOb5ogkJloq25WH4eLlQjhs0UQi/uTp
         hAJmBcHbGyYPpPtE7/HmYxTvcn48uZr4NRj5E=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:x-goomoji-body:date:message-id
         :subject:from:to:cc:content-type;
        b=P9IRZaAViJNvG0FGXVpWaIu2AtltF3VKbOv5scc4A2cXKw9U1QTMumVXKxfQ6/woDA
         fCkVi5vyirKt06Gbih0VwBiK4+kdJ8hZ6zKis2xYEfQDJS9pj7DFxbZSp3blZmfgGuQ3
         NJo0WB3allH29oXBZdLanMN8nyil1LT5N+9Qk=
MIME-Version: 1.0
In-Reply-To: <2a7683240908030233r1a69d32eyb88c68498661f6a2@mail.gmail.com>
References: <2a7683240908030233r1a69d32eyb88c68498661f6a2@mail.gmail.com>
X-Goomoji-Body: true
Date: Wed, 5 Aug 2009 11:04:46 +0800
Message-ID: <2a7683240908042004tb6e7c9bn8ef485104ff0c8ff@mail.gmail.com>
Subject: Re: Re: FYI X-RIME: Hadoop based large scale social network analysis 
	released
From: Bin Cai <caibinbupt@gmail.com>
To: edward@udanax.org
Cc: hama-user@incubator.apache.org, common-user@hadoop.apache.org, 
	mapreduce-user@hadoop.apache.org, mahout-user@lucene.apache.org
Content-Type: multipart/related; boundary=000e0cd2e522f7e56504705c4351
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd2e522f7e56504705c4351
Content-Type: multipart/alternative; boundary=000e0cd2e522f7e56104705c4350

--000e0cd2e522f7e56104705c4350
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi, Edward J. Yoon
    Sorry that I found I was not in hama-user maillist. Just joined[?]
    Xrime is based on Map/Reduce using HDFS to store graph information. It
is distributed and parallel. We will release some documents and examples
recently.
    I also noticed project Hamburg. It is interesting. The approach to store
graph in HBase would be helpful to solve some issues we found in our
solution.
    Thank you for your attention.

Best Regards
Cai Bin

> That's really cool. BTW, Have you tried these algorithms on the
> distributed environment?
>
> On Mon, Aug 3, 2009 at 6:33 PM, Bin Cai<caibinbupt@gmail.com> wrote:
> > *X-RIM**E**(http://xrime.sourceforge.net/): Hadoop based large scale social
> > network analysis*
> > *
> > Motivation*
> > Today's telecom service providers and Internet-based social network sites
> > possess huge user communities. They hold large amount of data about their
> > users and want to generate core competency from the data. A key enabler for
> > this is a cost efficient solution for social data management and social
> > network analysis (SNA).
> >
> > Such a solution faces a few challenges. The most important one is that the
> > solution should be able to handle massive and heterogeneous data sets.
> > Facing this challenge, the traditional data warehouse based solutions are
> > usually not cost efficient enough. On the other hand, existing SNA tools are
> > mostly used in single workstation mode, and not scalable enough. To this
> > end, low cost and highly scalable data management and processing
> > technologies from cloud computing society should be brought in to help.
> >
> > However, most of existing cloud based data analysis solutions are trying to
> > provide SQL-like general purpose query languages, and do not directly
> > support social network analysis. This makes them hard to optimize and hard
> > to use for SNA users. So, we came up with X-RIME to fix this gap.
> >
> > So, briefly speaking, X-RIME wants to provide a few value-added layers on
> > top of existing cloud infrastructure, to support smart decision loops based
> > on massive data sets and SNA. To end users, X-RIME is a library consists of
> > Map-Reduce programs, which are used to do raw data pre-processing,
> > transformation, SNA metrics and structures calculation, and graph / network
> > visualization. The library could be integrated with other Hadoop based data
> > warehouses (e.g., HIVE) to build more comprehensive solutions.>
> >
> > *Currently Supported SNA Metrics and Structures*
> > vertex degree statistics
> > weakly connected components (WCC)
> > strongly connected components (SCC)
> > bi-connected components (BCC)
> > ego-centric density
> > bread first search / single source shortest path (BFS/SSSP)
> > K-core
> > maximal cliques
> > pagerank
> > hyperlink-induced topic search (HITS)
> > minimal spanning tree (MST)
> >

--000e0cd2e522f7e56104705c4350
Content-Type: text/html; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable

<div>Hi, Edward J. Yoon<br>=A0=A0=A0 Sorry that I found I was not in hama-u=
ser maillist. Just joined<img style=3D"MARGIN: 0px 0.2ex; VERTICAL-ALIGN: m=
iddle" height=3D"12" src=3D"cid:330@goomoji.gmail" width=3D"12" goomoji=3D"=
330"><br>=A0=A0=A0 Xrime is based on Map/Reduce using HDFS to store graph i=
nformation. It is distributed and parallel. We will release some documents =
and examples recently.<br>
=A0=A0=A0 I also noticed project Hamburg. It is interesting. The approach t=
o store graph in HBase would be helpful to solve some issues we found in ou=
r solution.<br>=A0=A0=A0 Thank you for your attention.<br>=A0<br>Best Regar=
ds<br>Cai Bin</div>

<div><pre>&gt; That&#39;s really cool. BTW, Have you tried these algorithms=
 on the
&gt; distributed environment?
&gt;=20
&gt; On Mon, Aug 3, 2009 at 6:33 PM, Bin Cai&lt;<a href=3D"mailto:caibinbup=
t@gmail.com" target=3D"_blank">caibinbupt@gmail.com</a>&gt; wrote:
&gt; &gt; *X-RIM**E**(<a href=3D"http://xrime.sourceforge.net/" target=3D"_=
blank">http://xrime.sourceforge.net/</a>): Hadoop based large scale social
&gt; &gt; network analysis*
&gt; &gt; *
&gt; &gt; Motivation*
&gt; &gt; Today&#39;s telecom service providers and Internet-based social n=
etwork sites
&gt; &gt; possess huge user communities. They hold large amount of data abo=
ut their
&gt; &gt; users and want to generate core competency from the data. A key e=
nabler for
&gt; &gt; this is a cost efficient solution for social data management and =
social
&gt; &gt; network analysis (SNA).
&gt; &gt;
&gt; &gt; Such a solution faces a few challenges. The most important one is=
 that the
&gt; &gt; solution should be able to handle massive and heterogeneous data =
sets.
&gt; &gt; Facing this challenge, the traditional data warehouse based solut=
ions are
&gt; &gt; usually not cost efficient enough. On the other hand, existing SN=
A tools are
&gt; &gt; mostly used in single workstation mode, and not scalable enough. =
To this
&gt; &gt; end, low cost and highly scalable data management and processing
&gt; &gt; technologies from cloud computing society should be brought in to=
 help.
&gt; &gt;
&gt; &gt; However, most of existing cloud based data analysis solutions are=
 trying to
&gt; &gt; provide SQL-like general purpose query languages, and do not dire=
ctly
&gt; &gt; support social network analysis. This makes them hard to optimize=
 and hard
&gt; &gt; to use for SNA users. So, we came up with X-RIME to fix this gap.
&gt; &gt;
&gt; &gt; So, briefly speaking, X-RIME wants to provide a few value-added l=
ayers on
&gt; &gt; top of existing cloud infrastructure, to support smart decision l=
oops based
&gt; &gt; on massive data sets and SNA. To end users, X-RIME is a library c=
onsists of
&gt; &gt; Map-Reduce programs, which are used to do raw data pre-processing=
,
&gt; &gt; transformation, SNA metrics and structures calculation, and graph=
 / network
&gt; &gt; visualization. The library could be integrated with other Hadoop =
based data
&gt; &gt; warehouses (e.g., HIVE) to build more comprehensive solutions.&gt=
;=20
&gt; &gt;
&gt; &gt; *Currently Supported SNA Metrics and Structures*
&gt; &gt; vertex degree statistics
&gt; &gt; weakly connected components (WCC)
&gt; &gt; strongly connected components (SCC)
&gt; &gt; bi-connected components (BCC)
&gt; &gt; ego-centric density
&gt; &gt; bread first search / single source shortest path (BFS/SSSP)
&gt; &gt; K-core
&gt; &gt; maximal cliques
&gt; &gt; pagerank
&gt; &gt; hyperlink-induced topic search (HITS)
&gt; &gt; minimal spanning tree (MST)
&gt; &gt;

</pre></div>

--000e0cd2e522f7e56104705c4350--
--000e0cd2e522f7e56504705c4351--

From common-user-return-16549-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 08:05:19 2009
Return-Path: <common-user-return-16549-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 74858 invoked from network); 5 Aug 2009 08:05:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 08:05:19 -0000
Received: (qmail 4502 invoked by uid 500); 5 Aug 2009 08:05:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 4416 invoked by uid 500); 5 Aug 2009 08:05:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 4406 invoked by uid 99); 5 Aug 2009 08:05:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 08:05:24 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of amansk@gmail.com designates 209.85.132.246 as permitted sender)
Received: from [209.85.132.246] (HELO an-out-0708.google.com) (209.85.132.246)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 08:05:16 +0000
Received: by an-out-0708.google.com with SMTP id c38so2641260ana.29
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 01:04:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=lKtyy4k3CMMag0T3qjyQUZ+vw3xk54q95z8Lb6E8nIY=;
        b=S/eQmINLut+Uk/j0jQioMnmXgV9GJTDhx4C0C4zxIyLvnI9d7vi9qJx0a7BjKMngyb
         8cW4UHwczdVoJC62/QAJBk2ne8cOBpn+CMsTqoDe6Ed8BfxulZZkX1jPpWI2IHFvnPpv
         6GGxCKdCdSKUQWVJ8SmbPzZQTtjD+fPIfxZsI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=ClPNlYZ7ygM81+Eydau+ME15r7uEhP9iExHcjOG+uNY5mMYdj6yq5pl1t0boTsgSs+
         wZFpcVSDiCRdmnr3QZMXDYGnBSGlvQqRokC49eYrCFc8ZbKsm7aFkYzKEKvTyqOE+6s3
         lKd+Pms0Cot0aglDO+EkKD9yPFHvm+eO2JXJc=
MIME-Version: 1.0
Received: by 10.100.255.10 with SMTP id c10mr10740311ani.32.1249459495078; 
	Wed, 05 Aug 2009 01:04:55 -0700 (PDT)
In-Reply-To: <9cafbc680908041610n683a7868ua85ebe6518fc476b@mail.gmail.com>
References: <9cafbc680908041610n683a7868ua85ebe6518fc476b@mail.gmail.com>
From: Amandeep Khurana <amansk@gmail.com>
Date: Wed, 5 Aug 2009 01:04:35 -0700
Message-ID: <35a22e220908050104n2f1c4c1co8684a0b0c0bdac4c@mail.gmail.com>
Subject: Re: how to get out of Safe Mode?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016368e1fc35d8c8f0470607576
X-Virus-Checked: Checked by ClamAV on apache.org

--0016368e1fc35d8c8f0470607576
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Two alternatives:

1. Do bin/hadoop namenode -format. That'll format the metadata and you can
start afresh.

2. If that doesnt work, manually go and delete everything that resides in
the directories to which you've pointed your Namenode and Datanodes to store
their stuff in.




On Tue, Aug 4, 2009 at 4:10 PM, Phil Whelan <phil123@gmail.com> wrote:

> Hi,
>
> In setting up my cluster and brought a few machines up and down. I did
> have some data in which I moved to Trash. Now that data is not 100%
> available, which is fine, because I didn't want it.
> But now I'm stuck in "Safe Mode", because it cannot find the data. I
> cannot purge the Trash because it's in read-only due to Safe Mode.
>
>   Safe mode is ON.
>   The ratio of reported blocks 0.9931 has not reached the threshold 0.9990.
>   Safe mode will be turned off automatically.
>   459 files and directories, 583 blocks = 1042 total. Heap Size is
> 7.8 MB / 992.31 MB (0%)
>
> I want to just want format the entire HDFS filesystem. I have nothing
> I need in there. How can I do this?
>
> Phil
>

--0016368e1fc35d8c8f0470607576--

From common-user-return-16550-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 08:34:51 2009
Return-Path: <common-user-return-16550-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80192 invoked from network); 5 Aug 2009 08:34:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 08:34:50 -0000
Received: (qmail 28468 invoked by uid 500); 5 Aug 2009 08:34:55 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 28378 invoked by uid 500); 5 Aug 2009 08:34:55 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 28368 invoked by uid 99); 5 Aug 2009 08:34:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 08:34:55 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 08:34:41 +0000
Received: from EGL-EX07CAS02.ds.corp.yahoo.com (egl-ex07cas02.eglbp.corp.yahoo.com [203.83.248.209])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n758XLw4040407;
	Wed, 5 Aug 2009 01:33:22 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=SzG8EYJiuygGeznjzpMc0Th7I9ynl8b0sMtgK36labEh1O2DF1Cxc+aSwgpSdxdC
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.205]) by
 EGL-EX07CAS02.ds.corp.yahoo.com ([203.83.248.216]) with mapi; Wed, 5 Aug 2009
 14:03:20 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>,
        "mathias.demare@gmail.com" <mathias.demare@gmail.com>
Date: Wed, 5 Aug 2009 14:02:22 +0530
Subject: RE: Some tasks fail to report status between the end of the map and
 the 	beginning of the merge
Thread-Topic: Some tasks fail to report status between the end of the map
 and the 	beginning of the merge
Thread-Index: AcoVmw3YWfSSJn9ER/iVesI/vz89egAC7FWA
Message-ID: <616DA47B2EF5B944B91846785B512FF4BD3663BEFC@EGL-EX07VS01.ds.corp.yahoo.com>
References: <375c60f40908050002n3a110d66ua2672a40bb8ad866@mail.gmail.com>
In-Reply-To: <375c60f40908050002n3a110d66ua2672a40bb8ad866@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

10 mins reminds me of parameter mapred.task.timeout . This is configurable.=
 Or alternatively you might just do a sysout to let tracker know of its exi=
stence ( not an ideal solution though )

Thanks,
Amogh

-----Original Message-----
From: Mathias De Mar=E9 [mailto:mathias.demare@gmail.com]
Sent: Wednesday, August 05, 2009 12:33 PM
To: common-user@hadoop.apache.org
Subject: Some tasks fail to report status between the end of the map and th=
e beginning of the merge

Hi,

I'm having some problems (Hadoop 0.20.0) where map tasks fail to report
status for 10 minutes and get killed eventually. All of the tasks output
around the same amount of data, some only take a few seconds before startin=
g
the 'merge' on the segments, but some seem to fail by just stopping to work
for about 10 minutes.

Several of these failed tasks eventually do succeed, on their 2nd or 3rd
task attempt. It's nice to see them succeed eventually, but each of those
tasks crawls a few thousand websites, and it seems like a terrible waste to
let them retry a few times, in the meantime downloading all of those
websites again, after 10 minutes of doing nothing.

Even more annoyingly, eventually, one of the tasks fails completely, which
then kills the entire job.

I could probably increase the amount of task attempts and simply hope the
tasks will succeed eventually, but that doesn't solve the huge slowdowns an=
d
the recrawling required.

Here's an example of a successful task attempt (this is attempt 3 of a
specific task -- note that it takes around 8 seconds between spill 133 and
spill 134):

2009-08-04 18:38:48,059 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 129

2009-08-04 18:39:00,626 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full =3D true
2009-08-04 18:39:00,626 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 2492163; bufend =3D 628913; bufvoid =3D 2988446

2009-08-04 18:39:00,626 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 9727; kvend =3D 7760; length =3D 9830
2009-08-04 18:39:01,467 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 130
2009-08-04 18:39:08,136 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full =3D true

2009-08-04 18:39:08,136 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 628913; bufend =3D 1880222; bufvoid =3D 2988448
2009-08-04 18:39:08,136 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 7760; kvend =3D 5793; length =3D 9830

2009-08-04 18:39:08,463 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 131
2009-08-04 18:39:12,456 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full =3D true
2009-08-04 18:39:12,459 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 1880222; bufend =3D 136018; bufvoid =3D 2988448

2009-08-04 18:39:12,459 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 5793; kvend =3D 3826; length =3D 9830
2009-08-04 18:39:12,697 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 132
2009-08-04 18:39:23,138 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full =3D true

2009-08-04 18:39:23,138 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 136018; bufend =3D 1347353; bufvoid =3D 2988448
2009-08-04 18:39:23,138 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 3826; kvend =3D 1859; length =3D 9830

2009-08-04 18:39:25,747 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 133
2009-08-04 18:47:49,823 INFO org.apache.hadoop.mapred.MapTask:
Starting flush of map output
2009-08-04 18:47:50,132 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 134

2009-08-04 18:47:50,525 INFO org.apache.hadoop.mapred.Merger: Merging
135 sorted segments
2009-08-04 18:47:50,528 INFO org.apache.hadoop.mapred.Merger: Merging
9 intermediate segments out of a total of 135
2009-08-04 18:47:52,224 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 127

2009-08-04 18:47:53,837 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 118
2009-08-04 18:47:55,417 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 109

2009-08-04 18:47:56,990 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 100
2009-08-04 18:47:58,492 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 91

2009-08-04 18:48:00,191 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 82
2009-08-04 18:48:02,315 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 73

2009-08-04 18:48:04,184 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 64
2009-08-04 18:48:06,162 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 55

2009-08-04 18:48:08,149 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 46
2009-08-04 18:48:09,888 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 37

2009-08-04 18:48:11,744 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 28
2009-08-04 18:48:13,544 INFO org.apache.hadoop.mapred.Merger: Merging
10 intermediate segments out of a total of 19

2009-08-04 18:48:21,177 INFO org.apache.hadoop.mapred.Merger: Down to
the last merge-pass, with 10 segments left of total size: 153426836
bytes
2009-08-04 18:48:46,226 INFO org.apache.hadoop.mapred.TaskRunner:
Task:attempt_200908041626_0001_m_000133_2 is done. And is in the
process of commiting

2009-08-04 18:48:46,373 INFO org.apache.hadoop.mapred.TaskRunner: Task
'attempt_200908041626_0001_m_000133_2' done.

And here the same task, but an earlier attempt (it only goes up to spill
132, but those do vary slightly in size, right?):

2009-08-04 17:15:49,112 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 321905; bufend =3D 1464691; bufvoid =3D 2988448
2009-08-04 17:15:49,112 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 7764; kvend =3D 5797; length =3D 9830

2009-08-04 17:15:49,910 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 126
2009-08-04 17:16:00,785 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full =3D true
2009-08-04 17:16:00,785 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 1464691; bufend =3D 2580856; bufvoid =3D 2988448

2009-08-04 17:16:00,785 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 5797; kvend =3D 3830; length =3D 9830
2009-08-04 17:16:05,728 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 127
2009-08-04 17:16:20,883 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full =3D true

2009-08-04 17:16:20,883 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 2580856; bufend =3D 1000978; bufvoid =3D 2988448
2009-08-04 17:16:20,883 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 3830; kvend =3D 1863; length =3D 9830

2009-08-04 17:16:21,709 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 128
2009-08-04 17:16:24,461 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full =3D true
2009-08-04 17:16:24,461 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 1000978; bufend =3D 2246166; bufvoid =3D 2988448

2009-08-04 17:16:24,461 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 1863; kvend =3D 9727; length =3D 9830
2009-08-04 17:16:24,934 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 129
2009-08-04 17:16:40,853 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full =3D true

2009-08-04 17:16:40,853 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 2246166; bufend =3D 374750; bufvoid =3D 2988435
2009-08-04 17:16:40,853 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 9727; kvend =3D 7760; length =3D 9830

2009-08-04 17:16:43,740 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 130
2009-08-04 17:16:49,141 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full =3D true
2009-08-04 17:16:49,141 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 374750; bufend =3D 1653302; bufvoid =3D 2988448

2009-08-04 17:16:49,141 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 7760; kvend =3D 5793; length =3D 9830
2009-08-04 17:16:49,868 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 131
2009-08-04 17:17:04,902 INFO org.apache.hadoop.mapred.MapTask:
Spilling map output: record full =3D true

2009-08-04 17:17:04,902 INFO org.apache.hadoop.mapred.MapTask:
bufstart =3D 1653302; bufend =3D 2882491; bufvoid =3D 2988448
2009-08-04 17:17:04,902 INFO org.apache.hadoop.mapred.MapTask: kvstart
=3D 5793; kvend =3D 3826; length =3D 9830

2009-08-04 17:17:05,355 INFO org.apache.hadoop.mapred.MapTask:
Finished spill 132

There's no more output after that last spill, since the task eventually got
killed after 10 minutes of nothing.

And in case it can help, here's a thread dump for one of those failed tasks=
:
2009-08-04 18:53:23,460 INFO org.apache.hadoop.mapred.TaskTracker:
attempt_200908041626_0001_m_000135_3: Task
attempt_200908041626_0001_m_000135_3 failed to report status for 602
seconds. Killing!
2009-08-04 18:53:23,470 INFO org.apache.hadoop.mapred.TaskTracker: Process
Thread Dump: lost task
31 active threads
Thread 1673 (process reaper):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    java.lang.UNIXProcess.waitForProcessExit(Native Method)
    java.lang.UNIXProcess.access$900(UNIXProcess.java:20)
    java.lang.UNIXProcess$1$1.run(UNIXProcess.java:132)
Thread 1672 (JVM Runner jvm_200908041626_0001_m_1938204689 spawned.):
  State: WAITING
  Blocked count: 1
  Waited count: 2
  Waiting on java.lang.UNIXProcess@155d434
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    java.lang.UNIXProcess.waitFor(UNIXProcess.java:165)
    org.apache.hadoop.util.Shell.runCommand(Shell.java:186)
    org.apache.hadoop.util.Shell.run(Shell.java:134)

org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.runChild(Jv=
mManager.java:335)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.run(JvmMana=
ger.java:324)
Thread 1671 (Thread-1040):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.lang.Object@1ba4552
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:409)
Thread 1646 (process reaper):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    java.lang.UNIXProcess.waitForProcessExit(Native Method)
    java.lang.UNIXProcess.access$900(UNIXProcess.java:20)
    java.lang.UNIXProcess$1$1.run(UNIXProcess.java:132)
Thread 1645 (JVM Runner jvm_200908041626_0001_m_2100332869 spawned.):
  State: WAITING
  Blocked count: 1
  Waited count: 2
  Waiting on java.lang.UNIXProcess@5e34ce
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    java.lang.UNIXProcess.waitFor(UNIXProcess.java:165)
    org.apache.hadoop.util.Shell.runCommand(Shell.java:186)
    org.apache.hadoop.util.Shell.run(Shell.java:134)

org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.runChild(Jv=
mManager.java:335)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.run(JvmMana=
ger.java:324)
Thread 1644 (Thread-1023):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.lang.Object@1bee6f
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:409)
Thread 143 (process reaper):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    java.lang.UNIXProcess.waitForProcessExit(Native Method)
    java.lang.UNIXProcess.access$900(UNIXProcess.java:20)
    java.lang.UNIXProcess$1$1.run(UNIXProcess.java:132)
Thread 141 (JVM Runner jvm_200908041626_0001_r_-836397802 spawned.):
  State: WAITING
  Blocked count: 1
  Waited count: 2
  Waiting on java.lang.UNIXProcess@11fceed
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    java.lang.UNIXProcess.waitFor(UNIXProcess.java:165)
    org.apache.hadoop.util.Shell.runCommand(Shell.java:186)
    org.apache.hadoop.util.Shell.run(Shell.java:134)

org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.runChild(Jv=
mManager.java:335)

org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.run(JvmMana=
ger.java:324)
Thread 140 (Thread-89):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.lang.Object@1c63791
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:409)
Thread 33 (IPC Client (47) connection to localhost/127.0.0.1:9001 from
root):
  State: TIMED_WAITING
  Blocked count: 5563
  Waited count: 5552
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:403)
    org.apache.hadoop.ipc.Client$Connection.run(Client.java:445)
Thread 32 (Directory/File cleanup thread):
  State: WAITING
  Blocked count: 0
  Waited count: 165
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@fdffb=
1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await=
(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)

org.apache.hadoop.mapred.CleanupQueue$PathCleanupThread.run(CleanupQueue.ja=
va:89)
Thread 8 (taskCleanup):
  State: WAITING
  Blocked count: 0
  Waited count: 2
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@19c20=
5b
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await=
(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.mapred.TaskTracker$1.run(TaskTracker.java:352)
    java.lang.Thread.run(Thread.java:619)
Thread 31 (TaskLauncher for task):
  State: WAITING
  Blocked count: 4
  Waited count: 5
  Waiting on java.util.LinkedList@1d9d565
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)

org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:1662=
)
Thread 30 (TaskLauncher for task):
  State: WAITING
  Blocked count: 783
  Waited count: 781
  Waiting on java.util.LinkedList@1fbebee
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)

org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:1662=
)
Thread 29 (Map-events fetcher for all reduce tasks on
tracker_ip-10-244-145-237.ec2.internal:localhost/127.0.0.1:40135):
  State: TIMED_WAITING
  Blocked count: 10965
  Waited count: 10957
  Stack:
    java.lang.Object.wait(Native Method)

org.apache.hadoop.mapred.TaskTracker$MapEventsFetcherThread.run(TaskTracker=
.java:671)
Thread 27 (IPC Server handler 7 on 40135):
  State: WAITING
  Blocked count: 5
  Waited count: 2565
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da6=
90
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await=
(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 26 (IPC Server handler 6 on 40135):
  State: WAITING
  Blocked count: 11
  Waited count: 2565
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da6=
90
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await=
(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 25 (IPC Server handler 5 on 40135):
  State: WAITING
  Blocked count: 11
  Waited count: 2566
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da6=
90
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await=
(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 24 (IPC Server handler 4 on 40135):
  State: WAITING
  Blocked count: 7
  Waited count: 2565
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da6=
90
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await=
(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 23 (IPC Server handler 3 on 40135):
  State: WAITING
  Blocked count: 10
  Waited count: 2565
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da6=
90
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await=
(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 22 (IPC Server handler 2 on 40135):
  State: WAITING
  Blocked count: 11
  Waited count: 2566
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da6=
90
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await=
(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 21 (IPC Server handler 1 on 40135):
  State: WAITING
  Blocked count: 15
  Waited count: 2567
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da6=
90
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await=
(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 20 (IPC Server handler 0 on 40135):
  State: WAITING
  Blocked count: 12
  Waited count: 2565
  Waiting on
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@17da6=
90
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)

java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await=
(AbstractQueuedSynchronizer.java:1925)

java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:939)
Thread 17 (IPC Server listener on 40135):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:84)
    org.apache.hadoop.ipc.Server$Listener.run(Server.java:318)
Thread 19 (IPC Server Responder):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)
    org.apache.hadoop.ipc.Server$Responder.run(Server.java:478)
Thread 16 (Timer-0):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 298
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:509)
    java.util.TimerThread.run(Timer.java:462)
Thread 15 (11502424@qtp0-0 - Acceptor0 SelectChannelConnector@0.0.0.0:50060
):
  State: RUNNABLE
  Blocked count: 50
  Waited count: 1
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)

org.mortbay.io.nio.SelectorManager$SelectSet.doSelect(SelectorManager.java:=
429)
    org.mortbay.io.nio.SelectorManager.doSelect(SelectorManager.java:185)

org.mortbay.jetty.nio.SelectChannelConnector.accept(SelectChannelConnector.=
java:124)

org.mortbay.jetty.AbstractConnector$Acceptor.run(AbstractConnector.java:707=
)

org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:52=
2)
Thread 4 (Signal Dispatcher):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
Thread 3 (Finalizer):
  State: WAITING
  Blocked count: 424
  Waited count: 425
  Waiting on java.lang.ref.ReferenceQueue$Lock@7b6d1c
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:134)
    java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)
Thread 2 (Reference Handler):
  State: WAITING
  Blocked count: 445
  Waited count: 446
  Waiting on java.lang.ref.Reference$Lock@16ee240
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)
Thread 1 (main):
  State: RUNNABLE
  Blocked count: 2973
  Waited count: 5789
  Stack:
    sun.management.ThreadImpl.getThreadInfo0(Native Method)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:147)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:123)

org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java=
:149)

org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:2=
03)

org.apache.hadoop.mapred.TaskTracker.markUnresponsiveTasks(TaskTracker.java=
:1383)
    org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:1129=
)
    org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:1779)
    org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:2881)

2009-08-04 18:53:23,471 INFO org.apache.hadoop.mapred.TaskTracker: About to
purge task: attempt_200908041626_0001_m_000135_3
2009-08-04 18:53:23,471 INFO org.apache.hadoop.mapred.TaskTracker:
addFreeSlot : current free slots : 3
2009-08-04 18:53:23,471 INFO org.apache.hadoop.mapred.TaskRunner:
attempt_200908041626_0001_m_000135_3 done; removing files.
2009-08-04 18:53:23,550 INFO org.apache.hadoop.mapred.IndexCache: Map ID
attempt_200908041626_0001_m_000135_3 not found in cache


Thanks in advance for any response!
I'm afraid I'm somewhat clueless about this.

Mathias

From common-user-return-16551-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 09:42:10 2009
Return-Path: <common-user-return-16551-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 5796 invoked from network); 5 Aug 2009 09:42:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 09:42:09 -0000
Received: (qmail 21501 invoked by uid 500); 5 Aug 2009 09:42:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21415 invoked by uid 500); 5 Aug 2009 09:42:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21405 invoked by uid 99); 5 Aug 2009 09:42:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 09:42:14 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of clarkemjj@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 09:42:05 +0000
Received: by fxm24 with SMTP id 24so3813135fxm.36
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 02:41:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=cudxnV8zSH7mJ61h9FZ6hGRXaphKOdTw7gC0lz14ruo=;
        b=XIGgPLdGZUIGD+qWJHob9G4zNGqzWyzTxMQqQ8EA8EAhOcQKGdF4y9L/Eokp5miwz+
         BLqE915oRU00NsR9i1FZd/2II5EA3GBfQwVsZ7ryh5fj8ITXyYAVyXKA/z+raDMA6jVW
         TqL2evNFhyDzCgnJbJfwtN2fhZsfjApcIYnlU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=Ld3B9f714dKt9SNxlh8f4ck52gDbOauREHAhKviklJ4pC+cJn5uuAjV9fPHu2AsWYi
         MkabC4lrViVH7D23zzFlIsPuEVsAC2EQlv8IwI8urA+pN7P4z8m0fhlAcM53s9Z7WiCU
         2r8Xi2lvjRv3I7tnqQCG1nAAo3H7Mf03du2TM=
MIME-Version: 1.0
Received: by 10.204.62.133 with SMTP id x5mr723490bkh.60.1249465304865; Wed, 
	05 Aug 2009 02:41:44 -0700 (PDT)
Date: Wed, 5 Aug 2009 10:41:44 +0100
Message-ID: <4238036a0908050241v31227566nf6ba6439108eee89@mail.gmail.com>
Subject: Hadoop 0.19.2 + eclipse 3.5
From: John Clarke <clarkemjj@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c5b470a7dd70047061cf4a
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5b470a7dd70047061cf4a
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

I am trying to get my Eclipse Galileo 3.5 envronment working with the Hadoop
0.19.2 Eclipse plugin. I am running Windows XP.

Previously, I tried to use Hadoop 0.18.3 with this Eclipse and it partly
worked. I could browse the DFS but could not run a project because when I
clicked Run on Hadoop no dialog came up. Also, it is odd that Eclipse needs
to be launched via Cygwin for the DFS browsing to work.

So, my next attempt was to try 0.19.2 but this time it is like the plugin is
not recognized at all as there is no MapReduce perspective. I had removed
the 0.18.3 plugin and restarted.

Any help would be much appreciated,
John

--001636c5b470a7dd70047061cf4a--

From common-user-return-16552-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 09:46:06 2009
Return-Path: <common-user-return-16552-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7901 invoked from network); 5 Aug 2009 09:46:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 09:46:06 -0000
Received: (qmail 30908 invoked by uid 500); 5 Aug 2009 09:46:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 30855 invoked by uid 500); 5 Aug 2009 09:46:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 30845 invoked by uid 99); 5 Aug 2009 09:46:10 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 09:46:10 +0000
X-ASF-Spam-Status: No, hits=-1.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [199.64.220.26] (HELO az18ip008.honeywell.com) (199.64.220.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 09:45:58 +0000
X-IronPort-AV: E=Sophos;i="4.43,327,1246863600"; 
   d="scan'208";a="256614821"
Received: from unknown (HELO az18ex6003.global.ds.honeywell.com) ([10.192.23.92])
  by az18ip008.honeywell.com with ESMTP; 05 Aug 2009 02:45:37 -0700
Received: from IE10EV813.global.ds.honeywell.com ([199.63.32.243]) by az18ex6003.global.ds.honeywell.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Wed, 5 Aug 2009 02:45:36 -0700
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
Subject: RE: Hadoop 0.19.2 + eclipse 3.5
Date: Wed, 5 Aug 2009 15:15:33 +0530
Message-ID: <CEDB38A443476D40901289F9F19E288A02C6832E@IE10EV813.global.ds.honeywell.com>
In-Reply-To: <4238036a0908050241v31227566nf6ba6439108eee89@mail.gmail.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: Hadoop 0.19.2 + eclipse 3.5
Thread-Index: AcoVsQgpsnK/xawnThavtFxBKmSZxwAAEdCw
References: <4238036a0908050241v31227566nf6ba6439108eee89@mail.gmail.com>
From: "Puri, Aseem" <Aseem.Puri@Honeywell.com>
To: <common-user@hadoop.apache.org>
X-OriginalArrivalTime: 05 Aug 2009 09:45:36.0625 (UTC) FILETIME=[7BF0BE10:01CA15B1]
X-Virus-Checked: Checked by ClamAV on apache.org

John,

You need to Eclipse Europa for that.

You can download it from http://archive.eclipse.org/eclipse/downloads/=20

Regards,
Aseem Puri

-----Original Message-----
From: John Clarke [mailto:clarkemjj@gmail.com]=20
Sent: Wednesday, August 05, 2009 3:12 PM
To: common-user@hadoop.apache.org
Subject: Hadoop 0.19.2 + eclipse 3.5

Hi,

I am trying to get my Eclipse Galileo 3.5 envronment working with the
Hadoop
0.19.2 Eclipse plugin. I am running Windows XP.

Previously, I tried to use Hadoop 0.18.3 with this Eclipse and it partly
worked. I could browse the DFS but could not run a project because when
I
clicked Run on Hadoop no dialog came up. Also, it is odd that Eclipse
needs
to be launched via Cygwin for the DFS browsing to work.

So, my next attempt was to try 0.19.2 but this time it is like the
plugin is
not recognized at all as there is no MapReduce perspective. I had
removed
the 0.18.3 plugin and restarted.

Any help would be much appreciated,
John

From common-user-return-16553-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 10:05:32 2009
Return-Path: <common-user-return-16553-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 13481 invoked from network); 5 Aug 2009 10:05:32 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 10:05:32 -0000
Received: (qmail 37134 invoked by uid 500); 5 Aug 2009 09:48:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 37059 invoked by uid 500); 5 Aug 2009 09:48:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 37049 invoked by uid 99); 5 Aug 2009 09:48:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 09:48:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of clarkemjj@gmail.com designates 209.85.218.210 as permitted sender)
Received: from [209.85.218.210] (HELO mail-bw0-f210.google.com) (209.85.218.210)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 09:48:03 +0000
Received: by bwz6 with SMTP id 6so3770726bwz.29
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 02:47:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=UldEbimM8Vpdt/8rdxhgOaMaYvbFPhE1wm+6qAwZgh0=;
        b=NyeH3bDdltub7nSTz7IHrJq3fHBRPwODuCN7GCDl613TcDOGzUceHl6ZSVzYyZzSp7
         js8oWc4b5R9oVUya3xjO8q8yccdD7/19MIJGsrd3s++wE3aeClrMzqk6ANC4fNVSGWgj
         j8ljzwgwAt/XtS6SdiZh9pTf6n9zfjTyDA1NI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=ma/CW/Mc2OROnF4mvXQqBNbEraHVZ13t0f9NRIxxHnjO/zip1hmpJ4LJTOhlAw0xmV
         /Lf8QZgbT78J7WUOVf/bPdNrRcNud8JFkVrr+3w13EH1xkrC6OP4UdgkvcAJzktrtCCR
         4ZoKxY83PHm53rShgR0sGXMuL51Zw55Jf2qAk=
MIME-Version: 1.0
Received: by 10.204.62.133 with SMTP id x5mr728558bkh.60.1249465661718; Wed, 
	05 Aug 2009 02:47:41 -0700 (PDT)
In-Reply-To: <CEDB38A443476D40901289F9F19E288A02C6832E@IE10EV813.global.ds.honeywell.com>
References: <4238036a0908050241v31227566nf6ba6439108eee89@mail.gmail.com>
	 <CEDB38A443476D40901289F9F19E288A02C6832E@IE10EV813.global.ds.honeywell.com>
Date: Wed, 5 Aug 2009 10:47:41 +0100
Message-ID: <4238036a0908050247qbaa66c1s379bcf545def753b@mail.gmail.com>
Subject: Re: Hadoop 0.19.2 + eclipse 3.5
From: John Clarke <clarkemjj@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c5b470ed0381047061e402
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5b470ed0381047061e402
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks for the quick reply!

Hmm that's a shame as I have my Galileo env set up nicely :/

I'll go get Europa so!

cheers



2009/8/5 Puri, Aseem <Aseem.Puri@honeywell.com>

> John,
>
> You need to Eclipse Europa for that.
>
> You can download it from http://archive.eclipse.org/eclipse/downloads/
>
> Regards,
> Aseem Puri
>
> -----Original Message-----
> From: John Clarke [mailto:clarkemjj@gmail.com]
> Sent: Wednesday, August 05, 2009 3:12 PM
> To: common-user@hadoop.apache.org
> Subject: Hadoop 0.19.2 + eclipse 3.5
>
> Hi,
>
> I am trying to get my Eclipse Galileo 3.5 envronment working with the
> Hadoop
> 0.19.2 Eclipse plugin. I am running Windows XP.
>
> Previously, I tried to use Hadoop 0.18.3 with this Eclipse and it partly
> worked. I could browse the DFS but could not run a project because when
> I
> clicked Run on Hadoop no dialog came up. Also, it is odd that Eclipse
> needs
> to be launched via Cygwin for the DFS browsing to work.
>
> So, my next attempt was to try 0.19.2 but this time it is like the
> plugin is
> not recognized at all as there is no MapReduce perspective. I had
> removed
> the 0.18.3 plugin and restarted.
>
> Any help would be much appreciated,
> John
>

--001636c5b470ed0381047061e402--

From common-user-return-16554-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 11:17:44 2009
Return-Path: <common-user-return-16554-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 46794 invoked from network); 5 Aug 2009 11:17:44 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 11:17:44 -0000
Received: (qmail 49800 invoked by uid 500); 5 Aug 2009 11:17:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 49719 invoked by uid 500); 5 Aug 2009 11:17:48 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 49709 invoked by uid 99); 5 Aug 2009 11:17:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 11:17:47 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mathias.demare@gmail.com designates 209.85.218.210 as permitted sender)
Received: from [209.85.218.210] (HELO mail-bw0-f210.google.com) (209.85.218.210)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 11:17:39 +0000
Received: by bwz6 with SMTP id 6so9992bwz.29
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 04:17:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:cc:content-type;
        bh=mkysc709gU/fPlTIfsGyMgBPg6yA5v6LbXxL52e9amY=;
        b=jKemyP/fvYRcpXB4wVuFbiKcSecfl/W5XZ3JUnHOcaacNRrMa7Kt/RTq8fnFcZtrDk
         4eCNgzTJYTHHKwfp2inkcW+4YCDGo6wjvlAiL41yVuf++TsjUpnRMd0uQfqfHLwNyw1g
         F0Axkf/z7EgilS0tv4243xr+ookoMS986qPX4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        b=S33qgJ038dTcIo7cr2yalG4uFEpEQubP42PsO1iiKTPTybya9/L16bVbN0/XAWBIcD
         CxXlfeZAt4NXdjLpEtOgDSrPZEvMNnziP2gsx3aIYK4I9vV2zNJHowvYM++i/uVBPMD9
         zBuiYNycwV2wj5QaxGCXcYrJJGaFvrf89AwTs=
MIME-Version: 1.0
Received: by 10.223.117.209 with SMTP id s17mr1732179faq.14.1249471038270; 
	Wed, 05 Aug 2009 04:17:18 -0700 (PDT)
Reply-To: mathias.demare@gmail.com
In-Reply-To: <616DA47B2EF5B944B91846785B512FF4BD3663BEFC@EGL-EX07VS01.ds.corp.yahoo.com>
References: <375c60f40908050002n3a110d66ua2672a40bb8ad866@mail.gmail.com> 
	<616DA47B2EF5B944B91846785B512FF4BD3663BEFC@EGL-EX07VS01.ds.corp.yahoo.com>
From: =?UTF-8?Q?Mathias_De_Mar=C3=A9?= <mathias.demare@gmail.com>
Date: Wed, 5 Aug 2009 13:16:58 +0200
Message-ID: <375c60f40908050416w1780c87bl422cb53b6ee77950@mail.gmail.com>
Subject: Re: Some tasks fail to report status between the end of the map and 
	the beginning of the merge
To: Amogh Vasekar <amogh@yahoo-inc.com>
Cc: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Content-Type: multipart/alternative; boundary=001636c5b9ac64b12f04706325b7
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5b9ac64b12f04706325b7
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

> On Wed, Aug 5, 2009 at 9:38 AM, Jothi Padmanabhan <jothipn@yahoo-inc.com>wrote:
> Hi,
>
> Could you please try setting this parameter
> mapred.merge.recordsBeforeProgress to a lower number?
> See https://issues.apache.org/jira/browse/HADOOP-4714
>
> Cheers
> Jothi


Hm, that bug looks like it's applicable during the merge, but my case is a
block right before the merge (but seemingly right after all of the map tasks
finish).
I tried putting mapred.merge.recordsBeforeProgress to 100, and it didn't
make a difference.

On Wed, Aug 5, 2009 at 10:32 AM, Amogh Vasekar <amogh@yahoo-inc.com> wrote:

> 10 mins reminds me of parameter mapred.task.timeout . This is configurable.
> Or alternatively you might just do a sysout to let tracker know of its
> existence ( not an ideal solution though )
>
> Thanks,
> Amogh


Well, the map tasks take around 30 minutes to run. Letting the task idle for
a large number of minutes after that is a lot of useless time, imho. I tried
with 20 minutes now, but I still get timeouts.

I don't know if it's useful, but here are the settings of the map tasks at
the moment:

<configuration>
  <property>
    <name>mapred.job.tracker</name>
    <value>localhost:9001</value>
  </property>
  <property>
    <name>io.sort.mb</name>
    <value>3</value>
    <description>The total amount of buffer memory to use while sorting
    files, in megabytes.  By default, gives each merge stream 1MB, which
    should minimize seeks.</description>
  </property>
<property>
  <name>mapred.tasktracker.map.tasks.maximum</name>
  <value>4</value>
  <description>The maximum number of map tasks that will be run
  simultaneously by a task tracker.
  </description>
</property>

<property>
  <name>mapred.tasktracker.reduce.tasks.maximum</name>
  <value>4</value>
  <description>The maximum number of reduce tasks that will be run
  simultaneously by a task tracker.
  </description>
</property>

<property>
  <name>mapred.max.split.size</name>
  <value>1000000</value>
</property>

<property>
  <name>mapred.child.java.opts</name>
  <value>-Xmx400m</value>
</property>

<property>
<name>mapred.merge.recordsBeforeProgress</name>
<value>100</value>
</property>

<property>
<name>mapred.task.timeout</name>
<value>1200000</value>
</property>

</configuration>

Ideally, I would want to get rid of the delay that causes the timeouts, yet
also increase the split size somewhat (though I think a larger split size
would increase the delay even more?).
The map tasks take around 8000-11000 records as input, and can produce up to
1 000 000 records as output (in case this is relevant).

Mathias

--001636c5b9ac64b12f04706325b7--

From common-user-return-16555-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 12:29:04 2009
Return-Path: <common-user-return-16555-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80557 invoked from network); 5 Aug 2009 12:29:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 12:29:04 -0000
Received: (qmail 36085 invoked by uid 500); 5 Aug 2009 12:29:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35993 invoked by uid 500); 5 Aug 2009 12:29:09 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35983 invoked by uid 99); 5 Aug 2009 12:29:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 12:29:09 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ryan.justin.smith@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 12:28:59 +0000
Received: by ewy26 with SMTP id 26so56477ewy.29
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 05:28:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=0CApQKK9BwaLu1P4BOtYgMmmtliNy5mCK6lfw1LOJ9s=;
        b=LO+LP4y7F2qTnXJ0qETukaNL/UjvTfc+lZi+8dBwfx6AC8YpNl9VnpSbhrvD4J2b9g
         nysHLjLY9RhMQzDFbd3DfdZ59TFhCy6GmtVpaKm0zt3J/W+0iQtn6nUezO6SDIGyfUdj
         fBIqJ3HzYsw9+GO/xuk2VofNtGUJzik61RKZI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=nVGTZZZkfTMCE9yJTYZukmdsBMw/Uv+IG03KY7AISRtYcvA31W79MPNcDnniroR21g
         VPSwFvjhd66cs+8b/XkxIrKsECLS4m5uirKnRRYZ5TcCgjkywQHq9s+yw2h5xLR/VK5n
         2mjE7FvBMAXG6cBilsmG8hJKk8fTtZxpMM4aQ=
MIME-Version: 1.0
Received: by 10.216.19.68 with SMTP id m46mr1811836wem.7.1249475319464; Wed, 
	05 Aug 2009 05:28:39 -0700 (PDT)
Date: Wed, 5 Aug 2009 08:28:39 -0400
Message-ID: <ae4767d10908050528o18c0fbfey61e89fc732811908@mail.gmail.com>
Subject: network interface trunking
From: Ryan Smith <ryan.justin.smith@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64c271892823d04706424ff
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64c271892823d04706424ff
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello everyone,
If I have a machine (DN) with 2 network cards, can i get double bandwidth
for my data node in hadoop?
Or is the preferred solution to link aggregate the 2 interfaces on the os
layer?  Any thoughts on this would be appreciated.
Thanks in advance.
-Ryan

--0016e64c271892823d04706424ff--

From common-user-return-16556-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 13:09:31 2009
Return-Path: <common-user-return-16556-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 94888 invoked from network); 5 Aug 2009 13:09:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 13:09:31 -0000
Received: (qmail 94169 invoked by uid 500); 5 Aug 2009 13:09:36 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 94088 invoked by uid 500); 5 Aug 2009 13:09:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 94078 invoked by uid 99); 5 Aug 2009 13:09:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 13:09:35 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of eddymier@gmail.com designates 209.85.211.200 as permitted sender)
Received: from [209.85.211.200] (HELO mail-yw0-f200.google.com) (209.85.211.200)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 13:09:26 +0000
Received: by ywh38 with SMTP id 38so98635ywh.20
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 06:09:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=1zS2/AwnS82qQ4XSUwXoQe1Gwpx0gSAiV1WBjR3fuGQ=;
        b=R2ijVIB9Yio4jal/xlD/G0poTZCqlN5nR28ZR/aesOjFsGw8BKb4xmfyGzWFbcym4a
         kC3iOvzz3AzNrQqIpe0titwL4m0wUQxjbT1DTEhl41nWnny2NocJxvRF5QP9HvAOJqfh
         2aFZq2+whmVijiyiRrOLUZ3JQOUexQlMbClPM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=eKaoKOnEyVnkiPq5oKwDTujyRHgG2NF7XanKftWxbl8zon+iG4MEDMK1Fy++SMpfkt
         EhHYolZP5DTS+6pOTv7UFFyM3vioYt8qUsCeUY3MWiijq+AEpkeeZsw7AnDVA86e8jFQ
         A1PR/jCjYZsAXHwSNBjv9D3zOuf7ljS9ToXb0=
MIME-Version: 1.0
Received: by 10.231.12.5 with SMTP id v5mr2669867ibv.55.1249477744974; Wed, 05 
	Aug 2009 06:09:04 -0700 (PDT)
Date: Wed, 5 Aug 2009 21:09:04 +0800
Message-ID: <b4e9dc6e0908050609pe4f9506ib79bdbfe927f14d5@mail.gmail.com>
Subject: questions about HDFS file access synchronization
From: "Zhang Bingjun (Eddy)" <eddymier@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000325574c8624dd31047064b5b2
X-Virus-Checked: Checked by ClamAV on apache.org

--000325574c8624dd31047064b5b2
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hi All,

I am quite new to Hadoop. May I ask a simple question about HDFS file access
synchronization?

For some very typical scenarios below, how does HDFS respond? Is there a way
to synchronize file access in HDFS?

A tries to read a file currently being written by B.
A tries to write a file currently being written by B.
A tries to write a file currently being read by B.

We plan to put some shared data in HDFS so that multiple applications can
share the data between them. The ideal case is that the underlying
distributed file system (HDFS here) will provide file access synchronization
so that applications know when they can or cannot operate on a certain file.
Is this way of thinking correct? What is the typical design for this kind of
application scenario?

I am quite confused. Definitely need to read more about HDFS and other
distributed file systems. But before that, I would appreciate very much the
input from experts in the mailing list.

Thanks a lot!

Best regards,
Zhang Bingjun (Eddy)

E-mail: eddymier@gmail.com, bingjun@nus.edu.sg, bingjun@comp.nus.edu.sg
Tel No: +65-96188110 (M)

--000325574c8624dd31047064b5b2--

From common-user-return-16557-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 14:06:04 2009
Return-Path: <common-user-return-16557-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 30039 invoked from network); 5 Aug 2009 14:06:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 14:06:04 -0000
Received: (qmail 99109 invoked by uid 500); 5 Aug 2009 14:06:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 99037 invoked by uid 500); 5 Aug 2009 14:06:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 99027 invoked by uid 99); 5 Aug 2009 14:06:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 14:06:08 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of clarkemjj@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 14:05:59 +0000
Received: by fxm24 with SMTP id 24so113735fxm.36
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 07:05:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=EWqBjtXJ3zfU9MMXvEz3a6BlRWF5GWXnKStoGlPzV2s=;
        b=HDd4Xmsz1KC5W+hOtGVzFKTk5Q3RUE4Ijw95NtG0ijpBOijt+V7495fV2TGiML3F7k
         M+0fF2spj+mZj8iODsQA+PdR0kJWJaFScSC7fT/2dLBhXo/B1OxROBMPSADvENEo6GvC
         Oxy7cJQZ8HxV6bLHYkqplgQDpzvqwR17aygKI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=bF5Hgwc64EAXXA9YtIO/NXSPm9W/fG7gGW9tuZSyH/ArrnMDjO19dHYN+L1QqgTN+j
         +4Pb3CIpBqx5nI/8Rg9qjv/FfeUuKDZnC9GCEu24Jt01rr+0f6CanCsJMc6LaPNRpfB7
         ZXhx0Gr0h+Dk3eKn4op2xzj1fxA+uLEpUjD+s=
MIME-Version: 1.0
Received: by 10.204.51.210 with SMTP id e18mr936994bkg.38.1249480763876; Wed, 
	05 Aug 2009 06:59:23 -0700 (PDT)
Date: Wed, 5 Aug 2009 14:59:23 +0100
Message-ID: <4238036a0908050659r2d4a35d0j6b695a9088b0e2b4@mail.gmail.com>
Subject: Eclipse plugin - user permissions
From: John Clarke <clarkemjj@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c5a69c15a7030470656996
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5a69c15a7030470656996
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

I have installed Eclipse Europa and the Hadoop 0.18.3 plugin. I am running
Windows XP. My Hadoop test environment is Ubuntu 9.04 running via
VirtualBox.

I have a user called "hadoop" in Ubuntu that I use to run Hadoop. I launched
all the namenode/datanode etc etc with this user.

Back in Eclipse in Windows XP I have created a new Map/Reduce Location
pointing at the Ubuntu virtual machine. I set the Username to be "hadoop".

I can browse the DFS from Eclipse but the namenode throws this exception:

==========
org.apache.hadoop.fs.permission.AccessControlException: Permission denied:
user=johnc, access=READ_EXECUTE, inode="system":hadoop:supergroup:rwx-wx-wx

==========


Now, johnc is my user under Windows XP that Eclipse is running in. Why is
the plugin using this value rather than the Username I defined in the
Map/Reduce Location?

Any idea on how I can resolve this issue?

Cheers,
John

--001636c5a69c15a7030470656996--

From common-user-return-16558-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 15:21:40 2009
Return-Path: <common-user-return-16558-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 74120 invoked from network); 5 Aug 2009 15:21:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 15:21:40 -0000
Received: (qmail 41235 invoked by uid 500); 5 Aug 2009 15:21:45 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 41135 invoked by uid 500); 5 Aug 2009 15:21:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 41125 invoked by uid 99); 5 Aug 2009 15:21:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 15:21:45 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.211.200] (HELO mail-yw0-f200.google.com) (209.85.211.200)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 15:21:37 +0000
Received: by ywh38 with SMTP id 38so228974ywh.20
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 08:21:16 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.117.13 with SMTP id p13mr4049949agc.12.1249485675824; Wed, 
	05 Aug 2009 08:21:15 -0700 (PDT)
In-Reply-To: <ae4767d10908050528o18c0fbfey61e89fc732811908@mail.gmail.com>
References: <ae4767d10908050528o18c0fbfey61e89fc732811908@mail.gmail.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Wed, 5 Aug 2009 08:20:55 -0700
Message-ID: <45f85f70908050820y1079b8c8o35d31b45fef9de94@mail.gmail.com>
Subject: Re: network interface trunking
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016362836ccdc06b00470668d1e
X-Virus-Checked: Checked by ClamAV on apache.org

--0016362836ccdc06b00470668d1e
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Ryan,
Yes, you can do this -- the term is called "interface bonding" and isn't too
hard to set up in Linux as long as your switch supports it. However, it is
pretty rare that it provides an appreciable performance benefit on typical
hardware and workloads -- probably not worth the doubled switch port
requirement in most cases.

-Todd

On Wed, Aug 5, 2009 at 5:28 AM, Ryan Smith <ryan.justin.smith@gmail.com>wrote:

> Hello everyone,
> If I have a machine (DN) with 2 network cards, can i get double bandwidth
> for my data node in hadoop?
> Or is the preferred solution to link aggregate the 2 interfaces on the os
> layer?  Any thoughts on this would be appreciated.
> Thanks in advance.
> -Ryan
>

--0016362836ccdc06b00470668d1e--

From common-user-return-16559-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 17:38:08 2009
Return-Path: <common-user-return-16559-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 24181 invoked from network); 5 Aug 2009 17:38:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 17:38:07 -0000
Received: (qmail 55580 invoked by uid 500); 5 Aug 2009 17:19:07 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 55553 invoked by uid 500); 5 Aug 2009 17:19:07 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 55542 invoked by uid 99); 5 Aug 2009 17:19:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:19:06 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:18:57 +0000
Received: by qyk26 with SMTP id 26so246800qyk.5
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 10:18:35 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.54.3 with SMTP id o3mr7375173qag.92.1249492715419; Wed, 05 
	Aug 2009 10:18:35 -0700 (PDT)
In-Reply-To: <35a22e220908050104n2f1c4c1co8684a0b0c0bdac4c@mail.gmail.com>
References: <9cafbc680908041610n683a7868ua85ebe6518fc476b@mail.gmail.com> 
	<35a22e220908050104n2f1c4c1co8684a0b0c0bdac4c@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 5 Aug 2009 10:18:15 -0700
Message-ID: <d6d7c4410908051018m331e6b65ue11e53247826b000@mail.gmail.com>
Subject: Re: how to get out of Safe Mode?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175d677273b9eb04706831b0
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175d677273b9eb04706831b0
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

For future reference,
$ bin/hadoop dfsadmin safemode -leave
will also just cause HDFS to exit safemode forcibly.

- Aaron

On Wed, Aug 5, 2009 at 1:04 AM, Amandeep Khurana <amansk@gmail.com> wrote:

> Two alternatives:
>
> 1. Do bin/hadoop namenode -format. That'll format the metadata and you can
> start afresh.
>
> 2. If that doesnt work, manually go and delete everything that resides in
> the directories to which you've pointed your Namenode and Datanodes to
> store
> their stuff in.
>
>
>
>
> On Tue, Aug 4, 2009 at 4:10 PM, Phil Whelan <phil123@gmail.com> wrote:
>
> > Hi,
> >
> > In setting up my cluster and brought a few machines up and down. I did
> > have some data in which I moved to Trash. Now that data is not 100%
> > available, which is fine, because I didn't want it.
> > But now I'm stuck in "Safe Mode", because it cannot find the data. I
> > cannot purge the Trash because it's in read-only due to Safe Mode.
> >
> >   Safe mode is ON.
> >   The ratio of reported blocks 0.9931 has not reached the threshold
> 0.9990.
> >   Safe mode will be turned off automatically.
> >   459 files and directories, 583 blocks = 1042 total. Heap Size is
> > 7.8 MB / 992.31 MB (0%)
> >
> > I want to just want format the entire HDFS filesystem. I have nothing
> > I need in there. How can I do this?
> >
> > Phil
> >
>

--0015175d677273b9eb04706831b0--

From common-user-return-16560-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 17:38:21 2009
Return-Path: <common-user-return-16560-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 25239 invoked from network); 5 Aug 2009 17:38:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 17:38:21 -0000
Received: (qmail 56563 invoked by uid 500); 5 Aug 2009 17:23:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 56538 invoked by uid 500); 5 Aug 2009 17:23:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 56528 invoked by uid 99); 5 Aug 2009 17:23:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:23:28 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.92.27] (HELO qw-out-2122.google.com) (74.125.92.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:23:19 +0000
Received: by qw-out-2122.google.com with SMTP id 8so94294qwh.35
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 10:22:58 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.54.3 with SMTP id o3mr7381320qag.92.1249492978126; Wed, 05 
	Aug 2009 10:22:58 -0700 (PDT)
In-Reply-To: <b4e9dc6e0908050609pe4f9506ib79bdbfe927f14d5@mail.gmail.com>
References: <b4e9dc6e0908050609pe4f9506ib79bdbfe927f14d5@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 5 Aug 2009 10:22:38 -0700
Message-ID: <d6d7c4410908051022j74ff9e67j37a09de6657b77ba@mail.gmail.com>
Subject: Re: questions about HDFS file access synchronization
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175d67721c51450470684187
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175d67721c51450470684187
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Wed, Aug 5, 2009 at 6:09 AM, Zhang Bingjun (Eddy) <eddymier@gmail.com>wrote:

> Hi All,
>
> I am quite new to Hadoop. May I ask a simple question about HDFS file
> access
> synchronization?
>
> For some very typical scenarios below, how does HDFS respond? Is there a
> way
> to synchronize file access in HDFS?
>
> A tries to read a file currently being written by B.


There is no sync() call in HDFS. A will read whatever portion of B's data
has already been committed to disk by the datanode. It is unspecified how
much data this will contain. It may be variable depending on which replica
of the file A is reading. After B close()'s the file, all the data will be
available to A.


>
> A tries to write a file currently being written by B.


This will fail. HDFS does not allow multiple writers to a file. The
FileSystem.create() call used by A to open the file for write access will
throw IOException.


>
> A tries to write a file currently being read by B.


This will fail. HDFS does not allow file updates, so if the file already
exists and B is reading it, the FileSystem.create() call used by A will fail
with IOException.


>
>
> We plan to put some shared data in HDFS so that multiple applications can
> share the data between them. The ideal case is that the underlying
> distributed file system (HDFS here) will provide file access
> synchronization
> so that applications know when they can or cannot operate on a certain
> file.
> Is this way of thinking correct? What is the typical design for this kind
> of
> application scenario?


You'll have to think carefully. You can't update files. There is also no
equivalent of flock(), so you can't use files as locks for exclusive access
to some part of a work flow. If that's what you need, you may want to look
at the ZooKeeper project and see if you can't integrate ZK into your system.
ZK is specifically designed to handle locking, mutual exclusion, and other
distributed synchronization problems.



>
>
> I am quite confused. Definitely need to read more about HDFS and other
> distributed file systems. But before that, I would appreciate very much the
> input from experts in the mailing list.


http://hadoop.apache.org/common/docs/r0.20.0/hdfs_user_guide.html and
http://hadoop.apache.org/common/docs/r0.20.0/hdfs_design.html are good
places to start.


>
>
> Thanks a lot!
>
> Best regards,
> Zhang Bingjun (Eddy)
>
> E-mail: eddymier@gmail.com, bingjun@nus.edu.sg, bingjun@comp.nus.edu.sg
> Tel No: +65-96188110 (M)
>

Cheers,
- Aaron

--0015175d67721c51450470684187--

From common-user-return-16561-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 17:38:37 2009
Return-Path: <common-user-return-16561-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 26408 invoked from network); 5 Aug 2009 17:38:37 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 17:38:37 -0000
Received: (qmail 57939 invoked by uid 500); 5 Aug 2009 17:28:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 57914 invoked by uid 500); 5 Aug 2009 17:28:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 57892 invoked by uid 99); 5 Aug 2009 17:28:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:28:35 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:28:23 +0000
Received: by qyk26 with SMTP id 26so253822qyk.5
        for <multiple recipients>; Wed, 05 Aug 2009 10:28:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.54.3 with SMTP id o3mr7388424qag.92.1249493282124; Wed, 05 
	Aug 2009 10:28:02 -0700 (PDT)
In-Reply-To: <bcaf338a0908032015h41cff744l1b0f74ea60cc32df@mail.gmail.com>
References: <bcaf338a0908032015h41cff744l1b0f74ea60cc32df@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 5 Aug 2009 10:27:42 -0700
Message-ID: <d6d7c4410908051027y22f68eb5ufa9989be16d3e846@mail.gmail.com>
Subject: Re: how to dump data from a mysql cluster to hdfs?
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175d67723af325047068535b
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175d67723af325047068535b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

mysqldump to local files on all 50 nodes, scp them to datanodes, and then
bin/hadoop fs -put?
- Aaron

On Mon, Aug 3, 2009 at 8:15 PM, Min Zhou <coderplay@gmail.com> wrote:

> hi all,
>
> We need to dump data from a mysql cluster with about 50 nodes to a hdfs
> file. Considered about the issues on security , we can't use tools like
> sqoop, where all datanodes must hold a connection to mysql. any
> suggestions?
>
>
> Thanks,
> Min
> --
> My research interests are distributed systems, parallel computing and
> bytecode based virtual machine.
>
> My profile:
> http://www.linkedin.com/in/coderplay
> My blog:
> http://coderplay.javaeye.com
>

--0015175d67723af325047068535b--

From common-user-return-16562-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 17:38:40 2009
Return-Path: <common-user-return-16562-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 26522 invoked from network); 5 Aug 2009 17:38:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 17:38:40 -0000
Received: (qmail 57975 invoked by uid 500); 5 Aug 2009 17:28:36 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 57947 invoked by uid 500); 5 Aug 2009 17:28:36 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 57897 invoked by uid 500); 5 Aug 2009 17:28:35 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 57892 invoked by uid 99); 5 Aug 2009 17:28:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:28:35 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:28:23 +0000
Received: by qyk26 with SMTP id 26so253822qyk.5
        for <multiple recipients>; Wed, 05 Aug 2009 10:28:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.54.3 with SMTP id o3mr7388424qag.92.1249493282124; Wed, 05 
	Aug 2009 10:28:02 -0700 (PDT)
In-Reply-To: <bcaf338a0908032015h41cff744l1b0f74ea60cc32df@mail.gmail.com>
References: <bcaf338a0908032015h41cff744l1b0f74ea60cc32df@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 5 Aug 2009 10:27:42 -0700
Message-ID: <d6d7c4410908051027y22f68eb5ufa9989be16d3e846@mail.gmail.com>
Subject: Re: how to dump data from a mysql cluster to hdfs?
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175d67723af325047068535b
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175d67723af325047068535b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

mysqldump to local files on all 50 nodes, scp them to datanodes, and then
bin/hadoop fs -put?
- Aaron

On Mon, Aug 3, 2009 at 8:15 PM, Min Zhou <coderplay@gmail.com> wrote:

> hi all,
>
> We need to dump data from a mysql cluster with about 50 nodes to a hdfs
> file. Considered about the issues on security , we can't use tools like
> sqoop, where all datanodes must hold a connection to mysql. any
> suggestions?
>
>
> Thanks,
> Min
> --
> My research interests are distributed systems, parallel computing and
> bytecode based virtual machine.
>
> My profile:
> http://www.linkedin.com/in/coderplay
> My blog:
> http://coderplay.javaeye.com
>

--0015175d67723af325047068535b--

From common-user-return-16563-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 17:38:50 2009
Return-Path: <common-user-return-16563-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 26937 invoked from network); 5 Aug 2009 17:38:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 17:38:50 -0000
Received: (qmail 58573 invoked by uid 500); 5 Aug 2009 17:30:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 58535 invoked by uid 500); 5 Aug 2009 17:30:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 58518 invoked by uid 500); 5 Aug 2009 17:30:28 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 58513 invoked by uid 99); 5 Aug 2009 17:30:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:30:28 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bradfordstephens@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:30:17 +0000
Received: by gxk18 with SMTP id 18so306245gxk.5
        for <multiple recipients>; Wed, 05 Aug 2009 10:29:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=BybqNUmZ51XjCraEXh4SZUF8AvmE1FmQzMTuRfRXPBU=;
        b=jSRWlonKIyovVFZMVQQEKBrIMokVOeOegdv3/bprUAJ5uh1RhUWZVRkpiYWujX0y6o
         TYSLlcLAmEm8AaH3w/y68WhNzT31WV2R1N4h1q0Dx86TgrRJRr/sYSgrzNkErZ2NjpND
         XkB7eB1TtMibk1UwTBi4qbH73bcNFqkLL26SE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=rj6N89SpX+zkNRF4aVU5SkG6e8JsEZLj9CW7Rt2yMe+7IyRUIv6TpG/+cRUEcVnWIh
         ASC/+lLp8YL4UEaeGalpTnl8sE2KnvZqsriU5tnyhTl/8uLNDqca/kRDWjjo+nHEn7y1
         jtLbaOn+SqlK7xMLf8S3IkCOjyagktmwFRPsI=
MIME-Version: 1.0
Received: by 10.90.84.2 with SMTP id h2mr4163609agb.10.1249493396490; Wed, 05 
	Aug 2009 10:29:56 -0700 (PDT)
In-Reply-To: <860544ed0907291652j3318349emc8e66864f2436958@mail.gmail.com>
References: <860544ed0907271216p7b3169dcree68278ca111bd7a@mail.gmail.com>
	 <860544ed0907281125l579a379dr4888708139ce19db@mail.gmail.com>
	 <860544ed0907291652j3318349emc8e66864f2436958@mail.gmail.com>
Date: Wed, 5 Aug 2009 10:29:56 -0700
Message-ID: <860544ed0908051029n64f8e68eo654015e8e853e55b@mail.gmail.com>
Subject: Re: THIS WEEK: PNW Hadoop, HBase / Apache Cloud Stack Users' Meeting, 
	Wed Jul 29th, Seattle
From: Bradford Stephens <bradfordstephens@gmail.com>
To: core-user@hadoop.apache.org, solr-user@lucene.apache.org, 
	java-user@lucene.apache.org, hbase-user@hadoop.apache.org, 
	Bradford Stephens <bstephens@visibletechnologies.com>
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

A big "thanks" to everyone who came out despite the heat! Hope to see
you again the last week of August, probably at UW.

On Wed, Jul 29, 2009 at 4:52 PM, Bradford
Stephens<bradfordstephens@gmail.com> wrote:
> Don't forget this is tonight! Excited to see everyone there.
>
> On Tue, Jul 28, 2009 at 11:25 AM, Bradford
> Stephens<bradfordstephens@gmail.com> wrote:
>> Hey everyone,
>>
>> SLIGHT change of plans.
>>
>> A few people have asked me to move to a place with Air Conditioning,
>> since the temperature's in the 90's this week. So, here we go:
>>
>> Big Time Brewing Company
>> 4133 University Way NE
>> Seattle, WA 98105
>>
>> Call me at 904-415-3009 if you have any questions.
>>
>>
>> On Mon, Jul 27, 2009 at 12:16 PM, Bradford
>> Stephens<bradfordstephens@gmail.com> wrote:
>>> Hello again!
>>>
>>> Yes, I know some of us are still recovering from OSCON. It's time for
>>> another delicious meetup to chat about Hadoop, HBase, Solr, Lucene,
>>> and more!
>>>
>>> UW is quite a pain for us to access until August, so we're changing
>>> the venue to one pretty close:
>>>
>>> Piccolo's Pizza
>>> 5301 Roosevelt Way NE
>>> (between 53rd St & 55th St)
>>>
>>> 6:45pm - 8:30 (or when we get bored)!
>>>
>>> As usual, people are more than welcome to give talks, whether they're
>>> long-format or lightning. I'd also really like to start thinking about
>>> hackathons, perhaps we could have one next month?
>>>
>>> I'll be talking about HBase .20 and the possibility of low-latency
>>> HBase Analytics. I'd be very excited to hear what people are up to!
>>>
>>> Contact me if there's any questions: 904-415-3009
>>>
>>> Cheers,
>>> Bradford
>>>
>>> --
>>> http://www.roadtofailure.com -- The Fringes of Scalability, Social
>>> Media, and Computer Science
>>>
>>
>>
>>
>> --
>> http://www.roadtofailure.com -- The Fringes of Scalability, Social
>> Media, and Computer Science
>>
>
>
>
> --
> http://www.roadtofailure.com -- The Fringes of Scalability, Social
> Media, and Computer Science
>



-- 
http://www.roadtofailure.com -- The Fringes of Scalability, Social
Media, and Computer Science

From common-user-return-16564-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 17:39:23 2009
Return-Path: <common-user-return-16564-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 27638 invoked from network); 5 Aug 2009 17:39:22 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 17:39:22 -0000
Received: (qmail 59836 invoked by uid 500); 5 Aug 2009 17:38:17 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 59475 invoked by uid 500); 5 Aug 2009 17:38:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 58756 invoked by uid 99); 5 Aug 2009 17:33:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:33:38 +0000
X-ASF-Spam-Status: No, hits=4.9 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_NEUTRAL,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:33:29 +0000
Received: by qyk26 with SMTP id 26so257576qyk.5
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 10:33:07 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.37.71 with SMTP id w7mr3942581qad.302.1249493587391; Wed, 
	05 Aug 2009 10:33:07 -0700 (PDT)
In-Reply-To: <73d592f60908031926x47775532j7debd2deed07aef9@mail.gmail.com>
References: <73d592f60908031208p41a4fcb0ob90523eddfedd01e@mail.gmail.com> 
	<45f85f70908031221h256cd12bq10316f7a96ec6170@mail.gmail.com> 
	<73d592f60908031926x47775532j7debd2deed07aef9@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 5 Aug 2009 10:32:47 -0700
Message-ID: <d6d7c4410908051032v235d7133m18d2d121f0263ae@mail.gmail.com>
Subject: Re: namenode -upgrade problem
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175ccf6a6d57020470686582
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175ccf6a6d57020470686582
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Are you sure you stopped all the daemons? Use 'sudo jps' to make sure :)
- Aaron

On Mon, Aug 3, 2009 at 7:26 PM, bharath vissapragada <
bharathvissapragada1990@gmail.com> wrote:

> Todd thanks for replying ..
>
> I stopped the cluster and issued the command
>
> "bin/hadoop namenode -upgrade" and iam getting this exception
>
> 09/08/04 07:52:39 ERROR namenode.NameNode: java.net.BindException: Problem
> binding to master/10.2.24.21:54310 : Address already in use
>    at org.apache.hadoop.ipc.Server.bind(Server.java:171)
>    at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:234)
>    at org.apache.hadoop.ipc.Server.<init>(Server.java:960)
>    at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:465)
>    at org.apache.hadoop.ipc.RPC.getServer(RPC.java:427)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:153)
>     at
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
>    at
>
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
>    at
> org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> Caused by: java.net.BindException: Address already in use
>    at sun.nio.ch.Net.bind(Native Method)
>    at
> sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:119)
>    at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
>    at org.apache.hadoop.ipc.Server.bind(Server.java:169)
>    ... 9 more
>
> any clue?
>
> On Tue, Aug 4, 2009 at 12:51 AM, Todd Lipcon <todd@cloudera.com> wrote:
>
> > On Mon, Aug 3, 2009 at 12:08 PM, bharath vissapragada <
> > bharathvissapragada1990@gmail.com> wrote:
> >
> > > Hi all ,
> > >
> > > I have noticed some problem in my cluster when i changed the hadoop
> > version
> > > on the same DFS directory .. The namenode log on the master says the
> > > following ..
> > >
> > >
> > > ile system image contains an old layout version -16.
> > > *An upgrade to version -18 is required.
> > > Please restart NameNode with -upgrade option.
> > > *
> >
> >
> > See bolded text above -- you need to run namenode -upgrade to upgrade
> your
> > metadata format to the current version.
> >
> > -Todd
> >
> >   at
> > >
> >
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
> > >    at
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
> > >    at
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
> > >    at
> > > org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> > > 2009-08-04 00:27:51,498 INFO org.apache.hadoop.ipc.Server: Stopping
> > server
> > > on 54310
> > > 2009-08-04 00:27:51,498 ERROR
> > > org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException:
> > > File system image contains an old layout version -16.
> > > An upgrade to version -18 is required.
> > > Please restart NameNode with -upgrade option.
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
> > >    at
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
> > >    at
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
> > >    at
> > > org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> > >
> > > 2009-08-04 00:27:51,499 INFO
> > > org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG
> > >
> > > Can anyone explain me the reason ... i googled it .. but those
> > explanations
> > > weren't quite useful
> > >
> > > Thanks
> > >
> >
>

--0015175ccf6a6d57020470686582--

From common-user-return-16565-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 17:39:33 2009
Return-Path: <common-user-return-16565-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 27985 invoked from network); 5 Aug 2009 17:39:32 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 17:39:32 -0000
Received: (qmail 60159 invoked by uid 500); 5 Aug 2009 17:38:18 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 59941 invoked by uid 500); 5 Aug 2009 17:38:18 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 59349 invoked by uid 500); 5 Aug 2009 17:38:16 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 58710 invoked by uid 99); 5 Aug 2009 17:32:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:32:11 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:32:02 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MYkL0-0006x0-3a
	for core-user@hadoop.apache.org; Wed, 05 Aug 2009 10:31:42 -0700
Message-ID: <24832499.post@talk.nabble.com>
Date: Wed, 5 Aug 2009 10:31:42 -0700 (PDT)
From: jchernandez <jchernandez@agnitio.es>
To: core-user@hadoop.apache.org
Subject: Re: Questions on "dfs.datanode.du.reserved"
In-Reply-To: <279a90ff0810012228gc32c58dwacefdeab91155b6@mail.gmail.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: jchernandez@agnitio.es
References: <279a90ff0810012228gc32c58dwacefdeab91155b6@mail.gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org


Hi all, 

Does anyone has an answer to this question? I've search on forums, Hadoop
change logs, and issues and it seems it still is an open issue. Has anyone
seen this parameter working, and under what situations?

Thank you, 
Julian


Taeho Kang wrote:
> 
> Dear All,
> I have few questions on "dfs.datanode.du.reserved" property in
> hadoop-site.xml configuration...
> 
> Assuming that I have "dfs.datanode.du.reserved = 10GB" and the partition
> assigned for HDFS has already been filled up to its capacity.
> (In this case, it will be Total disk size minus 10GB)
> What happens if I change "dfs.datanode.du.reserved" value to something
> greater than 10GB, like 20GB?
> Will HDFS remove or move blocks to meet that settings?
> 
> Also, is it possible to set that "dfs.datanode.du.reserved" separately on
> each partition?
> (e.g. reserve 30GB for /data1 partition, reserve 100GB for /data2
> partition)
> 
> Many thanks,
> 
> Taeho
> 
> 

-- 
View this message in context: http://www.nabble.com/Questions-on-%22dfs.datanode.du.reserved%22-tp19773597p24832499.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-16566-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 17:53:48 2009
Return-Path: <common-user-return-16566-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 37344 invoked from network); 5 Aug 2009 17:53:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 17:53:48 -0000
Received: (qmail 21522 invoked by uid 500); 5 Aug 2009 17:53:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21445 invoked by uid 500); 5 Aug 2009 17:53:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21435 invoked by uid 99); 5 Aug 2009 17:53:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:53:53 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bharathvissapragada1990@gmail.com designates 74.125.92.25 as permitted sender)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 17:53:44 +0000
Received: by qw-out-2122.google.com with SMTP id 8so103051qwh.35
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 10:53:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=CLK0F2St4Cma63P2bRl87XKfVgjn/0R/SZXDQE0alns=;
        b=WnHP+Z5wkLGNu2V8a8BH3/7bQn9hmWkqHQSEMp1ZJy3inmVVSBVL8BDbxtKOUcjE6e
         IE0E5P+MGaJEaJsXy2d4RgfjHRGoN06mjeyMzww2fIxnypBYxcS4J8YtoP5KyeOGUyjA
         SHawWna1LCCNkjSPIo7znb92IpegX5J8b5laQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=W+ZRRh6hvT08W130uG7hDGnMKNXGzwamhZy92Cw/vZhuFQ+8Q7trIN9m4jNEv80nO6
         4Xs6iMpoIn00MJKl44vZ2bAfi13bvEZ/tteLdOJ6U6GMJcKVf0wcVFzPK3WC/3HUaCLu
         Ou/30uMzQYdt37JC76Rc3zBIn2BK1FZi7TE04=
MIME-Version: 1.0
Received: by 10.229.83.213 with SMTP id g21mr2600224qcl.86.1249494803326; Wed, 
	05 Aug 2009 10:53:23 -0700 (PDT)
In-Reply-To: <d6d7c4410908051032v235d7133m18d2d121f0263ae@mail.gmail.com>
References: <73d592f60908031208p41a4fcb0ob90523eddfedd01e@mail.gmail.com> 
	<45f85f70908031221h256cd12bq10316f7a96ec6170@mail.gmail.com> 
	<73d592f60908031926x47775532j7debd2deed07aef9@mail.gmail.com> 
	<d6d7c4410908051032v235d7133m18d2d121f0263ae@mail.gmail.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Wed, 5 Aug 2009 23:23:03 +0530
Message-ID: <73d592f60908051053i16f12d96n84d57afd356b8e81@mail.gmail.com>
Subject: Re: namenode -upgrade problem
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163646bf48e6a6f8047068ad77
X-Virus-Checked: Checked by ClamAV on apache.org

--00163646bf48e6a6f8047068ad77
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

yes .. I have stopped all the daemons ... when i use jps ...i get only ...
"<pid> Jps"

Actually .. i upgraded the version from 18.2 to 19.x  on the same path of
hdfs .. is it a problem?


On Wed, Aug 5, 2009 at 11:02 PM, Aaron Kimball <aaron@cloudera.com> wrote:

> Are you sure you stopped all the daemons? Use 'sudo jps' to make sure :)
> - Aaron
>
> On Mon, Aug 3, 2009 at 7:26 PM, bharath vissapragada <
> bharathvissapragada1990@gmail.com> wrote:
>
> > Todd thanks for replying ..
> >
> > I stopped the cluster and issued the command
> >
> > "bin/hadoop namenode -upgrade" and iam getting this exception
> >
> > 09/08/04 07:52:39 ERROR namenode.NameNode: java.net.BindException:
> Problem
> > binding to master/10.2.24.21:54310 : Address already in use
> >    at org.apache.hadoop.ipc.Server.bind(Server.java:171)
> >    at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:234)
> >    at org.apache.hadoop.ipc.Server.<init>(Server.java:960)
> >    at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:465)
> >    at org.apache.hadoop.ipc.RPC.getServer(RPC.java:427)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:153)
> >     at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
> >    at
> >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
> >    at
> > org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> > Caused by: java.net.BindException: Address already in use
> >    at sun.nio.ch.Net.bind(Native Method)
> >    at
> > sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:119)
> >    at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
> >    at org.apache.hadoop.ipc.Server.bind(Server.java:169)
> >    ... 9 more
> >
> > any clue?
> >
> > On Tue, Aug 4, 2009 at 12:51 AM, Todd Lipcon <todd@cloudera.com> wrote:
> >
> > > On Mon, Aug 3, 2009 at 12:08 PM, bharath vissapragada <
> > > bharathvissapragada1990@gmail.com> wrote:
> > >
> > > > Hi all ,
> > > >
> > > > I have noticed some problem in my cluster when i changed the hadoop
> > > version
> > > > on the same DFS directory .. The namenode log on the master says the
> > > > following ..
> > > >
> > > >
> > > > ile system image contains an old layout version -16.
> > > > *An upgrade to version -18 is required.
> > > > Please restart NameNode with -upgrade option.
> > > > *
> > >
> > >
> > > See bolded text above -- you need to run namenode -upgrade to upgrade
> > your
> > > metadata format to the current version.
> > >
> > > -Todd
> > >
> > >   at
> > > >
> > >
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
> > > >    at
> > > >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
> > > >    at
> > > >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
> > > >    at
> > > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> > > > 2009-08-04 00:27:51,498 INFO org.apache.hadoop.ipc.Server: Stopping
> > > server
> > > > on 54310
> > > > 2009-08-04 00:27:51,498 ERROR
> > > > org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException:
> > > > File system image contains an old layout version -16.
> > > > An upgrade to version -18 is required.
> > > > Please restart NameNode with -upgrade option.
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
> > > >    at
> > > >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
> > > >    at
> > > >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
> > > >    at
> > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
> > > >    at
> > > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> > > >
> > > > 2009-08-04 00:27:51,499 INFO
> > > > org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG
> > > >
> > > > Can anyone explain me the reason ... i googled it .. but those
> > > explanations
> > > > weren't quite useful
> > > >
> > > > Thanks
> > > >
> > >
> >
>

--00163646bf48e6a6f8047068ad77--

From common-user-return-16567-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 19:22:22 2009
Return-Path: <common-user-return-16567-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81270 invoked from network); 5 Aug 2009 19:22:22 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 19:22:22 -0000
Received: (qmail 29475 invoked by uid 500); 5 Aug 2009 19:22:27 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 29392 invoked by uid 500); 5 Aug 2009 19:22:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 29382 invoked by uid 99); 5 Aug 2009 19:22:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 19:22:27 +0000
X-ASF-Spam-Status: No, hits=4.9 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_NEUTRAL,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 19:22:18 +0000
Received: by qyk26 with SMTP id 26so335381qyk.5
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 12:21:57 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.74.76 with SMTP id t12mr7504031qaj.281.1249500117122; Wed, 
	05 Aug 2009 12:21:57 -0700 (PDT)
In-Reply-To: <73d592f60908051053i16f12d96n84d57afd356b8e81@mail.gmail.com>
References: <73d592f60908031208p41a4fcb0ob90523eddfedd01e@mail.gmail.com> 
	<45f85f70908031221h256cd12bq10316f7a96ec6170@mail.gmail.com> 
	<73d592f60908031926x47775532j7debd2deed07aef9@mail.gmail.com> 
	<d6d7c4410908051032v235d7133m18d2d121f0263ae@mail.gmail.com> 
	<73d592f60908051053i16f12d96n84d57afd356b8e81@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 5 Aug 2009 12:21:37 -0700
Message-ID: <d6d7c4410908051221i2686feddk847d92f37eec6ab7@mail.gmail.com>
Subject: Re: namenode -upgrade problem
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175d015ea0c20f047069eae6
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175d015ea0c20f047069eae6
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

The only time you would need to upgrade is if you've increased the Hadoop
version but are retaining the same HDFS :) So, that's the normal case.

What does "netstat --listening --numeric --program" report?
- Aaron

On Wed, Aug 5, 2009 at 10:53 AM, bharath vissapragada <
bharathvissapragada1990@gmail.com> wrote:

> yes .. I have stopped all the daemons ... when i use jps ...i get only ...
> "<pid> Jps"
>
> Actually .. i upgraded the version from 18.2 to 19.x  on the same path of
> hdfs .. is it a problem?
>
>
> On Wed, Aug 5, 2009 at 11:02 PM, Aaron Kimball <aaron@cloudera.com> wrote:
>
> > Are you sure you stopped all the daemons? Use 'sudo jps' to make sure :)
> > - Aaron
> >
> > On Mon, Aug 3, 2009 at 7:26 PM, bharath vissapragada <
> > bharathvissapragada1990@gmail.com> wrote:
> >
> > > Todd thanks for replying ..
> > >
> > > I stopped the cluster and issued the command
> > >
> > > "bin/hadoop namenode -upgrade" and iam getting this exception
> > >
> > > 09/08/04 07:52:39 ERROR namenode.NameNode: java.net.BindException:
> > Problem
> > > binding to master/10.2.24.21:54310 : Address already in use
> > >    at org.apache.hadoop.ipc.Server.bind(Server.java:171)
> > >    at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:234)
> > >    at org.apache.hadoop.ipc.Server.<init>(Server.java:960)
> > >    at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:465)
> > >    at org.apache.hadoop.ipc.RPC.getServer(RPC.java:427)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:153)
> > >     at
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
> > >    at
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
> > >    at
> > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
> > >    at
> > > org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> > > Caused by: java.net.BindException: Address already in use
> > >    at sun.nio.ch.Net.bind(Native Method)
> > >    at
> > >
> sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:119)
> > >    at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
> > >    at org.apache.hadoop.ipc.Server.bind(Server.java:169)
> > >    ... 9 more
> > >
> > > any clue?
> > >
> > > On Tue, Aug 4, 2009 at 12:51 AM, Todd Lipcon <todd@cloudera.com>
> wrote:
> > >
> > > > On Mon, Aug 3, 2009 at 12:08 PM, bharath vissapragada <
> > > > bharathvissapragada1990@gmail.com> wrote:
> > > >
> > > > > Hi all ,
> > > > >
> > > > > I have noticed some problem in my cluster when i changed the hadoop
> > > > version
> > > > > on the same DFS directory .. The namenode log on the master says
> the
> > > > > following ..
> > > > >
> > > > >
> > > > > ile system image contains an old layout version -16.
> > > > > *An upgrade to version -18 is required.
> > > > > Please restart NameNode with -upgrade option.
> > > > > *
> > > >
> > > >
> > > > See bolded text above -- you need to run namenode -upgrade to upgrade
> > > your
> > > > metadata format to the current version.
> > > >
> > > > -Todd
> > > >
> > > >   at
> > > > >
> > > >
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
> > > > >    at
> > > > >
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
> > > > >    at
> > > > >
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
> > > > >    at
> > > > >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> > > > > 2009-08-04 00:27:51,498 INFO org.apache.hadoop.ipc.Server: Stopping
> > > > server
> > > > > on 54310
> > > > > 2009-08-04 00:27:51,498 ERROR
> > > > > org.apache.hadoop.hdfs.server.namenode.NameNode:
> java.io.IOException:
> > > > > File system image contains an old layout version -16.
> > > > > An upgrade to version -18 is required.
> > > > > Please restart NameNode with -upgrade option.
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:312)
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:309)
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:288)
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:163)
> > > > >    at
> > > > >
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:208)
> > > > >    at
> > > > >
> > >
> org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:194)
> > > > >    at
> > > > >
> > > > >
> > > >
> > >
> >
> org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:859)
> > > > >    at
> > > > >
> > org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:868)
> > > > >
> > > > > 2009-08-04 00:27:51,499 INFO
> > > > > org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG
> > > > >
> > > > > Can anyone explain me the reason ... i googled it .. but those
> > > > explanations
> > > > > weren't quite useful
> > > > >
> > > > > Thanks
> > > > >
> > > >
> > >
> >
>

--0015175d015ea0c20f047069eae6--

From common-user-return-16568-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 19:37:12 2009
Return-Path: <common-user-return-16568-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 87329 invoked from network); 5 Aug 2009 19:37:12 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 19:37:12 -0000
Received: (qmail 54302 invoked by uid 500); 5 Aug 2009 19:37:17 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 54220 invoked by uid 500); 5 Aug 2009 19:37:17 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 54210 invoked by uid 500); 5 Aug 2009 19:37:17 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 54207 invoked by uid 99); 5 Aug 2009 19:37:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 19:37:17 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of taiping.du@gmail.com designates 209.85.200.169 as permitted sender)
Received: from [209.85.200.169] (HELO wf-out-1314.google.com) (209.85.200.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 19:37:09 +0000
Received: by wf-out-1314.google.com with SMTP id 23so86917wfg.2
        for <core-user@hadoop.apache.org>; Wed, 05 Aug 2009 12:36:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=Nq//zVfo/9v0HsZa0Xe6nK3OSbYi6ydW0sITeJbHXyM=;
        b=WExDpzuBIEElkR4U8wtTzUnVKTX/b9Rr+yq+fpHcEvmnKYN4Z9XbwsO2iardGuXN2A
         yoE4ZRltO6GahlHm+N6pgr0KNIGcTTgLmGt7Nt+2wBjwz53y1aWnqnnvOadBmM2ck8Wr
         JW3+pQ7lcTB8GyDleXLsh8LH9UrRuxCMPEv5E=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=B9wmpHhgaEOWJYgxezLubj0ZF3X6ZGyMxDJgev9xjH5n61DIObikrWPnw5IiaeZbC6
         cfqjV+jfpez1i3zE/CVSF1wAiVORB128c+nJ/Qk5rxXvcGJp4tdkRml5xD0fUnWHBMAV
         0Zav7Wl3hmhdUF08YA8LlammuR5/xcaO6FwlM=
MIME-Version: 1.0
Received: by 10.142.215.17 with SMTP id n17mr890350wfg.34.1249501009142; Wed, 
	05 Aug 2009 12:36:49 -0700 (PDT)
Date: Wed, 5 Aug 2009 12:36:49 -0700
Message-ID: <710ef8220908051236jfd39ecesdf08a5a27cc9f506@mail.gmail.com>
Subject: distcp between 0.17 and 0.18.3 issues
From: charles du <taiping.du@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd14510cbe58f04706a1f58
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd14510cbe58f04706a1f58
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi:

I tried to use "distcp" to copy files from one cluster running hadoop 0.17.0
to another cluster running hadoop 0.18.3, and got the following errors.

With failures, global counters are inaccurate; consider running with -i
Copy failed: java.io.IOException: Not supported
        at
org.apache.hadoop.dfs.HftpFileSystem.delete(HftpFileSystem.java:263)
        at org.apache.hadoop.fs.FileUtil.fullyDelete(FileUtil.java:119)
        at org.apache.hadoop.tools.DistCp.fullyDelete(DistCp.java:843)
        at org.apache.hadoop.tools.DistCp.copy(DistCp.java:623)
        at org.apache.hadoop.tools.DistCp.run(DistCp.java:768)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.tools.DistCp.main(DistCp.java:788)


I ran the distcp from the 0.18.3 cluster. does the error message mean that
distcp does not support 0.17.0 as the copy source?

Regards

-- 
tp

--000e0cd14510cbe58f04706a1f58--

From common-user-return-16569-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 20:50:13 2009
Return-Path: <common-user-return-16569-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 15433 invoked from network); 5 Aug 2009 20:50:12 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 20:50:12 -0000
Received: (qmail 61618 invoked by uid 500); 5 Aug 2009 20:50:17 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 61535 invoked by uid 500); 5 Aug 2009 20:50:17 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 61521 invoked by uid 99); 5 Aug 2009 20:50:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 20:50:17 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [216.252.110.210] (HELO web56201.mail.re3.yahoo.com) (216.252.110.210)
    by apache.org (qpsmtpd/0.29) with SMTP; Wed, 05 Aug 2009 20:50:06 +0000
Received: (qmail 63229 invoked by uid 60001); 5 Aug 2009 20:49:45 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1249505385; bh=0UpUcM08VMZUTispQD5n2N6Cd8zfGUhoW0i8mCc6mZ0=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=hkgAGWl0Xoyv2sHB2owQ2rGtfaOEELHzP89ICRv/i78NmuqBTB8g/c0M1uqdM9+ZBWqlkMzB7yVQpZAgEQs6NrQjK+eNej5/FmsB5nuGblZwr1mQ5kuvJ3IcH4gRx3tIsTc3WMR7ISfQe4R9ZnbcRkO9CM5oxzUH6cnvvYxAeuk=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=FCW4Y7MkwmsIMDtG1JgZilfyO2FW00drOoE+qGi7TEOp4tXArkC9Wtv5AFaJmFb7P9DOEEZjYQrrSYcd4992nAo6pNWMtLGRRW31aUu0oMGAiIInyF4u+JZ0stFguPULL2rzO1kJppG7Ceq5tevV+ni4+vYz8YFhmQyYCfjTQBk=;
Message-ID: <579522.63213.qm@web56201.mail.re3.yahoo.com>
X-YMail-OSG: gdbhfuEVM1kjUJMAuRz0yPjQHfqzq9_FYQ73Ijte7xW.mX_RZ5zGQ1iAq9GEIPDQ.s_DPsDpCNCCJ80Ln9hho_jlQuOP0dfOMOP.YRFlJg7Ugv4dhV3uc_Yfp71Ikv2RjVRw3c03xTvdopVvsnV9oVEr7T7xLNqlsQtVKWrlv5cABeSdBTljKH78SR4qAvg.KEHwmQF2QTSZk02XZwsaNaZeoalZpysUuA2DMK_h0.lbaQzJS4PSuuuQLRMkKEEHTjAiDLlnTZXKsgn.6J5Qy4FiIdlXFOt9TTO3Wa5ZNmW70QrC4cWmmfdQ3U3tUS_vHIp9fVwKvcl1ECuUpuYqO45wy54L9EKDNBQXy1GQ0g--
Received: from [216.145.54.158] by web56201.mail.re3.yahoo.com via HTTP; Wed, 05 Aug 2009 13:49:45 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.2
References: <710ef8220908051236jfd39ecesdf08a5a27cc9f506@mail.gmail.com>
Date: Wed, 5 Aug 2009 13:49:45 -0700 (PDT)
From: "Tsz Wo \(Nicholas\), Sze" <s29752-hadoopuser@yahoo.com>
Subject: Re: distcp between 0.17 and 0.18.3 issues
To: common-user@hadoop.apache.org
In-Reply-To: <710ef8220908051236jfd39ecesdf08a5a27cc9f506@mail.gmail.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
X-Virus-Checked: Checked by ClamAV on apache.org

Hi tp,

distcp definitely supports copying file from a 0.17 cluster to a 0.18 cluster.  The error message is saying that the delete operation is not supported in HftpFileSystem.  Would you mind to show me the actual command used?

Nicholas Sze




----- Original Message ----
> From: charles du <taiping.du@gmail.com>
> To: core-user@hadoop.apache.org
> Sent: Wednesday, August 5, 2009 12:36:49 PM
> Subject: distcp between 0.17 and 0.18.3 issues
> 
> Hi:
> 
> I tried to use "distcp" to copy files from one cluster running hadoop 0.17.0
> to another cluster running hadoop 0.18.3, and got the following errors.
> 
> With failures, global counters are inaccurate; consider running with -i
> Copy failed: java.io.IOException: Not supported
>         at
> org.apache.hadoop.dfs.HftpFileSystem.delete(HftpFileSystem.java:263)
>         at org.apache.hadoop.fs.FileUtil.fullyDelete(FileUtil.java:119)
>         at org.apache.hadoop.tools.DistCp.fullyDelete(DistCp.java:843)
>         at org.apache.hadoop.tools.DistCp.copy(DistCp.java:623)
>         at org.apache.hadoop.tools.DistCp.run(DistCp.java:768)
>         at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
>         at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
>         at org.apache.hadoop.tools.DistCp.main(DistCp.java:788)
> 
> 
> I ran the distcp from the 0.18.3 cluster. does the error message mean that
> distcp does not support 0.17.0 as the copy source?
> 
> Regards
> 
> -- 
> tp


From common-user-return-16570-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 20:55:21 2009
Return-Path: <common-user-return-16570-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 18543 invoked from network); 5 Aug 2009 20:55:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 20:55:21 -0000
Received: (qmail 70119 invoked by uid 500); 5 Aug 2009 20:55:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 70025 invoked by uid 500); 5 Aug 2009 20:55:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 70012 invoked by uid 99); 5 Aug 2009 20:55:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 20:55:26 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of taiping.du@gmail.com designates 209.85.200.174 as permitted sender)
Received: from [209.85.200.174] (HELO wf-out-1314.google.com) (209.85.200.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 20:55:17 +0000
Received: by wf-out-1314.google.com with SMTP id 23so100755wfg.2
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 13:54:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=0Pk3hNvzHQK0QVKk6X5Q8TYv8++U8lDZpdl/iPO5IXY=;
        b=BYgpBKnWVOTZBVezizudtCAvMv3mLLeJzmlZajvcKSzNhijNZJmy8yJRMx6D4HYy6Z
         +qRkOqeaiysJ4ZkT4Z8L0GBvKw/gt0AKpQi8680Fkvrgz5ylPQPg3Yb/QWNDUYfolaPt
         UHuhYiAP1AAp1iGOhZGijkXzOCZSiPjrfPvqQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=Rl6qrVRmnyQwxtdxctDc3Kdeupls3Ui/zWpG2UlBrrKyqKJtwWswJnpOlnJwGYNn95
         odpUc1eniYhIe34ldK8Yoi4ONspXZDOLREqkvx+q4S3x9aG3OBWJ+/bTw81nz1Hr1oFx
         pfA4+Xj27hNSWsDbJXb1+JtQStSm4TRTpX9H0=
MIME-Version: 1.0
Received: by 10.142.147.20 with SMTP id u20mr408453wfd.277.1249505695839; Wed, 
	05 Aug 2009 13:54:55 -0700 (PDT)
In-Reply-To: <579522.63213.qm@web56201.mail.re3.yahoo.com>
References: <710ef8220908051236jfd39ecesdf08a5a27cc9f506@mail.gmail.com>
	 <579522.63213.qm@web56201.mail.re3.yahoo.com>
Date: Wed, 5 Aug 2009 13:54:55 -0700
Message-ID: <710ef8220908051354t407aa405oeb22a6c13f411f5a@mail.gmail.com>
Subject: Re: distcp between 0.17 and 0.18.3 issues
From: charles du <taiping.du@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd23d3825357e04706b3727
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd23d3825357e04706b3727
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Nicholas:

The command I used is

   hadoop distcp -i hftp://nn1:50070/src hftp://nn2:50070/dest

I ran "hadoop ls" on both src and destination, and it lists files just fine.
nn1 is 0.17.0, and nn2 is 0.18.3

Thanks.

tp

On Wed, Aug 5, 2009 at 1:49 PM, Tsz Wo (Nicholas), Sze <
s29752-hadoopuser@yahoo.com> wrote:

> Hi tp,
>
> distcp definitely supports copying file from a 0.17 cluster to a 0.18
> cluster.  The error message is saying that the delete operation is not
> supported in HftpFileSystem.  Would you mind to show me the actual command
> used?
>
> Nicholas Sze
>
>
>
>
> ----- Original Message ----
> > From: charles du <taiping.du@gmail.com>
> > To: core-user@hadoop.apache.org
> > Sent: Wednesday, August 5, 2009 12:36:49 PM
> > Subject: distcp between 0.17 and 0.18.3 issues
> >
> > Hi:
> >
> > I tried to use "distcp" to copy files from one cluster running hadoop
> 0.17.0
> > to another cluster running hadoop 0.18.3, and got the following errors.
> >
> > With failures, global counters are inaccurate; consider running with -i
> > Copy failed: java.io.IOException: Not supported
> >         at
> > org.apache.hadoop.dfs.HftpFileSystem.delete(HftpFileSystem.java:263)
> >         at org.apache.hadoop.fs.FileUtil.fullyDelete(FileUtil.java:119)
> >         at org.apache.hadoop.tools.DistCp.fullyDelete(DistCp.java:843)
> >         at org.apache.hadoop.tools.DistCp.copy(DistCp.java:623)
> >         at org.apache.hadoop.tools.DistCp.run(DistCp.java:768)
> >         at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
> >         at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
> >         at org.apache.hadoop.tools.DistCp.main(DistCp.java:788)
> >
> >
> > I ran the distcp from the 0.18.3 cluster. does the error message mean
> that
> > distcp does not support 0.17.0 as the copy source?
> >
> > Regards
> >
> > --
> > tp
>
>


-- 
tp

--000e0cd23d3825357e04706b3727--

From common-user-return-16571-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 21:04:39 2009
Return-Path: <common-user-return-16571-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 26052 invoked from network); 5 Aug 2009 21:04:39 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 21:04:39 -0000
Received: (qmail 91835 invoked by uid 500); 5 Aug 2009 21:04:43 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91764 invoked by uid 500); 5 Aug 2009 21:04:43 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91754 invoked by uid 99); 5 Aug 2009 21:04:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 21:04:43 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [216.252.110.215] (HELO web56206.mail.re3.yahoo.com) (216.252.110.215)
    by apache.org (qpsmtpd/0.29) with SMTP; Wed, 05 Aug 2009 21:04:34 +0000
Received: (qmail 81467 invoked by uid 60001); 5 Aug 2009 21:04:12 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1249506252; bh=PCadGl9JULXHymgqQEk6Tfluqlv0CunP/0R2Mki7Flg=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=jsRmnTRAZqYeJXi1MAYK1qXouQQVOol0XlFHOdl9cijKal8YihXm7f+wNobRddPcaZPNT8ryoiv84nig5Lu/5RddSrlDkwgQWuDInH63/T2JHz5ere4DXPy8M9/kMilCs/csyBw3qOKpn5Q0BseiHsWvaLUn3hI2spF5ZTkbk5w=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=jO5LYiCOf9OzyijZ1eJPz2cVyDLKWQeNsjl1gJdbQWVWj711tOXTGyloBc5ctq2c5np1tsk954deaURWYej3eWUyzQkSLOjqMpYFqe21xuXvf5PyDLB12HpfTDCyr2Eu9Mee9589AXeSexKPi/NXYdnPcDqa4zgc3T+Tnq6nwnc=;
Message-ID: <546170.81195.qm@web56206.mail.re3.yahoo.com>
X-YMail-OSG: 5RY5NCYVM1mYpm5NzoK7rG00RWyOFXmuaXQBpNch5_qGDUMfh_LN3qIGLsnFd9EBsA7KIbtymL.5acF3xmZdu70CJdt0wSj9aCCVtFTTrrpdiBigwKqk.whcQb0X2iTAXSUGfF6yWYbMjJ2HSqU3a8m4aW2GCDGWykewN3wh78wEBzBWqiQb92E7hdgTyF.7V7KW12SIRQBT5ucpLLAhr2yv1iyUrxlS7x8cfFX6sgkROFxIc3SGH02ACYU4LsMBkvMPQ2YAo04eqZ4eRIPTBkBhMEsAPm52SBXmSUkyfMIhIDPyl7J48kCY2hz.9ZPc1.Lu43dr0r8-
Received: from [216.145.54.158] by web56206.mail.re3.yahoo.com via HTTP; Wed, 05 Aug 2009 14:04:12 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.2
References: <710ef8220908051236jfd39ecesdf08a5a27cc9f506@mail.gmail.com>  <579522.63213.qm@web56201.mail.re3.yahoo.com> <710ef8220908051354t407aa405oeb22a6c13f411f5a@mail.gmail.com>
Date: Wed, 5 Aug 2009 14:04:12 -0700 (PDT)
From: "Tsz Wo \(Nicholas\), Sze" <s29752-hadoopuser@yahoo.com>
Subject: Re: distcp between 0.17 and 0.18.3 issues
To: common-user@hadoop.apache.org
In-Reply-To: <710ef8220908051354t407aa405oeb22a6c13f411f5a@mail.gmail.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
X-Virus-Checked: Checked by ClamAV on apache.org

>    hadoop distcp -i hftp://nn1:50070/src hftp://nn2:50070/dest
The problem in the command above is hftp://nn2:50070/dest while hftp (i.e. HftpFileSystem) is a read-only file system.  You may change it to hdfs://nn2:xxxx/dest, where xxxx is a different port.  You may find the port number from the NN's web page.


Nicholas



----- Original Message ----
> From: charles du <taiping.du@gmail.com>
> To: common-user@hadoop.apache.org
> Sent: Wednesday, August 5, 2009 1:54:55 PM
> Subject: Re: distcp between 0.17 and 0.18.3 issues
> 
> Hi Nicholas:
> 
> The command I used is
> 
>    hadoop distcp -i hftp://nn1:50070/src hftp://nn2:50070/dest
> 
> I ran "hadoop ls" on both src and destination, and it lists files just fine.
> nn1 is 0.17.0, and nn2 is 0.18.3
> 
> Thanks.
> 
> tp
> 
> On Wed, Aug 5, 2009 at 1:49 PM, Tsz Wo (Nicholas), Sze <
> s29752-hadoopuser@yahoo.com> wrote:
> 
> > Hi tp,
> >
> > distcp definitely supports copying file from a 0.17 cluster to a 0.18
> > cluster.  The error message is saying that the delete operation is not
> > supported in HftpFileSystem.  Would you mind to show me the actual command
> > used?
> >
> > Nicholas Sze
> >
> >
> >
> >
> > ----- Original Message ----
> > > From: charles du 
> > > To: core-user@hadoop.apache.org
> > > Sent: Wednesday, August 5, 2009 12:36:49 PM
> > > Subject: distcp between 0.17 and 0.18.3 issues
> > >
> > > Hi:
> > >
> > > I tried to use "distcp" to copy files from one cluster running hadoop
> > 0.17.0
> > > to another cluster running hadoop 0.18.3, and got the following errors.
> > >
> > > With failures, global counters are inaccurate; consider running with -i
> > > Copy failed: java.io.IOException: Not supported
> > >         at
> > > org.apache.hadoop.dfs.HftpFileSystem.delete(HftpFileSystem.java:263)
> > >         at org.apache.hadoop.fs.FileUtil.fullyDelete(FileUtil.java:119)
> > >         at org.apache.hadoop.tools.DistCp.fullyDelete(DistCp.java:843)
> > >         at org.apache.hadoop.tools.DistCp.copy(DistCp.java:623)
> > >         at org.apache.hadoop.tools.DistCp.run(DistCp.java:768)
> > >         at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
> > >         at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
> > >         at org.apache.hadoop.tools.DistCp.main(DistCp.java:788)
> > >
> > >
> > > I ran the distcp from the 0.18.3 cluster. does the error message mean
> > that
> > > distcp does not support 0.17.0 as the copy source?
> > >
> > > Regards
> > >
> > > --
> > > tp
> >
> >
> 
> 
> -- 
> tp


From common-user-return-16572-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 21:25:25 2009
Return-Path: <common-user-return-16572-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 33229 invoked from network); 5 Aug 2009 21:25:24 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 21:25:24 -0000
Received: (qmail 14873 invoked by uid 500); 5 Aug 2009 21:25:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 14769 invoked by uid 500); 5 Aug 2009 21:25:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 14759 invoked by uid 99); 5 Aug 2009 21:25:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 21:25:29 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of taiping.du@gmail.com designates 209.85.198.224 as permitted sender)
Received: from [209.85.198.224] (HELO rv-out-0506.google.com) (209.85.198.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 21:25:21 +0000
Received: by rv-out-0506.google.com with SMTP id k40so111604rvb.29
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 14:25:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=m/evWS3tU/mhqGa+LhD9Z19woyQOTRqtlGxe9SLYY2M=;
        b=tp3U4XvPkrYBf+J6SjG6A7dKGWyrykr9Sry3VucmCMCshz3uDZU+fcrOkErcjCKJWc
         +qcr7lac/sJWbdJ0d0FTdyNexCxv2fNKACiyEvtf5xQR/xbj8YuqkU2bXp/U3ID3AEjw
         Drd8bpRDFs3J8hzR23ijCSPvlEqVxWgCJ6vpo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=Q56Ui03FG5+NW6fB9F9JeO5vbbF83e+oP+E2mK8c8x3v+dZff6SzafSmsa8/IHPLwQ
         y6O7axIB/7EyTmR09V9IyqLSrAW35Yy9lJaDRHryMQIzz+fwPuv2CHB+XBDVhOzxJIpR
         DptGEjBV7qb0xjii24NM6wXbGe15TDPVdMYsY=
MIME-Version: 1.0
Received: by 10.143.14.14 with SMTP id r14mr1095418wfi.82.1249507500972; Wed, 
	05 Aug 2009 14:25:00 -0700 (PDT)
In-Reply-To: <546170.81195.qm@web56206.mail.re3.yahoo.com>
References: <710ef8220908051236jfd39ecesdf08a5a27cc9f506@mail.gmail.com>
	 <579522.63213.qm@web56201.mail.re3.yahoo.com>
	 <710ef8220908051354t407aa405oeb22a6c13f411f5a@mail.gmail.com>
	 <546170.81195.qm@web56206.mail.re3.yahoo.com>
Date: Wed, 5 Aug 2009 14:25:00 -0700
Message-ID: <710ef8220908051425ob12d02meb3b0928351f285f@mail.gmail.com>
Subject: Re: distcp between 0.17 and 0.18.3 issues
From: charles du <taiping.du@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636e0a701bd5b2a04706ba290
X-Virus-Checked: Checked by ClamAV on apache.org

--001636e0a701bd5b2a04706ba290
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks a lot. It solved my problem.

Chuang

On Wed, Aug 5, 2009 at 2:04 PM, Tsz Wo (Nicholas), Sze <
s29752-hadoopuser@yahoo.com> wrote:

> >    hadoop distcp -i hftp://nn1:50070/src hftp://nn2:50070/dest
> The problem in the command above is hftp://nn2:50070/dest while hftp (i.e.
> HftpFileSystem) is a read-only file system.  You may change it to
> hdfs://nn2:xxxx/dest, where xxxx is a different port.  You may find the port
> number from the NN's web page.
>
>
> Nicholas
>
>
>
> ----- Original Message ----
> > From: charles du <taiping.du@gmail.com>
> > To: common-user@hadoop.apache.org
> > Sent: Wednesday, August 5, 2009 1:54:55 PM
> > Subject: Re: distcp between 0.17 and 0.18.3 issues
> >
> > Hi Nicholas:
> >
> > The command I used is
> >
> >    hadoop distcp -i hftp://nn1:50070/src hftp://nn2:50070/dest
> >
> > I ran "hadoop ls" on both src and destination, and it lists files just
> fine.
> > nn1 is 0.17.0, and nn2 is 0.18.3
> >
> > Thanks.
> >
> > tp
> >
> > On Wed, Aug 5, 2009 at 1:49 PM, Tsz Wo (Nicholas), Sze <
> > s29752-hadoopuser@yahoo.com> wrote:
> >
> > > Hi tp,
> > >
> > > distcp definitely supports copying file from a 0.17 cluster to a 0.18
> > > cluster.  The error message is saying that the delete operation is not
> > > supported in HftpFileSystem.  Would you mind to show me the actual
> command
> > > used?
> > >
> > > Nicholas Sze
> > >
> > >
> > >
> > >
> > > ----- Original Message ----
> > > > From: charles du
> > > > To: core-user@hadoop.apache.org
> > > > Sent: Wednesday, August 5, 2009 12:36:49 PM
> > > > Subject: distcp between 0.17 and 0.18.3 issues
> > > >
> > > > Hi:
> > > >
> > > > I tried to use "distcp" to copy files from one cluster running hadoop
> > > 0.17.0
> > > > to another cluster running hadoop 0.18.3, and got the following
> errors.
> > > >
> > > > With failures, global counters are inaccurate; consider running with
> -i
> > > > Copy failed: java.io.IOException: Not supported
> > > >         at
> > > > org.apache.hadoop.dfs.HftpFileSystem.delete(HftpFileSystem.java:263)
> > > >         at
> org.apache.hadoop.fs.FileUtil.fullyDelete(FileUtil.java:119)
> > > >         at
> org.apache.hadoop.tools.DistCp.fullyDelete(DistCp.java:843)
> > > >         at org.apache.hadoop.tools.DistCp.copy(DistCp.java:623)
> > > >         at org.apache.hadoop.tools.DistCp.run(DistCp.java:768)
> > > >         at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
> > > >         at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
> > > >         at org.apache.hadoop.tools.DistCp.main(DistCp.java:788)
> > > >
> > > >
> > > > I ran the distcp from the 0.18.3 cluster. does the error message mean
> > > that
> > > > distcp does not support 0.17.0 as the copy source?
> > > >
> > > > Regards
> > > >
> > > > --
> > > > tp
> > >
> > >
> >
> >
> > --
> > tp
>
>


-- 
tp

--001636e0a701bd5b2a04706ba290--

From common-user-return-16573-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 22:59:59 2009
Return-Path: <common-user-return-16573-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 82772 invoked from network); 5 Aug 2009 22:59:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 22:59:59 -0000
Received: (qmail 43219 invoked by uid 500); 5 Aug 2009 23:00:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 43134 invoked by uid 500); 5 Aug 2009 23:00:03 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 43124 invoked by uid 99); 5 Aug 2009 23:00:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 23:00:03 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zeevmisc@gmail.com designates 209.85.200.169 as permitted sender)
Received: from [209.85.200.169] (HELO wf-out-1314.google.com) (209.85.200.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 22:59:54 +0000
Received: by wf-out-1314.google.com with SMTP id 23so119772wfg.2
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 15:59:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=7r7590ytK5uQNQBQq5YGn1X8/PiWYQfCuzSYqpJlcq4=;
        b=AZ/a48g4lsOqaqDQWx+fEMbyO9xuQAFPZshhJ7YSjkJ5mhWdZ3+9Nch1ImOueC87mw
         pHAvfKPMiDlbBu0RUYoD7uPgv16DA4B86V07+zFrngpwAKltkJbUZVex2IWYXlUQPTDo
         8Qn4QFLFvOlG5f0J82vsi2rWBRVysCwUD176Y=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=OFHwFSbvM43MQ6wC0V5J1i8yklfkdodnlqjc5mLozZfAU+FZWDjzVFktX6EflEVKGk
         5mnLdmUXjFOCWwRmbMNQhgP28wJ1M79T1HTwlTdd6QobsIhd+pbO0btOCcVvpOpwXTHp
         0UIamYlr1GweYylPAyhUPZGKjoz4/SiG3dB2A=
MIME-Version: 1.0
Received: by 10.142.48.14 with SMTP id v14mr1127532wfv.190.1249513173457; Wed, 
	05 Aug 2009 15:59:33 -0700 (PDT)
Date: Wed, 5 Aug 2009 15:59:33 -0700
Message-ID: <abdb77f90908051559t342c6c72rd52eb77995b52da7@mail.gmail.com>
Subject: Maps running - how to increase?
From: Zeev Milin <zeevmisc@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd3116ad89ba604706cf430
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd3116ad89ba604706cf430
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I have a map/reduce job that has a total of 6000 map tasks. The issue is
that the number of maps that is "running" at any given time is 6 (number of
nodes) and rest are pending. Does anyone know how to force the cluster to
run more maps in parallel to increase the throughput? This is the only job
that is running on this cluster.

Cluster summary:  0.19.2, 6 nodes, Map tasks capacity: 192, Avg tasks/Node:
64

Thanks,
Zeev

--000e0cd3116ad89ba604706cf430--

From common-user-return-16574-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 23:16:21 2009
Return-Path: <common-user-return-16574-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 88611 invoked from network); 5 Aug 2009 23:16:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 23:16:21 -0000
Received: (qmail 61251 invoked by uid 500); 5 Aug 2009 23:16:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 61156 invoked by uid 500); 5 Aug 2009 23:16:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 61146 invoked by uid 99); 5 Aug 2009 23:16:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 23:16:26 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of trsell@gmail.com designates 74.125.78.24 as permitted sender)
Received: from [74.125.78.24] (HELO ey-out-2122.google.com) (74.125.78.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 23:16:16 +0000
Received: by ey-out-2122.google.com with SMTP id 22so243302eye.35
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 16:15:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=PN8/APvQSM9t+Ol+Wap3XuS53kIAn4AOLzH5FNR36hI=;
        b=g5mZXDD+hTAxCUo70z04zfNXk8Ac0QliVWQZ71TG4P6rFngcg7Q723bD8OMbUadoP7
         hoXgO6kfgoPxvP2KI08jXDZ4p3q0VU+mQxB+nG4dRcENyiL6BvQ/Nil5qv9HYaZccLTj
         QDEx8zu224Syt+jrlVk9ihHoY96wgmbSwiEUI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=Oh9BK2Y9HduW+HjsyJE3tizRyR6rz8kdh3PJNFaMbX/zGNLPAYDYdMpQSVXPGtfnPg
         k3uBCtahBYgHfrJlnB4+haKox897BEUco8ykRti8sAIvPwv1euC0+HvKuIJZkfKZtCYf
         a86GN/RzuqMdiClJDFKrXP5S7qepPg4RT/t3c=
MIME-Version: 1.0
Received: by 10.210.110.2 with SMTP id i2mr11233658ebc.8.1249514156759; Wed, 
	05 Aug 2009 16:15:56 -0700 (PDT)
In-Reply-To: <abdb77f90908051559t342c6c72rd52eb77995b52da7@mail.gmail.com>
References: <abdb77f90908051559t342c6c72rd52eb77995b52da7@mail.gmail.com>
Date: Thu, 6 Aug 2009 00:15:56 +0100
Message-ID: <92c4d8c10908051615x1bcff245s3c8830c04a3aebf9@mail.gmail.com>
Subject: Re: Maps running - how to increase?
From: Tim Sell <trsell@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

have you set:
mapred.tasktracker.map.tasks.maximum
?

That specifies the number of maps that can run on single node at a time.

2009/8/5 Zeev Milin <zeevmisc@gmail.com>:
> I have a map/reduce job that has a total of 6000 map tasks. The issue is
> that the number of maps that is "running" at any given time is 6 (number =
of
> nodes) and rest are pending. Does anyone know how to force the cluster to
> run more maps in parallel to increase the throughput? This is the only jo=
b
> that is running on this cluster.
>
> Cluster summary: =A00.19.2, 6 nodes, Map tasks capacity: 192, Avg tasks/N=
ode:
> 64
>
> Thanks,
> Zeev
>

From common-user-return-16575-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 05 23:26:04 2009
Return-Path: <common-user-return-16575-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 92299 invoked from network); 5 Aug 2009 23:26:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 5 Aug 2009 23:26:04 -0000
Received: (qmail 73165 invoked by uid 500); 5 Aug 2009 23:26:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 73106 invoked by uid 500); 5 Aug 2009 23:26:09 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 73096 invoked by uid 99); 5 Aug 2009 23:26:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 23:26:08 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zeevmisc@gmail.com designates 209.85.222.172 as permitted sender)
Received: from [209.85.222.172] (HELO mail-pz0-f172.google.com) (209.85.222.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 05 Aug 2009 23:25:59 +0000
Received: by pzk2 with SMTP id 2so365892pzk.30
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 16:25:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=nGSscQ5KHExdzkhkt044t8QL3HzY0Ll7aZ3fkMrP63A=;
        b=n6KECw1C6epkYrA+MMXqeVbUyxH9tzTjzEricu+Ydg8SzC2fgPKGthWTBMVaV3qKvU
         PIrcmfP6ZRvA87DEUHTN8zbO6jvEN+/1MvHsCF366j/1/wxrD/MkoFTiV0a4Xh+qYD/k
         LY8vYvwGtlgvtxyNvg+n+RJNjWBtNoiqKu0gU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=Q5PTo/zRVPmprpElaTaY2IltKotYHBa0XLyP7gl/JJT/44mFThgCG90QhzpPgpDqX+
         iE1gU9q3F/ZPA7bC4J9v83DDVufcZsCKZwPCeQvCkdv4+ER02sHpI3XLxZL2WKlhOusG
         S53hGjPo2cI5dNU5apj5/xFr0HSPeDjtFNFT4=
MIME-Version: 1.0
Received: by 10.142.239.17 with SMTP id m17mr1028179wfh.2.1249514738669; Wed, 
	05 Aug 2009 16:25:38 -0700 (PDT)
In-Reply-To: <92c4d8c10908051615x1bcff245s3c8830c04a3aebf9@mail.gmail.com>
References: <abdb77f90908051559t342c6c72rd52eb77995b52da7@mail.gmail.com>
	 <92c4d8c10908051615x1bcff245s3c8830c04a3aebf9@mail.gmail.com>
Date: Wed, 5 Aug 2009 16:25:38 -0700
Message-ID: <abdb77f90908051625v546bd0fcw753896689e3eb611@mail.gmail.com>
Subject: Re: Maps running - how to increase?
From: Zeev Milin <zeevmisc@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd145f223d81604706d52ce
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd145f223d81604706d52ce
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

This is the setting in hadoop-site.xml file:

<property>
 <name>mapred.tasktracker.map.tasks.maximum</name>
 <value>32</value>
</property>

When I look at the job configuration file (xml), I see that this parameter
is set to 2. Not sure why the hadoop-site value is not being used.

--000e0cd145f223d81604706d52ce--

From common-user-return-16576-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 00:06:46 2009
Return-Path: <common-user-return-16576-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 221 invoked from network); 6 Aug 2009 00:06:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 00:06:46 -0000
Received: (qmail 1697 invoked by uid 500); 6 Aug 2009 00:06:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 1626 invoked by uid 500); 6 Aug 2009 00:06:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 1616 invoked by uid 99); 6 Aug 2009 00:06:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 00:06:51 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zeevmisc@gmail.com designates 209.85.198.228 as permitted sender)
Received: from [209.85.198.228] (HELO rv-out-0506.google.com) (209.85.198.228)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 00:06:43 +0000
Received: by rv-out-0506.google.com with SMTP id k40so134099rvb.29
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 17:06:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=M5mH8L0ZUJYFucywr+Nj3ksqDaCd6vrHELAWg0vjgco=;
        b=ACxrCqcLpIdP65OnKYX0xN7+EQu8HdkIpX3wLLhWgCyu8BtPs29Ywsh9gK0i5Y9aGu
         r/47PKBn67yNufQ+cNQDXVx2L+R1ffxIw0vB1abMw60dT0cqePznsRYAzS3pzGnOe6q5
         CbAnV2rr2Yy6Mbkc9W9Futs4UIC3+hjv8TR9s=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=iR521rmob53IwxkLtoogIhiQYTl4sbBvEF4F7o6KWGOfpaoOmFtP9MYhFqjpN09hKT
         GYLKpe6mVrPfb+1Y3lR97EvLWNiOl86saQJez97LASJhnvQxaBBkMyxKMpP6brjTj2S4
         laUo1LzfjtQ6GidOnmtqh7WAWxXq85R6cBVCk=
MIME-Version: 1.0
Received: by 10.142.57.7 with SMTP id f7mr544955wfa.317.1249517183244; Wed, 05 
	Aug 2009 17:06:23 -0700 (PDT)
In-Reply-To: <abdb77f90908051625v546bd0fcw753896689e3eb611@mail.gmail.com>
References: <abdb77f90908051559t342c6c72rd52eb77995b52da7@mail.gmail.com>
	 <92c4d8c10908051615x1bcff245s3c8830c04a3aebf9@mail.gmail.com>
	 <abdb77f90908051625v546bd0fcw753896689e3eb611@mail.gmail.com>
Date: Wed, 5 Aug 2009 17:06:23 -0700
Message-ID: <abdb77f90908051706t482b492cq4a4f2688bccf0379@mail.gmail.com>
Subject: Re: Maps running - how to increase?
From: Zeev Milin <zeevmisc@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636e0a964d91a5204706de3d8
X-Virus-Checked: Checked by ClamAV on apache.org

--001636e0a964d91a5204706de3d8
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I now see that the mapred.tasktracker.map.tasks.maximum=32 on the job level
and still only 6 maps running and 5000+ pending..

Not sure how to force the cluster to run more maps.

--001636e0a964d91a5204706de3d8--

From common-user-return-16577-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 04:03:24 2009
Return-Path: <common-user-return-16577-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 69201 invoked from network); 6 Aug 2009 04:03:24 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 04:03:24 -0000
Received: (qmail 69015 invoked by uid 500); 6 Aug 2009 04:03:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 68923 invoked by uid 500); 6 Aug 2009 04:03:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 68913 invoked by uid 99); 6 Aug 2009 04:03:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 04:03:28 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of coderplay@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 04:03:16 +0000
Received: by fxm24 with SMTP id 24so606104fxm.36
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 21:02:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=l0XL2gvLhR0jBl8jbUjEsxW12hjpMflrYclHUqQsJcw=;
        b=C6p9iNfCWsALriv0R7XJ6D1SEIUngwl7/dYn4dI921O/TWetMjwxLwBzf+XOp+iodC
         VQvBhwBuRLQqt/lnIntwDxCxgnBnJO4DmeA7fGTMhc1fASPwKl/Ef2RGgtSBqVWyjSsh
         7g6V5MNcXbl/q2ByJKyFgp22BnAfYRY5LQxt8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=DlXXZuGPYkCZ3Fv3lnD0fI1aQiUX/n/+cRoYTkYvwkjb2PCDmzN6FX1QSb5SQp5moW
         1X0wSnja8NtmXsPOsOztq/frYb1A2oa2SrUSJd5NWWsa9ItDURCIpbHG/nizx43ws5JI
         h8scbgusrjKDtD/KsCnhWxAEsf/FDyN5vNz/Y=
MIME-Version: 1.0
Received: by 10.239.148.206 with SMTP id g14mr901590hbb.54.1249531375823; Wed, 
	05 Aug 2009 21:02:55 -0700 (PDT)
In-Reply-To: <d6d7c4410908051027y22f68eb5ufa9989be16d3e846@mail.gmail.com>
References: <bcaf338a0908032015h41cff744l1b0f74ea60cc32df@mail.gmail.com>
	 <d6d7c4410908051027y22f68eb5ufa9989be16d3e846@mail.gmail.com>
Date: Thu, 6 Aug 2009 12:02:55 +0800
Message-ID: <bcaf338a0908052102v4607b9afn293b47875f50cdc8@mail.gmail.com>
Subject: Re: how to dump data from a mysql cluster to hdfs?
From: Min Zhou <coderplay@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f7c414caaa4404707131d2
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f7c414caaa4404707131d2
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Aaron,

We couldnot run mysqldump on the nodes mysqld runs on. The only way is
handling a connection to a gateway of the mysql cluster. Our hadoop cluster
serves us with also gateways, it's not allowed hadoop datanodes directly
connect to mysql gateway.

Min

On Thu, Aug 6, 2009 at 1:27 AM, Aaron Kimball <aaron@cloudera.com> wrote:

> mysqldump to local files on all 50 nodes, scp them to datanodes, and then
> bin/hadoop fs -put?
> - Aaron
>
> On Mon, Aug 3, 2009 at 8:15 PM, Min Zhou <coderplay@gmail.com> wrote:
>
> > hi all,
> >
> > We need to dump data from a mysql cluster with about 50 nodes to a hdfs
> > file. Considered about the issues on security , we can't use tools like
> > sqoop, where all datanodes must hold a connection to mysql. any
> > suggestions?
> >
> >
> > Thanks,
> > Min
> > --
> > My research interests are distributed systems, parallel computing and
> > bytecode based virtual machine.
> >
> > My profile:
> > http://www.linkedin.com/in/coderplay
> > My blog:
> > http://coderplay.javaeye.com
> >
>



-- 
My research interests are distributed systems, parallel computing and
bytecode based virtual machine.

My profile:
http://www.linkedin.com/in/coderplay
My blog:
http://coderplay.javaeye.com

--001485f7c414caaa4404707131d2--

From common-user-return-16578-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 04:52:10 2009
Return-Path: <common-user-return-16578-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75600 invoked from network); 6 Aug 2009 04:52:10 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 04:52:10 -0000
Received: (qmail 98244 invoked by uid 500); 6 Aug 2009 04:52:15 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 98153 invoked by uid 500); 6 Aug 2009 04:52:15 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 98143 invoked by uid 99); 6 Aug 2009 04:52:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 04:52:15 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pareekash@gmail.com designates 209.85.222.186 as permitted sender)
Received: from [209.85.222.186] (HELO mail-pz0-f186.google.com) (209.85.222.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 04:52:06 +0000
Received: by pzk16 with SMTP id 16so561052pzk.20
        for <multiple recipients>; Wed, 05 Aug 2009 21:51:46 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=TfEeDCUWEAt3JQbNwjIMJARmiPpvNYt8DEwnRl4x2Mg=;
        b=Q4OJkmPp25vIeqMMncooVLo5/xiioFmiBYdfamB+r3RrR6ELBG1uf0rp9aeG8fTOWr
         H3ZadbG1lN1s8T6F33OcPA1JgViIoN31Rhp8W3Y3UDhI4U+xU0+2uI7cV1zaWcUo//cR
         yuZHvekeHxXjT9bePiJxg4eXL/mvQ25gnW69c=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=W14gYk0Z1O3kPgP8Czy1AYgoCQGqLYUXFUy4nihKfN4Z7dXV8HZaEVo+i6nVii0y/f
         /7k1kHDi4zIzQ+a08/QLVNr+xFxFpItaVrAyAcz2JPWiR24ajDH6VTsl+tuDCu49zwyF
         RCEkaArXQXKHKdJ8a6ZmVlMtfM8MghAXUUry0=
MIME-Version: 1.0
Received: by 10.114.108.18 with SMTP id g18mr9652938wac.191.1249534306318; 
	Wed, 05 Aug 2009 21:51:46 -0700 (PDT)
Date: Thu, 6 Aug 2009 10:21:46 +0530
Message-ID: <45d9159d0908052151j24ade0fct38c7acdd8b74d2ce@mail.gmail.com>
Subject: Help in running hadoop from eclipse
From: ashish pareek <pareekash@gmail.com>
To: hadoop-user@hadoop.apache.org, common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163646ba64767a12047071e0d9
X-Virus-Checked: Checked by ClamAV on apache.org

--00163646ba64767a12047071e0d9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Everybody,

                  I am trying to run hadoop from eclipse... but when i run
NmaeNode.java as java appliaction i get following error..... Please help in
getting rid of this problem.



2009-08-05 23:42:00,760 INFO  dfs.NameNode
(StringUtils.java:startupShutdownMessage(464)) - STARTUP_MSG:

/************************************************************

STARTUP_MSG: Starting NameNode

STARTUP_MSG:   host = datanode1/10.0.1.109

STARTUP_MSG:   args = []

STARTUP_MSG:   version = Unknown

STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Unknown' on Unknown

************************************************************/

2009-08-05 23:42:00,806 ERROR dfs.NameNode (NameNode.java:main(843)) -
java.lang.NullPointerException

            at
org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)

            at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)

            at org.apache.hadoop.dfs.NameNode.initialize(NameNode.java:136)

            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:193)

            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:179)

            at
org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:830)

            at org.apache.hadoop.dfs.NameNode.main(NameNode.java:839)



2009-08-05 23:42:00,807 INFO  dfs.NameNode (StringUtils.java:run(479)) -
SHUTDOWN_MSG:

/************************************************************

SHUTDOWN_MSG: Shutting down NameNode at datanode1/10.0.1.109

************************************************************/

--00163646ba64767a12047071e0d9--

From common-user-return-16579-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 05:52:35 2009
Return-Path: <common-user-return-16579-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 94590 invoked from network); 6 Aug 2009 05:52:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 05:52:35 -0000
Received: (qmail 29275 invoked by uid 500); 6 Aug 2009 05:52:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 29187 invoked by uid 500); 6 Aug 2009 05:52:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 29177 invoked by uid 99); 6 Aug 2009 05:52:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 05:52:40 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yangzhou.ebay@gmail.com designates 209.85.218.215 as permitted sender)
Received: from [209.85.218.215] (HELO mail-bw0-f215.google.com) (209.85.218.215)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 05:52:29 +0000
Received: by bwz11 with SMTP id 11so547786bwz.15
        for <common-user@hadoop.apache.org>; Wed, 05 Aug 2009 22:52:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=8ToxxGNuTfxSm/lf8h3efWHhxXrLoZ3CSYU6CQI9aY8=;
        b=dR2FNG4uT/u0PBroK+YJnc881oBZgI3afSbR2X6n+fY/5dxzD0HhZIT0qem0U5JKJ8
         w3njqsrvvLBPcFYIjieW5EtA0b6id4k661VEB1yzMnCnsneZaTmYSlgWPxMtHNNOd/01
         Un4vmRtoVNMO9Xlzwxg+LZbglMR89jfQhltO8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=EmL3C3mShr7v+LAyBwWK/sOEf+dtmwvZN4lIdhOGENUsexCGHMNRq9IhR9UZlzmxuN
         gmFh+ok+IArB0y/1F0/SVZEK0ikcFY69VdX027iyfZ8xf0MbCzyjReDIUHbU25pFsPBi
         LdTmo3feNoI70OAWwpwCHwwfqNGCWrFNKf3mk=
MIME-Version: 1.0
Received: by 10.239.151.147 with SMTP id r19mr1011477hbb.70.1249537927367; 
	Wed, 05 Aug 2009 22:52:07 -0700 (PDT)
In-Reply-To: <bcaf338a0908052102v4607b9afn293b47875f50cdc8@mail.gmail.com>
References: <bcaf338a0908032015h41cff744l1b0f74ea60cc32df@mail.gmail.com>
	 <d6d7c4410908051027y22f68eb5ufa9989be16d3e846@mail.gmail.com>
	 <bcaf338a0908052102v4607b9afn293b47875f50cdc8@mail.gmail.com>
Date: Thu, 6 Aug 2009 13:52:07 +0800
Message-ID: <2970f47f0908052252x4bb8881dy2c1bffc1604ac676@mail.gmail.com>
Subject: Re: how to dump data from a mysql cluster to hdfs?
From: Yang Zhou <yangzhou.ebay@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f1dcd64b4c36047072b824
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f1dcd64b4c36047072b824
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Write a Java program which will dump data from mysql cluster and save them
into HDFS at the same time.
Run it on namenode. I assume namenode should be able to connect to mysql
gateway.
Will it work?

On Thu, Aug 6, 2009 at 12:02 PM, Min Zhou <coderplay@gmail.com> wrote:

> Hi Aaron,
>
> We couldnot run mysqldump on the nodes mysqld runs on. The only way is
> handling a connection to a gateway of the mysql cluster. Our hadoop cluster
> serves us with also gateways, it's not allowed hadoop datanodes directly
> connect to mysql gateway.
>
> Min
>
> On Thu, Aug 6, 2009 at 1:27 AM, Aaron Kimball <aaron@cloudera.com> wrote:
>
> > mysqldump to local files on all 50 nodes, scp them to datanodes, and then
> > bin/hadoop fs -put?
> > - Aaron
> >
> > On Mon, Aug 3, 2009 at 8:15 PM, Min Zhou <coderplay@gmail.com> wrote:
> >
> > > hi all,
> > >
> > > We need to dump data from a mysql cluster with about 50 nodes to a hdfs
> > > file. Considered about the issues on security , we can't use tools like
> > > sqoop, where all datanodes must hold a connection to mysql. any
> > > suggestions?
> > >
> > >
> > > Thanks,
> > > Min
> > > --
> > > My research interests are distributed systems, parallel computing and
> > > bytecode based virtual machine.
> > >
> > > My profile:
> > > http://www.linkedin.com/in/coderplay
> > > My blog:
> > > http://coderplay.javaeye.com
> > >
> >
>
>
>
> --
> My research interests are distributed systems, parallel computing and
> bytecode based virtual machine.
>
> My profile:
> http://www.linkedin.com/in/coderplay
> My blog:
> http://coderplay.javaeye.com
>

--001485f1dcd64b4c36047072b824--

From common-user-return-16580-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 09:08:27 2009
Return-Path: <common-user-return-16580-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 53109 invoked from network); 6 Aug 2009 09:08:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 09:08:26 -0000
Received: (qmail 79079 invoked by uid 500); 6 Aug 2009 09:08:31 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 78996 invoked by uid 500); 6 Aug 2009 09:08:31 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 78986 invoked by uid 99); 6 Aug 2009 09:08:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 09:08:31 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of tamirkamara@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 09:08:22 +0000
Received: by ewy26 with SMTP id 26so740257ewy.29
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 02:08:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=jWCfbW91cEK3izlgo+oNVscd61PGgDXd/OrFHQ35OH0=;
        b=StiqEsoK9jkNxiEe+uq3ABgaJAec1nstRC7W8rQX8LJWCE0uD1WkVGYXUX0ATe92Q3
         hP4vspJGfBEeAqkTkqJF4cQwKwEbUDt4TvzZyCiUZLEl+Kq4clhkd70fCETdVcYFv72R
         8vTlHRwCMll+fGd/Qa6wFOK+N2sLFNaNSPknw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=tKHOgAFztc4EFsDpes+ZL3fvFAioB65AJjt2auktTXz+M2mEa5JemcR2tOEnQt3l+Z
         2qhyFEHvYs7LRVJkrG4FuO8SKxOh+pJEI1CkHgAqZkOaPYjC5L5OoeT4BTGn7zleEhvw
         0j8CcUf14TcwmTUQJJsSS4oOpT7OdWohyS0Dg=
MIME-Version: 1.0
Received: by 10.216.22.206 with SMTP id t56mr2066713wet.131.1249549681645; 
	Thu, 06 Aug 2009 02:08:01 -0700 (PDT)
Date: Thu, 6 Aug 2009 12:08:01 +0300
Message-ID: <6d10e930908060208i1ce9b91dl63bf7338406f3c5c@mail.gmail.com>
Subject: 0.19.2 Native Libraries Issue
From: Tamir Kamara <tamirkamara@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016364c7d1be7585804707574e7
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364c7d1be7585804707574e7
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

When using native compression libraries that come with 0.19.2 there seem to
be an issue on certain OS that wasn't there on 0.19.1. Some of our machines
are RHEL4 and some RHEL5 and when using compression on RHEL4 the JVMs are
having critical errors with the native code, RHEL5 is working fine.
I tried to check if there're changes that might cause this but didn't see
anything, nevertheless the size of the libraries themselves changed from
108K in 0.19.1 to 125K in 0.19.2 - so it seems that something has changed.
Does someone know what changed and why would that cause issues?

My solution for now is to use the libraries from 0.19.1 which seem to work
just fine.


Thanks,
Tamir

--0016364c7d1be7585804707574e7--

From common-user-return-16581-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 09:17:10 2009
Return-Path: <common-user-return-16581-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 56416 invoked from network); 6 Aug 2009 09:17:10 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 09:17:10 -0000
Received: (qmail 95355 invoked by uid 500); 6 Aug 2009 09:17:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95279 invoked by uid 500); 6 Aug 2009 09:17:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95010 invoked by uid 99); 6 Aug 2009 09:17:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 09:17:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pareekash@gmail.com designates 209.85.222.189 as permitted sender)
Received: from [209.85.222.189] (HELO mail-pz0-f189.google.com) (209.85.222.189)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 09:17:04 +0000
Received: by pzk27 with SMTP id 27so884121pzk.2
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 02:16:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=xzInpiYwkwW87Y8I81x0ymIh//3SFVbrpk2PiYfD4qI=;
        b=Xf0vOSFzOliZ9PNGXpikWdYGI2uqnzPJYe2hFrjneG0cuxN4Wmq8HGEle9OsgSo7Hu
         XOIWvofU3BbKtfQq6tzyxj+kUml1m83VPqcE3iQp81FKzEjLueokulucoKrXFVnpqtIm
         UzOafLZVDUVQs3QeDtlG9bUJy5MMg8tAB0Ta8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=a0WabOuasTlzJy6G9WQTlk2opx1kyMrIZFxUXGpDgtxOmG8Uf0lj58sGDaCSuacBfL
         IcqlGplMYZON8offTmhvR3MCiLpp/4x/h47KgPvUQgdNVK1nyBeXgnIIfmMf0SkhD3Bs
         rlxh0RFywwimbePaznKcXgCja+s4D7bg1Wf5U=
MIME-Version: 1.0
Received: by 10.114.205.17 with SMTP id c17mr13052336wag.64.1249550204687; 
	Thu, 06 Aug 2009 02:16:44 -0700 (PDT)
Date: Thu, 6 Aug 2009 14:46:44 +0530
Message-ID: <45d9159d0908060216m193f259k756f179768b46e8f@mail.gmail.com>
Subject: Help in building and running hadoop from eclipse
From: ashish pareek <pareekash@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64aec3a14575f04707594d7
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64aec3a14575f04707594d7
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi All,


                 I am trying to learn building  Hadoop  as I have to make
few changes to FShell code . I tried the link given in the
http://www.*wiki*.apache.org/*hadoop*/*Eclipse*Environment but always landed
up in errors.

             Then there was error like .eclipse.template missing ... so I
download it from
http://svn.apache.org/repos/asf/hadoop/common/tags/release-0.18.3/.eclipse.templates/
               But thing was .classpath in svn link was different from
hadoop 0.18.3 I had offline.
                When I tried to build with .classpath I had offline....
following the steps given in the following video. But still there seems to
be java errors after build liek button cannot be resolved , Tabconfiguration
cannot be resolved etc..

                 But when I tried with .classpath from svn link build was
successful  expect few warnnings. :)

                 Now I want to run in eclispe to trace hadoop to find more
about it.... but when I try to run hadoop-site.xml as java application I get
errors like NUllexception or
                 STRATUP_MSG = build bu UNKNOWN on UNKNOWN time etc and Name
Node shutdown.


Error Message is as follows :::


009-08-05 23:42:00,760 INFO  dfs.NameNode (StringUtils.java:

startupShutdownMessage(464)) - STARTUP_MSG:

/************************************************************

STARTUP_MSG: Starting NameNode

STARTUP_MSG:   host = datanode1/10.0.1.109

STARTUP_MSG:   args = []

STARTUP_MSG:   version = Unknown

STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Unknown' on Unknown

************************************************************/

2009-08-05 23:42:00,806 ERROR dfs.NameNode (NameNode.java:main(843)) -
java.lang.NullPointerException

            at
org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)

            at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)

            at org.apache.hadoop.dfs.NameNode.initialize(NameNode.java:136)

            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:193)

            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:179)

            at
org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:830)

            at org.apache.hadoop.dfs.NameNode.main(NameNode.java:839)



2009-08-05 23:42:00,807 INFO  dfs.NameNode (StringUtils.java:run(479)) -
SHUTDOWN_MSG:

/************************************************************

SHUTDOWN_MSG: Shutting down NameNode at datanode1/10.0.1.109

************************************************************/



                Can you please help with building and running Hadoop in
eclipse.

Thanks for your percious time.

Ashish.

--0016e64aec3a14575f04707594d7--

From common-user-return-16582-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 10:32:28 2009
Return-Path: <common-user-return-16582-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 4302 invoked from network); 6 Aug 2009 10:32:27 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 10:32:27 -0000
Received: (qmail 3764 invoked by uid 500); 6 Aug 2009 10:32:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 3674 invoked by uid 500); 6 Aug 2009 10:32:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 3664 invoked by uid 99); 6 Aug 2009 10:32:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 10:32:32 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of coderplay@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 10:32:20 +0000
Received: by fxm24 with SMTP id 24so782082fxm.36
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 03:31:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=Ns/oRiyrr4/kclnDDW0rHnlZlLLTX/HMoU5i2DR8fnE=;
        b=xgUrMyl22EkUBwp4aizpTWKZzoh86HWeCcMGcDmy3PVR0uth1gEVMe4wKoOc/j5D46
         4jtvPGvf7umSIqT8GAJu6NrMwozocG/SeoQJhyjET1Egi89K7S5qs36s64R+H9+wVZka
         bLsX9zpIogt4KfVq1l6eGN88ffEN7G88Napmc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=nzaUeo4wmmCrTkoRaw4wdMeREP74corSDTD6Hbv0iRMnWy06cbjWWW+A0Hf5KAthzC
         LIAl9ps0oKVvMWaJWtpR0jbmukYxKvACB65L8jJnhO/Qeuy0hBtPBRz+DXGIGiNuX4Js
         XWeBO+SgQRawVaaUmETdngp957jMsbqCYOC9s=
MIME-Version: 1.0
Received: by 10.239.136.68 with SMTP id g4mr1042417hbg.58.1249554719814; Thu, 
	06 Aug 2009 03:31:59 -0700 (PDT)
In-Reply-To: <2970f47f0908052252x4bb8881dy2c1bffc1604ac676@mail.gmail.com>
References: <bcaf338a0908032015h41cff744l1b0f74ea60cc32df@mail.gmail.com>
	 <d6d7c4410908051027y22f68eb5ufa9989be16d3e846@mail.gmail.com>
	 <bcaf338a0908052102v4607b9afn293b47875f50cdc8@mail.gmail.com>
	 <2970f47f0908052252x4bb8881dy2c1bffc1604ac676@mail.gmail.com>
Date: Thu, 6 Aug 2009 18:31:59 +0800
Message-ID: <bcaf338a0908060331y46a085d8ua8d19660673b6a7b@mail.gmail.com>
Subject: Re: how to dump data from a mysql cluster to hdfs?
From: Min Zhou <coderplay@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f9a85833b5ca047076a128
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f9a85833b5ca047076a128
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I guess I havenot expressed clearly. Neither datanodes nor namenodes is
allowed to be directly connected.
Even though, namenode is often in heavy work, it would be burdened dumping
data on them.

On Thu, Aug 6, 2009 at 1:52 PM, Yang Zhou <yangzhou.ebay@gmail.com> wrote:

> Write a Java program which will dump data from mysql cluster and save them
> into HDFS at the same time.
> Run it on namenode. I assume namenode should be able to connect to mysql
> gateway.
> Will it work?
>
> On Thu, Aug 6, 2009 at 12:02 PM, Min Zhou <coderplay@gmail.com> wrote:
>
> > Hi Aaron,
> >
> > We couldnot run mysqldump on the nodes mysqld runs on. The only way is
> > handling a connection to a gateway of the mysql cluster. Our hadoop
> cluster
> > serves us with also gateways, it's not allowed hadoop datanodes directly
> > connect to mysql gateway.
> >
> > Min
> >
> > On Thu, Aug 6, 2009 at 1:27 AM, Aaron Kimball <aaron@cloudera.com>
> wrote:
> >
> > > mysqldump to local files on all 50 nodes, scp them to datanodes, and
> then
> > > bin/hadoop fs -put?
> > > - Aaron
> > >
> > > On Mon, Aug 3, 2009 at 8:15 PM, Min Zhou <coderplay@gmail.com> wrote:
> > >
> > > > hi all,
> > > >
> > > > We need to dump data from a mysql cluster with about 50 nodes to a
> hdfs
> > > > file. Considered about the issues on security , we can't use tools
> like
> > > > sqoop, where all datanodes must hold a connection to mysql. any
> > > > suggestions?
> > > >
> > > >
> > > > Thanks,
> > > > Min
> > > > --
> > > > My research interests are distributed systems, parallel computing and
> > > > bytecode based virtual machine.
> > > >
> > > > My profile:
> > > > http://www.linkedin.com/in/coderplay
> > > > My blog:
> > > > http://coderplay.javaeye.com
> > > >
> > >
> >
> >
> >
> > --
> > My research interests are distributed systems, parallel computing and
> > bytecode based virtual machine.
> >
> > My profile:
> > http://www.linkedin.com/in/coderplay
> > My blog:
> > http://coderplay.javaeye.com
> >
>



-- 
My research interests are distributed systems, parallel computing and
bytecode based virtual machine.

My profile:
http://www.linkedin.com/in/coderplay
My blog:
http://coderplay.javaeye.com

--001485f9a85833b5ca047076a128--

From common-user-return-16583-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 10:58:03 2009
Return-Path: <common-user-return-16583-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 8337 invoked from network); 6 Aug 2009 10:58:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 10:58:02 -0000
Received: (qmail 25876 invoked by uid 500); 6 Aug 2009 10:58:07 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25771 invoked by uid 500); 6 Aug 2009 10:58:07 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25761 invoked by uid 99); 6 Aug 2009 10:58:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 10:58:07 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of timrobertson100@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 10:57:54 +0000
Received: by ewy26 with SMTP id 26so798125ewy.29
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 03:57:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=eax34IBpDi5NtYZHIM+unem2aD6qYMw0reKWTpVOB34=;
        b=QO4ONHuOEKWIU2AnGiFf/REtFMejb+5le6qAcnZfJkjz2TYOlX5qNLCa/oYXn5yyq/
         SHsRAclNUFYvP44CgrwKPnAJVMVcZP8o/loyQ8oTeKe7DY/gUo5uhn4HxUcQ1ZE4Z6iA
         Yx8j9nJMFwOXu2SlM13cY+TqYn5H6nt0gNRUw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=Nv6ptR9oJeN67od71unUDdKns4Kyl/zfu8FKy8zvAP5K2eXfe9/HdPQSJGU+hdvX5m
         KpL9JYz0TsYI0ALKWZdgGfntkxgNS5y+l/XbQkrdw/echsiAuH3wh+hhifkEKnQgDSZM
         OCuYmQYj7H8O/UJvs8GvjRzV/FFNqZqAsgsQo=
MIME-Version: 1.0
Received: by 10.216.93.141 with SMTP id l13mr1994350wef.67.1249556254274; Thu, 
	06 Aug 2009 03:57:34 -0700 (PDT)
In-Reply-To: <bcaf338a0908060331y46a085d8ua8d19660673b6a7b@mail.gmail.com>
References: <bcaf338a0908032015h41cff744l1b0f74ea60cc32df@mail.gmail.com>
	 <d6d7c4410908051027y22f68eb5ufa9989be16d3e846@mail.gmail.com>
	 <bcaf338a0908052102v4607b9afn293b47875f50cdc8@mail.gmail.com>
	 <2970f47f0908052252x4bb8881dy2c1bffc1604ac676@mail.gmail.com>
	 <bcaf338a0908060331y46a085d8ua8d19660673b6a7b@mail.gmail.com>
Date: Thu, 6 Aug 2009 12:57:34 +0200
Message-ID: <32120a6a0908060357x21c712f3pd494cfce8356b32d@mail.gmail.com>
Subject: Re: how to dump data from a mysql cluster to hdfs?
From: tim robertson <timrobertson100@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Sounds like you don't have many other options other than finding a
machine that can get to the mysql gateway, do some mysql export, copy
to a machine which can talk to the Hadoop gateway (if necessary) and
then copy it in to HDFS.

I'm not sure what else you could do.

Cheers

Tim



On Thu, Aug 6, 2009 at 12:31 PM, Min Zhou<coderplay@gmail.com> wrote:
> I guess I havenot expressed clearly. Neither datanodes nor namenodes is
> allowed to be directly connected.
> Even though, namenode is often in heavy work, it would be burdened dumping
> data on them.
>
> On Thu, Aug 6, 2009 at 1:52 PM, Yang Zhou <yangzhou.ebay@gmail.com> wrote:
>
>> Write a Java program which will dump data from mysql cluster and save them
>> into HDFS at the same time.
>> Run it on namenode. I assume namenode should be able to connect to mysql
>> gateway.
>> Will it work?
>>
>> On Thu, Aug 6, 2009 at 12:02 PM, Min Zhou <coderplay@gmail.com> wrote:
>>
>> > Hi Aaron,
>> >
>> > We couldnot run mysqldump on the nodes mysqld runs on. The only way is
>> > handling a connection to a gateway of the mysql cluster. Our hadoop
>> cluster
>> > serves us with also gateways, it's not allowed hadoop datanodes directly
>> > connect to mysql gateway.
>> >
>> > Min
>> >
>> > On Thu, Aug 6, 2009 at 1:27 AM, Aaron Kimball <aaron@cloudera.com>
>> wrote:
>> >
>> > > mysqldump to local files on all 50 nodes, scp them to datanodes, and
>> then
>> > > bin/hadoop fs -put?
>> > > - Aaron
>> > >
>> > > On Mon, Aug 3, 2009 at 8:15 PM, Min Zhou <coderplay@gmail.com> wrote:
>> > >
>> > > > hi all,
>> > > >
>> > > > We need to dump data from a mysql cluster with about 50 nodes to a
>> hdfs
>> > > > file. Considered about the issues on security , we can't use tools
>> like
>> > > > sqoop, where all datanodes must hold a connection to mysql. any
>> > > > suggestions?
>> > > >
>> > > >
>> > > > Thanks,
>> > > > Min
>> > > > --
>> > > > My research interests are distributed systems, parallel computing and
>> > > > bytecode based virtual machine.
>> > > >
>> > > > My profile:
>> > > > http://www.linkedin.com/in/coderplay
>> > > > My blog:
>> > > > http://coderplay.javaeye.com
>> > > >
>> > >
>> >
>> >
>> >
>> > --
>> > My research interests are distributed systems, parallel computing and
>> > bytecode based virtual machine.
>> >
>> > My profile:
>> > http://www.linkedin.com/in/coderplay
>> > My blog:
>> > http://coderplay.javaeye.com
>> >
>>
>
>
>
> --
> My research interests are distributed systems, parallel computing and
> bytecode based virtual machine.
>
> My profile:
> http://www.linkedin.com/in/coderplay
> My blog:
> http://coderplay.javaeye.com
>

From common-user-return-16584-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 14:08:42 2009
Return-Path: <common-user-return-16584-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 89673 invoked from network); 6 Aug 2009 14:08:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 14:08:42 -0000
Received: (qmail 43255 invoked by uid 500); 6 Aug 2009 14:08:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 43176 invoked by uid 500); 6 Aug 2009 14:08:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 43166 invoked by uid 500); 6 Aug 2009 14:08:47 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 43136 invoked by uid 99); 6 Aug 2009 14:08:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 14:08:44 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 14:08:33 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MZ3dc-0002BI-PE
	for core-user@hadoop.apache.org; Thu, 06 Aug 2009 07:08:12 -0700
Message-ID: <24847289.post@talk.nabble.com>
Date: Thu, 6 Aug 2009 07:08:12 -0700 (PDT)
From: thkunkel <thkunkel@gmail.com>
To: core-user@hadoop.apache.org
Subject: Accessing HDFS over network
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: thkunkel@gmail.com
X-Virus-Checked: Checked by ClamAV on apache.org


Hello,
I have an HDFS cluster using Ubuntu.
I want to load IIS logs into the HDFS and then do some processing with them. 
The IIS logs come from Windows 2003 servers.
Currently in Ubuntu I have mounts set up that point to the IIS logs on the
Windows servers.  From there I copy the logs from the mounts into the HDFS
using the -copyFromLocal command.

This works fine enough, but I was wondering if there is a way to share or
open a folder on the HDFS to the network so that, for example, my Windows
machines could see it and copy to it directly.

Is there a way to do that?  Or should I use ssh?

Thanks much,
-T
-- 
View this message in context: http://www.nabble.com/Accessing-HDFS-over-network-tp24847289p24847289.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-16585-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 15:28:33 2009
Return-Path: <common-user-return-16585-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 39640 invoked from network); 6 Aug 2009 15:28:33 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 15:28:33 -0000
Received: (qmail 15417 invoked by uid 500); 6 Aug 2009 15:28:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 15331 invoked by uid 500); 6 Aug 2009 15:28:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 15321 invoked by uid 99); 6 Aug 2009 15:28:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 15:28:38 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.222.186 as permitted sender)
Received: from [209.85.222.186] (HELO mail-pz0-f186.google.com) (209.85.222.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 15:28:28 +0000
Received: by pzk16 with SMTP id 16so989703pzk.20
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 08:28:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=qnFfIZCTIZL2ZgKyggXUjXMaWADqDGf558oa3AevIG8=;
        b=iyNO0GKc9fb3IvU3qai5wbttWLhN5dnqC4Ssk/ChePtBa7ulIkLzz+W1fnEWqJI2UC
         82Vh1kMVmXkDqvZ63OPUxOJGcSsxM3WvU+/shQW8Pk3eVDAUD7aFpRS5DbPxuWzv6TlQ
         0Ry9c856GILQwqwL1vBzMRuTY+IHS9FHLeC8A=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=RalNZKoTy+tv6R4Nbx7twGEJOZw/ofx8n0eyxYHq18qSIT3p+vG3BMBBrE5upjvz7A
         jWzn7guPVIQDIUQUOunSkt65hf05nF5wA/m5Pk7oU5D1LGblid1P/NW1l/gEtwuJskQP
         hd2g9GUyE2rCk5AMkeEKujne8cD8PuCGNb3rc=
MIME-Version: 1.0
Received: by 10.142.237.18 with SMTP id k18mr1027923wfh.250.1249572487086; 
	Thu, 06 Aug 2009 08:28:07 -0700 (PDT)
In-Reply-To: <24847289.post@talk.nabble.com>
References: <24847289.post@talk.nabble.com>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Thu, 6 Aug 2009 20:57:47 +0530
Message-ID: <e01b80590908060827u1bc3095eld9f078c0a77bd033@mail.gmail.com>
Subject: Re: Accessing HDFS over network
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd32e8c36c55704707ac4e4
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd32e8c36c55704707ac4e4
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Why can't you use -copyFromLocal to copy stuff directly from the Windows
machines to HDFS? If you install hadoop on the windows machine, you should
be able to push log files to HDFS (btw the Windows machine doesn't have to
be part of the cluster).

- Harish

On Thu, Aug 6, 2009 at 7:38 PM, thkunkel <thkunkel@gmail.com> wrote:

>
> Hello,
> I have an HDFS cluster using Ubuntu.
> I want to load IIS logs into the HDFS and then do some processing with
> them.
> The IIS logs come from Windows 2003 servers.
> Currently in Ubuntu I have mounts set up that point to the IIS logs on the
> Windows servers.  From there I copy the logs from the mounts into the HDFS
> using the -copyFromLocal command.
>
> This works fine enough, but I was wondering if there is a way to share or
> open a folder on the HDFS to the network so that, for example, my Windows
> machines could see it and copy to it directly.
>
> Is there a way to do that?  Or should I use ssh?
>
> Thanks much,
> -T
> --
> View this message in context:
> http://www.nabble.com/Accessing-HDFS-over-network-tp24847289p24847289.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>
>


-- 
Harish Mallipeddi
http://blog.poundbang.in

--000e0cd32e8c36c55704707ac4e4--

From common-user-return-16586-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 17:46:37 2009
Return-Path: <common-user-return-16586-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 9193 invoked from network); 6 Aug 2009 17:46:36 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 17:46:36 -0000
Received: (qmail 37297 invoked by uid 500); 6 Aug 2009 17:46:41 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 37241 invoked by uid 500); 6 Aug 2009 17:46:41 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 37231 invoked by uid 500); 6 Aug 2009 17:46:41 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 37228 invoked by uid 99); 6 Aug 2009 17:46:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 17:46:41 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 17:46:32 +0000
Received: by fxm24 with SMTP id 24so1050485fxm.36
        for <core-user@hadoop.apache.org>; Thu, 06 Aug 2009 10:46:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=mu0ImHx5xIZeLzqSJwxjq6e599uO4rQrr87pCzLZ/FY=;
        b=l1QZJBCMKtNlcpZRk3UPWolt8gU4jNwViJmZaU4Hn5B828HcpOL9s8SoYtc7IHX7wf
         k29F0iLslOQp4m9a71mgCsbw5NvJFpCZo0WnaYSUBPjeKc0fytaN/xlgka2yyUjA4EiJ
         yeOcHZ6SPhIBKdH6qR9idin67NRsABNT8eLgk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=a0Shhlm35Uy9kKO4WJayZCPaCY539PxguMeh0dcX5fe+uqhLDUShJbDu8y6J4bpiQ9
         JgKx+9p9H3LMu6NNxBdAjqwfZ/LBy7+Pirau6zxIbaBfyB/KZMTM1hWcwjeY5TlSXH3C
         USSUmvzJ57+7LXoyZzIxL1qtbkLSg8F9dBkJY=
MIME-Version: 1.0
Received: by 10.223.114.74 with SMTP id d10mr50449faq.87.1249580772161; Thu, 
	06 Aug 2009 10:46:12 -0700 (PDT)
Date: Thu, 6 Aug 2009 20:46:12 +0300
Message-ID: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com>
Subject: HADOOP-4539 question
From: Stas Oskin <stas.oskin@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016368e2bc90af7aa04707cb209
X-Virus-Checked: Checked by ClamAV on apache.org

--0016368e2bc90af7aa04707cb209
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

I checked this ticket and I like what I found.

Had question about it, and hoped someone can answer it:

If I have a NN, and BN, and the NN fails, how the DFS clients will know how
to connect to the new IP?

It will be a config level setting?

Or it needs to be achieved via external Linux HA scripts?

Thanks!

--0016368e2bc90af7aa04707cb209--

From common-user-return-16587-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 17:53:19 2009
Return-Path: <common-user-return-16587-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11787 invoked from network); 6 Aug 2009 17:53:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 17:53:19 -0000
Received: (qmail 44485 invoked by uid 500); 6 Aug 2009 17:53:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 44408 invoked by uid 500); 6 Aug 2009 17:53:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 44398 invoked by uid 99); 6 Aug 2009 17:53:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 17:53:24 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 17:53:12 +0000
Received: by qw-out-2122.google.com with SMTP id 8so390955qwh.35
        for <multiple recipients>; Thu, 06 Aug 2009 10:52:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.67.137 with SMTP id r9mr217840qai.167.1249581171142; Thu, 
	06 Aug 2009 10:52:51 -0700 (PDT)
In-Reply-To: <45d9159d0908052151j24ade0fct38c7acdd8b74d2ce@mail.gmail.com>
References: <45d9159d0908052151j24ade0fct38c7acdd8b74d2ce@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Thu, 6 Aug 2009 10:52:31 -0700
Message-ID: <d6d7c4410908061052t522b0da7r5fe9534fdeed93a2@mail.gmail.com>
Subject: Re: Help in running hadoop from eclipse
To: common-user@hadoop.apache.org
Cc: hadoop-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175cb85ad2f20e04707cc9bb
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175cb85ad2f20e04707cc9bb
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

May I ask why you're trying to run the NameNode in Eclipse? This is likely
going to cause you lots of classpath headaches. I think your current problem
is that it can't find its config files, so it's not able to read in the
strings for what addresses it should listen on.

If you want to see what's happening inside the namenode, I'd run
"bin/hadoop-daemon.sh start namenode" to start it, then fire up Eclipse and
attach the debugger externally. You can then point it at your copy of the
Hadoop source code so you can set breakpoints, trace, etc.

- A

On Wed, Aug 5, 2009 at 9:51 PM, ashish pareek <pareekash@gmail.com> wrote:

> Hi Everybody,
>
>                  I am trying to run hadoop from eclipse... but when i run
> NmaeNode.java as java appliaction i get following error..... Please help in
> getting rid of this problem.
>
>
>
> 2009-08-05 23:42:00,760 INFO  dfs.NameNode
> (StringUtils.java:startupShutdownMessage(464)) - STARTUP_MSG:
>
> /************************************************************
>
> STARTUP_MSG: Starting NameNode
>
> STARTUP_MSG:   host = datanode1/10.0.1.109
>
> STARTUP_MSG:   args = []
>
> STARTUP_MSG:   version = Unknown
>
> STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Unknown' on Unknown
>
> ************************************************************/
>
> 2009-08-05 23:42:00,806 ERROR dfs.NameNode (NameNode.java:main(843)) -
> java.lang.NullPointerException
>
>            at
> org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
>
>            at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
>
>            at org.apache.hadoop.dfs.NameNode.initialize(NameNode.java:136)
>
>            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:193)
>
>            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:179)
>
>            at
> org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:830)
>
>            at org.apache.hadoop.dfs.NameNode.main(NameNode.java:839)
>
>
>
> 2009-08-05 23:42:00,807 INFO  dfs.NameNode (StringUtils.java:run(479)) -
> SHUTDOWN_MSG:
>
> /************************************************************
>
> SHUTDOWN_MSG: Shutting down NameNode at datanode1/10.0.1.109
>
> ************************************************************/
>

--0015175cb85ad2f20e04707cc9bb--

From common-user-return-16588-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 18:00:08 2009
Return-Path: <common-user-return-16588-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 15513 invoked from network); 6 Aug 2009 18:00:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 18:00:07 -0000
Received: (qmail 54348 invoked by uid 500); 6 Aug 2009 18:00:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 54256 invoked by uid 500); 6 Aug 2009 18:00:12 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 54246 invoked by uid 99); 6 Aug 2009 18:00:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 18:00:12 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [74.125.92.27] (HELO qw-out-2122.google.com) (74.125.92.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 18:00:03 +0000
Received: by qw-out-2122.google.com with SMTP id 8so393157qwh.35
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 10:59:42 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.74.79 with SMTP id t15mr190279qaj.331.1249581582090; Thu, 
	06 Aug 2009 10:59:42 -0700 (PDT)
In-Reply-To: <abdb77f90908051706t482b492cq4a4f2688bccf0379@mail.gmail.com>
References: <abdb77f90908051559t342c6c72rd52eb77995b52da7@mail.gmail.com> 
	<92c4d8c10908051615x1bcff245s3c8830c04a3aebf9@mail.gmail.com> 
	<abdb77f90908051625v546bd0fcw753896689e3eb611@mail.gmail.com> 
	<abdb77f90908051706t482b492cq4a4f2688bccf0379@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Thu, 6 Aug 2009 10:59:22 -0700
Message-ID: <d6d7c4410908061059m6a742d6sf461f3167f58f3f9@mail.gmail.com>
Subject: Re: Maps running - how to increase?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175d6754518e3104707ce233
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175d6754518e3104707ce233
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Is that setting in the hadoop-site.xml file on every node? Each tasktracker
reads in that file once and sets its max map tasks from that. There's no way
to control this setting on a per-job basis or from the client (submitting)
system. If you've changed hadoop-site.xml after starting the tasktracker,
you need to restart the tasktracker daemon on each node.

Note that 32 maps/node is considered a *lot*. This will likely not provide
you with optimal throughput, since they'll be competing for cores, RAM, I/O,
etc. ...Unless you've got some really super-charged machines in your
datacenter :grin:

Also, in terms of optimizing your job -- do you really have 6,000 big files
worth reading? Or are you running a job over 6,000 small files (where small
means less than 100 MB or so)? If the latter, consider using
MultiFileInputFormat to allow each task to operate on multiple files. See
http://www.cloudera.com/blog/2009/02/02/the-small-files-problem/ for some
more detail. Even after all 6,000 map tasks run, you'll have to deal with
reassembling 6,000 intermediate data shards into 6 or 12 reduce tasks. This
will also be slow, unless you bunch up multiple files into a single task.

Cheers,
- Aaron


On Wed, Aug 5, 2009 at 5:06 PM, Zeev Milin <zeevmisc@gmail.com> wrote:

> I now see that the mapred.tasktracker.map.tasks.maximum=32 on the job level
> and still only 6 maps running and 5000+ pending..
>
> Not sure how to force the cluster to run more maps.
>

--0015175d6754518e3104707ce233--

From common-user-return-16589-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 18:10:39 2009
Return-Path: <common-user-return-16589-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 23782 invoked from network); 6 Aug 2009 18:10:39 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 18:10:39 -0000
Received: (qmail 71129 invoked by uid 500); 6 Aug 2009 18:10:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 71046 invoked by uid 500); 6 Aug 2009 18:10:44 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 71029 invoked by uid 99); 6 Aug 2009 18:10:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 18:10:43 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 18:10:34 +0000
Received: by qyk26 with SMTP id 26so1010979qyk.5
        for <multiple recipients>; Thu, 06 Aug 2009 11:10:13 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.54.129 with SMTP id q1mr211493qag.299.1249582213097; Thu, 
	06 Aug 2009 11:10:13 -0700 (PDT)
In-Reply-To: <45d9159d0908052151j24ade0fct38c7acdd8b74d2ce@mail.gmail.com>
References: <45d9159d0908052151j24ade0fct38c7acdd8b74d2ce@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Thu, 6 Aug 2009 11:09:53 -0700
Message-ID: <d6d7c4410908061109o21ef1d0ak372037cc24106fab@mail.gmail.com>
Subject: Re: Help in running hadoop from eclipse
To: common-user@hadoop.apache.org
Cc: hadoop-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

May I ask why you're trying to run the NameNode in Eclipse? This is
likely going to cause you lots of classpath headaches. I think your
current problem is that it can't find its config files, so it's not
able to read in the strings for what addresses it should listen on.

If you want to see what's happening inside the namenode, I'd run
"bin/hadoop-daemon.sh start namenode" to start it, then fire up
Eclipse and attach the debugger externally. You can then point it at
your copy of the Hadoop source code so you can set breakpoints, trace,
etc.

- A

On Wed, Aug 5, 2009 at 9:51 PM, ashish pareek <pareekash@gmail.com> wrote:
>
> Hi Everybody,
>
> =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0I am trying to run hadoop from eclipse=
... but when i run
> NmaeNode.java as java appliaction i get following error..... Please help =
in
> getting rid of this problem.
>
>
>
> 2009-08-05 23:42:00,760 INFO =A0dfs.NameNode
> (StringUtils.java:startupShutdownMessage(464)) - STARTUP_MSG:
>
> /************************************************************
>
> STARTUP_MSG: Starting NameNode
>
> STARTUP_MSG: =A0 host =3D datanode1/10.0.1.109
>
> STARTUP_MSG: =A0 args =3D []
>
> STARTUP_MSG: =A0 version =3D Unknown
>
> STARTUP_MSG: =A0 build =3D Unknown -r Unknown; compiled by 'Unknown' on U=
nknown
>
> ************************************************************/
>
> 2009-08-05 23:42:00,806 ERROR dfs.NameNode (NameNode.java:main(843)) -
> java.lang.NullPointerException
>
> =A0 =A0 =A0 =A0 =A0 =A0at
> org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
>
> =A0 =A0 =A0 =A0 =A0 =A0at org.apache.hadoop.dfs.NameNode.getAddress(NameN=
ode.java:116)
>
> =A0 =A0 =A0 =A0 =A0 =A0at org.apache.hadoop.dfs.NameNode.initialize(NameN=
ode.java:136)
>
> =A0 =A0 =A0 =A0 =A0 =A0at org.apache.hadoop.dfs.NameNode.<init>(NameNode.=
java:193)
>
> =A0 =A0 =A0 =A0 =A0 =A0at org.apache.hadoop.dfs.NameNode.<init>(NameNode.=
java:179)
>
> =A0 =A0 =A0 =A0 =A0 =A0at
> org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:830)
>
> =A0 =A0 =A0 =A0 =A0 =A0at org.apache.hadoop.dfs.NameNode.main(NameNode.ja=
va:839)
>
>
>
> 2009-08-05 23:42:00,807 INFO =A0dfs.NameNode (StringUtils.java:run(479)) =
-
> SHUTDOWN_MSG:
>
> /************************************************************
>
> SHUTDOWN_MSG: Shutting down NameNode at datanode1/10.0.1.109
>
> ************************************************************/

From common-user-return-16590-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 18:41:51 2009
Return-Path: <common-user-return-16590-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 48326 invoked from network); 6 Aug 2009 18:41:51 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 18:41:51 -0000
Received: (qmail 21320 invoked by uid 500); 6 Aug 2009 18:41:56 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21234 invoked by uid 500); 6 Aug 2009 18:41:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21224 invoked by uid 99); 6 Aug 2009 18:41:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 18:41:56 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zeevmisc@gmail.com designates 209.85.222.189 as permitted sender)
Received: from [209.85.222.189] (HELO mail-pz0-f189.google.com) (209.85.222.189)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 18:41:46 +0000
Received: by pzk27 with SMTP id 27so1292300pzk.2
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 11:41:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=RyYigZ9sJiDHPbt0KWZAk+s4/1LdRifU0B9570TN7C0=;
        b=S/d916BXkdh4Dh0fj5RHsHHajZASt3r1789Z2i3bh8LQeOQrSRmr2Gz7s6k1LChEVv
         qwDxVuOeSB5LV2fEQckUydfCdSVcyt6ALCxx6PXuVKPwYghETfC+lzvruv5XG+2OiFzx
         kZDVPkHMDW7oqCz2ZSvzcMlXX3AkWclRNW0GY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=s41jW/ItT105j7AcUT/39MquqRADd8fdUXkyR1qRjF/b4hs/Uv9N9yYvfBK2CZFay/
         M5Mu54tlQbSkysdgs0Qgz/S9HEvF5ifHJoJuoSFRGgdrHLRxJM3mtWb2hevswNg+o/b7
         MbDgISixueirHnb6mSzsPk1khl7fOM7KCeqwg=
MIME-Version: 1.0
Received: by 10.142.97.5 with SMTP id u5mr50652wfb.44.1249584085545; Thu, 06 
	Aug 2009 11:41:25 -0700 (PDT)
In-Reply-To: <d6d7c4410908061059m6a742d6sf461f3167f58f3f9@mail.gmail.com>
References: <abdb77f90908051559t342c6c72rd52eb77995b52da7@mail.gmail.com>
	 <92c4d8c10908051615x1bcff245s3c8830c04a3aebf9@mail.gmail.com>
	 <abdb77f90908051625v546bd0fcw753896689e3eb611@mail.gmail.com>
	 <abdb77f90908051706t482b492cq4a4f2688bccf0379@mail.gmail.com>
	 <d6d7c4410908061059m6a742d6sf461f3167f58f3f9@mail.gmail.com>
Date: Thu, 6 Aug 2009 11:41:25 -0700
Message-ID: <abdb77f90908061141u52e7908s3d17a0d2456b6629@mail.gmail.com>
Subject: Re: Maps running - how to increase?
From: Zeev Milin <zeevmisc@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636e9107e89352704707d7746
X-Virus-Checked: Checked by ClamAV on apache.org

--001636e9107e89352704707d7746
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks Aaron,

I changed the settings in hadoop-site.xml file on all the machines. BTW,
some settings are only reflected on the job level when I change the
hadoop-default file, not sure why hadoop-site is being ignored (ex:
mapred.tasktracker.map.tasks.maximum).

The files I am trying load are fairly small (~4MB on average). The
configuration of each machine is: 2 dual cores (Xeon, 2.33Ghz), 8GB ram and
a local SCSI hard drive. (total of 6 nodes)

I will look into the article you mentioned, I understand that to load the
files is going to be slow, was just wondering why the machines are not being
utilized and mostly idle when more maps can be run in parallel. Maps running
is always 6.

Another option is to load one 20GB file but currently the speed is fairly
slow in my opinion: 1GB in 1.5min. What kind of tuning can be done to
speedup the load into hdfs? If you have any recommendation for specific
parameters that might help it will be great.

Thanks,
Zeev

--001636e9107e89352704707d7746--

From common-user-return-16591-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 20:46:46 2009
Return-Path: <common-user-return-16591-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 84011 invoked from network); 6 Aug 2009 20:46:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 20:46:46 -0000
Received: (qmail 95676 invoked by uid 500); 6 Aug 2009 20:46:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95590 invoked by uid 500); 6 Aug 2009 20:46:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95578 invoked by uid 99); 6 Aug 2009 20:46:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 20:46:50 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.92.27] (HELO qw-out-2122.google.com) (74.125.92.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 20:46:41 +0000
Received: by qw-out-2122.google.com with SMTP id 8so444220qwh.35
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 13:46:19 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.54.4 with SMTP id o4mr484087qag.78.1249591579290; Thu, 06 
	Aug 2009 13:46:19 -0700 (PDT)
In-Reply-To: <abdb77f90908061141u52e7908s3d17a0d2456b6629@mail.gmail.com>
References: <abdb77f90908051559t342c6c72rd52eb77995b52da7@mail.gmail.com> 
	<92c4d8c10908051615x1bcff245s3c8830c04a3aebf9@mail.gmail.com> 
	<abdb77f90908051625v546bd0fcw753896689e3eb611@mail.gmail.com> 
	<abdb77f90908051706t482b492cq4a4f2688bccf0379@mail.gmail.com> 
	<d6d7c4410908061059m6a742d6sf461f3167f58f3f9@mail.gmail.com> 
	<abdb77f90908061141u52e7908s3d17a0d2456b6629@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Thu, 6 Aug 2009 13:45:59 -0700
Message-ID: <d6d7c4410908061345o3f326b79xf5089608b1f9a6e2@mail.gmail.com>
Subject: Re: Maps running - how to increase?
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I don't know that your load-in speed is going to dramatically
increase. There's a number of parameters that adjust aspects of
MapReduce, but HDFS more or less works out of the box. You should run
some monitoring on your nodes (ganglia, nagios) or check out what
they're doing with top, iotop and iftop to see where you're
experiencing bottlenecks.
- Aaron

On Thu, Aug 6, 2009 at 11:41 AM, Zeev Milin<zeevmisc@gmail.com> wrote:
> Thanks Aaron,
>
> I changed the settings in hadoop-site.xml file on all the machines. BTW,
> some settings are only reflected on the job level when I change the
> hadoop-default file, not sure why hadoop-site is being ignored (ex:
> mapred.tasktracker.map.tasks.maximum).
>
> The files I am trying load are fairly small (~4MB on average). The
> configuration of each machine is: 2 dual cores (Xeon, 2.33Ghz), 8GB ram and
> a local SCSI hard drive. (total of 6 nodes)
>
> I will look into the article you mentioned, I understand that to load the
> files is going to be slow, was just wondering why the machines are not being
> utilized and mostly idle when more maps can be run in parallel. Maps running
> is always 6.
>
> Another option is to load one 20GB file but currently the speed is fairly
> slow in my opinion: 1GB in 1.5min. What kind of tuning can be done to
> speedup the load into hdfs? If you have any recommendation for specific
> parameters that might help it will be great.
>
> Thanks,
> Zeev
>

From common-user-return-16592-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 06 21:34:45 2009
Return-Path: <common-user-return-16592-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 99227 invoked from network); 6 Aug 2009 21:34:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 6 Aug 2009 21:34:45 -0000
Received: (qmail 52210 invoked by uid 500); 6 Aug 2009 21:34:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52152 invoked by uid 500); 6 Aug 2009 21:34:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52142 invoked by uid 99); 6 Aug 2009 21:34:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 21:34:49 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.218.215 as permitted sender)
Received: from [209.85.218.215] (HELO mail-bw0-f215.google.com) (209.85.218.215)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 06 Aug 2009 21:34:38 +0000
Received: by bwz11 with SMTP id 11so1085503bwz.15
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 14:34:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=ozQO0yjwoNn3401IU9uJmIIIXT2juZt2gOGXQyTQ2+o=;
        b=nc3+n8OM0uzCkfdNZNw67esLRI+RUIinURlo1WXWjzkzaHkSb7vj4Q2BdYA1HWvLJ1
         1l3VB6U9WzCp2T7mU/VNt9raMztijDJ/4JTd/1C1TXcr/S2u23RLxTAHKzK0OspTpG68
         6dKNEkCxONNDdk+7ifLmPt7ZlYbK4jojFEjnc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=eUVUmevrW3Pc7nkMmUhiVI6Nin9RN1j93snjfwsxYlRXVfd4gLSfz0rbdDUYq9iQF3
         GuLwa+g+2WU64agX/wqk3oNLu331MejTR9IqelSuZyL33oQuHljN2af8NbO51GiwV36J
         AJpZ44ehxS0Go2pB0do7Y+G2ysbTj4OgWBrF8=
MIME-Version: 1.0
Received: by 10.239.150.144 with SMTP id n16mr37892hbb.132.1249594458081; Thu, 
	06 Aug 2009 14:34:18 -0700 (PDT)
Date: Thu, 6 Aug 2009 17:34:18 -0400
Message-ID: <ad681e7f0908061434t6a8b567gb7b3d6bafdddb41c@mail.gmail.com>
Subject: Help with Hbase and Hadoop on S3
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f5b196c988b704707fe139
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f5b196c988b704707fe139
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I can't seem to get Hbase to run using the hadoop i have connected to my s3
bucket

Running
Hbase 0.19.2
Hadoop  0.19.2

Hadoop-site.xml
 < configuration>

<property>
  <name>fs.default.name</name>
  <value>s3://hbase</value>
</property>

<property>
  <name>fs.s3.awsAccessKeyId</name>
  <value>ID</value>
</property>

<property>
  <name>fs.s3.awsSecretAccessKey</name>
  <value>SECRET</value>
</property>
</configuration>

and it seems to start up no problem

my hbase-site.xml

<configuration>
    <property>
 <name>hbase.master</name>
     <value>174.129.15.236:60000</value>
     <description>The host and port that the HBase master runs at.
     A value of 'local' runs the master and a regionserver in
     a single process.
     </description>
   </property>

 <property>
    <name>hbase.rootdir</name>
    <value>s3://hbase</value>
    <description>The directory shared by region servers.
    </description>
  </property>

</configuration>


keeps giving me

]
2009-08-06 17:20:44,526 ERROR org.apache.hadoop.hbase.master.HMaster: Can
not start master
java.lang.NoClassDefFoundError: org/jets3t/service/S3ServiceException
        at
org.apache.hadoop.fs.s3.S3FileSystem.createDefaultStore(S3FileSystem.java:84)
        at
org.apache.hadoop.fs.s3.S3FileSystem.initialize(S3FileSystem.java:74)
        at
org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1367)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:56)
        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1379)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:215)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:120)
        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:186)
        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:156)
        at
org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:96)
        at
org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:78)
        at org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1013)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1057)
Caused by: java.lang.ClassNotFoundException:
org.jets3t.service.S3ServiceException
        at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:252)
        at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:320)


what am i doing wrong here?

Ananth T Sarathy

--001485f5b196c988b704707fe139--

From common-user-return-16593-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 00:51:14 2009
Return-Path: <common-user-return-16593-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63480 invoked from network); 7 Aug 2009 00:51:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 00:51:14 -0000
Received: (qmail 37209 invoked by uid 500); 7 Aug 2009 00:51:19 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 37117 invoked by uid 500); 7 Aug 2009 00:51:19 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 37107 invoked by uid 99); 7 Aug 2009 00:51:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 00:51:19 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of fulingting@gmail.com designates 209.85.146.183 as permitted sender)
Received: from [209.85.146.183] (HELO wa-out-1112.google.com) (209.85.146.183)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 00:51:09 +0000
Received: by wa-out-1112.google.com with SMTP id j32so281003waf.29
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 17:50:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=QBNxCvbuJk10PVUvor0IjYwauaHrYI52OJCFawtA8Kk=;
        b=S1OSnXUAZqiK6bMS/kouithWVRs+pbUW1syKRyqwfCFreoXL7KejL/Ws0J1l+yD/jG
         6gsfirHhKU+zyh/l32NRvdQ+Gj1SGM8eTWc0afTA1YcefOPgqSGat1StxY0HEUf+24IX
         VZvrOwnRDTNCdWDOA8adgE70BWqY0IyB2RVYE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=HjWYn0bHn77G8W2hrJyzTYrtYxoGB5GZTLcUVcunT9Kc1R/OE7MtXhnczU/apzur5p
         41rOk3rbuDxP2a7SxXL6EKL9NxlUa2I45Mk9rVUl14VAzPDV8XjTyMiqI524GZIFa2Z1
         TNCj80VyCKzHk9S8m/XoPI1iHWlWPezUY9gNY=
MIME-Version: 1.0
Received: by 10.114.56.20 with SMTP id e20mr709562waa.183.1249606249010; Thu, 
	06 Aug 2009 17:50:49 -0700 (PDT)
In-Reply-To: <d6d7c4410908061109o21ef1d0ak372037cc24106fab@mail.gmail.com>
References: <45d9159d0908052151j24ade0fct38c7acdd8b74d2ce@mail.gmail.com>
	 <d6d7c4410908061109o21ef1d0ak372037cc24106fab@mail.gmail.com>
Date: Fri, 7 Aug 2009 08:50:48 +0800
Message-ID: <7c534fe40908061750s6ac4b75fvc407051a7a5f5fc9@mail.gmail.com>
Subject: Re: Help in running hadoop from eclipse
From: =?GB2312?B?t/vQodfq?= <fulingting@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636458bd694d570047082a022
X-Virus-Checked: Checked by ClamAV on apache.org

--001636458bd694d570047082a022
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

thanx

2009/8/7 Aaron Kimball <aaron@cloudera.com>

> May I ask why you're trying to run the NameNode in Eclipse? This is
> likely going to cause you lots of classpath headaches. I think your
> current problem is that it can't find its config files, so it's not
> able to read in the strings for what addresses it should listen on.
>
> If you want to see what's happening inside the namenode, I'd run
> "bin/hadoop-daemon.sh start namenode" to start it, then fire up
> Eclipse and attach the debugger externally. You can then point it at
> your copy of the Hadoop source code so you can set breakpoints, trace,
> etc.
>
> - A
>
> On Wed, Aug 5, 2009 at 9:51 PM, ashish pareek <pareekash@gmail.com> wrote:
> >
> > Hi Everybody,
> >
> >                  I am trying to run hadoop from eclipse... but when i run
> > NmaeNode.java as java appliaction i get following error..... Please help
> in
> > getting rid of this problem.
> >
> >
> >
> > 2009-08-05 23:42:00,760 INFO  dfs.NameNode
> > (StringUtils.java:startupShutdownMessage(464)) - STARTUP_MSG:
> >
> > /************************************************************
> >
> > STARTUP_MSG: Starting NameNode
> >
> > STARTUP_MSG:   host = datanode1/10.0.1.109
> >
> > STARTUP_MSG:   args = []
> >
> > STARTUP_MSG:   version = Unknown
> >
> > STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Unknown' on
> Unknown
> >
> > ************************************************************/
> >
> > 2009-08-05 23:42:00,806 ERROR dfs.NameNode (NameNode.java:main(843)) -
> > java.lang.NullPointerException
> >
> >            at
> > org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
> >
> >            at
> org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
> >
> >            at
> org.apache.hadoop.dfs.NameNode.initialize(NameNode.java:136)
> >
> >            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:193)
> >
> >            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:179)
> >
> >            at
> > org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:830)
> >
> >            at org.apache.hadoop.dfs.NameNode.main(NameNode.java:839)
> >
> >
> >
> > 2009-08-05 23:42:00,807 INFO  dfs.NameNode (StringUtils.java:run(479)) -
> > SHUTDOWN_MSG:
> >
> > /************************************************************
> >
> > SHUTDOWN_MSG: Shutting down NameNode at datanode1/10.0.1.109
> >
> > ************************************************************/
>

--001636458bd694d570047082a022--

From common-user-return-16594-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 04:05:19 2009
Return-Path: <common-user-return-16594-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 16183 invoked from network); 7 Aug 2009 04:05:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 04:05:18 -0000
Received: (qmail 82536 invoked by uid 500); 7 Aug 2009 04:05:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82443 invoked by uid 500); 7 Aug 2009 04:05:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82433 invoked by uid 99); 7 Aug 2009 04:05:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 04:05:23 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pareekash@gmail.com designates 209.85.146.176 as permitted sender)
Received: from [209.85.146.176] (HELO wa-out-1112.google.com) (209.85.146.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 04:05:13 +0000
Received: by wa-out-1112.google.com with SMTP id j32so299718waf.29
        for <common-user@hadoop.apache.org>; Thu, 06 Aug 2009 21:04:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=E1NIr71uksnE8K552HVQZ2z1ryoRUwuz0ZVFcTmGd7U=;
        b=MiAwrY4EfGerHxmlWl1l/bM6+PRWm4PAsBTbkAwwEfZka64ncsL5sjbKL96g7XNZ17
         9kResVer/wtPsn0VAkBJocXkulgsmg2buwuh/13KuVGJ0T+gUYU6QHpuXo/gVqtCLTSn
         OcAGaVy6a6ZDaG0ofTEs8B3wAMDSTn2CFFjjE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=M+QG8PYuV/n+Nhq6vrnB01B12XYgjspufd7hRNcqWhYonwzoJ3uhH5l1tNJg5MWxc8
         chXlq6Mesi7iRqyiNdKnyPSKrL3jOK39WYpRjFlq09ZqR3x5p3LBYn3ABQIvyu8KCRhQ
         1fMz8D8doRVe4HPzezyHtB8tgDiejDXtleN2Y=
MIME-Version: 1.0
Received: by 10.114.46.19 with SMTP id t19mr335059wat.179.1249617893375; Thu, 
	06 Aug 2009 21:04:53 -0700 (PDT)
In-Reply-To: <d6d7c4410908061052t522b0da7r5fe9534fdeed93a2@mail.gmail.com>
References: <45d9159d0908052151j24ade0fct38c7acdd8b74d2ce@mail.gmail.com>
	 <d6d7c4410908061052t522b0da7r5fe9534fdeed93a2@mail.gmail.com>
Date: Fri, 7 Aug 2009 09:34:53 +0530
Message-ID: <45d9159d0908062104h14a7c281ud830fe1acdd8f493@mail.gmail.com>
Subject: Re: Help in running hadoop from eclipse
From: ashish pareek <pareekash@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636458464a3c367047085560f
X-Virus-Checked: Checked by ClamAV on apache.org

--001636458464a3c367047085560f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks to you Aaron, but whats the procedure for external debugging ? what
project name should be specified ? and what more information i need to fill
in remote debugging options

Regards,
Ashish.

On Thu, Aug 6, 2009 at 11:22 PM, Aaron Kimball <aaron@cloudera.com> wrote:

> May I ask why you're trying to run the NameNode in Eclipse? This is likely
> going to cause you lots of classpath headaches. I think your current
> problem
> is that it can't find its config files, so it's not able to read in the
> strings for what addresses it should listen on.
>
> If you want to see what's happening inside the namenode, I'd run
> "bin/hadoop-daemon.sh start namenode" to start it, then fire up Eclipse and
> attach the debugger externally. You can then point it at your copy of the
> Hadoop source code so you can set breakpoints, trace, etc.
>
> - A
>
> On Wed, Aug 5, 2009 at 9:51 PM, ashish pareek <pareekash@gmail.com> wrote:
>
> > Hi Everybody,
> >
> >                  I am trying to run hadoop from eclipse... but when i run
> > NmaeNode.java as java appliaction i get following error..... Please help
> in
> > getting rid of this problem.
> >
> >
> >
> > 2009-08-05 23:42:00,760 INFO  dfs.NameNode
> > (StringUtils.java:startupShutdownMessage(464)) - STARTUP_MSG:
> >
> > /************************************************************
> >
> > STARTUP_MSG: Starting NameNode
> >
> > STARTUP_MSG:   host = datanode1/10.0.1.109
> >
> > STARTUP_MSG:   args = []
> >
> > STARTUP_MSG:   version = Unknown
> >
> > STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Unknown' on
> Unknown
> >
> > ************************************************************/
> >
> > 2009-08-05 23:42:00,806 ERROR dfs.NameNode (NameNode.java:main(843)) -
> > java.lang.NullPointerException
> >
> >            at
> > org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
> >
> >            at
> org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
> >
> >            at
> org.apache.hadoop.dfs.NameNode.initialize(NameNode.java:136)
> >
> >            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:193)
> >
> >            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:179)
> >
> >            at
> > org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:830)
> >
> >            at org.apache.hadoop.dfs.NameNode.main(NameNode.java:839)
> >
> >
> >
> > 2009-08-05 23:42:00,807 INFO  dfs.NameNode (StringUtils.java:run(479)) -
> > SHUTDOWN_MSG:
> >
> > /************************************************************
> >
> > SHUTDOWN_MSG: Shutting down NameNode at datanode1/10.0.1.109
> >
> > ************************************************************/
> >
>

--001636458464a3c367047085560f--

From common-user-return-16595-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 08:59:49 2009
Return-Path: <common-user-return-16595-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 88272 invoked from network); 7 Aug 2009 08:59:49 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 08:59:49 -0000
Received: (qmail 11420 invoked by uid 500); 7 Aug 2009 08:59:54 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 11345 invoked by uid 500); 7 Aug 2009 08:59:54 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 11335 invoked by uid 99); 7 Aug 2009 08:59:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 08:59:54 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [192.6.10.2] (HELO colossus.hpl.hp.com) (192.6.10.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 08:59:42 +0000
Received: from localhost (localhost [127.0.0.1])
	by colossus.hpl.hp.com (Postfix) with ESMTP id 97EAD1BA3C0
	for <common-user@hadoop.apache.org>; Fri,  7 Aug 2009 09:59:21 +0100 (BST)
X-Virus-Scanned: Debian amavisd-new at hpl.hp.com
Received: from colossus.hpl.hp.com ([127.0.0.1])
	by localhost (colossus.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id 2HmqkwGkhJDx for <common-user@hadoop.apache.org>;
	Fri,  7 Aug 2009 09:59:21 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by colossus.hpl.hp.com (Postfix) with ESMTPS id 057FA1BA2FC
	for <common-user@hadoop.apache.org>; Fri,  7 Aug 2009 09:59:20 +0100 (BST)
MailScanner-NULL-Check: 1250240347.3182@DSqCZZ2EOuRRZigS3OR98Q
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n778x5j0020276
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Fri, 7 Aug 2009 09:59:06 +0100 (BST)
Message-ID: <4A7BECD9.20303@apache.org>
Date: Fri, 07 Aug 2009 09:59:05 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: HADOOP-4539 question
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com>
In-Reply-To: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n778x5j0020276
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

Stas Oskin wrote:
> Hi.
> 
> I checked this ticket and I like what I found.
> 
> Had question about it, and hoped someone can answer it:
> 
> If I have a NN, and BN, and the NN fails, how the DFS clients will know how
> to connect to the new IP?
> 
> It will be a config level setting?
> 
> Or it needs to be achieved via external Linux HA scripts?
> 
> Thanks!
> 

right now the new NN has to come up with the same hostname and IP 
address as the original

From common-user-return-16596-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 14:51:16 2009
Return-Path: <common-user-return-16596-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 27042 invoked from network); 7 Aug 2009 14:51:16 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 14:51:16 -0000
Received: (qmail 96517 invoked by uid 500); 7 Aug 2009 14:51:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 96445 invoked by uid 500); 7 Aug 2009 14:51:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 96435 invoked by uid 99); 7 Aug 2009 14:51:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 14:51:21 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ananth.t.sarathy@gmail.com designates 72.14.220.158 as permitted sender)
Received: from [72.14.220.158] (HELO fg-out-1718.google.com) (72.14.220.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 14:51:10 +0000
Received: by fg-out-1718.google.com with SMTP id 22so126874fge.12
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 07:50:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=fWhfPgq0pSgTs2r3671Us4UFnR46kCTofNvSaC/Tal8=;
        b=hgNDCm1K0cfIp5nU/ZbNXjTo4vAX1itZam7AZp8y+xnjCjb2kCW2h4ih0JqY7UpUGk
         P9xIemMyYzdgtPf4RTyU+yd4d3+A3JZGZYlXxO0MLNxwXQIIDs8fw9gXr5HfTk6EyUEi
         A8FnZzqNyS2kH/dHTZ9aVzdytE5XofRKQgLKc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=q+3pLBchxgl3y3tPc7wSrxoeCWmR3vMt+JDVHNFby2LtYyypwecmwjoiFzRAR+nH1z
         DA3hGjeE7Qp1SS6xtxHMXuehOaRp2ZGFtUa/UpEtOIvUh4Ch6Uxpdmh1N3yUL1jFESbi
         Bt+HADxjp0AWVf7HXcLgYl1bHeA+230y5tk7w=
MIME-Version: 1.0
Received: by 10.239.132.209 with SMTP id 17mr116516hbs.136.1249656649767; Fri, 
	07 Aug 2009 07:50:49 -0700 (PDT)
Date: Fri, 7 Aug 2009 10:50:49 -0400
Message-ID: <ad681e7f0908070750kc460ee3y23edc2e16d132057@mail.gmail.com>
Subject: Help with Hadoop/Hbase on s3
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f1da1ab35a4704708e5c55
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f1da1ab35a4704708e5c55
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I can't seem to get Hbase to run using the hadoop i have connected to my s3
bucket

Running
Hbase 0.19.2
Hadoop  0.19.2

Hadoop-site.xml
 < configuration>

<property>
  <name>fs.default.name</name>
  <value>s3://hbase</value>
</property>

<property>
  <name>fs.s3.awsAccessKeyId</name>
  <value>ID</value>
</property>

<property>
  <name>fs.s3.awsSecretAccessKey</name>
  <value>SECRET</value>
</property>
</configuration>

and it seems to start up no problem

my hbase-site.xml

<configuration>
    <property>
 <name>hbase.master</name>
     <value>174.129.15.236:60000</value>
     <description>The host and port that the HBase master runs at.
     A value of 'local' runs the master and a regionserver in
     a single process.
     </description>
   </property>

 <property>
    <name>hbase.rootdir</name>
    <value>s3://hbase</value>
    <description>The directory shared by region servers.
    </description>
  </property>

</configuration>


keeps giving me

]
2009-08-06 17:20:44,526 ERROR org.apache.hadoop.hbase.master.HMaster: Can
not start master
java.lang.NoClassDefFoundError: org/jets3t/service/S3ServiceException
        at
org.apache.hadoop.fs.s3.S3FileSystem.createDefaultStore(S3FileSystem.java:84)
        at
org.apache.hadoop.fs.s3.S3FileSystem.initialize(S3FileSystem.java:74)
        at
org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1367)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:56)
        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1379)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:215)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:120)
        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:186)
        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:156)
        at
org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:96)
        at
org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:78)
        at org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1013)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1057)
Caused by: java.lang.ClassNotFoundException:
org.jets3t.service.S3ServiceException
        at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:252)
        at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:320)


what am i doing wrong here?

Ananth T Sarathy

--001485f1da1ab35a4704708e5c55--

From common-user-return-16597-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 15:03:04 2009
Return-Path: <common-user-return-16597-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 30820 invoked from network); 7 Aug 2009 15:03:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 15:03:04 -0000
Received: (qmail 18544 invoked by uid 500); 7 Aug 2009 15:03:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 18471 invoked by uid 500); 7 Aug 2009 15:03:09 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 18461 invoked by uid 99); 7 Aug 2009 15:03:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 15:03:09 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of timrobertson100@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 15:02:58 +0000
Received: by ewy26 with SMTP id 26so1703901ewy.29
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 08:02:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=VlgIpmJT6hEQ9ST72Hj/4M3XPPgWBeSeU6MyIzXrtGk=;
        b=l9oqsTbG2YuVKa4XLc3swjbuIm4PDFJcp99sIQVu1roMgPuR3wMVw48MjUq6mp2qA9
         1l6iFyoZQOMQTZAVfiSZytusiNkkXRY1VhP/miutBWDEiuui0HlodPJ7Z7RvbXIa5rBD
         VM0JbfzpSwiXCidt/rzf7LLJ/AvXzXHQIp174=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=NnwUkx5CoLGPGP4PE+8r/VH76sXKIjRvX8cDlcuSsVG9vmuf9tWWIdVJnGOhNpIa5q
         7vab61KY/Ft3FJ3R9wxHFAMJZeTNkK43lS2oMmzs7H8vkx8IRPfIYPkmxeBc3+x4uOKL
         WqgT6WMVoLWK84fMvQdlAXXyqkbCCTksQ5+CI=
MIME-Version: 1.0
Received: by 10.216.21.206 with SMTP id r56mr263810wer.110.1249657356719; Fri, 
	07 Aug 2009 08:02:36 -0700 (PDT)
In-Reply-To: <ad681e7f0908070750kc460ee3y23edc2e16d132057@mail.gmail.com>
References: <ad681e7f0908070750kc460ee3y23edc2e16d132057@mail.gmail.com>
Date: Fri, 7 Aug 2009 17:02:36 +0200
Message-ID: <32120a6a0908070802pf251a4fl3b776f4b24ff6b31@mail.gmail.com>
Subject: Re: Help with Hadoop/Hbase on s3
From: tim robertson <timrobertson100@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Do you need to add the Amazon S3 toolkit on the HBase classpath
directly to use S3 as a store?
http://developer.amazonwebservices.com/connect/entry.jspa?externalID=3D617&=
categoryID=3D47

I'm guessing based on the "java.lang.NoClassDefFoundError:
org/jets3t/service/S3ServiceException"

Cheers

Tim


On Fri, Aug 7, 2009 at 4:50 PM, Ananth T.
Sarathy<ananth.t.sarathy@gmail.com> wrote:
> I can't seem to get Hbase to run using the hadoop i have connected to my =
s3
> bucket
>
> Running
> Hbase 0.19.2
> Hadoop =A00.19.2
>
> Hadoop-site.xml
> =A0< configuration>
>
> <property>
> =A0<name>fs.default.name</name>
> =A0<value>s3://hbase</value>
> </property>
>
> <property>
> =A0<name>fs.s3.awsAccessKeyId</name>
> =A0<value>ID</value>
> </property>
>
> <property>
> =A0<name>fs.s3.awsSecretAccessKey</name>
> =A0<value>SECRET</value>
> </property>
> </configuration>
>
> and it seems to start up no problem
>
> my hbase-site.xml
>
> <configuration>
> =A0 =A0<property>
> =A0<name>hbase.master</name>
> =A0 =A0 <value>174.129.15.236:60000</value>
> =A0 =A0 <description>The host and port that the HBase master runs at.
> =A0 =A0 A value of 'local' runs the master and a regionserver in
> =A0 =A0 a single process.
> =A0 =A0 </description>
> =A0 </property>
>
> =A0<property>
> =A0 =A0<name>hbase.rootdir</name>
> =A0 =A0<value>s3://hbase</value>
> =A0 =A0<description>The directory shared by region servers.
> =A0 =A0</description>
> =A0</property>
>
> </configuration>
>
>
> keeps giving me
>
> ]
> 2009-08-06 17:20:44,526 ERROR org.apache.hadoop.hbase.master.HMaster: Can
> not start master
> java.lang.NoClassDefFoundError: org/jets3t/service/S3ServiceException
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.fs.s3.S3FileSystem.createDefaultStore(S3FileSystem.java=
:84)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.fs.s3.S3FileSystem.initialize(S3FileSystem.java:74)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1367)
> =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.j=
ava:56)
> =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.ja=
va:1379)
> =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:215=
)
> =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:120=
)
> =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.j=
ava:186)
> =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.j=
ava:156)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:9=
6)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:7=
8)
> =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.j=
ava:1013)
> =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.main(HMaster.jav=
a:1057)
> Caused by: java.lang.ClassNotFoundException:
> org.jets3t.service.S3ServiceException
> =A0 =A0 =A0 =A0at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
> =A0 =A0 =A0 =A0at java.security.AccessController.doPrivileged(Native Meth=
od)
> =A0 =A0 =A0 =A0at java.net.URLClassLoader.findClass(URLClassLoader.java:1=
88)
> =A0 =A0 =A0 =A0at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
> =A0 =A0 =A0 =A0at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.jav=
a:301)
> =A0 =A0 =A0 =A0at java.lang.ClassLoader.loadClass(ClassLoader.java:252)
> =A0 =A0 =A0 =A0at java.lang.ClassLoader.loadClassInternal(ClassLoader.jav=
a:320)
>
>
> what am i doing wrong here?
>
> Ananth T Sarathy
>

From common-user-return-16598-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 15:07:09 2009
Return-Path: <common-user-return-16598-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 33849 invoked from network); 7 Aug 2009 15:07:08 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 15:07:08 -0000
Received: (qmail 33763 invoked by uid 500); 7 Aug 2009 15:07:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 33697 invoked by uid 500); 7 Aug 2009 15:07:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 33687 invoked by uid 99); 7 Aug 2009 15:07:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 15:07:13 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nvijayap@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 15:07:03 +0000
Received: by vws40 with SMTP id 40so1658565vws.2
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 08:06:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=vViS76++Vv1ZHvKqo8gw2PvG+OhUpnbj4ml2FCVN/Xc=;
        b=HdT0aiZHZTshp3bJSdiZ+F7UNg6ggFlBQ2NHHBseu+zuOF7Ubsux/yDntVe3cdORct
         q9Re703xh3dn/1rTjRaHroDYZ0RveQFe9LmWcBA8Qpd0EpRtE2gdNWQQfiMt5E3LSy4C
         EKYPubBcIkHBmsSBI+usKFur0TY37fhE1unkY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=jVkMWhkzT1i8UiZvLEkBmZDPEns5mqFJKVTAulnLCU7TRIqN8FWzoIvhsBLqwVfdS9
         0/LW6U55avijqYMNirsqnC/EbA+HGZSpLE+72Ul6h5FnN4WvJPohphb4b+Q54lJSpdHX
         GB9kPnnuyCj2DtPrt6zym5Z6e3/KyPIsxFjDo=
MIME-Version: 1.0
Received: by 10.220.83.210 with SMTP id g18mr900797vcl.65.1249657602942; Fri, 
	07 Aug 2009 08:06:42 -0700 (PDT)
Date: Fri, 7 Aug 2009 08:06:42 -0700
Message-ID: <773580c10908070806w2a1a3f84x8248af8324c66309@mail.gmail.com>
Subject: ~ Replacement for MapReduceBase ~
From: Naga Vijayapuram <nvijayap@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

I am using hadoop-0.20.0

What's the replacement for the deprecated MapReduceBase?

Thanks,
Naga Vijayapuram

From common-user-return-16599-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 15:27:16 2009
Return-Path: <common-user-return-16599-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 39491 invoked from network); 7 Aug 2009 15:27:15 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 15:27:15 -0000
Received: (qmail 73521 invoked by uid 500); 7 Aug 2009 15:27:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 73435 invoked by uid 500); 7 Aug 2009 15:27:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 73425 invoked by uid 99); 7 Aug 2009 15:27:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 15:27:20 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nvijayap@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 15:27:10 +0000
Received: by vws40 with SMTP id 40so1671767vws.2
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 08:26:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=xqiACe621i3BPLsi7WtqrHUnMmSeTc1dk81amM+Gt3g=;
        b=NzHFZy1NygIzi3buWva0L4R963W1/qhd5jXOmu6CzvhIpThGWDKS+7EqpPephpZ2GZ
         t313ZDyldXCsJqtgYAZmZATj1vXAlZS6EDQnIKDl2tt67jykynkuGb+9gAYIvDXLO1UM
         tN+DgdUyVj7O32ns5h/KYqaMbhJ7uwVJ0aDXU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=ctF2eMSy/K2n3eo27kFzqtMbmRBf0FfquLU1fwoPy8nXRgQp5CDM8uUGIxjwkHcH+e
         9bqndGXfhsFqprX4MYobN87YCtj55ef29fmS2h5/I56xW6rm7i0Tf6K+oS2L2P5YJFbZ
         4WVB8uSGfoUmH4CDsDUvZrmhYhKXb0Jhuf9bw=
MIME-Version: 1.0
Received: by 10.220.85.195 with SMTP id p3mr956565vcl.42.1249658809952; Fri, 
	07 Aug 2009 08:26:49 -0700 (PDT)
In-Reply-To: <773580c10908070806w2a1a3f84x8248af8324c66309@mail.gmail.com>
References: <773580c10908070806w2a1a3f84x8248af8324c66309@mail.gmail.com>
Date: Fri, 7 Aug 2009 08:26:49 -0700
Message-ID: <773580c10908070826y6a01b281vcecdea43aa8492ec@mail.gmail.com>
Subject: Re: ~ Replacement for MapReduceBase ~
From: Naga Vijayapuram <nvijayap@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Appears we just need to extend the Mapper class and not use
MapReduceBase anymore (in hadoop-0.20.0)

If that is not the case, I would like to know the recommended approach
in hadoop-0.20.0

Thanks,
Naga Vijayapuram


On Fri, Aug 7, 2009 at 8:06 AM, Naga Vijayapuram<nvijayap@gmail.com> wrote:
> Hello,
>
> I am using hadoop-0.20.0
>
> What's the replacement for the deprecated MapReduceBase?
>
> Thanks,
> Naga Vijayapuram
>

From common-user-return-16600-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 16:10:30 2009
Return-Path: <common-user-return-16600-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 54756 invoked from network); 7 Aug 2009 16:10:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 16:10:30 -0000
Received: (qmail 52417 invoked by uid 500); 7 Aug 2009 16:10:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52352 invoked by uid 500); 7 Aug 2009 16:10:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52342 invoked by uid 99); 7 Aug 2009 16:10:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 16:10:35 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of clarkemjj@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 16:10:27 +0000
Received: by bwz19 with SMTP id 19so1563921bwz.13
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 09:10:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=DD+tSNobeCDWDpUM+7ipDrK3tFaM0K5o02iNLLighiE=;
        b=aMr8lr/fDaBKPXxIsOl3EnNGw0G17WmckQVig417j9yny97wnuCcC0PFgW3aFNUaBE
         hcLG0bKRC+5PNEGEovotwnQGm3JCtGxls/YeD2TH2Go5pYWVe/MkIhlaqWHdHfKXq8xu
         vc54r9lxxQLZVWcmitMt/E6sWdCPimzRkMKsQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=C/4E7oZJ49IcGFBQFGtvQLSpP/od9FJ7SjNc3C0pEEV64d1vi0fbSCpvvPktRAEDTk
         udKqxLIXVU7iUbXeJ7Um/LSOOoyUF6hIwEXpQTQ/KOkKNJyy1O22wTPzmJor04yf9Ekx
         2OZFX74u3h101YYM7TPPKHhesUixNIqpvDm70=
MIME-Version: 1.0
Received: by 10.204.114.18 with SMTP id c18mr2581194bkq.211.1249661406114; 
	Fri, 07 Aug 2009 09:10:06 -0700 (PDT)
Date: Fri, 7 Aug 2009 17:10:06 +0100
Message-ID: <4238036a0908070910n16e5a24auc72a187aeea4ef66@mail.gmail.com>
Subject: changing logging
From: John Clarke <clarkemjj@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636b432973371f404708f7812
X-Virus-Checked: Checked by ClamAV on apache.org

--001636b432973371f404708f7812
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

I am using Hadoop 0.18.3. I'm trying to get my app to output DEBUG messages
to the console using a custom conversion pattern.

I'm editing the log4j.properties file in the conf folder but the changes
don't seem to work. All the log messages are still INFO and higher and the
pattern is not changing either.

I'm currently running as a local Java app in Eclipse rather than in Hadoop.

Any ideas?

Cheers,
John

--001636b432973371f404708f7812--

From common-user-return-16601-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 16:23:26 2009
Return-Path: <common-user-return-16601-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 59831 invoked from network); 7 Aug 2009 16:23:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 16:23:26 -0000
Received: (qmail 76834 invoked by uid 500); 7 Aug 2009 16:23:31 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 76759 invoked by uid 500); 7 Aug 2009 16:23:31 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 76749 invoked by uid 99); 7 Aug 2009 16:23:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 16:23:31 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pareekash@gmail.com designates 209.85.146.183 as permitted sender)
Received: from [209.85.146.183] (HELO wa-out-1112.google.com) (209.85.146.183)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 16:23:21 +0000
Received: by wa-out-1112.google.com with SMTP id j32so375188waf.29
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 09:23:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=6vJF8iFuh9JrItuvQHICQMVO7fXUa+cTPY2YTPDaNmo=;
        b=nkwgPx/bm9s5JPHKmoAk6/sSJ+VKZ09nQG0O9GAv6gvYqkxl0XWhNk4X6O1COMW9UX
         oT87DVcaYCpqbGHbleGq6EOCiAz2FXl3ITdL9cbdxEpFp7pokf15oYlb078BCnTTSzPb
         eyDS92zaDjWCY1PmTnwpuWzbp5gUowwbrbB0U=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=pqSIg20/hVd2qi5OvMXQ+aHagY88TddML1JR0mF0bUmBu6pcDFTNgMxaTdnhHtMSO4
         YskmXVS7BFeygA5MJomIiBu/UNX7XOuxr1ic/zr+JqxVLoyEzB/teANBzFgu2u0uSOzB
         NOggS0JSt4dkCK+0/j1nKRhmJ4y68LzqDJwPE=
MIME-Version: 1.0
Received: by 10.114.126.6 with SMTP id y6mr1722184wac.229.1249662181116; Fri, 
	07 Aug 2009 09:23:01 -0700 (PDT)
In-Reply-To: <45d9159d0908062104h14a7c281ud830fe1acdd8f493@mail.gmail.com>
References: <45d9159d0908052151j24ade0fct38c7acdd8b74d2ce@mail.gmail.com>
	 <d6d7c4410908061052t522b0da7r5fe9534fdeed93a2@mail.gmail.com>
	 <45d9159d0908062104h14a7c281ud830fe1acdd8f493@mail.gmail.com>
Date: Fri, 7 Aug 2009 21:53:01 +0530
Message-ID: <45d9159d0908070923i46d0a629qe5624f2a431609c8@mail.gmail.com>
Subject: Re: Help in running hadoop from eclipse
From: ashish pareek <pareekash@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163646d5dc650bfe04708fa6a9
X-Virus-Checked: Checked by ClamAV on apache.org

--00163646d5dc650bfe04708fa6a9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks Aron

  :)

             I got external debugging tool working  with eclipse. But would
like to know if I can debug entire Hadoop code instead of just NameNode and
if yes how ?

Thanks to you all

Regards,
Ashish

On Fri, Aug 7, 2009 at 9:34 AM, ashish pareek <pareekash@gmail.com> wrote:

> Thanks to you Aaron, but whats the procedure for external debugging ? what
> project name should be specified ? and what more information i need to fill
> in remote debugging options
>
> Regards,
> Ashish.
>
>
> On Thu, Aug 6, 2009 at 11:22 PM, Aaron Kimball <aaron@cloudera.com> wrote:
>
>> May I ask why you're trying to run the NameNode in Eclipse? This is likely
>> going to cause you lots of classpath headaches. I think your current
>> problem
>> is that it can't find its config files, so it's not able to read in the
>> strings for what addresses it should listen on.
>>
>> If you want to see what's happening inside the namenode, I'd run
>> "bin/hadoop-daemon.sh start namenode" to start it, then fire up Eclipse
>> and
>> attach the debugger externally. You can then point it at your copy of the
>> Hadoop source code so you can set breakpoints, trace, etc.
>>
>> - A
>>
>> On Wed, Aug 5, 2009 at 9:51 PM, ashish pareek <pareekash@gmail.com>
>> wrote:
>>
>> > Hi Everybody,
>> >
>> >                  I am trying to run hadoop from eclipse... but when i
>> run
>> > NmaeNode.java as java appliaction i get following error..... Please help
>> in
>> > getting rid of this problem.
>> >
>> >
>> >
>> > 2009-08-05 23:42:00,760 INFO  dfs.NameNode
>> > (StringUtils.java:startupShutdownMessage(464)) - STARTUP_MSG:
>> >
>> > /************************************************************
>> >
>> > STARTUP_MSG: Starting NameNode
>> >
>> > STARTUP_MSG:   host = datanode1/10.0.1.109
>> >
>> > STARTUP_MSG:   args = []
>> >
>> > STARTUP_MSG:   version = Unknown
>> >
>> > STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Unknown' on
>> Unknown
>> >
>> > ************************************************************/
>> >
>> > 2009-08-05 23:42:00,806 ERROR dfs.NameNode (NameNode.java:main(843)) -
>> > java.lang.NullPointerException
>> >
>> >            at
>> > org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
>> >
>> >            at
>> org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
>> >
>> >            at
>> org.apache.hadoop.dfs.NameNode.initialize(NameNode.java:136)
>> >
>> >            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:193)
>> >
>> >            at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:179)
>> >
>> >            at
>> > org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:830)
>> >
>> >            at org.apache.hadoop.dfs.NameNode.main(NameNode.java:839)
>> >
>> >
>> >
>> > 2009-08-05 23:42:00,807 INFO  dfs.NameNode (StringUtils.java:run(479)) -
>> > SHUTDOWN_MSG:
>> >
>> > /************************************************************
>> >
>> > SHUTDOWN_MSG: Shutting down NameNode at datanode1/10.0.1.109
>> >
>> > ************************************************************/
>> >
>>
>
>

--00163646d5dc650bfe04708fa6a9--

From common-user-return-16602-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 16:52:09 2009
Return-Path: <common-user-return-16602-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 69401 invoked from network); 7 Aug 2009 16:52:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 16:52:09 -0000
Received: (qmail 22564 invoked by uid 500); 7 Aug 2009 16:52:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 22484 invoked by uid 500); 7 Aug 2009 16:52:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 22474 invoked by uid 99); 7 Aug 2009 16:52:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 16:52:13 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 16:52:00 +0000
Received: by bwz19 with SMTP id 19so1585779bwz.13
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 09:51:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=BD+TAuHSM7x9V4Yi8fTAOHuRPxFopcyVumyzQlG9FKE=;
        b=Cqis5EN7Xv8URIz/+zK7kobWpi7zP7lrYRM/6gTyoaHM0fy3kVggV1JN5CU00+gbMJ
         NhjGbirtzVaL4F9gUzBtLHFJBHwxX9M8cYmzE5P2acIbypIaC4AkzSSgJe9TsUilevbP
         mKxPQLo+KPOJoDrRjgTmOIkjaMkCb3y1DplMI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=tSKZUeT4066xIhlcmH2bhUBYyg5Et8Ub5oGznpgx7ns2enLNAlpXGxITaErDg0Rz/N
         kVNCDHZWgaZFGgHVawSW2yO+v7Oafkw4WkuQY5wRgck+0UFoJRooLkeXtGPvzbGJF9kO
         4EW/zb8VC6LFDhY0oZIDaHVVmXR0POmzzHxZY=
MIME-Version: 1.0
Received: by 10.239.170.142 with SMTP id s14mr153109hbe.89.1249663900047; Fri, 
	07 Aug 2009 09:51:40 -0700 (PDT)
In-Reply-To: <32120a6a0908070802pf251a4fl3b776f4b24ff6b31@mail.gmail.com>
References: <ad681e7f0908070750kc460ee3y23edc2e16d132057@mail.gmail.com>
	 <32120a6a0908070802pf251a4fl3b776f4b24ff6b31@mail.gmail.com>
Date: Fri, 7 Aug 2009 12:51:39 -0400
Message-ID: <ad681e7f0908070951i64f2f969l89b959043a084d18@mail.gmail.com>
Subject: Re: Help with Hadoop/Hbase on s3
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636499eb5d9da340470900c84
X-Virus-Checked: Checked by ClamAV on apache.org

--001636499eb5d9da340470900c84
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

TIm,
 that got me a little further! Thanks...

but now i get a different error

hbase-site.xml

<configuration>
   <property>
  <name>hbase.master</name>
    <value>174.129.15.236:60000</value>
    <description>The host and port that the HBase master runs at.
    A value of 'local' runs the master and a regionserver in
    a single process.
    </description>
  </property>

  <property>
   <name>hbase.rootdir</name>
   <value>s3://testbucket</value>
   <description>The directory shared by region servers.
   </description>
  </property>
</configuration>

i copied a hadoop-site.xml with my access and secret key to my conf/ in
hbase....  i also tried using the s3://id:access@bucket and that didn't
work.

Fri Aug  7 12:47:45 EDT 2009 Starting master on ip-10-244-131-228
ulimit -n 1024
2009-08-07 12:47:45,850 INFO org.apache.hadoop.hbase.master.HMaster:
vmName=Java HotSpot(TM) Client VM, vmVendor=Sun Microsystems Inc.,
vmVersion=14.1-b02
2009-08-07 12:47:45,850 INFO org.apache.hadoop.hbase.master.HMaster:
vmInputArguments=[-Xmx1000m, -XX:+HeapDumpOnOutOfMemoryError,
-Dhbase.log.dir=/usr/hbase-0.19.2/bin/../logs,
-Dhbase.log.file=hbase-root-master-ip-10-244-131-228.log,
-Dhbase.home.dir=/usr/hbase-0.19.2/bin/.., -Dhbase.id.str=root,
-Dhbase.root.logger=INFO,DRFA,
-Djava.library.path=/usr/hbase-0.19.2/bin/../lib/native/Linux-i386-32]
2009-08-07 12:47:48,535 ERROR org.apache.hadoop.hbase.master.HMaster: Can
not start master
org.apache.hadoop.fs.s3.S3Exception: org.jets3t.service.S3ServiceException:
S3 PUT failed for '/' XML Error Message: <?xml version="1.0"
encoding="UTF-8"?><Error><Code>BucketAlreadyExists</Code><Message>The
requested bucket name is not available. The bucket namespace is shared by
all users of the system. Please select a different name and try
again.</Message><BucketName>testbucket</BucketName><RequestId>C0C7F562713BDE97</RequestId><HostId>ifY4rPOqmasjPkH+EiTS3LsgRzuDcbUTHy+y8p4HMnJWN1kUXCUe+FvYSZhIlYHg</HostId></Error>
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.createBucket(Jets3tFileSystemStore.java:108)
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.initialize(Jets3tFileSystemStore.java:96)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at
org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at
org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at $Proxy0.initialize(Unknown Source)
        at
org.apache.hadoop.fs.s3.S3FileSystem.initialize(S3FileSystem.java:76)
        at
org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1367)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:56)
        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1379)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:215)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:120)
        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:186)
        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:156)
        at
org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:96)
        at
org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:78)
        at org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1013)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1057)
Caused by: org.jets3t.service.S3ServiceException: S3 PUT failed for '/' XML
Error Message: <?xml version="1.0"
encoding="UTF-8"?><Error><Code>BucketAlreadyExists</Code><Message>The
requested bucket name is not available. The bucket namespace is shared by
all users of the system. Please select a different name and try
again.</Message><BucketName>testbucket</BucketName><RequestId>C0C7F562713BDE97</RequestId><HostId>ifY4rPOqmasjPkH+EiTS3LsgRzuDcbUTHy+y8p4HMnJWN1kUXCUe+FvYSZhIlYHg</HostId></Error>
        at
org.jets3t.service.impl.rest.httpclient.RestS3Service.performRequest(RestS3Service.java:416)
        at
org.jets3t.service.impl.rest.httpclient.RestS3Service.performRestPut(RestS3Service.java:800)
        at
org.jets3t.service.impl.rest.httpclient.RestS3Service.createObjectImpl(RestS3Service.java:1399)
        at
org.jets3t.service.impl.rest.httpclient.RestS3Service.createBucketImpl(RestS3Service.java:1270)
        at org.jets3t.service.S3Service.createBucket(S3Service.java:1558)
        at org.jets3t.service.S3Service.createBucket(S3Service.java:1257)
        at org.jets3t.service.S3Service.createBucket(S3Service.java:1284)
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.createBucket(Jets3tFileSystemStore.java:103)
        ... 20 more


Ananth T Sarathy


On Fri, Aug 7, 2009 at 11:02 AM, tim robertson <timrobertson100@gmail.com>wrote:

> Do you need to add the Amazon S3 toolkit on the HBase classpath
> directly to use S3 as a store?
>
> http://developer.amazonwebservices.com/connect/entry.jspa?externalID=617&categoryID=47
>
> I'm guessing based on the "java.lang.NoClassDefFoundError:
> org/jets3t/service/S3ServiceException"
>
> Cheers
>
> Tim
>
>
> On Fri, Aug 7, 2009 at 4:50 PM, Ananth T.
> Sarathy<ananth.t.sarathy@gmail.com> wrote:
> > I can't seem to get Hbase to run using the hadoop i have connected to my
> s3
> > bucket
> >
> > Running
> > Hbase 0.19.2
> > Hadoop  0.19.2
> >
> > Hadoop-site.xml
> >  < configuration>
> >
> > <property>
> >  <name>fs.default.name</name>
> >  <value>s3://hbase</value>
> > </property>
> >
> > <property>
> >  <name>fs.s3.awsAccessKeyId</name>
> >  <value>ID</value>
> > </property>
> >
> > <property>
> >  <name>fs.s3.awsSecretAccessKey</name>
> >  <value>SECRET</value>
> > </property>
> > </configuration>
> >
> > and it seems to start up no problem
> >
> > my hbase-site.xml
> >
> > <configuration>
> >    <property>
> >  <name>hbase.master</name>
> >     <value>174.129.15.236:60000</value>
> >     <description>The host and port that the HBase master runs at.
> >     A value of 'local' runs the master and a regionserver in
> >     a single process.
> >     </description>
> >   </property>
> >
> >  <property>
> >    <name>hbase.rootdir</name>
> >    <value>s3://hbase</value>
> >    <description>The directory shared by region servers.
> >    </description>
> >  </property>
> >
> > </configuration>
> >
> >
> > keeps giving me
> >
> > ]
> > 2009-08-06 17:20:44,526 ERROR org.apache.hadoop.hbase.master.HMaster: Can
> > not start master
> > java.lang.NoClassDefFoundError: org/jets3t/service/S3ServiceException
> >        at
> >
> org.apache.hadoop.fs.s3.S3FileSystem.createDefaultStore(S3FileSystem.java:84)
> >        at
> > org.apache.hadoop.fs.s3.S3FileSystem.initialize(S3FileSystem.java:74)
> >        at
> > org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1367)
> >        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:56)
> >        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1379)
> >        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:215)
> >        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:120)
> >        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:186)
> >        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:156)
> >        at
> >
> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:96)
> >        at
> >
> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:78)
> >        at
> org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1013)
> >        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1057)
> > Caused by: java.lang.ClassNotFoundException:
> > org.jets3t.service.S3ServiceException
> >        at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
> >        at java.security.AccessController.doPrivileged(Native Method)
> >        at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
> >        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
> >        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
> >        at java.lang.ClassLoader.loadClass(ClassLoader.java:252)
> >        at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:320)
> >
> >
> > what am i doing wrong here?
> >
> > Ananth T Sarathy
> >
>

--001636499eb5d9da340470900c84--

From common-user-return-16603-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 17:20:08 2009
Return-Path: <common-user-return-16603-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75473 invoked from network); 7 Aug 2009 17:20:08 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 17:20:08 -0000
Received: (qmail 58202 invoked by uid 500); 7 Aug 2009 17:20:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 58133 invoked by uid 500); 7 Aug 2009 17:20:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 58123 invoked by uid 99); 7 Aug 2009 17:20:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:20:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of billgraham@gmail.com designates 74.125.92.25 as permitted sender)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:20:05 +0000
Received: by qw-out-2122.google.com with SMTP id 8so645283qwh.35
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 10:19:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:date:message-id
         :subject:from:to:content-type;
        bh=LekXoWcQkZE3kac/ho6wNipCCYMs/iDfMsOcMKsUo7s=;
        b=GDuVcKQfJRYMGQ60sVaSGv1/YXu7zoXu2NnfOG0LNZWJVptV/VC7waE5FMyMgAVzMr
         OfxjwCcnnH/EUUAkzUtdd/rbMIdnaFoOXcodi1750SZHXdtgXb5xWAzUAwLJP6t7JL/n
         PriK6V2/YI8O9RhNBaIFcwlozCKR6tn0Cj6oo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:date:message-id:subject:from:to:content-type;
        b=ROIF284KaVPa1Hk/O66a2z4+QUEA+dCj+q2kF0Iq9vpF4Mc1IJm8IBDDt3xmdgZBIq
         8AZcUMJHgYEX99d9IryGb5JJOB2eY2c6aGNbmc1Kzh/kgLNIAY3u4LrCEsF5hBZdr3qL
         XbegnKI8QC5H/fcWVWyAN/2KOOs11zbDTYhm8=
MIME-Version: 1.0
Received: by 10.224.10.201 with SMTP id q9mr1368665qaq.134.1249665584060; Fri, 
	07 Aug 2009 10:19:44 -0700 (PDT)
Reply-To: billgraham@gmail.com
Date: Fri, 7 Aug 2009 10:19:44 -0700
Message-ID: <449b48760908071019j27ee2a8n1f260cbac7e19004@mail.gmail.com>
Subject: Best way to run Hadoop Streaming from a Java app
From: Bill Graham <billgraham@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175cdcb839da760470907133
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175cdcb839da760470907133
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

I have a need to run Hadoop streaming jobs from a Java app and I'm looking
for the best way to do this. I though there was discussion around this on
the list a few months back, but I couldn't fine it.

Looking through the code, I've found one way to do this, but it seems clunky
and I suspect there's a better approach:

String[] args = new String[] {
     "/path/to/hadoop-0.18.3-streaming.jar",
     "-input", "sample_data",
     "-output", "sample_data/output",
     "-file", "src-python/mapper.py",
     "-file", "src-python/reducer.py",
     "-mapper", "mapper.py", "-reducer", "reducer.py", "-inputformat",
     "org.apache.hadoop.mapred.KeyValueTextInputFormat"
    };

RunJar.main(args);

I'd like to have a more type-safe approach to running this jar than using a
String[] to pass params to a main method (i.e. using something like JobConf)
. Also, I'd like to not have to know the location of the streaming jar on
disk, but instead have it be taken from the classpath.

Does anyone have any examples or suggestions re how to do this?

thanks,
Bill

--0015175cdcb839da760470907133--

From common-user-return-16604-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 17:30:27 2009
Return-Path: <common-user-return-16604-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 82264 invoked from network); 7 Aug 2009 17:30:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 17:30:26 -0000
Received: (qmail 78546 invoked by uid 500); 7 Aug 2009 17:29:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 78466 invoked by uid 500); 7 Aug 2009 17:29:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 78456 invoked by uid 99); 7 Aug 2009 17:29:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:29:32 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of timrobertson100@gmail.com designates 74.125.78.25 as permitted sender)
Received: from [74.125.78.25] (HELO ey-out-2122.google.com) (74.125.78.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:29:19 +0000
Received: by ey-out-2122.google.com with SMTP id 22so537780eye.35
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 10:28:58 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=+FO1gGF7zNqeSYeTwansQg3u7D+Cr6OTiUBmFParj7k=;
        b=e1mibSISb6IHSZAfsNMNI10ikoIYcCVoXoWOCI5ObTSaDCr0CBTsK9Oqfs+ufQqOCy
         fLxcpGstPVJWL5y+XCZ5FW3Y6nTf2EuVmfZOWpSeEb9LqIv1rggCxau1jSR2HTcYwTNt
         /gxU3ZPYOxj+kF9WMuJ14mAzKsg6R/mix2mQ0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=rGh4FioMHEZyLoFigLfv5npQgcoNcvYK9m2JLrlZZnnqUCxJUftnj3ik4gaSNrPMs7
         cLo4B8zvn8qSCAzMo/2vw3u7QBsk1ggl9wvko4skKe5AxIkMYV8Y3ellm8+MKh5O++vX
         Te4T3Jk7MRxwV+YEWZ7fdZ1eQ8GqR7Fm/7Zb4=
MIME-Version: 1.0
Received: by 10.216.71.82 with SMTP id q60mr289450wed.169.1249666138652; Fri, 
	07 Aug 2009 10:28:58 -0700 (PDT)
In-Reply-To: <ad681e7f0908070951i64f2f969l89b959043a084d18@mail.gmail.com>
References: <ad681e7f0908070750kc460ee3y23edc2e16d132057@mail.gmail.com>
	 <32120a6a0908070802pf251a4fl3b776f4b24ff6b31@mail.gmail.com>
	 <ad681e7f0908070951i64f2f969l89b959043a084d18@mail.gmail.com>
Date: Fri, 7 Aug 2009 19:28:58 +0200
Message-ID: <32120a6a0908071028q8c67edya1d959e6c19c2167@mail.gmail.com>
Subject: Re: Help with Hadoop/Hbase on s3
From: tim robertson <timrobertson100@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Pointing out the obvious but something somewhere is trying to create a
bucket that has already been created.

Sorry, but I don't think I can help further - perhaps change
s3://testbucket to s3://testbucket2 just to be sure it is not that you
have created it in another process by accident?

Cheers

Tim


On Fri, Aug 7, 2009 at 6:51 PM, Ananth T.
Sarathy<ananth.t.sarathy@gmail.com> wrote:
> TIm,
> =A0that got me a little further! Thanks...
>
> but now i get a different error
>
> hbase-site.xml
>
> <configuration>
> =A0 <property>
> =A0<name>hbase.master</name>
> =A0 =A0<value>174.129.15.236:60000</value>
> =A0 =A0<description>The host and port that the HBase master runs at.
> =A0 =A0A value of 'local' runs the master and a regionserver in
> =A0 =A0a single process.
> =A0 =A0</description>
> =A0</property>
>
> =A0<property>
> =A0 <name>hbase.rootdir</name>
> =A0 <value>s3://testbucket</value>
> =A0 <description>The directory shared by region servers.
> =A0 </description>
> =A0</property>
> </configuration>
>
> i copied a hadoop-site.xml with my access and secret key to my conf/ in
> hbase.... =A0i also tried using the s3://id:access@bucket and that didn't
> work.
>
> Fri Aug =A07 12:47:45 EDT 2009 Starting master on ip-10-244-131-228
> ulimit -n 1024
> 2009-08-07 12:47:45,850 INFO org.apache.hadoop.hbase.master.HMaster:
> vmName=3DJava HotSpot(TM) Client VM, vmVendor=3DSun Microsystems Inc.,
> vmVersion=3D14.1-b02
> 2009-08-07 12:47:45,850 INFO org.apache.hadoop.hbase.master.HMaster:
> vmInputArguments=3D[-Xmx1000m, -XX:+HeapDumpOnOutOfMemoryError,
> -Dhbase.log.dir=3D/usr/hbase-0.19.2/bin/../logs,
> -Dhbase.log.file=3Dhbase-root-master-ip-10-244-131-228.log,
> -Dhbase.home.dir=3D/usr/hbase-0.19.2/bin/.., -Dhbase.id.str=3Droot,
> -Dhbase.root.logger=3DINFO,DRFA,
> -Djava.library.path=3D/usr/hbase-0.19.2/bin/../lib/native/Linux-i386-32]
> 2009-08-07 12:47:48,535 ERROR org.apache.hadoop.hbase.master.HMaster: Can
> not start master
> org.apache.hadoop.fs.s3.S3Exception: org.jets3t.service.S3ServiceExceptio=
n:
> S3 PUT failed for '/' XML Error Message: <?xml version=3D"1.0"
> encoding=3D"UTF-8"?><Error><Code>BucketAlreadyExists</Code><Message>The
> requested bucket name is not available. The bucket namespace is shared by
> all users of the system. Please select a different name and try
> again.</Message><BucketName>testbucket</BucketName><RequestId>C0C7F562713=
BDE97</RequestId><HostId>ifY4rPOqmasjPkH+EiTS3LsgRzuDcbUTHy+y8p4HMnJWN1kUXC=
Ue+FvYSZhIlYHg</HostId></Error>
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.fs.s3.Jets3tFileSystemStore.createBucket(Jets3tFileSyst=
emStore.java:108)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.fs.s3.Jets3tFileSystemStore.initialize(Jets3tFileSystem=
Store.java:96)
> =A0 =A0 =A0 =A0at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Met=
hod)
> =A0 =A0 =A0 =A0at
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:39)
> =A0 =A0 =A0 =A0at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
> =A0 =A0 =A0 =A0at java.lang.reflect.Method.invoke(Method.java:597)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvoc=
ationHandler.java:82)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationH=
andler.java:59)
> =A0 =A0 =A0 =A0at $Proxy0.initialize(Unknown Source)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.fs.s3.S3FileSystem.initialize(S3FileSystem.java:76)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1367)
> =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.j=
ava:56)
> =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.ja=
va:1379)
> =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:215=
)
> =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:120=
)
> =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.j=
ava:186)
> =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.j=
ava:156)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:9=
6)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:7=
8)
> =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.j=
ava:1013)
> =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.main(HMaster.jav=
a:1057)
> Caused by: org.jets3t.service.S3ServiceException: S3 PUT failed for '/' X=
ML
> Error Message: <?xml version=3D"1.0"
> encoding=3D"UTF-8"?><Error><Code>BucketAlreadyExists</Code><Message>The
> requested bucket name is not available. The bucket namespace is shared by
> all users of the system. Please select a different name and try
> again.</Message><BucketName>testbucket</BucketName><RequestId>C0C7F562713=
BDE97</RequestId><HostId>ifY4rPOqmasjPkH+EiTS3LsgRzuDcbUTHy+y8p4HMnJWN1kUXC=
Ue+FvYSZhIlYHg</HostId></Error>
> =A0 =A0 =A0 =A0at
> org.jets3t.service.impl.rest.httpclient.RestS3Service.performRequest(Rest=
S3Service.java:416)
> =A0 =A0 =A0 =A0at
> org.jets3t.service.impl.rest.httpclient.RestS3Service.performRestPut(Rest=
S3Service.java:800)
> =A0 =A0 =A0 =A0at
> org.jets3t.service.impl.rest.httpclient.RestS3Service.createObjectImpl(Re=
stS3Service.java:1399)
> =A0 =A0 =A0 =A0at
> org.jets3t.service.impl.rest.httpclient.RestS3Service.createBucketImpl(Re=
stS3Service.java:1270)
> =A0 =A0 =A0 =A0at org.jets3t.service.S3Service.createBucket(S3Service.jav=
a:1558)
> =A0 =A0 =A0 =A0at org.jets3t.service.S3Service.createBucket(S3Service.jav=
a:1257)
> =A0 =A0 =A0 =A0at org.jets3t.service.S3Service.createBucket(S3Service.jav=
a:1284)
> =A0 =A0 =A0 =A0at
> org.apache.hadoop.fs.s3.Jets3tFileSystemStore.createBucket(Jets3tFileSyst=
emStore.java:103)
> =A0 =A0 =A0 =A0... 20 more
>
>
> Ananth T Sarathy
>
>
> On Fri, Aug 7, 2009 at 11:02 AM, tim robertson <timrobertson100@gmail.com=
>wrote:
>
>> Do you need to add the Amazon S3 toolkit on the HBase classpath
>> directly to use S3 as a store?
>>
>> http://developer.amazonwebservices.com/connect/entry.jspa?externalID=3D6=
17&categoryID=3D47
>>
>> I'm guessing based on the "java.lang.NoClassDefFoundError:
>> org/jets3t/service/S3ServiceException"
>>
>> Cheers
>>
>> Tim
>>
>>
>> On Fri, Aug 7, 2009 at 4:50 PM, Ananth T.
>> Sarathy<ananth.t.sarathy@gmail.com> wrote:
>> > I can't seem to get Hbase to run using the hadoop i have connected to =
my
>> s3
>> > bucket
>> >
>> > Running
>> > Hbase 0.19.2
>> > Hadoop =A00.19.2
>> >
>> > Hadoop-site.xml
>> > =A0< configuration>
>> >
>> > <property>
>> > =A0<name>fs.default.name</name>
>> > =A0<value>s3://hbase</value>
>> > </property>
>> >
>> > <property>
>> > =A0<name>fs.s3.awsAccessKeyId</name>
>> > =A0<value>ID</value>
>> > </property>
>> >
>> > <property>
>> > =A0<name>fs.s3.awsSecretAccessKey</name>
>> > =A0<value>SECRET</value>
>> > </property>
>> > </configuration>
>> >
>> > and it seems to start up no problem
>> >
>> > my hbase-site.xml
>> >
>> > <configuration>
>> > =A0 =A0<property>
>> > =A0<name>hbase.master</name>
>> > =A0 =A0 <value>174.129.15.236:60000</value>
>> > =A0 =A0 <description>The host and port that the HBase master runs at.
>> > =A0 =A0 A value of 'local' runs the master and a regionserver in
>> > =A0 =A0 a single process.
>> > =A0 =A0 </description>
>> > =A0 </property>
>> >
>> > =A0<property>
>> > =A0 =A0<name>hbase.rootdir</name>
>> > =A0 =A0<value>s3://hbase</value>
>> > =A0 =A0<description>The directory shared by region servers.
>> > =A0 =A0</description>
>> > =A0</property>
>> >
>> > </configuration>
>> >
>> >
>> > keeps giving me
>> >
>> > ]
>> > 2009-08-06 17:20:44,526 ERROR org.apache.hadoop.hbase.master.HMaster: =
Can
>> > not start master
>> > java.lang.NoClassDefFoundError: org/jets3t/service/S3ServiceException
>> > =A0 =A0 =A0 =A0at
>> >
>> org.apache.hadoop.fs.s3.S3FileSystem.createDefaultStore(S3FileSystem.jav=
a:84)
>> > =A0 =A0 =A0 =A0at
>> > org.apache.hadoop.fs.s3.S3FileSystem.initialize(S3FileSystem.java:74)
>> > =A0 =A0 =A0 =A0at
>> > org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1367)
>> > =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem.access$200(FileSyste=
m.java:56)
>> > =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem=
.java:1379)
>> > =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:=
215)
>> > =A0 =A0 =A0 =A0at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:=
120)
>> > =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.<init>(HMaste=
r.java:186)
>> > =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.<init>(HMaste=
r.java:156)
>> > =A0 =A0 =A0 =A0at
>> >
>> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:=
96)
>> > =A0 =A0 =A0 =A0at
>> >
>> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:=
78)
>> > =A0 =A0 =A0 =A0at
>> org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1013)
>> > =A0 =A0 =A0 =A0at org.apache.hadoop.hbase.master.HMaster.main(HMaster.=
java:1057)
>> > Caused by: java.lang.ClassNotFoundException:
>> > org.jets3t.service.S3ServiceException
>> > =A0 =A0 =A0 =A0at java.net.URLClassLoader$1.run(URLClassLoader.java:20=
0)
>> > =A0 =A0 =A0 =A0at java.security.AccessController.doPrivileged(Native M=
ethod)
>> > =A0 =A0 =A0 =A0at java.net.URLClassLoader.findClass(URLClassLoader.jav=
a:188)
>> > =A0 =A0 =A0 =A0at java.lang.ClassLoader.loadClass(ClassLoader.java:307=
)
>> > =A0 =A0 =A0 =A0at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.=
java:301)
>> > =A0 =A0 =A0 =A0at java.lang.ClassLoader.loadClass(ClassLoader.java:252=
)
>> > =A0 =A0 =A0 =A0at java.lang.ClassLoader.loadClassInternal(ClassLoader.=
java:320)
>> >
>> >
>> > what am i doing wrong here?
>> >
>> > Ananth T Sarathy
>> >
>>
>

From common-user-return-16605-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 17:31:25 2009
Return-Path: <common-user-return-16605-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 82860 invoked from network); 7 Aug 2009 17:31:25 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 17:31:25 -0000
Received: (qmail 81763 invoked by uid 500); 7 Aug 2009 17:31:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 81685 invoked by uid 500); 7 Aug 2009 17:31:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 81675 invoked by uid 99); 7 Aug 2009 17:31:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:31:29 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:31:20 +0000
Received: by qw-out-2122.google.com with SMTP id 8so647847qwh.35
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 10:30:58 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.229.85.204 with SMTP id p12mr762369qcl.49.1249666258473; Fri, 
	07 Aug 2009 10:30:58 -0700 (PDT)
In-Reply-To: <4A719468.4070602@gmail.com>
References: <8131791a0907300127n7874c2b1l290b66d08a8a838@mail.gmail.com>
	 <4A7191C1.2040503@apache.org> <4A719468.4070602@gmail.com>
Date: Fri, 7 Aug 2009 10:30:58 -0700
Message-ID: <c9118d4c0908071030g51882deavc5d4c2aafe7c572a@mail.gmail.com>
Subject: Re: How to HA the NameNode?
From: Jeff Hammerbacher <hammer@cloudera.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016364ef3c46c923c04709099de
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364ef3c46c923c04709099de
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

As David mentions, you can find more information on one approach to HA for
the NN at http://www.cloudera.com/blog/2009/07/22/hadoop-ha-configuration/.

On Thu, Jul 30, 2009 at 5:39 AM, David B. Ritch <david.ritch@gmail.com>wrote:

> Check out the Cloudera blog (http://www.cloudera.com).  They posted
> instructions for one approach.
>
>
> On 7/30/2009 8:27 AM, Steve Loughran wrote:
> > imcaptor wrote:
> >> Dear All:
> >>   The NameNode is the Single Point of hadoop,
> >
> > It's *one* SPOF - unless your datacentre has multiple gigabit
> > backbones on separate switches and more than electricity supply from
> > different power supply grids, you have others out there. Then there's
> > the issue of which fault lines your facility is close to, whether it
> > is built on the mud flows of previous eruptions (Enumclaw, WA spring
> > to mind), etc.
> >
> >> I want to know how to HA the NameNode.
> >
> > This is a major engineering project that has been discussed on the
> > lists. If you want to get involved in it, and have the skills -and the
> > testing facilities- you would be welcome. Testing HA/failover is
> > tricky because of the many ways things can fail.
> >
> > Otherwise, focus on making sure your namenode data is streamed off
> > onto different disks, you have a secondary NN, and you  have a good
> > recovery process that includes the failure of the NN hardware
> >
> >
> >
> >
>
>

--0016364ef3c46c923c04709099de--

From common-user-return-16606-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 17:34:42 2009
Return-Path: <common-user-return-16606-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 84279 invoked from network); 7 Aug 2009 17:34:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 17:34:42 -0000
Received: (qmail 85733 invoked by uid 500); 7 Aug 2009 17:34:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 85648 invoked by uid 500); 7 Aug 2009 17:34:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 85636 invoked by uid 99); 7 Aug 2009 17:34:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:34:46 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:34:35 +0000
Received: by fxm24 with SMTP id 24so1775308fxm.36
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 10:34:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=hxl2XXI/FI8qxZa90/oIVGXbG0ZnTh7N5NYSuH/CAZw=;
        b=NRsH2OO0eERegnmeMfPo6sU4ASLR1bHXrurwSegPpurGlTXe9gp04wKvi/UHbwkDfv
         hZF1t4NltiPDpyN1jIXGhNK4tTJ6qbVjs+wuphF6sc9GHXt39pj6McYkuVAoc8wSdbge
         qKuxhGzRTbVb4+n7hGVv8ZyJ0OMGZD7vx8PPA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=bkde1WmRE6Kpn+xVz74UltK3IZ80GhVj3dBbsEvogRY5pnGtKXcjxxoeQAi+Uozoiq
         NWsD/6azDsD4ThYzbY1k83nUQbQEIlRXLAtkAcsP/UAUanr+NygRB8VIHMKfNhfiTOEd
         nfmAAek2pumCbQWLLVAmjGh4jgfPrmu0wB6mE=
MIME-Version: 1.0
Received: by 10.239.170.142 with SMTP id s14mr157936hbe.89.1249666453710; Fri, 
	07 Aug 2009 10:34:13 -0700 (PDT)
In-Reply-To: <32120a6a0908071028q8c67edya1d959e6c19c2167@mail.gmail.com>
References: <ad681e7f0908070750kc460ee3y23edc2e16d132057@mail.gmail.com>
	 <32120a6a0908070802pf251a4fl3b776f4b24ff6b31@mail.gmail.com>
	 <ad681e7f0908070951i64f2f969l89b959043a084d18@mail.gmail.com>
	 <32120a6a0908071028q8c67edya1d959e6c19c2167@mail.gmail.com>
Date: Fri, 7 Aug 2009 13:34:13 -0400
Message-ID: <ad681e7f0908071034l1a86f257n83d55fdbc335cd23@mail.gmail.com>
Subject: Re: Help with Hadoop/Hbase on s3
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636499eb50fa7af047090a5cf
X-Virus-Checked: Checked by ClamAV on apache.org

--001636499eb50fa7af047090a5cf
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks for whatever help you could give... when I try to something else I
get

Fri Aug  7 13:31:34 EDT 2009 Starting master on ip-10-244-131-228
ulimit -n 1024
2009-08-07 13:31:34,829 INFO org.apache.hadoop.hbase.master.HMaster:
vmName=Ja HotSpot(TM) Client VM, vmVendor=Sun Microsystems Inc.,
vmVersion=14.1-b02
2009-08-07 13:31:34,830 INFO org.apache.hadoop.hbase.master.HMaster:
vmInputArments=[-Xmx1000m, -XX:+HeapDumpOnOutOfMemoryError,
-Dhbase.log.dir=/usr/hbase-19.2/bin/../logs,
-Dhbase.log.file=hbase-root-master-ip-10-244-131-228.log,
-Dase.home.dir=/usr/hbase-0.19.2/bin/.., -Dhbase.id.str=root,
-Dhbase.root.loggeINFO,DRFA,
-Djava.library.path=/usr/hbase-0.19.2/bin/../lib/native/Linux-i386-]
2009-08-07 13:31:37,247 ERROR org.apache.hadoop.hbase.master.HMaster: Can
not art master
java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative
pathn absolute URI: s3://testbucketananth-ROOT-
        at org.apache.hadoop.fs.Path.initialize(Path.java:140)
        at org.apache.hadoop.fs.Path.<init>(Path.java:71)
        at org.apache.hadoop.fs.Path.<init>(Path.java:50)
        at
org.apache.hadoop.hbase.HTableDescriptor.getTableDir(HTableDescript.java:651)
        at
org.apache.hadoop.hbase.regionserver.HRegion.getRegionDir(HRegion.ja:2362)
        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:202)
        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:156)
        at
org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.va:96)
        at
org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.va:78)
        at org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1013)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1057)
Caused by: java.net.URISyntaxException: Relative path in absolute URI:
s3://tebucketananth-ROOT-
        at java.net.URI.checkPath(URI.java:1787)
        at java.net.URI.<init>(URI.java:735)
        at org.apache.hadoop.fs.Path.initialize(Path.java:137)
        ... 10 more



but the bigger issue is why is it trying to create a bucket and how I do
tell it not too.
Ananth T Sarathy


On Fri, Aug 7, 2009 at 1:28 PM, tim robertson <timrobertson100@gmail.com>wrote:

> Pointing out the obvious but something somewhere is trying to create a
> bucket that has already been created.
>
> Sorry, but I don't think I can help further - perhaps change
> s3://testbucket to s3://testbucket2 just to be sure it is not that you
> have created it in another process by accident?
>
> Cheers
>
> Tim
>
>
> On Fri, Aug 7, 2009 at 6:51 PM, Ananth T.
> Sarathy<ananth.t.sarathy@gmail.com> wrote:
> > TIm,
> >  that got me a little further! Thanks...
> >
> > but now i get a different error
> >
> > hbase-site.xml
> >
> > <configuration>
> >   <property>
> >  <name>hbase.master</name>
> >    <value>174.129.15.236:60000</value>
> >    <description>The host and port that the HBase master runs at.
> >    A value of 'local' runs the master and a regionserver in
> >    a single process.
> >    </description>
> >  </property>
> >
> >  <property>
> >   <name>hbase.rootdir</name>
> >   <value>s3://testbucket</value>
> >   <description>The directory shared by region servers.
> >   </description>
> >  </property>
> > </configuration>
> >
> > i copied a hadoop-site.xml with my access and secret key to my conf/ in
> > hbase....  i also tried using the s3://id:access@bucket and that didn't
> > work.
> >
> > Fri Aug  7 12:47:45 EDT 2009 Starting master on ip-10-244-131-228
> > ulimit -n 1024
> > 2009-08-07 12:47:45,850 INFO org.apache.hadoop.hbase.master.HMaster:
> > vmName=Java HotSpot(TM) Client VM, vmVendor=Sun Microsystems Inc.,
> > vmVersion=14.1-b02
> > 2009-08-07 12:47:45,850 INFO org.apache.hadoop.hbase.master.HMaster:
> > vmInputArguments=[-Xmx1000m, -XX:+HeapDumpOnOutOfMemoryError,
> > -Dhbase.log.dir=/usr/hbase-0.19.2/bin/../logs,
> > -Dhbase.log.file=hbase-root-master-ip-10-244-131-228.log,
> > -Dhbase.home.dir=/usr/hbase-0.19.2/bin/.., -Dhbase.id.str=root,
> > -Dhbase.root.logger=INFO,DRFA,
> > -Djava.library.path=/usr/hbase-0.19.2/bin/../lib/native/Linux-i386-32]
> > 2009-08-07 12:47:48,535 ERROR org.apache.hadoop.hbase.master.HMaster: Can
> > not start master
> > org.apache.hadoop.fs.s3.S3Exception:
> org.jets3t.service.S3ServiceException:
> > S3 PUT failed for '/' XML Error Message: <?xml version="1.0"
> > encoding="UTF-8"?><Error><Code>BucketAlreadyExists</Code><Message>The
> > requested bucket name is not available. The bucket namespace is shared by
> > all users of the system. Please select a different name and try
> >
> again.</Message><BucketName>testbucket</BucketName><RequestId>C0C7F562713BDE97</RequestId><HostId>ifY4rPOqmasjPkH+EiTS3LsgRzuDcbUTHy+y8p4HMnJWN1kUXCUe+FvYSZhIlYHg</HostId></Error>
> >        at
> >
> org.apache.hadoop.fs.s3.Jets3tFileSystemStore.createBucket(Jets3tFileSystemStore.java:108)
> >        at
> >
> org.apache.hadoop.fs.s3.Jets3tFileSystemStore.initialize(Jets3tFileSystemStore.java:96)
> >        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >        at
> >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> >        at
> >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> >        at java.lang.reflect.Method.invoke(Method.java:597)
> >        at
> >
> org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
> >        at
> >
> org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
> >        at $Proxy0.initialize(Unknown Source)
> >        at
> > org.apache.hadoop.fs.s3.S3FileSystem.initialize(S3FileSystem.java:76)
> >        at
> > org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1367)
> >        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:56)
> >        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1379)
> >        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:215)
> >        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:120)
> >        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:186)
> >        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:156)
> >        at
> >
> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:96)
> >        at
> >
> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:78)
> >        at
> org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1013)
> >        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1057)
> > Caused by: org.jets3t.service.S3ServiceException: S3 PUT failed for '/'
> XML
> > Error Message: <?xml version="1.0"
> > encoding="UTF-8"?><Error><Code>BucketAlreadyExists</Code><Message>The
> > requested bucket name is not available. The bucket namespace is shared by
> > all users of the system. Please select a different name and try
> >
> again.</Message><BucketName>testbucket</BucketName><RequestId>C0C7F562713BDE97</RequestId><HostId>ifY4rPOqmasjPkH+EiTS3LsgRzuDcbUTHy+y8p4HMnJWN1kUXCUe+FvYSZhIlYHg</HostId></Error>
> >        at
> >
> org.jets3t.service.impl.rest.httpclient.RestS3Service.performRequest(RestS3Service.java:416)
> >        at
> >
> org.jets3t.service.impl.rest.httpclient.RestS3Service.performRestPut(RestS3Service.java:800)
> >        at
> >
> org.jets3t.service.impl.rest.httpclient.RestS3Service.createObjectImpl(RestS3Service.java:1399)
> >        at
> >
> org.jets3t.service.impl.rest.httpclient.RestS3Service.createBucketImpl(RestS3Service.java:1270)
> >        at org.jets3t.service.S3Service.createBucket(S3Service.java:1558)
> >        at org.jets3t.service.S3Service.createBucket(S3Service.java:1257)
> >        at org.jets3t.service.S3Service.createBucket(S3Service.java:1284)
> >        at
> >
> org.apache.hadoop.fs.s3.Jets3tFileSystemStore.createBucket(Jets3tFileSystemStore.java:103)
> >        ... 20 more
> >
> >
> > Ananth T Sarathy
> >
> >
> > On Fri, Aug 7, 2009 at 11:02 AM, tim robertson <
> timrobertson100@gmail.com>wrote:
> >
> >> Do you need to add the Amazon S3 toolkit on the HBase classpath
> >> directly to use S3 as a store?
> >>
> >>
> http://developer.amazonwebservices.com/connect/entry.jspa?externalID=617&categoryID=47
> >>
> >> I'm guessing based on the "java.lang.NoClassDefFoundError:
> >> org/jets3t/service/S3ServiceException"
> >>
> >> Cheers
> >>
> >> Tim
> >>
> >>
> >> On Fri, Aug 7, 2009 at 4:50 PM, Ananth T.
> >> Sarathy<ananth.t.sarathy@gmail.com> wrote:
> >> > I can't seem to get Hbase to run using the hadoop i have connected to
> my
> >> s3
> >> > bucket
> >> >
> >> > Running
> >> > Hbase 0.19.2
> >> > Hadoop  0.19.2
> >> >
> >> > Hadoop-site.xml
> >> >  < configuration>
> >> >
> >> > <property>
> >> >  <name>fs.default.name</name>
> >> >  <value>s3://hbase</value>
> >> > </property>
> >> >
> >> > <property>
> >> >  <name>fs.s3.awsAccessKeyId</name>
> >> >  <value>ID</value>
> >> > </property>
> >> >
> >> > <property>
> >> >  <name>fs.s3.awsSecretAccessKey</name>
> >> >  <value>SECRET</value>
> >> > </property>
> >> > </configuration>
> >> >
> >> > and it seems to start up no problem
> >> >
> >> > my hbase-site.xml
> >> >
> >> > <configuration>
> >> >    <property>
> >> >  <name>hbase.master</name>
> >> >     <value>174.129.15.236:60000</value>
> >> >     <description>The host and port that the HBase master runs at.
> >> >     A value of 'local' runs the master and a regionserver in
> >> >     a single process.
> >> >     </description>
> >> >   </property>
> >> >
> >> >  <property>
> >> >    <name>hbase.rootdir</name>
> >> >    <value>s3://hbase</value>
> >> >    <description>The directory shared by region servers.
> >> >    </description>
> >> >  </property>
> >> >
> >> > </configuration>
> >> >
> >> >
> >> > keeps giving me
> >> >
> >> > ]
> >> > 2009-08-06 17:20:44,526 ERROR org.apache.hadoop.hbase.master.HMaster:
> Can
> >> > not start master
> >> > java.lang.NoClassDefFoundError: org/jets3t/service/S3ServiceException
> >> >        at
> >> >
> >>
> org.apache.hadoop.fs.s3.S3FileSystem.createDefaultStore(S3FileSystem.java:84)
> >> >        at
> >> > org.apache.hadoop.fs.s3.S3FileSystem.initialize(S3FileSystem.java:74)
> >> >        at
> >> > org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1367)
> >> >        at
> org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:56)
> >> >        at
> org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1379)
> >> >        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:215)
> >> >        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:120)
> >> >        at
> org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:186)
> >> >        at
> org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:156)
> >> >        at
> >> >
> >>
> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:96)
> >> >        at
> >> >
> >>
> org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:78)
> >> >        at
> >> org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1013)
> >> >        at
> org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1057)
> >> > Caused by: java.lang.ClassNotFoundException:
> >> > org.jets3t.service.S3ServiceException
> >> >        at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
> >> >        at java.security.AccessController.doPrivileged(Native Method)
> >> >        at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
> >> >        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
> >> >        at
> sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
> >> >        at java.lang.ClassLoader.loadClass(ClassLoader.java:252)
> >> >        at
> java.lang.ClassLoader.loadClassInternal(ClassLoader.java:320)
> >> >
> >> >
> >> > what am i doing wrong here?
> >> >
> >> > Ananth T Sarathy
> >> >
> >>
> >
>

--001636499eb50fa7af047090a5cf--

From common-user-return-16607-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 17:38:45 2009
Return-Path: <common-user-return-16607-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 87013 invoked from network); 7 Aug 2009 17:38:44 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 17:38:44 -0000
Received: (qmail 94534 invoked by uid 500); 7 Aug 2009 17:38:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 94429 invoked by uid 500); 7 Aug 2009 17:38:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 94419 invoked by uid 99); 7 Aug 2009 17:38:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:38:49 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of prashullegaddi@gmail.com designates 209.85.198.229 as permitted sender)
Received: from [209.85.198.229] (HELO rv-out-0506.google.com) (209.85.198.229)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:38:41 +0000
Received: by rv-out-0506.google.com with SMTP id k40so441574rvb.29
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 10:38:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=oBTkR35cYG738qfPUEB4FtLVydJnW+XqKwvTfxY7iPg=;
        b=KRssltuWaw7ikjRwQ8ONfbIr9z1F6ErCxN84+jH2YFbBwOnoIiGKTkkXAK/VuthlN5
         lcuh+gHh90lyACbXKOQZONJpJ3e+Zymqjlq2XPoc4fD7EXhwhCB2d6fgrtJucVirxMph
         pB9CSHNAQnPrED7DZVdGWC/8+itztQtaNSrlw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=mCaHxYUGgWY2u8zySR/mgeX6/CfGnfVvaY05jYRvLQE6lWmlCopHt2WsjiWSKqxMme
         4sVUoP1WIBAoNeiPIFd30kQoO1AnG7o80qsD4vckN6JswnpHdnvwgVV7xdEPDNAe/att
         dJy64vaGdrD5Jkb2NnTS5aznSJDbUwUeesiXI=
MIME-Version: 1.0
Received: by 10.141.5.14 with SMTP id h14mr504340rvi.176.1249666701054; Fri, 
	07 Aug 2009 10:38:21 -0700 (PDT)
Date: Fri, 7 Aug 2009 23:08:21 +0530
Message-ID: <ac6e61fc0908071038u563ae6u5dca31b79b9a6058@mail.gmail.com>
Subject: How to redistribute files on HDFS after adding new machines to 
	cluster?
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd11926cdd549047090b3b4
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd11926cdd549047090b3b4
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

We had a cluster of 9 machines with one name node, and 8 data nodes (2 had
220GB hard disk space, rest had 450GB).
Most of the space on first machines with 250GB disk space was consumed.
Now we added two new machines each with 450GB hard disk space as data nodes.

Is there any way to redistribute files on HDFS so that there will
considerable free space left on first two machines without
downloading the files to one local machine and then uploading it back on
HDFS?

~
Prashant,
SIEL,
IIIT-Hyderabad.

--000e0cd11926cdd549047090b3b4--

From common-user-return-16608-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 17:49:09 2009
Return-Path: <common-user-return-16608-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 92527 invoked from network); 7 Aug 2009 17:49:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 17:49:09 -0000
Received: (qmail 11033 invoked by uid 500); 7 Aug 2009 17:49:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10955 invoked by uid 500); 7 Aug 2009 17:49:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10942 invoked by uid 99); 7 Aug 2009 17:49:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:49:14 +0000
X-ASF-Spam-Status: No, hits=4.0 required=10.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rphulari@gmail.com designates 209.85.198.231 as permitted sender)
Received: from [209.85.198.231] (HELO rv-out-0506.google.com) (209.85.198.231)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:49:05 +0000
Received: by rv-out-0506.google.com with SMTP id k40so443137rvb.29
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 10:48:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:user-agent:date:subject:from
         :to:message-id:thread-topic:thread-index:in-reply-to:mime-version
         :content-type;
        bh=/q5XFX9AOupV5hWsBOTT4G//Pc430gr5BHfHAfa3PyQ=;
        b=c3llgQd+Q48ayQaoTMdJfxQS7DNjY9xVr9rEJ0twDh/PiyV5Gq64NEAiGP7Wxeb67S
         XhjsOm944VH5uWJD8Wq716Nd85hU8JpRuvlWfNNirFA1BaoH/F97cnvIMm9ybaWXwyj6
         VkHZXU9X1+Vx5KlM5xN5qMuYo8qOOdtmMSWrA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=user-agent:date:subject:from:to:message-id:thread-topic
         :thread-index:in-reply-to:mime-version:content-type;
        b=eXQjHRyKMbxrK/oR9dDzAapBvdzckHZcSo+ZxSZsYEkRRKvzTfChUzZ6H++SAvGKMN
         ibCvxJbaHUzSAkPBW7IWJuRolz2mu9DPy+7bjaZRMQiNjcxpnUhIQiwJaSPhVEMUctIt
         ysUCz6CyWJGVysl7M5nxGS0FJCsBp2YL7FLTw=
Received: by 10.141.21.12 with SMTP id y12mr490741rvi.248.1249667324528;
        Fri, 07 Aug 2009 10:48:44 -0700 (PDT)
Received: from ?10.72.121.206? (nat-dip4.cfw-a-gci.corp.yahoo.com [209.131.62.113])
        by mx.google.com with ESMTPS id f42sm7915601rvb.35.2009.08.07.10.48.42
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Fri, 07 Aug 2009 10:48:43 -0700 (PDT)
User-Agent: Microsoft-Entourage/12.20.0.090605
Date: Fri, 07 Aug 2009 10:48:41 -0700
Subject: Re: How to redistribute files on HDFS after adding new machines to 
 cluster?
From: Ravi Phulari <rphulari@gmail.com>
To: <common-user@hadoop.apache.org>,
	prashant ullegaddi <prashullegaddi@gmail.com>
Message-ID: <C6A1B709.10F83%rphulari@gmail.com>
Thread-Topic: How to redistribute files on HDFS after adding new machines to 
 cluster?
Thread-Index: AcoXhvrDXPwqjba5SLy58p+q/D6zugAAFIKb
In-Reply-To: <ac6e61fc0908071038u563ae6u5dca31b79b9a6058@mail.gmail.com>
Mime-version: 1.0
Content-type: multipart/alternative;
	boundary="B_3332486923_4621448"
X-Virus-Checked: Checked by ClamAV on apache.org

--B_3332486923_4621448
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit

Use Rebalancer 

http://hadoop.apache.org/common/docs/r0.20.0/hdfs_user_guide.html#Rebalancer
-
Ravi

On 8/7/09 10:38 AM, "prashant ullegaddi" <prashullegaddi@gmail.com> wrote:

> Hi,
> 
> We had a cluster of 9 machines with one name node, and 8 data nodes (2 had
> 220GB hard disk space, rest had 450GB).
> Most of the space on first machines with 250GB disk space was consumed.
> Now we added two new machines each with 450GB hard disk space as data nodes.
> 
> Is there any way to redistribute files on HDFS so that there will
> considerable free space left on first two machines without
> downloading the files to one local machine and then uploading it back on
> HDFS?
> 
> ~
> Prashant,
> SIEL,
> IIIT-Hyderabad.
> 


--B_3332486923_4621448--



From common-user-return-16609-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 17:59:09 2009
Return-Path: <common-user-return-16609-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 97708 invoked from network); 7 Aug 2009 17:59:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 17:59:09 -0000
Received: (qmail 27853 invoked by uid 500); 7 Aug 2009 17:59:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 27779 invoked by uid 500); 7 Aug 2009 17:59:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 27766 invoked by uid 99); 7 Aug 2009 17:59:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:59:09 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ted.dunning@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 17:59:01 +0000
Received: by gxk18 with SMTP id 18so2086084gxk.5
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 10:58:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=DO0tlfJX5PToLthvFCnWSx599t5JeU1+NMxZf3w72to=;
        b=TYbNR5Wevu7F/rSw/3f8BKe1wdDuIshjeec2qQ6vHQHsartxQdcw5U8pbk2oEy//mM
         EkH0d/JdzgvCu2aPCnwSbGyFfL8t8LUFlBDDhRaDKdxR/NwKM3sSzfyawLRaBROFTd+K
         AXCc3cKM9yLMWeNsa1y44qYw4e/DQ7A1FiO9M=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=BPnM8ajmU7i4eX+bSP7YQ/MaST/xGvZejXMwcuvjtZYuT3L3Lu44kt/5XBXapUyjzD
         PAT3XC4mmfqs0FUXA19SpfdAWwmok675qekpp+gY5lp7aI2ptNFyyvnKnI1hpk4vmUV3
         l8W3BeysHcnTnGVhskLSFhRaAxh4H8ngE9NwU=
MIME-Version: 1.0
Received: by 10.150.206.8 with SMTP id d8mr1689653ybg.85.1249667921096; Fri, 
	07 Aug 2009 10:58:41 -0700 (PDT)
In-Reply-To: <C6A1B709.10F83%rphulari@gmail.com>
References: <ac6e61fc0908071038u563ae6u5dca31b79b9a6058@mail.gmail.com> 
	<C6A1B709.10F83%rphulari@gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Fri, 7 Aug 2009 10:58:21 -0700
Message-ID: <c7d45fc70908071058v42c28b40w3efd182cb99fede3@mail.gmail.com>
Subject: Re: How to redistribute files on HDFS after adding new machines to 
	cluster?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd4cdde86304f047090fc00
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd4cdde86304f047090fc00
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Make sure you rebalance soon after adding the new node.  Otherwise, you will
have an age bias in file distribution.  This can, in some applications, lead
to some strange effects.  For example, if you have log files that you delete
when they get too old, disk space will be freed non-uniformly.  This
shouldn't much affect performance, but it can lead to a need to rebalance
again (and again) later.  Normal file churn combined with occasional
rebalancing should eventually fix this, but it is nicer not to.

On Fri, Aug 7, 2009 at 10:48 AM, Ravi Phulari <rphulari@gmail.com> wrote:

> Use Rebalancer
>
>
> http://hadoop.apache.org/common/docs/r0.20.0/hdfs_user_guide.html#Rebalancer
> -
> Ravi
>
> On 8/7/09 10:38 AM, "prashant ullegaddi" <prashullegaddi@gmail.com> wrote:
>
> > Hi,
> >
> > We had a cluster of 9 machines with one name node, and 8 data nodes (2
> had
> > 220GB hard disk space, rest had 450GB).
> > Most of the space on first machines with 250GB disk space was consumed.
> > Now we added two new machines each with 450GB hard disk space as data
> nodes.
> >
> > Is there any way to redistribute files on HDFS so that there will
> > considerable free space left on first two machines without
> > downloading the files to one local machine and then uploading it back on
> > HDFS?
> >
> > ~
> > Prashant,
> > SIEL,
> > IIIT-Hyderabad.
> >
>
>


-- 
Ted Dunning, CTO
DeepDyve

--000e0cd4cdde86304f047090fc00--

From common-user-return-16610-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 19:11:34 2009
Return-Path: <common-user-return-16610-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 38687 invoked from network); 7 Aug 2009 19:11:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 19:11:34 -0000
Received: (qmail 37677 invoked by uid 500); 7 Aug 2009 19:11:39 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 37598 invoked by uid 500); 7 Aug 2009 19:11:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 37588 invoked by uid 99); 7 Aug 2009 19:11:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 19:11:38 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of edlinuxguru@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 19:11:27 +0000
Received: by bwz19 with SMTP id 19so1653815bwz.13
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 12:11:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=2bU2+6hzifngVSrDnSQf86yxeD4gKLQVergBKcfz4Xg=;
        b=a0B8sVWnumWQw8pU6sZ3YDpSqIiEo6PidrwWdvw0osrJAc3QwLKVIekt/VploejkZd
         2PcItG0f3ei3LUpUPGOl5tLQlt7mKq4szmP/4kLczCehbbMmusqRYLpW7+7cPzZw0JSn
         ffGNh/LhFIWq+Rf6NRxs9Rb2Z9SGEFcJk0IAE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=ilwOIQAGAd034JDjdvogb5ET58pd0mQO5fwQkUlmWAFqGN4ESeAp3CF13pDSS7v9iR
         uLu9eHD7DFzkasbPBjys1lmLYE2uf5phb3XSPRQ4YQVkZSpVfJNcdzRuQYX6ZZWjU4TH
         Z4tH1VNLuM7XShO5FgsLqDPEMUK3XYmCcvLjU=
MIME-Version: 1.0
Received: by 10.239.153.81 with SMTP id y17mr166248hbb.55.1249672266129; Fri, 
	07 Aug 2009 12:11:06 -0700 (PDT)
Date: Fri, 7 Aug 2009 15:11:06 -0400
Message-ID: <cbbf4b570908071211o2d653d64ncb7260a1003be563@mail.gmail.com>
Subject: DataNode Drive failure. (Tails from the front lines)
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I have a hadoop 18.3 cluster. Today I got two nagios alerts. Actually,
I was excited by one of them because I never had a way to test
check_hpacucli. Worked first time NIIIIIIICCEEEEEEEE. (Borat voice.)
-------
Notification Type: PROBLEM

Service: check_remote_datanode
Host: nyhadoopdata10.ops.jointhegrid.com
Address: 10.12.9.20
State: CRITICAL

Date/Time: Fri Aug 7 18:24:58 GMT 2009

Additional Info:

Connection refused

----------------------------------------------------------------------------------------------------------------

Notification Type: PROBLEM

Service: check_hpacucli
Host: nyhadoopdata10.ops.jointhegrid.com
Address: 10.12.9.20
State: CRITICAL

Date/Time: Fri Aug 7 18:23:18 GMT 2009

Additional Info:

CRITICAL Smart Array P400 in Unknown Slot OK/OK/- (LD 1: OK [(1I:1:1
OK)] LD 2: OK [(1I:1:2 OK)] LD 3: OK [(1I:1:3 OK)] LD 4: OK [(1I:1:4
OK)] LD 5: OK [(2I:1:5 OK)] LD 6: OK [(2I:1:6 OK)] LD 7: Failed
[(2I:1:7 Failed)] LD 8: OK [(2I:1:8 OK)])

/usr/sbin/hpacucli ctrl all show config detail

 physicaldrive 2I:1:7
         Port: 2I
         Box: 1
         Bay: 7
         Status: Failed
         Drive Type: Data Drive
         Interface Type: SAS
         Size: 1TB
         Rotational Speed: 7200
         Firmware Revision: HPD1
         Serial Number: XXXXXXXXXXXXXXXXXXXXXXXX
         Model: HP      DB1000BABFF
         PHY Count: 2
         PHY Transfer Rate: 3.0GBPS, Unknown

The drive was labeled as failed. It was in a READ ONLY state and
sections of the drive would produce an IO error while attempting to
read.


The datanode logged.
2009-08-07 14:20:03,153 WARN org.apache.hadoop.dfs.DataNode: DataNode
is shutting down.
directory is not writable: /mnt/disk6/dfs/data/current
2009-08-07 14:20:03,244 INFO org.apache.hadoop.dfs.DataBlockScanner:
Exiting DataBlockScanner thread.
2009-08-07 14:20:03,430 INFO org.apache.hadoop.dfs.DataNode:
writeBlock blk_-2520177395705282298_448274 received exception
java.io.IOException: Read-only file system
2009-08-07 14:20:03,430 ERROR org.apache.hadoop.dfs.DataNode:
DatanodeRegistration(10.12.9.20:50010,
storageID=DS-520493036-10.12.9.20-50010-1239749144772, infoPort=50075,
ipcPort=50020):DataXceiver:
 java.io.IOException: Read-only file system
        at java.io.UnixFileSystem.createFileExclusively(Native Method)
        at java.io.File.createNewFile(File.java:883)
        at org.apache.hadoop.dfs.FSDataset$FSVolume.createTmpFile(FSDataset.java:388)
        at org.apache.hadoop.dfs.FSDataset$FSVolume.createTmpFile(FSDataset.java:359)
        at org.apache.hadoop.dfs.FSDataset.createTmpFile(FSDataset.java:1050)
        at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:983)
        at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2382)
        at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1234)
        at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1092)
        at java.lang.Thread.run(Thread.java:619)

2009-08-07 14:20:32,974 INFO org.apache.hadoop.dfs.DataNode:
DatanodeRegistration(10.12.9.20:50010,
storageID=DS-520493036-10.12.9.20-50010-1239749144772, infoPort=50075,
ipcPort=50020):Finishing Dat
aNode in: FSDataset{dirpath='/mnt/disk0/dfs/data/current,/mnt/disk1/dfs/data/current,/mnt/disk2/dfs/data/current,/mnt/disk3/dfs/data/current,/mnt/disk4/dfs/data/current,/mnt/disk5/dfs/data/current,/m
nt/disk6/dfs/data/current,/mnt/disk7/dfs/data/current'}
2009-08-07 14:20:32,974 INFO org.mortbay.util.ThreadedServer: Stopping
Acceptor ServerSocket[addr=0.0.0.0/0.0.0.0,port=0,localport=50075]
2009-08-07 14:20:32,977 INFO org.mortbay.http.SocketListener: Stopped
SocketListener on 0.0.0.0:50075
2009-08-07 14:20:33,155 INFO org.mortbay.util.Container: Stopped
HttpContext[/static,/static]
2009-08-07 14:20:33,293 INFO org.mortbay.util.Container: Stopped
HttpContext[/logs,/logs]
2009-08-07 14:20:33,293 INFO org.mortbay.util.Container: Stopped
org.mortbay.jetty.servlet.WebApplicationHandler@7444f787
2009-08-07 14:20:33,432 INFO org.mortbay.util.Container: Stopped
WebApplicationContext[/,/]
2009-08-07 14:20:33,432 INFO org.mortbay.util.Container: Stopped
org.mortbay.jetty.Server@b035079
2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: Stopping
server on 50020
2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: Stopping
IPC Server Responder
2009-08-07 14:20:33,432 INFO org.apache.hadoop.dfs.DataNode: Waiting
for threadgroup to exit, active threads is 0
2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: IPC Server
handler 0 on 50020: exiting
2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: Stopping
IPC Server listener on 50020
2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: IPC Server
handler 1 on 50020: exiting
2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: IPC Server
handler 2 on 50020: exiting
2009-08-07 14:20:33,434 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at nyhadoopdata10/10.12.9.20
************************************************************/

As we can see here the data node shutdown. Should one disk entering a
Read Only state really shut down the entire datanode? The datanode
happily restarts once the disk was unmounted. just wondering?

From common-user-return-16611-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 20:29:55 2009
Return-Path: <common-user-return-16611-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 57957 invoked from network); 7 Aug 2009 20:29:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 20:29:55 -0000
Received: (qmail 46286 invoked by uid 500); 7 Aug 2009 20:30:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 46219 invoked by uid 500); 7 Aug 2009 20:29:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 46209 invoked by uid 99); 7 Aug 2009 20:29:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 20:29:59 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 20:29:51 +0000
Received: by fxm24 with SMTP id 24so1873043fxm.36
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 13:29:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=X+s4pe1cfaU8hKdT+RkCDLY4J0zVJSAj69pQyuV7wNs=;
        b=xQ0t+J3eKmT4BE+U/EceoxKKSW7tnz4GAA4L6BWCA5siYavT7dgdlHrqtQ3pJEsiJX
         NRw1a/xOo5LA2XSiYjiFo5y/LuR0JXyllYGlFTIZYSCn5IEQ5SCBYim/NBfslpPBSI+z
         zVuMWJ615Qayg/r2oJEighsoPo0gJJ2Ku//yc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=tvW3+joyEguAwjhB3FaYq5aI4FpodrXeBT6K1iGve5FLo2USLCi6KXWbeg3cWgD58w
         MZFGu+xF0E17d+X9kuN/yGPh9Ucg9UnUhv0d2TXCYrwZNEYmbdv78ZITmtyNloigbYGY
         sOMIrztBNyV4Ac29jwMc6zNkx10J9Vf3ilvKs=
MIME-Version: 1.0
Received: by 10.223.115.12 with SMTP id g12mr382853faq.92.1249676970613; Fri, 
	07 Aug 2009 13:29:30 -0700 (PDT)
In-Reply-To: <4A7BECD9.20303@apache.org>
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com>
	 <4A7BECD9.20303@apache.org>
Date: Fri, 7 Aug 2009 23:29:30 +0300
Message-ID: <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com>
Subject: Re: HADOOP-4539 question
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c5b351eadb7b04709317c7
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5b351eadb7b04709317c7
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

What is the recommended a utility for this?

Thanks.

2009/8/7 Steve Loughran <stevel@apache.org>

> Stas Oskin wrote:
>
>> Hi.
>>
>> I checked this ticket and I like what I found.
>>
>> Had question about it, and hoped someone can answer it:
>>
>> If I have a NN, and BN, and the NN fails, how the DFS clients will know
>> how
>> to connect to the new IP?
>>
>> It will be a config level setting?
>>
>> Or it needs to be achieved via external Linux HA scripts?
>>
>> Thanks!
>>
>>
> right now the new NN has to come up with the same hostname and IP address
> as the original
>

--001636c5b351eadb7b04709317c7--

From common-user-return-16612-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 20:46:04 2009
Return-Path: <common-user-return-16612-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63291 invoked from network); 7 Aug 2009 20:46:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 20:46:03 -0000
Received: (qmail 80420 invoked by uid 500); 7 Aug 2009 20:46:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80362 invoked by uid 500); 7 Aug 2009 20:46:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 80352 invoked by uid 99); 7 Aug 2009 20:46:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 20:46:08 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 20:45:57 +0000
Received: by gxk18 with SMTP id 18so2216683gxk.5
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 13:45:35 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.79.17 with SMTP id c17mr1265727agb.9.1249677615340; Fri, 07 
	Aug 2009 13:40:15 -0700 (PDT)
From: Christophe Bisciglia <christophe@cloudera.com>
Date: Fri, 7 Aug 2009 13:39:54 -0700
Message-ID: <69035570908071339i35999f60sd0433d5aebc960cb@mail.gmail.com>
Subject: Job Posting: Sales Engineer @ Cloudera
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016361e8962589cac0470933ec8
X-Virus-Checked: Checked by ClamAV on apache.org

--0016361e8962589cac0470933ec8
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hadoop Fans,
We are looking to hire a sales engineer based in the bay area that can
travel as needed. Following is the full job description, but if you know
your Hadoop, have experience working with customers, and are excited about
helping new enterprise users work with lots of data, please read on. If you
are interested, please send a resume and introduction to
jobs+apache@cloudera.com <jobs%2Bapache@cloudera.com>

Cheers,
Christophe

No recruiters please.
Cloudera is looking for a Sales Engineer

Cloudera seeks a full-time Sales Engineer to provide hands-on assistance to
its sales team in technical customer engagements. This person will work
closely with Cloudera's sales team to develop opportunities. In this
capacity, the Sales Engineer will work remotely and on-site with customers
on installing, configuring and using Hadoop and related open source tools
and Cloudera's products. This requires a combination of software
architecture, design and implementation skills (hard-core coder). The SE
will accompany salespeople on customer calls, and in on-line meetings. When
necessary, the SE will work with customers before and after the sale to make
them successful. Projects will be handled remotely, from Cloudera's offices,
and on-site with customers.

*RESPONSIBILITIES*

   - Assist the sales team in assessing the technical fit of customer
   requirements to Cloudera products and services.
   - Explain to prospects, in meetings, by email, at conferences and
   elsewhere, how Hadoop and Cloudera's products work.
   - Provide advice and help, including hands-on coding and debugging, to
   make prospective and existing customers successful.
   - SEs are a critical part of the sales team, representing the company
   personally in customer engagements, and must be able to impart key
   technical, product and company information to advance an opportunity while
   maintaining a professional demeanor and positive attitude

*EXPERIENCE*

   - Must be capable of relationship development and opportunity
   identification
   - At least 4 years' experience in software development
   - At least 2 years' experience in a customer-facing technical role,
   preferably as a sales engineer
   - Excellent verbal, written and interpersonal communication skills
   - Strong development and debugging skills in Java, C++, C required.
   Knowledge of Perl, Python, PHP, Ruby and similar scripting languages
   preferred.
   - Knowledge of Hadoop strongly preferred. Experience in large-scale
   distributed systems accepted.
   - BS degree preferred

If you are interested, please send your resume to jobs+apache@cloudera.com.

Cloudera, the commercial Hadoop company, develops and distributes Hadoop,
the open source software that powers the data processing engines of the
world's largest and most popular web sites. Founded by leading experts on
big data from Facebook, Google, Oracle and Yahoo, Cloudera's mission is to
bring the power of Hadoop, MapReduce, and distributed storage to companies
of all sizes in the enterprise, Internet and government sectors.
Headquartered in Silicon Valley, Cloudera has financial backing from Accel
Partners and Greylock Partners with angel investors who include Jeff Weiner
(CEO of Linkedin), Caterina Fake (founder Flickr, Hunch), Diane Greene
(Founder and former CEO of VMware), Marten Mickos (former CEO of MySQL), and
Qi Lu (President of Online Services at Microsoft). Cloudera's advisors
include the founders of the Hadoop project, Doug Cutting and Mike Cafarella.
Cloudera's engineering team is a flat organization with minimal process, and
an emphasis on inter-personal communication to stay coordinated while
keeping everything extremely agile. Cloudera is located in Burlingame, CA.

-- 
get hadoop: cloudera.com/hadoop
online training: cloudera.com/hadoop-training
blog: cloudera.com/blog
twitter: twitter.com/cloudera

--0016361e8962589cac0470933ec8--

From common-user-return-16613-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 21:02:42 2009
Return-Path: <common-user-return-16613-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70381 invoked from network); 7 Aug 2009 21:02:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 21:02:42 -0000
Received: (qmail 5821 invoked by uid 500); 7 Aug 2009 21:02:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 5724 invoked by uid 500); 7 Aug 2009 21:02:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 5714 invoked by uid 99); 7 Aug 2009 21:02:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 21:02:46 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nvijayap@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 21:02:32 +0000
Received: by vws40 with SMTP id 40so1867059vws.2
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 14:02:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=KFfao0rB+b7KEMHOsEwof92rjUmU/4dg7nlbp3Tf4Qk=;
        b=jJNoSc5OXNRVkVTRZJlI2vw+Jy6BRU9Pl5rnIa7vgwgJAv+dE5Xl8Mu5nV3s7+O6ho
         TMSzEse5WbpkbfZctkYyuRarzKKVB8r0cVfKTRipuKNNuCHXraVPxWPNkIYXrYhSE1P3
         ZeGP1MOcInZPt68mnZ/ZmhtV2w3KGZgirHVJc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=pQyAaNEL3uMP/0ZXHXVW29/pUScnWQbRKdXi6VnX0q36Q4zBD+inbhIYimife7ttoC
         1pNuZGAts7N7ZrUXbpktsUioeKXfuU1P1xaWEqjYYDsxnJHpChsfwmfZW5p4OvxsKBLW
         SPi+RiI1hZbhZM+u/dbTANM+BDOhTDghkU8qY=
MIME-Version: 1.0
Received: by 10.220.92.137 with SMTP id r9mr1574405vcm.40.1249678930362; Fri, 
	07 Aug 2009 14:02:10 -0700 (PDT)
In-Reply-To: <69035570908071339i35999f60sd0433d5aebc960cb@mail.gmail.com>
References: <69035570908071339i35999f60sd0433d5aebc960cb@mail.gmail.com>
Date: Fri, 7 Aug 2009 14:02:10 -0700
Message-ID: <773580c10908071402u2afd5d9dybbbe0857a3a12746@mail.gmail.com>
Subject: Re: Job Posting: Sales Engineer @ Cloudera
From: Naga Vijayapuram <nvijayap@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

I am resident of bay area and have experience with business
development / customer support.

You can view my resume at - http://www.sansthal-us.com/naga/vijay.html
- Use naga / vijayRes1729 to login.

Thanks,
Naga Vijayapuram - 650-759-6990


On Fri, Aug 7, 2009 at 1:39 PM, Christophe
Bisciglia<christophe@cloudera.com> wrote:
> Hadoop Fans,
> We are looking to hire a sales engineer based in the bay area that can
> travel as needed. Following is the full job description, but if you know
> your Hadoop, have experience working with customers, and are excited abou=
t
> helping new enterprise users work with lots of data, please read on. If y=
ou
> are interested, please send a resume and introduction to
> jobs+apache@cloudera.com <jobs%2Bapache@cloudera.com>
>
> Cheers,
> Christophe
>
> No recruiters please.
> Cloudera is looking for a Sales Engineer
>
> Cloudera seeks a full-time Sales Engineer to provide hands-on assistance =
to
> its sales team in technical customer engagements. This person will work
> closely with Cloudera's sales team to develop opportunities. In this
> capacity, the Sales Engineer will work remotely and on-site with customer=
s
> on installing, configuring and using Hadoop and related open source tools
> and Cloudera's products. This requires a combination of software
> architecture, design and implementation skills (hard-core coder). The SE
> will accompany salespeople on customer calls, and in on-line meetings. Wh=
en
> necessary, the SE will work with customers before and after the sale to m=
ake
> them successful. Projects will be handled remotely, from Cloudera's offic=
es,
> and on-site with customers.
>
> *RESPONSIBILITIES*
>
> =A0 - Assist the sales team in assessing the technical fit of customer
> =A0 requirements to Cloudera products and services.
> =A0 - Explain to prospects, in meetings, by email, at conferences and
> =A0 elsewhere, how Hadoop and Cloudera's products work.
> =A0 - Provide advice and help, including hands-on coding and debugging, t=
o
> =A0 make prospective and existing customers successful.
> =A0 - SEs are a critical part of the sales team, representing the company
> =A0 personally in customer engagements, and must be able to impart key
> =A0 technical, product and company information to advance an opportunity =
while
> =A0 maintaining a professional demeanor and positive attitude
>
> *EXPERIENCE*
>
> =A0 - Must be capable of relationship development and opportunity
> =A0 identification
> =A0 - At least 4 years' experience in software development
> =A0 - At least 2 years' experience in a customer-facing technical role,
> =A0 preferably as a sales engineer
> =A0 - Excellent verbal, written and interpersonal communication skills
> =A0 - Strong development and debugging skills in Java, C++, C required.
> =A0 Knowledge of Perl, Python, PHP, Ruby and similar scripting languages
> =A0 preferred.
> =A0 - Knowledge of Hadoop strongly preferred. Experience in large-scale
> =A0 distributed systems accepted.
> =A0 - BS degree preferred
>
> If you are interested, please send your resume to jobs+apache@cloudera.co=
m.
>
> Cloudera, the commercial Hadoop company, develops and distributes Hadoop,
> the open source software that powers the data processing engines of the
> world's largest and most popular web sites. Founded by leading experts on
> big data from Facebook, Google, Oracle and Yahoo, Cloudera's mission is t=
o
> bring the power of Hadoop, MapReduce, and distributed storage to companie=
s
> of all sizes in the enterprise, Internet and government sectors.
> Headquartered in Silicon Valley, Cloudera has financial backing from Acce=
l
> Partners and Greylock Partners with angel investors who include Jeff Wein=
er
> (CEO of Linkedin), Caterina Fake (founder Flickr, Hunch), Diane Greene
> (Founder and former CEO of VMware), Marten Mickos (former CEO of MySQL), =
and
> Qi Lu (President of Online Services at Microsoft). Cloudera's advisors
> include the founders of the Hadoop project, Doug Cutting and Mike Cafarel=
la.
> Cloudera's engineering team is a flat organization with minimal process, =
and
> an emphasis on inter-personal communication to stay coordinated while
> keeping everything extremely agile. Cloudera is located in Burlingame, CA=
.
>
> --
> get hadoop: cloudera.com/hadoop
> online training: cloudera.com/hadoop-training
> blog: cloudera.com/blog
> twitter: twitter.com/cloudera
>

From common-user-return-16614-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 07 23:03:43 2009
Return-Path: <common-user-return-16614-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 16955 invoked from network); 7 Aug 2009 23:03:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 7 Aug 2009 23:03:43 -0000
Received: (qmail 99469 invoked by uid 500); 7 Aug 2009 23:03:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 99374 invoked by uid 500); 7 Aug 2009 23:03:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 99364 invoked by uid 99); 7 Aug 2009 23:03:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 23:03:47 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 07 Aug 2009 23:03:36 +0000
Received: from SNV-EXBH01.ds.corp.yahoo.com (snv-exbh01.ds.corp.yahoo.com [207.126.227.249])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n77N2pGY037999
	for <common-user@hadoop.apache.org>; Fri, 7 Aug 2009 16:02:53 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:cc:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=QUHFjO1yGzeI/aW+5xPyvIHN+6S23X1yjH7L+dBUlEiBPYoNoTOGTuMdGbcC6zJF
Received: from SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.87]) by SNV-EXBH01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Fri, 7 Aug 2009 16:02:51 -0700
Received: from 172.21.148.186 ([172.21.148.186]) by SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.84]) via Exchange Front-End Server snv-webmail.corp.yahoo.com ([207.126.227.60]) with Microsoft Exchange Server HTTP-DAV ;
 Fri,  7 Aug 2009 23:02:15 +0000
User-Agent: Microsoft-Entourage/12.20.0.090605
Date: Fri, 07 Aug 2009 16:02:14 -0700
Subject: Re: DataNode Drive failure. (Tails from the front lines)
From: Koji Noguchi <knoguchi@yahoo-inc.com>
To: <common-user@hadoop.apache.org>
CC: Boris Shkolnik <borya@yahoo-inc.com>
Message-ID: <C6A20086.14C4A%knoguchi@yahoo-inc.com>
Thread-Topic: DataNode Drive failure. (Tails from the front lines)
Thread-Index: AcoXsxo4MAWCgdpFtUeYz8ZG/hA/xQ==
In-Reply-To: <cbbf4b570908071211o2d653d64ncb7260a1003be563@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-OriginalArrivalTime: 07 Aug 2009 23:02:51.0681 (UTC) FILETIME=[30AE8910:01CA17B3]
X-Virus-Checked: Checked by ClamAV on apache.org

You probably want this.
https://issues.apache.org/jira/browse/HDFS-457

Koji

> As we can see here the data node shutdown. Should one disk entering a
> Read Only state really shut down the entire datanode? The datanode
> happily restarts once the disk was unmounted. just wondering?


On 8/7/09 12:11 PM, "Edward Capriolo" <edlinuxguru@gmail.com> wrote:

> I have a hadoop 18.3 cluster. Today I got two nagios alerts. Actually,
> I was excited by one of them because I never had a way to test
> check_hpacucli. Worked first time NIIIIIIICCEEEEEEEE. (Borat voice.)
> -------
> Notification Type: PROBLEM
> 
> Service: check_remote_datanode
> Host: nyhadoopdata10.ops.jointhegrid.com
> Address: 10.12.9.20
> State: CRITICAL
> 
> Date/Time: Fri Aug 7 18:24:58 GMT 2009
> 
> Additional Info:
> 
> Connection refused
> 
> ------------------------------------------------------------------------------
> ----------------------------------
> 
> Notification Type: PROBLEM
> 
> Service: check_hpacucli
> Host: nyhadoopdata10.ops.jointhegrid.com
> Address: 10.12.9.20
> State: CRITICAL
> 
> Date/Time: Fri Aug 7 18:23:18 GMT 2009
> 
> Additional Info:
> 
> CRITICAL Smart Array P400 in Unknown Slot OK/OK/- (LD 1: OK [(1I:1:1
> OK)] LD 2: OK [(1I:1:2 OK)] LD 3: OK [(1I:1:3 OK)] LD 4: OK [(1I:1:4
> OK)] LD 5: OK [(2I:1:5 OK)] LD 6: OK [(2I:1:6 OK)] LD 7: Failed
> [(2I:1:7 Failed)] LD 8: OK [(2I:1:8 OK)])
> 
> /usr/sbin/hpacucli ctrl all show config detail
> 
>  physicaldrive 2I:1:7
>          Port: 2I
>          Box: 1
>          Bay: 7
>          Status: Failed
>          Drive Type: Data Drive
>          Interface Type: SAS
>          Size: 1TB
>          Rotational Speed: 7200
>          Firmware Revision: HPD1
>          Serial Number: XXXXXXXXXXXXXXXXXXXXXXXX
>          Model: HP      DB1000BABFF
>          PHY Count: 2
>          PHY Transfer Rate: 3.0GBPS, Unknown
> 
> The drive was labeled as failed. It was in a READ ONLY state and
> sections of the drive would produce an IO error while attempting to
> read.
> 
> 
> The datanode logged.
> 2009-08-07 14:20:03,153 WARN org.apache.hadoop.dfs.DataNode: DataNode
> is shutting down.
> directory is not writable: /mnt/disk6/dfs/data/current
> 2009-08-07 14:20:03,244 INFO org.apache.hadoop.dfs.DataBlockScanner:
> Exiting DataBlockScanner thread.
> 2009-08-07 14:20:03,430 INFO org.apache.hadoop.dfs.DataNode:
> writeBlock blk_-2520177395705282298_448274 received exception
> java.io.IOException: Read-only file system
> 2009-08-07 14:20:03,430 ERROR org.apache.hadoop.dfs.DataNode:
> DatanodeRegistration(10.12.9.20:50010,
> storageID=DS-520493036-10.12.9.20-50010-1239749144772, infoPort=50075,
> ipcPort=50020):DataXceiver:
>  java.io.IOException: Read-only file system
>         at java.io.UnixFileSystem.createFileExclusively(Native Method)
>         at java.io.File.createNewFile(File.java:883)
>         at 
> org.apache.hadoop.dfs.FSDataset$FSVolume.createTmpFile(FSDataset.java:388)
>         at 
> org.apache.hadoop.dfs.FSDataset$FSVolume.createTmpFile(FSDataset.java:359)
>         at org.apache.hadoop.dfs.FSDataset.createTmpFile(FSDataset.java:1050)
>         at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:983)
>         at 
> org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2382)
>         at 
> org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1234)
>         at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1092)
>         at java.lang.Thread.run(Thread.java:619)
> 
> 2009-08-07 14:20:32,974 INFO org.apache.hadoop.dfs.DataNode:
> DatanodeRegistration(10.12.9.20:50010,
> storageID=DS-520493036-10.12.9.20-50010-1239749144772, infoPort=50075,
> ipcPort=50020):Finishing Dat
> aNode in: 
> FSDataset{dirpath='/mnt/disk0/dfs/data/current,/mnt/disk1/dfs/data/current,/mn
> t/disk2/dfs/data/current,/mnt/disk3/dfs/data/current,/mnt/disk4/dfs/data/curre
> nt,/mnt/disk5/dfs/data/current,/m
> nt/disk6/dfs/data/current,/mnt/disk7/dfs/data/current'}
> 2009-08-07 14:20:32,974 INFO org.mortbay.util.ThreadedServer: Stopping
> Acceptor ServerSocket[addr=0.0.0.0/0.0.0.0,port=0,localport=50075]
> 2009-08-07 14:20:32,977 INFO org.mortbay.http.SocketListener: Stopped
> SocketListener on 0.0.0.0:50075
> 2009-08-07 14:20:33,155 INFO org.mortbay.util.Container: Stopped
> HttpContext[/static,/static]
> 2009-08-07 14:20:33,293 INFO org.mortbay.util.Container: Stopped
> HttpContext[/logs,/logs]
> 2009-08-07 14:20:33,293 INFO org.mortbay.util.Container: Stopped
> org.mortbay.jetty.servlet.WebApplicationHandler@7444f787
> 2009-08-07 14:20:33,432 INFO org.mortbay.util.Container: Stopped
> WebApplicationContext[/,/]
> 2009-08-07 14:20:33,432 INFO org.mortbay.util.Container: Stopped
> org.mortbay.jetty.Server@b035079
> 2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: Stopping
> server on 50020
> 2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: Stopping
> IPC Server Responder
> 2009-08-07 14:20:33,432 INFO org.apache.hadoop.dfs.DataNode: Waiting
> for threadgroup to exit, active threads is 0
> 2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 0 on 50020: exiting
> 2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: Stopping
> IPC Server listener on 50020
> 2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 1 on 50020: exiting
> 2009-08-07 14:20:33,432 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 2 on 50020: exiting
> 2009-08-07 14:20:33,434 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG:
> /************************************************************
> SHUTDOWN_MSG: Shutting down DataNode at nyhadoopdata10/10.12.9.20
> ************************************************************/
> 
> As we can see here the data node shutdown. Should one disk entering a
> Read Only state really shut down the entire datanode? The datanode
> happily restarts once the disk was unmounted. just wondering?


From common-user-return-16615-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 08 02:04:02 2009
Return-Path: <common-user-return-16615-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 64468 invoked from network); 8 Aug 2009 02:04:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 8 Aug 2009 02:04:02 -0000
Received: (qmail 91968 invoked by uid 500); 8 Aug 2009 02:04:07 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91886 invoked by uid 500); 8 Aug 2009 02:04:07 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91876 invoked by uid 99); 8 Aug 2009 02:04:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 08 Aug 2009 02:04:07 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bharathvissapragada1990@gmail.com designates 209.85.221.188 as permitted sender)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 08 Aug 2009 02:03:58 +0000
Received: by qyk26 with SMTP id 26so1848261qyk.5
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 19:03:37 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=dd/E7mQVrEmTbHfLyB+64PLIIYetXyrAy3Jjxm4m9Oo=;
        b=poSyz7Pas3TiANVbmuHzlPVzTo1mYAilNRZD50ttiEEAGs2fRZ3XzrVFCBiJ4rzdII
         gcK0gV2hPwIy66mnZytOd6Xx/DBCpSvtAz4tS86T5zurAXpaJFZLO0Ieh1x/ypmVrMKf
         czZVjugFiGCIHuWAKTP7nw5PPedtFUjAJduVs=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=oQIG4i9Wi0o+pWcL6y9W+GZSxQE8bBi7NpJ3Z/f1o3gf6CZNhBgZL31QLDTHAvbtxF
         iDT7dybkYwemWTkyXb/QvRlURWw1n6m9KlFkjMgoYSQlUxJgLgbfBkV3/zrqh/wNJrPl
         d3pkCF6q40O0awv72uh926Fas+SCGR+7EghJ8=
MIME-Version: 1.0
Received: by 10.229.97.144 with SMTP id l16mr906596qcn.26.1249697017124; Fri, 
	07 Aug 2009 19:03:37 -0700 (PDT)
In-Reply-To: <4238036a0908070910n16e5a24auc72a187aeea4ef66@mail.gmail.com>
References: <4238036a0908070910n16e5a24auc72a187aeea4ef66@mail.gmail.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Sat, 8 Aug 2009 07:33:17 +0530
Message-ID: <73d592f60908071903j5dc036b6qb1e06d2d8c42d8de@mail.gmail.com>
Subject: Re: changing logging
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016364ef507c857bc047097c2ab
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364ef507c857bc047097c2ab
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Print Statements worked out in my case ,,, Dunno whether that approach is
right or not .. but it works fine ..


On Fri, Aug 7, 2009 at 9:40 PM, John Clarke <clarkemjj@gmail.com> wrote:

> Hi,
>
> I am using Hadoop 0.18.3. I'm trying to get my app to output DEBUG messages
> to the console using a custom conversion pattern.
>
> I'm editing the log4j.properties file in the conf folder but the changes
> don't seem to work. All the log messages are still INFO and higher and the
> pattern is not changing either.
>
> I'm currently running as a local Java app in Eclipse rather than in Hadoop.
>
> Any ideas?
>
> Cheers,
> John
>

--0016364ef507c857bc047097c2ab--

From common-user-return-16616-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 08 05:11:20 2009
Return-Path: <common-user-return-16616-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 94846 invoked from network); 8 Aug 2009 05:11:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 8 Aug 2009 05:11:19 -0000
Received: (qmail 83534 invoked by uid 500); 8 Aug 2009 05:11:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 83471 invoked by uid 500); 8 Aug 2009 05:11:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 83461 invoked by uid 99); 8 Aug 2009 05:11:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 08 Aug 2009 05:11:24 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of prashullegaddi@gmail.com designates 209.85.198.233 as permitted sender)
Received: from [209.85.198.233] (HELO rv-out-0506.google.com) (209.85.198.233)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 08 Aug 2009 05:11:15 +0000
Received: by rv-out-0506.google.com with SMTP id k40so298034rvb.5
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 22:10:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=zofPTIyFBE4weVd00EDfxGaSWHp6YmSiX19DXkEP9E8=;
        b=dKPv9G+frt80mZPu9kqIrkLgquFWgDr+Rr2JhqP7Rg7PWzuCUxalFduWGnO0sjuf6L
         TJ5SWTSTcVbHs1Y0SsXa0LcC+vHN5s9FvOvMVQZKhAM944pXDn+LTRhf2dhm8ZfIssws
         qCQlLH0az7+fjVQVIwRi4m7yjuIcl7eaaoYao=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=IvPP7W3GR/Lq9hK5yrrfWj4ETqsRxT3RBH+bz08LWjF3z746g8zRDRORd71lWXo28q
         icml/wnqWcrMSwkpsvRqwSXb8n3elPONCfAsTaNId4HgvO8ZBWtuCcFeI6wbaBwsHLdV
         Cm7A62d18PT9wIP3rE4JyLaXpsBS2yr5jw4bw=
MIME-Version: 1.0
Received: by 10.141.3.15 with SMTP id f15mr745050rvi.4.1249708252026; Fri, 07 
	Aug 2009 22:10:52 -0700 (PDT)
In-Reply-To: <c7d45fc70908071058v42c28b40w3efd182cb99fede3@mail.gmail.com>
References: <ac6e61fc0908071038u563ae6u5dca31b79b9a6058@mail.gmail.com>
	 <C6A1B709.10F83%rphulari@gmail.com>
	 <c7d45fc70908071058v42c28b40w3efd182cb99fede3@mail.gmail.com>
Date: Sat, 8 Aug 2009 10:40:52 +0530
Message-ID: <ac6e61fc0908072210x60350caaw854b30ccd3fdca53@mail.gmail.com>
Subject: Re: How to redistribute files on HDFS after adding new machines to 
	cluster?
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd113606f573504709a60eb
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd113606f573504709a60eb
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thank you Ravi and Ted.

I ran hadoop balancer without default threshold. It's been running for last
8 hours!
How long does it take given the following DFS stats:

*3140 files and directories, 10295 blocks = 13435 total. Heap Size is 17.88
MB / 963 MB (1%)
*   Capacity : 3.93 TB DFS Remaining : 2.11 TB DFS Used : 1.31 TB DFS
Used%:33.44 % Live
Nodes <http://megh01:50070/dfshealth.jsp#LiveNodes> : 10 Dead
Nodes<http://megh01:50070/dfshealth.jsp#DeadNodes>
: 0

If I interrupt it now, what will happen? I've to run a job now. I think
balancing and running a job
may not happen together as one will slow down the other.

Thanks,
Prashant.

On Fri, Aug 7, 2009 at 11:28 PM, Ted Dunning <ted.dunning@gmail.com> wrote:

> Make sure you rebalance soon after adding the new node.  Otherwise, you
> will
> have an age bias in file distribution.  This can, in some applications,
> lead
> to some strange effects.  For example, if you have log files that you
> delete
> when they get too old, disk space will be freed non-uniformly.  This
> shouldn't much affect performance, but it can lead to a need to rebalance
> again (and again) later.  Normal file churn combined with occasional
> rebalancing should eventually fix this, but it is nicer not to.
>
> On Fri, Aug 7, 2009 at 10:48 AM, Ravi Phulari <rphulari@gmail.com> wrote:
>
> > Use Rebalancer
> >
> >
> >
> http://hadoop.apache.org/common/docs/r0.20.0/hdfs_user_guide.html#Rebalancer
> > -
> > Ravi
> >
> > On 8/7/09 10:38 AM, "prashant ullegaddi" <prashullegaddi@gmail.com>
> wrote:
> >
> > > Hi,
> > >
> > > We had a cluster of 9 machines with one name node, and 8 data nodes (2
> > had
> > > 220GB hard disk space, rest had 450GB).
> > > Most of the space on first machines with 250GB disk space was consumed.
> > > Now we added two new machines each with 450GB hard disk space as data
> > nodes.
> > >
> > > Is there any way to redistribute files on HDFS so that there will
> > > considerable free space left on first two machines without
> > > downloading the files to one local machine and then uploading it back
> on
> > > HDFS?
> > >
> > > ~
> > > Prashant,
> > > SIEL,
> > > IIIT-Hyderabad.
> > >
> >
> >
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>

--000e0cd113606f573504709a60eb--

From common-user-return-16617-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 08 05:14:41 2009
Return-Path: <common-user-return-16617-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 95197 invoked from network); 8 Aug 2009 05:14:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 8 Aug 2009 05:14:41 -0000
Received: (qmail 85637 invoked by uid 500); 8 Aug 2009 05:14:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 85556 invoked by uid 500); 8 Aug 2009 05:14:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 85546 invoked by uid 99); 8 Aug 2009 05:14:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 08 Aug 2009 05:14:46 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of prashullegaddi@gmail.com designates 209.85.198.232 as permitted sender)
Received: from [209.85.198.232] (HELO rv-out-0506.google.com) (209.85.198.232)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 08 Aug 2009 05:14:38 +0000
Received: by rv-out-0506.google.com with SMTP id k40so516422rvb.29
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 22:14:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=vCOAXoNZSpvmAn5+EBHbmrXjWz48AJhshFqP+iaJPoA=;
        b=CJOQ0eywWkmpPNna6FQGxxYW7ornYY4zSl4fTV+DTHkJzlUUH0uV85Tma/SZBnCYdm
         VNZNtJVwhqqNT/crVl81QU1FYRr/xvz/CZ8PkEsI9J7lk5poY/Ax+e355Y1XNsmJSLjh
         LGIMmaQnY+xJrQK3Z4q4Eh+sdF1pLSGT8B03Q=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=cWTiItXvvXnziK5PO/IZVQxmXQ6MHhRPbkRjXT8jdIK6ZfJJlGdAEC0TrPaw5rP4gI
         N4A3RC6x5TrLE+mHlyLDWHJUoBhkS8Mv9F2o7pJcCeeEC+zieEiLxIKyfTmNvdEp6bIn
         uoaKD/WtDGskegZLIb4XWbcG2EFzQL1tWKWVg=
MIME-Version: 1.0
Received: by 10.141.5.1 with SMTP id h1mr806815rvi.293.1249708457865; Fri, 07 
	Aug 2009 22:14:17 -0700 (PDT)
In-Reply-To: <ac6e61fc0908072210x60350caaw854b30ccd3fdca53@mail.gmail.com>
References: <ac6e61fc0908071038u563ae6u5dca31b79b9a6058@mail.gmail.com>
	 <C6A1B709.10F83%rphulari@gmail.com>
	 <c7d45fc70908071058v42c28b40w3efd182cb99fede3@mail.gmail.com>
	 <ac6e61fc0908072210x60350caaw854b30ccd3fdca53@mail.gmail.com>
Date: Sat, 8 Aug 2009 10:44:17 +0530
Message-ID: <ac6e61fc0908072214r4802ba76if915adf9d937d421@mail.gmail.com>
Subject: Re: How to redistribute files on HDFS after adding new machines to 
	cluster?
From: prashant ullegaddi <prashullegaddi@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd0ecaab4343204709a6cb5
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd0ecaab4343204709a6cb5
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Sorry for the mistake in the previous mail. I meant I ran balancer with
default threshold.


On Sat, Aug 8, 2009 at 10:40 AM, prashant ullegaddi <
prashullegaddi@gmail.com> wrote:

> Thank you Ravi and Ted.
>
> I ran hadoop balancer without default threshold. It's been running for last
> 8 hours!
> How long does it take given the following DFS stats:
>
> *3140 files and directories, 10295 blocks = 13435 total. Heap Size is
> 17.88 MB / 963 MB (1%)
> *   Capacity : 3.93 TB DFS Remaining : 2.11 TB DFS Used : 1.31 TB DFS
> Used% : 33.44 % Live Nodes <http://megh01:50070/dfshealth.jsp#LiveNodes> :10 Dead
> Nodes <http://megh01:50070/dfshealth.jsp#DeadNodes>  : 0
>
> If I interrupt it now, what will happen? I've to run a job now. I think
> balancing and running a job
> may not happen together as one will slow down the other.
>
> Thanks,
> Prashant.
>
>
> On Fri, Aug 7, 2009 at 11:28 PM, Ted Dunning <ted.dunning@gmail.com>wrote:
>
>> Make sure you rebalance soon after adding the new node.  Otherwise, you
>> will
>> have an age bias in file distribution.  This can, in some applications,
>> lead
>> to some strange effects.  For example, if you have log files that you
>> delete
>> when they get too old, disk space will be freed non-uniformly.  This
>> shouldn't much affect performance, but it can lead to a need to rebalance
>> again (and again) later.  Normal file churn combined with occasional
>> rebalancing should eventually fix this, but it is nicer not to.
>>
>> On Fri, Aug 7, 2009 at 10:48 AM, Ravi Phulari <rphulari@gmail.com> wrote:
>>
>> > Use Rebalancer
>> >
>> >
>> >
>> http://hadoop.apache.org/common/docs/r0.20.0/hdfs_user_guide.html#Rebalancer
>> > -
>> > Ravi
>> >
>> > On 8/7/09 10:38 AM, "prashant ullegaddi" <prashullegaddi@gmail.com>
>> wrote:
>> >
>> > > Hi,
>> > >
>> > > We had a cluster of 9 machines with one name node, and 8 data nodes (2
>> > had
>> > > 220GB hard disk space, rest had 450GB).
>> > > Most of the space on first machines with 250GB disk space was
>> consumed.
>> > > Now we added two new machines each with 450GB hard disk space as data
>> > nodes.
>> > >
>> > > Is there any way to redistribute files on HDFS so that there will
>> > > considerable free space left on first two machines without
>> > > downloading the files to one local machine and then uploading it back
>> on
>> > > HDFS?
>> > >
>> > > ~
>> > > Prashant,
>> > > SIEL,
>> > > IIIT-Hyderabad.
>> > >
>> >
>> >
>>
>>
>> --
>> Ted Dunning, CTO
>> DeepDyve
>>
>
>

--000e0cd0ecaab4343204709a6cb5--

From common-user-return-16618-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 08 05:42:52 2009
Return-Path: <common-user-return-16618-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 4781 invoked from network); 8 Aug 2009 05:42:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 8 Aug 2009 05:42:52 -0000
Received: (qmail 94149 invoked by uid 500); 8 Aug 2009 05:42:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 94080 invoked by uid 500); 8 Aug 2009 05:42:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 94070 invoked by uid 99); 8 Aug 2009 05:42:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 08 Aug 2009 05:42:56 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 08 Aug 2009 05:42:47 +0000
Received: by gxk18 with SMTP id 18so2475053gxk.5
        for <common-user@hadoop.apache.org>; Fri, 07 Aug 2009 22:42:26 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=X50legd4jL72mEd3uqgKAjn2IjEnr/eM0OldS1jKFiw=;
        b=gwJ78RLZkNRoqtVDbcVsPhhUP0Ee5F7vDDmSkj3X3PDs7RThs/1iNeRI4DH90WR4np
         xrWVIq06An7Ug1lIsQTi5VsGzLTQe2OED22srj/BMZTk/n8cj0bwrk0cCzrH35klZzge
         Gok8yNMI/MqnhUEzhZWY/EJMlut/8S5y/6X1w=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=NwHZr4eo4mNjs3ia4D5oZ0rO27MWGXvc6XGvI/RIP29dF17vl+s/y9BYiPp+HKf/Oj
         dFFm2tZIJCId/VNZCzFKwelKbP37eaojEKtCsyWsjxKindY5K1d2NFtmcWIGI7CzslJf
         G2+y9ZJ2vdBSGurReZNyaTagM4EYs7H+0JOGA=
MIME-Version: 1.0
Received: by 10.151.108.10 with SMTP id k10mr209842ybm.107.1249710146314; Fri, 
	07 Aug 2009 22:42:26 -0700 (PDT)
In-Reply-To: <ac6e61fc0908072210x60350caaw854b30ccd3fdca53@mail.gmail.com>
References: <ac6e61fc0908071038u563ae6u5dca31b79b9a6058@mail.gmail.com> 
	<C6A1B709.10F83%rphulari@gmail.com> <c7d45fc70908071058v42c28b40w3efd182cb99fede3@mail.gmail.com> 
	<ac6e61fc0908072210x60350caaw854b30ccd3fdca53@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Fri, 7 Aug 2009 22:42:06 -0700
Message-ID: <c7d45fc70908072242j31d12cabwba70c738176fda9b@mail.gmail.com>
Subject: Re: How to redistribute files on HDFS after adding new machines to 
	cluster?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001517573e0857e1b104709ad167
X-Virus-Checked: Checked by ClamAV on apache.org

--001517573e0857e1b104709ad167
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

I think that I remember that you essentially doubled your storage before
starting balancing.

This means that about 1 TB will need to be copied.  By default the balancer
only moves 1MB/s (per node, I believe).  This means that it will take a LONG
time to balance your cluster.  You can increase this speed limit, but there
isn't usually much need to do so.  Running the balancer while using your
cluster is generally not a big deal since the balancer consumes so little
bandwidth.

On Fri, Aug 7, 2009 at 10:10 PM, prashant ullegaddi <
prashullegaddi@gmail.com> wrote:

> *   Capacity : 3.93 TB DFS Remaining : 2.11 TB DFS Used : 1.31 TB DFS
> Used%:33.44 % Live
> Nodes <http://megh01:50070/dfshealth.jsp#LiveNodes> : 10 Dead
> Nodes<http://megh01:50070/dfshealth.jsp#DeadNodes>
> : 0
>
> If I interrupt it now, what will happen? I've to run a job now. I think
> balancing and running a job
> may not happen together as one will slow down the other.
>



-- 
Ted Dunning, CTO
DeepDyve

--001517573e0857e1b104709ad167--

From common-user-return-16619-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 02:28:27 2009
Return-Path: <common-user-return-16619-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 64059 invoked from network); 9 Aug 2009 02:28:27 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 02:28:27 -0000
Received: (qmail 70015 invoked by uid 500); 9 Aug 2009 02:28:31 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 69920 invoked by uid 500); 9 Aug 2009 02:28:31 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 69910 invoked by uid 99); 9 Aug 2009 02:28:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 02:28:31 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of harold.valdivia@upr.edu designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 02:28:22 +0000
Received: by ewy26 with SMTP id 26so2410856ewy.29
        for <common-user@hadoop.apache.org>; Sat, 08 Aug 2009 19:28:01 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.210.102.12 with SMTP id z12mr3436210ebb.5.1249784881434; Sat, 
	08 Aug 2009 19:28:01 -0700 (PDT)
Date: Sat, 8 Aug 2009 22:28:01 -0400
Message-ID: <c1f27e270908081928r73c39555n39043c583c30acee@mail.gmail.com>
Subject: How to break a hadoop-cluster in subclusters (how to group physical 
	nodes)?
From: Harold Valdivia Garcia <harold.valdivia@upr.edu>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015174c4320e750320470ac3729
X-Virus-Checked: Checked by ClamAV on apache.org

--0015174c4320e750320470ac3729
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi, everyone. How can I split the cluster in subcluster?. I want to break my
cluster in regions (physical groups of nodes), for example I'd like to have
a region for only sorting, other for only joins, other for only groupby, and
so on..... If I submit a "x-task" the JobTracker should send this job to the
"x-region".

Is there a way to make phisical groups of TaskTrackers?

Please. Can anyone give me a hint?. Thanks for all.
Harold.

-- 
******************************************
Harold Dwight Valdivia Garcia
Graduate Student
M.S Computer Engineering
University of Puerto Rico, Mayaguez Campus
******************************************

--0015174c4320e750320470ac3729--

From common-user-return-16620-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 04:52:45 2009
Return-Path: <common-user-return-16620-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 2269 invoked from network); 9 Aug 2009 04:52:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 04:52:45 -0000
Received: (qmail 17258 invoked by uid 500); 9 Aug 2009 04:52:50 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 17177 invoked by uid 500); 9 Aug 2009 04:52:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 17167 invoked by uid 99); 9 Aug 2009 04:52:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 04:52:50 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ted.dunning@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 04:52:42 +0000
Received: by yxe15 with SMTP id 15so3149823yxe.5
        for <common-user@hadoop.apache.org>; Sat, 08 Aug 2009 21:52:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=jevdLM2CwzlkE07nr5gELQwIv5sV0kAeAgJj8WOTCvU=;
        b=vDvPzNaNdnRbGWXAQwCIKyX+JfFb2ECcr4O1PWnfpaZi+YFsroQRRaQUZo3QYCpay7
         5V6izrgQMeXxAmVEKuELaNMW9iGNv8Zdf9fGDxpXPUPr75vTn+mYM5ZN3vL0VjFoNYfq
         IhLu9ngK8k1FpaZ46yVqrx6fa7lSuXhz44gzI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=kXmTUeRxUqTJqX5wZHumZRFOQxc6PHhb6TJRtkTZaJmsmT1hQz2lcZUCv4in/q+4DG
         pXbAU5y9DK9K0opCjMVqu9mc0NP2pTkhCl+/WSsyrTvsBwo+vxgeQR3gZOAF+B4IjvPN
         EyiIMiQtbF8dB94W91W9pPaeFAKtIYnwIjdYc=
MIME-Version: 1.0
Received: by 10.150.133.13 with SMTP id g13mr371725ybd.131.1249793541218; Sat, 
	08 Aug 2009 21:52:21 -0700 (PDT)
In-Reply-To: <c1f27e270908081928r73c39555n39043c583c30acee@mail.gmail.com>
References: <c1f27e270908081928r73c39555n39043c583c30acee@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Sat, 8 Aug 2009 21:52:01 -0700
Message-ID: <c7d45fc70908082152j9f3b716l8e2aa4b008ed27e5@mail.gmail.com>
Subject: Re: How to break a hadoop-cluster in subclusters (how to group 
	physical nodes)?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd47df81122f70470ae3c04
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd47df81122f70470ae3c04
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Why?

I would imagine that you could create multiple clusters of TaskTrackers each
associated with a single JobTracker all of which would use the same data
cluster composed of a NameNode plus data nodes.

But what do you think that would buy you?  Mostly like you will simply wind
up with much lower cluster utilization combined with configuration
headaches.

On Sat, Aug 8, 2009 at 7:28 PM, Harold Valdivia Garcia <
harold.valdivia@upr.edu> wrote:

> for example I'd like to have a region for only sorting, other for only
> joins, other for only groupby
>



-- 
Ted Dunning, CTO
DeepDyve

--000e0cd47df81122f70470ae3c04--

From common-user-return-16621-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 09:19:30 2009
Return-Path: <common-user-return-16621-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 55430 invoked from network); 9 Aug 2009 09:19:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 09:19:30 -0000
Received: (qmail 1619 invoked by uid 500); 9 Aug 2009 09:19:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 1547 invoked by uid 500); 9 Aug 2009 09:19:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 1537 invoked by uid 99); 9 Aug 2009 09:19:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 09:19:34 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mathias.demare@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 09:19:26 +0000
Received: by bwz10 with SMTP id 10so821313bwz.29
        for <common-user@hadoop.apache.org>; Sun, 09 Aug 2009 02:19:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:cc:content-type;
        bh=Vdrna/glslfS52IHiK4PsYCPR2068GTRqz/rD2YvU/E=;
        b=KSK2JyBvXPrbcs3RyY+U0LS5w6JiUgMf/etyPTJKM/oHhTJuOcK0oUBXF8Pomq1lKn
         Rb3zooRWFXODS05xkKnaZqxEimaJcPjwHPAcNtinF/8tVbmRBPnCeO7gqel/NWi3fOME
         b+Q4lVfM1csjDZ59IquMWC6WX9PtOXEOtLR4k=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        b=s9xxlZ2wht2R+uJY+k/b6IvKyULaXuo3sNsdFZAN372hVtuDQvAaK7XYj+/kHNsE97
         zgFijGmIHjOhgqcuZOtbaPO5e6ntolwtJcUdiyYo2mwMraJ25W0U5z2jBzPw1j1rQuM7
         EXUFnTKzBKR4BBYRGHWnWZBWYva/JTwA/1KZA=
MIME-Version: 1.0
Received: by 10.223.110.72 with SMTP id m8mr648306fap.1.1249809545110; Sun, 09 
	Aug 2009 02:19:05 -0700 (PDT)
Reply-To: mathias.demare@gmail.com
In-Reply-To: <375c60f40908050416w1780c87bl422cb53b6ee77950@mail.gmail.com>
References: <375c60f40908050002n3a110d66ua2672a40bb8ad866@mail.gmail.com> 
	<616DA47B2EF5B944B91846785B512FF4BD3663BEFC@EGL-EX07VS01.ds.corp.yahoo.com> 
	<375c60f40908050416w1780c87bl422cb53b6ee77950@mail.gmail.com>
From: =?UTF-8?Q?Mathias_De_Mar=C3=A9?= <mathias.demare@gmail.com>
Date: Sun, 9 Aug 2009 11:18:45 +0200
Message-ID: <375c60f40908090218i364a5596hbbd3c42a626882f7@mail.gmail.com>
Subject: Re: Some tasks fail to report status between the end of the map and 
	the beginning of the merge
To: Amogh Vasekar <amogh@yahoo-inc.com>
Cc: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Content-Type: multipart/alternative; boundary=001636c5b297f9274d0470b1f599
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5b297f9274d0470b1f599
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I changed the maximum split size to 30000, and now most tasks actually
succeed.
However, I still have the failure problem with some tasks (with a job I was
running yesterday, I got a failure after 1900 tasks).
The problem is that these very few failures can bring down the entire job,
as they sometimes seem to just keep failing.
I looked through the mapred-default.xml, but I didn't find a config option
that allows ignoring tasks that fail. Is there a way to do this (it seems
like the only alternative I have, since I can't make the failures stop)?

Mathias

2009/8/5 Mathias De Mar=C3=A9 <mathias.demare@gmail.com>

>
> On Wed, Aug 5, 2009 at 9:38 AM, Jothi Padmanabhan <jothipn@yahoo-inc.com>=
wrote:
>> Hi,
>>
>> Could you please try setting this parameter
>> mapred.merge.recordsBeforeProgress to a lower number?
>> See https://issues.apache.org/jira/browse/HADOOP-4714
>>
>> Cheers
>> Jothi
>
>
> Hm, that bug looks like it's applicable during the merge, but my case is =
a
> block right before the merge (but seemingly right after all of the map ta=
sks
> finish).
> I tried putting mapred.merge.recordsBeforeProgress to 100, and it didn't
> make a difference.
>
> On Wed, Aug 5, 2009 at 10:32 AM, Amogh Vasekar <amogh@yahoo-inc.com>wrote=
:
>
>> 10 mins reminds me of parameter mapred.task.timeout . This is
>> configurable. Or alternatively you might just do a sysout to let tracker
>> know of its existence ( not an ideal solution though )
>>
>> Thanks,
>> Amogh
>
>
> Well, the map tasks take around 30 minutes to run. Letting the task idle
> for a large number of minutes after that is a lot of useless time, imho. =
I
> tried with 20 minutes now, but I still get timeouts.
>
> I don't know if it's useful, but here are the settings of the map tasks a=
t
> the moment:
>
> <configuration>
>   <property>
>     <name>mapred.job.tracker</name>
>     <value>localhost:9001</value>
>   </property>
>   <property>
>     <name>io.sort.mb</name>
>     <value>3</value>
>     <description>The total amount of buffer memory to use while sorting
>     files, in megabytes.  By default, gives each merge stream 1MB, which
>     should minimize seeks.</description>
>   </property>
> <property>
>   <name>mapred.tasktracker.map.tasks.maximum</name>
>   <value>4</value>
>   <description>The maximum number of map tasks that will be run
>   simultaneously by a task tracker.
>   </description>
> </property>
>
> <property>
>   <name>mapred.tasktracker.reduce.tasks.maximum</name>
>   <value>4</value>
>   <description>The maximum number of reduce tasks that will be run
>   simultaneously by a task tracker.
>   </description>
> </property>
>
> <property>
>   <name>mapred.max.split.size</name>
>   <value>1000000</value>
> </property>
>
> <property>
>   <name>mapred.child.java.opts</name>
>   <value>-Xmx400m</value>
> </property>
>
> <property>
> <name>mapred.merge.recordsBeforeProgress</name>
> <value>100</value>
> </property>
>
> <property>
> <name>mapred.task.timeout</name>
> <value>1200000</value>
> </property>
>
> </configuration>
>
> Ideally, I would want to get rid of the delay that causes the timeouts, y=
et
> also increase the split size somewhat (though I think a larger split size
> would increase the delay even more?).
> The map tasks take around 8000-11000 records as input, and can produce up
> to 1 000 000 records as output (in case this is relevant).
>
> Mathias
>
>

--001636c5b297f9274d0470b1f599--

From common-user-return-16622-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 15:17:58 2009
Return-Path: <common-user-return-16622-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 46963 invoked from network); 9 Aug 2009 15:17:57 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 15:17:57 -0000
Received: (qmail 48772 invoked by uid 500); 9 Aug 2009 15:18:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 48695 invoked by uid 500); 9 Aug 2009 15:18:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 48685 invoked by uid 99); 9 Aug 2009 15:18:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 15:18:02 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of harold.valdivia@upr.edu designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 15:17:54 +0000
Received: by ewy26 with SMTP id 26so2583308ewy.29
        for <common-user@hadoop.apache.org>; Sun, 09 Aug 2009 08:17:32 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.210.113.19 with SMTP id l19mr1919565ebc.3.1249831052024; Sun, 
	09 Aug 2009 08:17:32 -0700 (PDT)
In-Reply-To: <c7d45fc70908082152j9f3b716l8e2aa4b008ed27e5@mail.gmail.com>
References: <c1f27e270908081928r73c39555n39043c583c30acee@mail.gmail.com>
	 <c7d45fc70908082152j9f3b716l8e2aa4b008ed27e5@mail.gmail.com>
Date: Sun, 9 Aug 2009 11:17:32 -0400
Message-ID: <c1f27e270908090817p29e4498di51af7ffdb5f3fcb4@mail.gmail.com>
Subject: Re: How to break a hadoop-cluster in subclusters (how to group 
	physical nodes)?
From: Harold Valdivia Garcia <harold.valdivia@upr.edu>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd1fe0ce2a46b0470b6f7de
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd1fe0ce2a46b0470b6f7de
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Ok, you mean that I could setup an instance of HDFS, then install multiple
cluster of tasktracker with the same HDFS.?

In this configuration as you say I'd loss data-locatily because map-task
consume splits remotely, isnt it?

In my work, I want to execution each of the relational operations in a
query-plan as a couple of mapreduce task and link them

Thanks for your comment.

On Sun, Aug 9, 2009 at 12:52 AM, Ted Dunning <ted.dunning@gmail.com> wrote:

> Why?
>
> I would imagine that you could create multiple clusters of TaskTrackers
> each
> associated with a single JobTracker all of which would use the same data
> cluster composed of a NameNode plus data nodes.
>
> But what do you think that would buy you?  Mostly like you will simply wind
> up with much lower cluster utilization combined with configuration
> headaches.
>
> On Sat, Aug 8, 2009 at 7:28 PM, Harold Valdivia Garcia <
> harold.valdivia@upr.edu> wrote:
>
> > for example I'd like to have a region for only sorting, other for only
> > joins, other for only groupby
> >
>
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>



-- 
******************************************
Harold Dwight Valdivia Garcia
Graduate Student
M.S Computer Engineering
University of Puerto Rico, Mayaguez Campus
******************************************

--000e0cd1fe0ce2a46b0470b6f7de--

From common-user-return-16623-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 15:42:09 2009
Return-Path: <common-user-return-16623-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 51577 invoked from network); 9 Aug 2009 15:42:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 15:42:09 -0000
Received: (qmail 66370 invoked by uid 500); 9 Aug 2009 15:42:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 66297 invoked by uid 500); 9 Aug 2009 15:42:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 66287 invoked by uid 99); 9 Aug 2009 15:42:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 15:42:14 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of popo6190@gmail.com designates 209.85.200.169 as permitted sender)
Received: from [209.85.200.169] (HELO wf-out-1314.google.com) (209.85.200.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 15:42:05 +0000
Received: by wf-out-1314.google.com with SMTP id 23so881474wfg.2
        for <common-user@hadoop.apache.org>; Sun, 09 Aug 2009 08:41:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=qQRgdkVYO+7XhsfFvo7s3ALTg3b3QuG8kWbRr1uqCCg=;
        b=HjyM+oYBXTn8JtTeF8Ii3rnVqUKlZokHvyU0ehymK4Eaq+jVSTiHNItOBuUOCBIHDt
         a8sluBen9q7gU2/Q3Zj13uKecEHhnJs8eN+kU+JC6srBcFBYTmrxY1BJwdH5m7iU51W1
         6QHRUplCzmlHojRWu36sCJsS4bZxPOYW+tkk8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=KkxKucsytht2r1QL86lMuCPf0p2GE3juMIA7ClmsG/jBdHhHFzM4TPzSCnqZwImBj8
         yHy3YXoGbE4YFWP/0Sm51Ikt6H5LIc0xMwemCvQMrA+UJOrk4SDC/g6Jy2z4POdZXlBH
         3ZYRYnLzD/hZfX5qvCRFKKRnxRelJCi23GEJk=
MIME-Version: 1.0
Received: by 10.142.108.13 with SMTP id g13mr617858wfc.271.1249832503959; Sun, 
	09 Aug 2009 08:41:43 -0700 (PDT)
Date: Sun, 9 Aug 2009 22:41:43 +0700
Message-ID: <45f11e410908090841p6a8e7342t9c00cabd539226ee@mail.gmail.com>
Subject: hdfs and small file size
From: Budianto Lie <popo6190@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636e910836d5ff00470b74eab
X-Virus-Checked: Checked by ClamAV on apache.org

--001636e910836d5ff00470b74eab
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello,
As we know the block size of hdfs is big (64M).
If I've large amount of files but the average file size is small (less than
50kb). And they are stored into hdfs.
What's the performance, compare with storing a big files?

Thanks,
Budianto

--001636e910836d5ff00470b74eab--

From common-user-return-16624-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 15:54:07 2009
Return-Path: <common-user-return-16624-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 53593 invoked from network); 9 Aug 2009 15:54:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 15:54:07 -0000
Received: (qmail 73694 invoked by uid 500); 9 Aug 2009 15:54:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 73613 invoked by uid 500); 9 Aug 2009 15:54:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 73599 invoked by uid 99); 9 Aug 2009 15:54:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 15:54:11 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jdcryans@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 15:54:01 +0000
Received: by fxm24 with SMTP id 24so2743378fxm.36
        for <common-user@hadoop.apache.org>; Sun, 09 Aug 2009 08:53:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:sender:received:in-reply-to
         :references:date:x-google-sender-auth:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=z8AhLIDB0/usllwHQ7bIWhzYJ6v67jzdRxLQidSIi0A=;
        b=NZWXQo5M+7ftdElUf4j9GZCHdLZLfjEVwoJBAzS1hjfK3PrfMmYQiaeA+A5urQAed1
         E0TwcHm86Oh0ai1Apr39EnP3FaDvHB7AM21IZOFw1R94ntQgjd95acK6bebqhR88LrrX
         JShqTCxrISF0cJxoSwXqO9vImDs1PNiRVcO3c=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:sender:in-reply-to:references:date
         :x-google-sender-auth:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=qW698SiVc1ofI1Pkkb9sQ/Nl4D8/ZKQyFvrAxkLStg+cd0QDLlycZ65S9XpG+P/4Cl
         0pPF6KeuKyevFrVHpn7IsMuUXcJMUZhrsSnepNx7kaX8/W2dYTW6Q/AD8v4o+PCfsPs9
         kIhQ7id/A6NJD8SZcql9CTWCixei3GqB+wUBs=
MIME-Version: 1.0
Sender: jdcryans@gmail.com
Received: by 10.223.112.6 with SMTP id u6mr122791fap.63.1249833220834; Sun, 09 
	Aug 2009 08:53:40 -0700 (PDT)
In-Reply-To: <45f11e410908090841p6a8e7342t9c00cabd539226ee@mail.gmail.com>
References: <45f11e410908090841p6a8e7342t9c00cabd539226ee@mail.gmail.com>
Date: Sun, 9 Aug 2009 08:53:40 -0700
X-Google-Sender-Auth: 9c4c95dd71fd23dc
Message-ID: <31a243e70908090853s7a6bc23dr33410dfbd1f6a7fb@mail.gmail.com>
Subject: Re: hdfs and small file size
From: Jean-Daniel Cryans <jdcryans@apache.org>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Have a look at http://www.cloudera.com/blog/2009/02/02/the-small-files-problem/

J-D

On Sun, Aug 9, 2009 at 8:41 AM, Budianto Lie<popo6190@gmail.com> wrote:
> Hello,
> As we know the block size of hdfs is big (64M).
> If I've large amount of files but the average file size is small (less than
> 50kb). And they are stored into hdfs.
> What's the performance, compare with storing a big files?
>
> Thanks,
> Budianto
>

From common-user-return-16625-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 18:37:48 2009
Return-Path: <common-user-return-16625-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 5176 invoked from network); 9 Aug 2009 18:37:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 18:37:48 -0000
Received: (qmail 72330 invoked by uid 500); 9 Aug 2009 18:37:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 72239 invoked by uid 500); 9 Aug 2009 18:37:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 72227 invoked by uid 99); 9 Aug 2009 18:37:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 18:37:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ted.dunning@gmail.com designates 209.85.211.172 as permitted sender)
Received: from [209.85.211.172] (HELO mail-yw0-f172.google.com) (209.85.211.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 18:37:44 +0000
Received: by ywh2 with SMTP id 2so6311566ywh.2
        for <common-user@hadoop.apache.org>; Sun, 09 Aug 2009 11:37:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=SmbXqF5SMlAt/a9HORcYVG5qvrzweBZmeY3DMK60Bgg=;
        b=EIgVj9XqAZdfOZXvxiklwt1CZV7Mn4U7QdBTMnjomB9/bQifLtnNei2peWpybHA7bN
         9pLbK1I37voSOtbOlYfFs3uZNrcQaUblfomqCHVD5B1YQ22tGzPNJ/RXZFPLqRvgr+t0
         aKdsVMFjLNcNu7bCgg7Ohi0crex1SjYmP5mY0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=KpVEhDNNELglxbQihV9+04PQPYnrAu7fTMzSx7fAdJ90TIbzfnUOAOBGbucBVnMeV1
         WYpDbMzX9IuriCMxDo+Me6BLwPXgOasshHp7jS8ppbecQrtWoqsPgXTRzykdT2GSPURZ
         NFX6qxNTHbT2fvUVIjwsU2z3UsODY66hJqRnI=
MIME-Version: 1.0
Received: by 10.151.144.19 with SMTP id w19mr6499420ybn.159.1249843044090; 
	Sun, 09 Aug 2009 11:37:24 -0700 (PDT)
In-Reply-To: <c1f27e270908090817p29e4498di51af7ffdb5f3fcb4@mail.gmail.com>
References: <c1f27e270908081928r73c39555n39043c583c30acee@mail.gmail.com> 
	<c7d45fc70908082152j9f3b716l8e2aa4b008ed27e5@mail.gmail.com> 
	<c1f27e270908090817p29e4498di51af7ffdb5f3fcb4@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Sun, 9 Aug 2009 11:37:04 -0700
Message-ID: <c7d45fc70908091137u6cfa17a8ndcddc9b14700c4f6@mail.gmail.com>
Subject: Re: How to break a hadoop-cluster in subclusters (how to group 
	physical nodes)?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015174bec9aab04360470b9c25a
X-Virus-Checked: Checked by ClamAV on apache.org

--0015174bec9aab04360470b9c25a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

On Sun, Aug 9, 2009 at 8:17 AM, Harold Valdivia Garcia <
harold.valdivia@upr.edu> wrote:

> Ok, you mean that I could setup an instance of HDFS, then install multiple
> cluster of tasktracker with the same HDFS.?


I think so.

In this configuration as you say I'd loss data-locatily because map-task
> consume splits remotely, isnt it?


Yes.  You would also lose most of the speed of your cluster because your
different operations will occur at different times and each will only use
part of the cluster.  What you are suggesting will make your cluster slower
by a substantial factor.


> In my work, I want to execution each of the relational operations in a
> query-plan as a couple of mapreduce task and link them


This is a very common desire.  But most people do better by having as large
a cluster as possible for all operations.

--0015174bec9aab04360470b9c25a--

From common-user-return-16626-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 21:39:35 2009
Return-Path: <common-user-return-16626-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 52437 invoked from network); 9 Aug 2009 21:39:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 21:39:35 -0000
Received: (qmail 44645 invoked by uid 500); 9 Aug 2009 21:39:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 44561 invoked by uid 500); 9 Aug 2009 21:39:39 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 44550 invoked by uid 99); 9 Aug 2009 21:39:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 21:39:39 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [64.78.17.142] (HELO EXSMTP012-11.exch012.intermedia.net) (64.78.17.142)
    by apache.org (qpsmtpd/0.29) with SMTP; Sun, 09 Aug 2009 21:39:31 +0000
Received: from EXVBE012-14.exch012.intermedia.net ([10.254.2.74]) by EXSMTP012-11.exch012.intermedia.net with Microsoft SMTPSVC(6.0.3790.1830);
	 Sun, 9 Aug 2009 14:39:10 -0700
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01CA1939.D4A57A43"
Subject: OutputCommitter for rollbacks?
Date: Sun, 9 Aug 2009 14:37:28 -0700
Message-ID: <FAE2AFC892D2DC43AF29AADCF271940A016A01F6@EXVBE012-14.exch012.intermedia.net>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: OutputCommitter for rollbacks?
Thread-Index: AcoZOZd0u0dE9KQlQ4qissty9gDFQQ==
From: "Deepika Khera" <deepikak@collarity.com>
To: <common-user@hadoop.apache.org>
X-OriginalArrivalTime: 09 Aug 2009 21:39:10.0734 (UTC) FILETIME=[D4CA52E0:01CA1939]
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01CA1939.D4A57A43
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Hi,

=20

I am trying to use the OutputCommitter.cleanupJob() to commit and
rollback my job. The cleanup() method is called whether the job was
successful, killed or failed.

=20

I need to know in the cleanupJob(jobContext) method the status of job so
far, especially if it failed or was killed.

=20

The issue is that no matter whether the job failed or was
killed/successful, the job status in the committer is "running" (which
makes sense but not what I need). It seems that I can only know the job
status when the entire job (including the cleanup task) has finished.=20

=20

I see an open JIRA  which is related , but until we have a resolution to
that is there any other  way to achieve this?

=20

http://issues.apache.org/jira/browse/HADOOP-6005

=20

So, what I need is make the decision in the cleanupJob() whether I
should do  a commit or rollback(Killed/Failed vs Successful).

=20

Would appreciate any help on this.

=20

Thanks,

Deepika


------_=_NextPart_001_01CA1939.D4A57A43--

From common-user-return-16627-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 22:39:38 2009
Return-Path: <common-user-return-16627-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 60774 invoked from network); 9 Aug 2009 22:39:38 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 22:39:38 -0000
Received: (qmail 64665 invoked by uid 500); 9 Aug 2009 22:39:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 64566 invoked by uid 500); 9 Aug 2009 22:39:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 64551 invoked by uid 99); 9 Aug 2009 22:39:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 22:39:40 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 22:39:32 +0000
Received: by vws40 with SMTP id 40so2553131vws.2
        for <multiple recipients>; Sun, 09 Aug 2009 15:39:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:from:date
         :message-id:subject:to:content-type;
        bh=+n5HaX7NSjHMNaG9QNdiO3nhmOP+HhXeO80JymF4qVo=;
        b=GQz3Km19yomMHKcQM/CT59MygN4+X6cQin4snUsrRh3XSg4ZfmR5BGaKkwakJQoOmX
         JGMqZcJ9uHFdIi60hR7d/8yjo/Me19VZ4U2j9gBouHnbUyrP9oB3U2HoiWwqjBDhLpKB
         G5yn7TCdgLgdL5/OyqzeoDRXJJpYJj+8twp9c=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:from:date:message-id:subject:to:content-type;
        b=XeG8Jq51hQM3iyoGnlPr8Fz6coDA5JY5OpS5vq1aisgkeQ7KPdVXkK5GzDIp6QT/+9
         HtY4HszcyCVxAo4Ch3jV5FZarm8W5Ky7wVcqj+YkVQc6gwdDaNhCCgJrn2hkr2DAdYbr
         AOEbHaiSUppS8KE+8nAIaPngY+fnb9mOc11fc=
MIME-Version: 1.0
Received: by 10.220.94.16 with SMTP id x16mr3835451vcm.74.1249857551087; Sun, 
	09 Aug 2009 15:39:11 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 9 Aug 2009 18:38:51 -0400
Message-ID: <1e7471d50908091538hba43b0ag998d644e511cd20f@mail.gmail.com>
Subject: LineReader, Buffering for FileInputFormat
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163630eff35a399e0470bd239b
X-Virus-Checked: Checked by ClamAV on apache.org

--00163630eff35a399e0470bd239b
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hello,
I am using the TextInputFormat and its associated LineReader. In the
RecordReader for this class,
it reads key and value, using LineReader.
My question is does LineReader hit the disk every time it needs to read a
line?
I notice it uses DataInputStream, does that do some internal buffering?

I guess it would be be performance hit if LineReader read from disk every
time it needs to fetch a line,
so I'm guessing it reads a chunk and parses lines from the chunk, but i
didn't see that happening.

I am using Hadoop 0.20

Any comments would be appreciated.

Regards
Saptarshi

--00163630eff35a399e0470bd239b--

From common-user-return-16628-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 22:39:39 2009
Return-Path: <common-user-return-16628-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 60796 invoked from network); 9 Aug 2009 22:39:38 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 22:39:38 -0000
Received: (qmail 64798 invoked by uid 500); 9 Aug 2009 22:39:41 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 64647 invoked by uid 500); 9 Aug 2009 22:39:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 64562 invoked by uid 500); 9 Aug 2009 22:39:40 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 64551 invoked by uid 99); 9 Aug 2009 22:39:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 22:39:40 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 22:39:32 +0000
Received: by vws40 with SMTP id 40so2553131vws.2
        for <multiple recipients>; Sun, 09 Aug 2009 15:39:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:from:date
         :message-id:subject:to:content-type;
        bh=+n5HaX7NSjHMNaG9QNdiO3nhmOP+HhXeO80JymF4qVo=;
        b=GQz3Km19yomMHKcQM/CT59MygN4+X6cQin4snUsrRh3XSg4ZfmR5BGaKkwakJQoOmX
         JGMqZcJ9uHFdIi60hR7d/8yjo/Me19VZ4U2j9gBouHnbUyrP9oB3U2HoiWwqjBDhLpKB
         G5yn7TCdgLgdL5/OyqzeoDRXJJpYJj+8twp9c=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:from:date:message-id:subject:to:content-type;
        b=XeG8Jq51hQM3iyoGnlPr8Fz6coDA5JY5OpS5vq1aisgkeQ7KPdVXkK5GzDIp6QT/+9
         HtY4HszcyCVxAo4Ch3jV5FZarm8W5Ky7wVcqj+YkVQc6gwdDaNhCCgJrn2hkr2DAdYbr
         AOEbHaiSUppS8KE+8nAIaPngY+fnb9mOc11fc=
MIME-Version: 1.0
Received: by 10.220.94.16 with SMTP id x16mr3835451vcm.74.1249857551087; Sun, 
	09 Aug 2009 15:39:11 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 9 Aug 2009 18:38:51 -0400
Message-ID: <1e7471d50908091538hba43b0ag998d644e511cd20f@mail.gmail.com>
Subject: LineReader, Buffering for FileInputFormat
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163630eff35a399e0470bd239b
X-Virus-Checked: Checked by ClamAV on apache.org

--00163630eff35a399e0470bd239b
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hello,
I am using the TextInputFormat and its associated LineReader. In the
RecordReader for this class,
it reads key and value, using LineReader.
My question is does LineReader hit the disk every time it needs to read a
line?
I notice it uses DataInputStream, does that do some internal buffering?

I guess it would be be performance hit if LineReader read from disk every
time it needs to fetch a line,
so I'm guessing it reads a chunk and parses lines from the chunk, but i
didn't see that happening.

I am using Hadoop 0.20

Any comments would be appreciated.

Regards
Saptarshi

--00163630eff35a399e0470bd239b--

From common-user-return-16629-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 23:41:34 2009
Return-Path: <common-user-return-16629-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 42140 invoked from network); 9 Aug 2009 23:41:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 23:41:34 -0000
Received: (qmail 78524 invoked by uid 500); 9 Aug 2009 23:41:39 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 78417 invoked by uid 500); 9 Aug 2009 23:41:39 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 78407 invoked by uid 99); 9 Aug 2009 23:41:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 23:41:39 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of harold.valdivia@upr.edu designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 23:41:29 +0000
Received: by ewy26 with SMTP id 26so2739623ewy.29
        for <common-user@hadoop.apache.org>; Sun, 09 Aug 2009 16:41:09 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.210.51.10 with SMTP id y10mr2343866eby.4.1249861269700; Sun, 
	09 Aug 2009 16:41:09 -0700 (PDT)
In-Reply-To: <1e7471d50908091538hba43b0ag998d644e511cd20f@mail.gmail.com>
References: <1e7471d50908091538hba43b0ag998d644e511cd20f@mail.gmail.com>
Date: Sun, 9 Aug 2009 19:41:09 -0400
Message-ID: <c1f27e270908091641k64727649n77f58c4f154ec34b@mail.gmail.com>
Subject: Re: LineReader, Buffering for FileInputFormat
From: Harold Valdivia Garcia <harold.valdivia@upr.edu>
To: common-user@hadoop.apache.org, saptarshi.guha@gmail.com
Content-Type: multipart/alternative; boundary=0015174bedceffc0170470be0091
X-Virus-Checked: Checked by ClamAV on apache.org

--0015174bedceffc0170470be0091
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

You can see this two files:

http://svn.apache.org/viewvc/hadoop/mapreduce/trunk/src/java/org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java?revision=796148

http://svn.apache.org/viewvc/hadoop/common/trunk/src/java/org/apache/hadoop/util/LineReader.java?revision=786726

I think It doesnt access the disk every time it read a line.

LineReader read 64k bytes  into a buffer, and then try to parse the data in
lines.



On Sun, Aug 9, 2009 at 6:38 PM, Saptarshi Guha <saptarshi.guha@gmail.com>wrote:

> Hello,
> I am using the TextInputFormat and its associated LineReader. In the
> RecordReader for this class,
> it reads key and value, using LineReader.
> My question is does LineReader hit the disk every time it needs to read a
> line?
> I notice it uses DataInputStream, does that do some internal buffering?
>
> I guess it would be be performance hit if LineReader read from disk every
> time it needs to fetch a line,
> so I'm guessing it reads a chunk and parses lines from the chunk, but i
> didn't see that happening.
>
> I am using Hadoop 0.20
>
> Any comments would be appreciated.
>
> Regards
> Saptarshi
>



-- 
******************************************
Harold Dwight Valdivia Garcia
Graduate Student
M.S Computer Engineering
University of Puerto Rico, Mayaguez Campus
******************************************

--0015174bedceffc0170470be0091--

From common-user-return-16630-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 09 23:44:26 2009
Return-Path: <common-user-return-16630-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 42377 invoked from network); 9 Aug 2009 23:44:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 9 Aug 2009 23:44:26 -0000
Received: (qmail 80391 invoked by uid 500); 9 Aug 2009 23:44:31 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80308 invoked by uid 500); 9 Aug 2009 23:44:30 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 80298 invoked by uid 99); 9 Aug 2009 23:44:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 23:44:30 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 09 Aug 2009 23:44:21 +0000
Received: by vws40 with SMTP id 40so2569767vws.2
        for <common-user@hadoop.apache.org>; Sun, 09 Aug 2009 16:44:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:cc:content-type;
        bh=8VHy+nKPgfewXpbkvmGDENffPTw4DYK6Ehsoy5zOipk=;
        b=DQdQuKPTJ4TWjHr/kY2XyxrBwui+2WuitxehjukFfPgzIyXKO7w+5EhFGx6YyVI72b
         pGwp3V3aH2UDIAduT5NWnc2N72av1o5EJSznjv+dxfADdM5F8ukZ+5G42f75RRyE0bnj
         sVHUr6beIucKc0tY4AzKPjoBlZcUr95RiI24c=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        b=wlfLqW/JaYBWEUj2mWq6mN9DXo4oX8aI3xdIMzaY/1Wa6t/oHfJvHIJ3m/FRxrQjlF
         n4zGjkMD0fmGNwxDB+liYKMQVBvylbvQe604hw9VFo/pRCa2MTKl3vqvKtN1+T05irgC
         VFc0U/NNGMh9wRHJr3xY1O0WuKEok5RwUSKwI=
MIME-Version: 1.0
Received: by 10.220.93.72 with SMTP id u8mr3837714vcm.56.1249861440069; Sun, 
	09 Aug 2009 16:44:00 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
In-Reply-To: <c1f27e270908091641k64727649n77f58c4f154ec34b@mail.gmail.com>
References: <1e7471d50908091538hba43b0ag998d644e511cd20f@mail.gmail.com> 
	<c1f27e270908091641k64727649n77f58c4f154ec34b@mail.gmail.com>
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 9 Aug 2009 19:43:40 -0400
Message-ID: <1e7471d50908091643k736f1269v5c82c33b51e3ebcc@mail.gmail.com>
Subject: Re: LineReader, Buffering for FileInputFormat
To: Harold Valdivia Garcia <harold.valdivia@upr.edu>
Cc: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163628513e2760d90470be0b1a
X-Virus-Checked: Checked by ClamAV on apache.org

--00163628513e2760d90470be0b1a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Thank you. Is 64KB a good choice? From experience, there is a payoff between
large chunks and time taken to read the chunk.
I wonder if a larger value would be better.

On Sun, Aug 9, 2009 at 7:41 PM, Harold Valdivia Garcia <
harold.valdivia@upr.edu> wrote:

> You can see this two files:
>
>
> http://svn.apache.org/viewvc/hadoop/mapreduce/trunk/src/java/org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java?revision=796148
>
>
> http://svn.apache.org/viewvc/hadoop/common/trunk/src/java/org/apache/hadoop/util/LineReader.java?revision=786726
>
> I think It doesnt access the disk every time it read a line.
>
> LineReader read 64k bytes  into a buffer, and then try to parse the data in
> lines.
>
>
>
>
> On Sun, Aug 9, 2009 at 6:38 PM, Saptarshi Guha <saptarshi.guha@gmail.com>wrote:
>
>> Hello,
>> I am using the TextInputFormat and its associated LineReader. In the
>> RecordReader for this class,
>> it reads key and value, using LineReader.
>> My question is does LineReader hit the disk every time it needs to read a
>> line?
>> I notice it uses DataInputStream, does that do some internal buffering?
>>
>> I guess it would be be performance hit if LineReader read from disk every
>> time it needs to fetch a line,
>> so I'm guessing it reads a chunk and parses lines from the chunk, but i
>> didn't see that happening.
>>
>> I am using Hadoop 0.20
>>
>> Any comments would be appreciated.
>>
>> Regards
>> Saptarshi
>>
>
>
>
> --
> ******************************************
> Harold Dwight Valdivia Garcia
> Graduate Student
> M.S Computer Engineering
> University of Puerto Rico, Mayaguez Campus
> ******************************************
>

--00163628513e2760d90470be0b1a--

From common-user-return-16631-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 02:28:24 2009
Return-Path: <common-user-return-16631-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 89324 invoked from network); 10 Aug 2009 02:28:24 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 02:28:24 -0000
Received: (qmail 35945 invoked by uid 500); 10 Aug 2009 02:28:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35864 invoked by uid 500); 10 Aug 2009 02:28:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35854 invoked by uid 99); 10 Aug 2009 02:28:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 02:28:28 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of popo6190@gmail.com designates 209.85.222.172 as permitted sender)
Received: from [209.85.222.172] (HELO mail-pz0-f172.google.com) (209.85.222.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 02:28:19 +0000
Received: by pzk2 with SMTP id 2so2646992pzk.30
        for <common-user@hadoop.apache.org>; Sun, 09 Aug 2009 19:27:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=ifDlh1ab/+DWSC9Vuh9hcEfJUBAq6Yow8wrEUdmHLDQ=;
        b=jaYrdtV0u8CsH89smsXKZacRAi3z1pq6YsrQ62ZvSUWb4SCTuldfEZVR3FFQJoZnQj
         K2DL4N1fKtF0K1JMsapWsXTVbj6b1pukY+s512h8KpbNdH+v5QTbrvhKARnmvKa/UhRK
         WZmm1qQHr0f/vrzfR7H5wv5UPMGLRBgQhTLtM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=PFwFgj5K1UP251vdsVUYHo4IgkjVYMYxCjkdD/Dv/8M2TT9BCtUdeTdGKgJ/ZT5VOj
         xhbCH280aGDIz5YzjB2S7gBC45L5WJzhSaYEzcRkP9ftfZUAB9yuDXwWW7+XgkwTAVAE
         PgZN1LmS+DqvO60AmwLrZwKipAkiIG9kQo1LI=
MIME-Version: 1.0
Received: by 10.142.222.21 with SMTP id u21mr272445wfg.287.1249871278939; Sun, 
	09 Aug 2009 19:27:58 -0700 (PDT)
In-Reply-To: <31a243e70908090853s7a6bc23dr33410dfbd1f6a7fb@mail.gmail.com>
References: <45f11e410908090841p6a8e7342t9c00cabd539226ee@mail.gmail.com>
	 <31a243e70908090853s7a6bc23dr33410dfbd1f6a7fb@mail.gmail.com>
Date: Mon, 10 Aug 2009 09:27:58 +0700
Message-ID: <45f11e410908091927y550d5f35ua77fec5c1c0721a2@mail.gmail.com>
Subject: Re: hdfs and small file size
From: Budianto Lie <popo6190@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks

On 8/9/09, Jean-Daniel Cryans <jdcryans@apache.org> wrote:
> Have a look at
> http://www.cloudera.com/blog/2009/02/02/the-small-files-problem/
>
> J-D
>
> On Sun, Aug 9, 2009 at 8:41 AM, Budianto Lie<popo6190@gmail.com> wrote:
>> Hello,
>> As we know the block size of hdfs is big (64M).
>> If I've large amount of files but the average file size is small (less
>> than
>> 50kb). And they are stored into hdfs.
>> What's the performance, compare with storing a big files?
>>
>> Thanks,
>> Budianto
>>
>

From common-user-return-16632-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 03:27:21 2009
Return-Path: <common-user-return-16632-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 6827 invoked from network); 10 Aug 2009 03:27:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 03:27:21 -0000
Received: (qmail 66914 invoked by uid 500); 10 Aug 2009 03:27:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 66810 invoked by uid 500); 10 Aug 2009 03:27:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 66800 invoked by uid 500); 10 Aug 2009 03:27:25 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 66797 invoked by uid 99); 10 Aug 2009 03:27:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 03:27:25 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of grafan@gmail.com designates 209.85.222.189 as permitted sender)
Received: from [209.85.222.189] (HELO mail-pz0-f189.google.com) (209.85.222.189)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 03:27:16 +0000
Received: by pzk27 with SMTP id 27so2885144pzk.2
        for <core-user@hadoop.apache.org>; Sun, 09 Aug 2009 20:26:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=Jf0JbG1yZqQndE1Gqt0u/h+nw6ADD9yC0ijEveOAnWQ=;
        b=p1wHxibowz84hlQ5IuEZmsy2ULyHOLudn77292LdjwMgYpQQD/GWE9OjZgNlg3BcXN
         OyQSnVku+zOMpTthkL5A6R0dvxKnFXd00Q6ay+UWjGDuutF6PkoI4AC/2nG2Cauuhgnf
         s8UCfcW2QZ3SuOKcKjrvlz/XsOqJ+mbMkrCV4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=ZUbgt0wsOhx7E17m+2PFFNVvJTgksdOw685i3DrJd7MmIs1+WKI3FlUBDl/lZbjStX
         mzWrJogHHyrpIQ1oybx3qxIpGC58CjqC0clSujR+26opzmAw+yq449wJ0B4fhF1cvRvH
         pXeLSqxsPs2/Q9LYMA3K6GNCadYZ9heTRPc9k=
MIME-Version: 1.0
Received: by 10.114.109.12 with SMTP id h12mr4509802wac.154.1249874814668; 
	Sun, 09 Aug 2009 20:26:54 -0700 (PDT)
Date: Mon, 10 Aug 2009 11:26:54 +0800
Message-ID: <6eb82e0908092026o497a3bdfw51872d34cb5b410f@mail.gmail.com>
Subject: MultipleOutputFormat and key class
From: Rong-en Fan <grafan@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

I'm playing with MultipleOutputFormat in 0.19.2. However, it seems to
me that I can not change key class in MOF. For example, my Map outputs
<Text, Text> but in the end, I want to store <LongWritable, Text>. The
reason that Map outputs Text as key is to encode information for MOF.
In my MOF class I use

public class MyMOF<K,V> extends MOF<K,V>
{
   public LongWritable generateActualKey(Key, Value)
   {
      return LongWritable(...)
   }
}

But it seems somehow this method is not used and mapred complains my
final key is not a class of LongWritable (I did
JobConf.setOutputKeyClass(LongWritable.class)).

Any idea?

Thanks,
Rong-En Fan

From common-user-return-16633-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 03:59:18 2009
Return-Path: <common-user-return-16633-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 21096 invoked from network); 10 Aug 2009 03:59:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 03:59:18 -0000
Received: (qmail 78479 invoked by uid 500); 10 Aug 2009 03:59:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 78380 invoked by uid 500); 10 Aug 2009 03:59:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 78370 invoked by uid 99); 10 Aug 2009 03:59:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 03:59:23 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kevinweil@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 03:59:13 +0000
Received: by yxe15 with SMTP id 15so3643022yxe.5
        for <common-user@hadoop.apache.org>; Sun, 09 Aug 2009 20:58:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=2vVP+b7CKPwshTts4+MhHlom1zB2FlUrMQNJl/3sIhE=;
        b=XXiQ1Z09VZIRujLmgW6paUEaAsJRTix5seVX8gXIu8kTpQmsaLP0XAnP3qX/N1WSMf
         /0qkNCJOGLJnShOXXCmIYyLO9q3hXkqLpheSg4IQDp1ZQaXdFu37y/mhzsbRhVwkrl4N
         5Rp8wyJIimwOyOG41VKzwvdvoqTTB9VxxNblg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=uLDC8C203lzbZis1syntFHL0kdTe/tu01zVSHGLWm+m41sSdyOj4NUu2Nh3TdcqNFn
         3OThkI4iy3wvAVrlhD+tQQCWX/1nMVmMlBvzvcI8u2X70Wf0TxQzUNtmzfmZgqvan5Iu
         2aOOi7kx12kryKhGpQjtWTiQuJoRPhsW823L0=
MIME-Version: 1.0
Received: by 10.100.254.15 with SMTP id b15mr2948183ani.27.1249876732850; Sun, 
	09 Aug 2009 20:58:52 -0700 (PDT)
Date: Sun, 9 Aug 2009 20:58:52 -0700
Message-ID: <9c8643e30908092058k43f207earf16e22325a777601@mail.gmail.com>
Subject: status of hadoop 0.20.1?
From: Kevin Weil <kevinweil@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016369fa374acb2640470c19a36
X-Virus-Checked: Checked by ClamAV on apache.org

--0016369fa374acb2640470c19a36
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

What is the current status/timeframe for the 0.20.1 release?  It seems like
there are a lot of relevant fixes, and it's been sitting idle with the same
four JIRAs open for a few weeks now.

Thanks,
Kevin

--0016369fa374acb2640470c19a36--

From common-user-return-16634-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 04:07:52 2009
Return-Path: <common-user-return-16634-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 22352 invoked from network); 10 Aug 2009 04:07:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 04:07:52 -0000
Received: (qmail 84809 invoked by uid 500); 10 Aug 2009 04:07:56 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 84752 invoked by uid 500); 10 Aug 2009 04:07:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 84742 invoked by uid 99); 10 Aug 2009 04:07:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 04:07:56 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.20] (HELO mrout1-b.corp.re1.yahoo.com) (69.147.107.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 04:07:44 +0000
Received: from ownstrong-lr.eglbp.corp.yahoo.com (ownstrong-lr.eglbp.corp.yahoo.com [10.66.74.39])
	by mrout1-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7A46Ov9052535
	for <common-user@hadoop.apache.org>; Sun, 9 Aug 2009 21:06:25 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=iek29X3Gv6iwQmwqWgVchsi5SpP3hMi0B4oleIwW+2A4jcQ/Qcx7XRguet9LaJ0F
Message-ID: <4A7F9C86.7000406@yahoo-inc.com>
Date: Mon, 10 Aug 2009 09:35:26 +0530
From: Amareshwari Sriramadasu <amarsri@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: OutputCommitter for rollbacks?
References: <FAE2AFC892D2DC43AF29AADCF271940A016A01F6@EXVBE012-14.exch012.intermedia.net>
In-Reply-To: <FAE2AFC892D2DC43AF29AADCF271940A016A01F6@EXVBE012-14.exch012.intermedia.net>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Deepika,

You can use the fact that map progress and reduce progress 1.0 for 
succeeded jobs and is <1.0 for failed or killed jobs.
Hope this helps.

Thanks
Amareshwari

Deepika Khera wrote:
> Hi,
>
>  
>
> I am trying to use the OutputCommitter.cleanupJob() to commit and
> rollback my job. The cleanup() method is called whether the job was
> successful, killed or failed.
>
>  
>
> I need to know in the cleanupJob(jobContext) method the status of job so
> far, especially if it failed or was killed.
>
>  
>
> The issue is that no matter whether the job failed or was
> killed/successful, the job status in the committer is "running" (which
> makes sense but not what I need). It seems that I can only know the job
> status when the entire job (including the cleanup task) has finished. 
>
>  
>
> I see an open JIRA  which is related , but until we have a resolution to
> that is there any other  way to achieve this?
>
>  
>
> http://issues.apache.org/jira/browse/HADOOP-6005
>
>  
>
> So, what I need is make the decision in the cleanupJob() whether I
> should do  a commit or rollback(Killed/Failed vs Successful).
>
>  
>
> Would appreciate any help on this.
>
>  
>
> Thanks,
>
> Deepika
>
>
>   


From common-user-return-16635-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 08:39:58 2009
Return-Path: <common-user-return-16635-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 1243 invoked from network); 10 Aug 2009 08:39:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 08:39:58 -0000
Received: (qmail 78280 invoked by uid 500); 10 Aug 2009 08:40:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 78197 invoked by uid 500); 10 Aug 2009 08:40:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 78187 invoked by uid 99); 10 Aug 2009 08:40:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 08:40:02 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of spodxx@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 08:39:53 +0000
Received: by ewy26 with SMTP id 26so2895869ewy.29
        for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 01:39:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=LjXP8A4ambRNOpyc1EQHurUU/BV++wmj08rwYB71cOA=;
        b=jMufU4nAACEeG9So9XkPSUxsYaW+NGGQU4hYzABGAGn7lTOl9X488zRBbWXimP5uKR
         0Cqz2+y1Uddss9auvtOIb1CPvodckHwp4keXXlQynMvS+5cXcjqjoZjCEXZg47r6owx7
         x5EMhTeBWSfrSmX+4fjNG06a/KSP5U/Rzi8DI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=a7scu5RuQJsKmKMNNbeRwipmk1l3/4y/Xe/C5trzMuRvgLJMGXqpOanhshcqQgy4u0
         URXxdYoPmL6Gck103u8x8lu67c7B/wjlP0T6TLx4MRUyARZOf0wUDSCYkF4Mil4irTIK
         W/0JdlFcVE9Z2MI8zlGwfKxNEUABUN1Hv3NDI=
MIME-Version: 1.0
Received: by 10.216.89.129 with SMTP id c1mr852719wef.35.1249893572782; Mon, 
	10 Aug 2009 01:39:32 -0700 (PDT)
In-Reply-To: <00d901ca1016$c05ac6e0$411054a0$@indiana.edu>
References: <AcoQFr27u2nsyqGHQqOK/g/ESMk3cg==>
	 <00d901ca1016$c05ac6e0$411054a0$@indiana.edu>
Date: Mon, 10 Aug 2009 10:39:32 +0200
Message-ID: <de8e1ae30908100139t67d0b66q659a18721d3d2f5e@mail.gmail.com>
Subject: Re: Using Hadoop with executables and binary data
From: Stefan Podkowinski <spodxx@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Jaliya,

did you consider Hadoop Streaming for your case?
http://wiki.apache.org/hadoop/HadoopStreaming


On Wed, Jul 29, 2009 at 8:35 AM, Jaliya
Ekanayake<jekanaya@cs.indiana.edu> wrote:
> Dear Hadoop devs,
>
>
>
> Please help me to figure out a way to program the following problem using
> Hadoop.
>
> I have a program which I need to invoke in parallel using Hadoop. The
> program takes an input file(binary) and produce an output file (binary)
>
>
>
> Input.bin ->prog.exe-> output.bin
>
>
>
> The input data set is about 1TB in size. Each input data file is about 33=
MB
> in size. (So I have about 31000 files)
>
> The output binary file is about 9KBs in size.
>
>
>
> I have implemented this program using Hadoop in the following way.
>
>
>
> I keep the input data in a shared parallel file system (Lustre File Syste=
m).
>
> Then, I collect the input file names and write them to a collection of fi=
les
> in HDFS (let's say hdfs_input_0.txt ..).
>
> Each hdfs_input file contains roughly the equal number of files URIs to t=
he
> original input file.
>
> The map task, simply take a string Value which is a URI to an original in=
put
> data file and execute the program as an external program.
>
> The output of the program is also written to the shared file system (Lust=
re
> File System).
>
>
>
> The problem in this approach is I am not utilizing the true benefit of
> MapReduce. The use of local disks.
>
> Could =A0you please suggest me a way to use local disks for the above
> problem.?
>
>
>
> I thought, of the following way, but would like to verify from you if the=
re
> is a better way.
>
>
>
> 1. =A0 =A0 =A0 Upload the original data files in HDFS
>
> 2. =A0 =A0 =A0 In the map task, read the data file as an binary object.
>
> 3. =A0 =A0 =A0 Save it in the local file system.
>
> 4. =A0 =A0 =A0 Call the executable
>
> 5. =A0 =A0 =A0 Push the output from the local file system to HDFS.
>
>
>
> Any suggestion is greatly appreciated.
>
>
> Thank you,
>
> Jaliya
>
>
>
>
>
>
>
>
>
>

From common-user-return-16636-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 09:47:43 2009
Return-Path: <common-user-return-16636-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 22073 invoked from network); 10 Aug 2009 09:47:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 09:47:42 -0000
Received: (qmail 22005 invoked by uid 500); 10 Aug 2009 09:47:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21895 invoked by uid 500); 10 Aug 2009 09:47:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21883 invoked by uid 99); 10 Aug 2009 09:47:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 09:47:47 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lamfeeling@126.com designates 220.181.15.111 as permitted sender)
Received: from [220.181.15.111] (HELO m15-111.126.com) (220.181.15.111)
    by apache.org (qpsmtpd/0.29) with SMTP; Mon, 10 Aug 2009 09:47:37 +0000
Received: from SongPC (unknown [114.221.93.111])
	by smtp1 (Coremail) with SMTP id C8mowKBb_wql7H9KqHmUBg--.12062S2;
	Mon, 10 Aug 2009 17:47:18 +0800 (CST)
From: =?gb2312?B?wfjLyQ==?= <lamfeeling@126.com>
To: <common-user@hadoop.apache.org>
References: <9c8643e30908092058k43f207earf16e22325a777601@mail.gmail.com>
In-Reply-To: <9c8643e30908092058k43f207earf16e22325a777601@mail.gmail.com>
Subject: re: status of hadoop 0.20.1?
Date: Mon, 10 Aug 2009 17:47:14 +0800
Message-ID: <000001ca199f$8ac8cb70$a05a6250$@com>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="gb2312"
Content-Transfer-Encoding: quoted-printable
X-Mailer: Microsoft Office Outlook 12.0
Thread-Index: AcoZbu+TKkdWeLjzS5i42Aq7DaPpewAMIcEA
Content-Language: zh-cn
X-CM-TRANSID: C8mowKBb_wql7H9KqHmUBg--.12062S2
X-Coremail-Antispam: 1Uf129KBjDUn29KB7ZKAUJUUUUUYxn0WfASr-VFAUDa7-sFnT
	9fnUUIcSsGvfJTRUUUjKxYjxAI6xkYrwAYjxAI6xAIw28IcVW8XFylb7IF0VCF04k20xvE
	w2I207IF0wAYjxAI6xCIbckI1I0E57IF64kEYxAxM7k0a2IF6r1UM7kC6x804xWl14x267
	AKxVWUJVW8JwAFxVCF77xC6IxKo4kEV4yl1I0EscIYIxCEI4klw4CSwwAFIxvE14AKwVWU
	JVWUGwA2z4x0Y4vE2Ix0cI8IcVAFwI0_tr0E3s1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI
	0_GcCE3s1l84ACjcxK6I8E87Iv67AKxVW0oVCq3wA2z4x0Y4vEx4A2jsIEc7CjxVAFwI0_
	GcCE3s1ln7IjY7xE6298Mc804VCqF7xvr2I5Mc02F40EFcxC0VAKzVAqx4xG6I80ewAv7V
	C0I7IYx2IY67AKxVWUJVWUGwAv7VC2z280aVAFwI0_Jr0_Gr1lF7xvr2IYc2Ij64vIr41l
	FVAaXTZC67ZELSn0mTvEwaV2v3VFvVW8Mx02cVAKzwCY1Ik26cxK620vw7xCY7Wlc2xSY4
	AK67AK6r4fMxkI7II2jI8vz4vEwIxGrwCF04k20xvY0x0EwIxGrwCF72vE52k0Y41lx4CE
	17CEb7AF67AKxVWUJVWUXwCIc40Y0x0EwIxGrbIYCTnIWIevJa73UjIFyTuYvjxUO38nDU
	UUU
X-CM-SenderInfo: xodpwvxhol0wa6rslhhfrp/
X-Virus-Checked: Checked by ClamAV on apache.org

I also want to ask this question...

-----=D3=CA=BC=FE=D4=AD=BC=FE-----
=B7=A2=BC=FE=C8=CB: =
common-user-return-16633-lamfeeling=3D126.com@hadoop.apache.org
[mailto:common-user-return-16633-lamfeeling=3D126.com@hadoop.apache.org] =
=B4=FA=B1=ED
Kevin Weil
=B7=A2=CB=CD=CA=B1=BC=E4: 2009=C4=EA8=D4=C210=C8=D5 11:59
=CA=D5=BC=FE=C8=CB: common-user@hadoop.apache.org
=D6=F7=CC=E2: status of hadoop 0.20.1?

What is the current status/timeframe for the 0.20.1 release?  It seems =
like
there are a lot of relevant fixes, and it's been sitting idle with the =
same
four JIRAs open for a few weeks now.

Thanks,
Kevin



From common-user-return-16637-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 10:27:48 2009
Return-Path: <common-user-return-16637-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 50420 invoked from network); 10 Aug 2009 10:27:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 10:27:48 -0000
Received: (qmail 65650 invoked by uid 500); 10 Aug 2009 10:27:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 65550 invoked by uid 500); 10 Aug 2009 10:27:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 65540 invoked by uid 99); 10 Aug 2009 10:27:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 10:27:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of clarkemjj@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 10:27:44 +0000
Received: by bwz10 with SMTP id 10so1188575bwz.29
        for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 03:27:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=SXOEch3TQFYYOtBfVgpETeAcePuTnFe9kUMskZctM+k=;
        b=tp8GismRupkbau9UGfDEXnaJ7A7BFK6XMYO0BwKTy++pcYhQL6/JfepDlwnx2jHzoW
         rV6yXgOgTe1oaxAc3HfZ5QNPhsYuwYN1brfB1dL5icw0SAXwH2mlsosztzusSgm9WQo5
         1qwWm0CE/e9lyXQgny+MiwWOKtFQKNcpkQYYc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=m/98KI5V9jLh4pzW3gXpTeHvgwZk54RZVjmI3YUm56Zh8tl5LNuVRMInjjUAl0BIoj
         a7qtMxvpv1fB73MciPP9InXf8x2jffJk5+3y8VbO+5aNYT4COdWfJGLZb30GL+s8rKYR
         4j+jy2nosE1lcqjTjqkbmO+KlIq6CV18/rDvc=
MIME-Version: 1.0
Received: by 10.223.120.197 with SMTP id e5mr330676far.30.1249900043394; Mon, 
	10 Aug 2009 03:27:23 -0700 (PDT)
In-Reply-To: <73d592f60908071903j5dc036b6qb1e06d2d8c42d8de@mail.gmail.com>
References: <4238036a0908070910n16e5a24auc72a187aeea4ef66@mail.gmail.com>
	 <73d592f60908071903j5dc036b6qb1e06d2d8c42d8de@mail.gmail.com>
Date: Mon, 10 Aug 2009 11:27:23 +0100
Message-ID: <4238036a0908100327x281de118ge3132817fc744ce8@mail.gmail.com>
Subject: Re: changing logging
From: John Clarke <clarkemjj@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c5b7121760470470c708ea
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5b7121760470470c708ea
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks for the reply. I considered that but I have a lot of threads in my
application and it's v handy to have log4j output the thread name with the
log message.

It's like the log4j.properties file in the conf/ directory is not being used
as any changes I make seem to have no effect!




2009/8/8 bharath vissapragada <bharathvissapragada1990@gmail.com>

> Print Statements worked out in my case ,,, Dunno whether that approach is
> right or not .. but it works fine ..
>
>
> On Fri, Aug 7, 2009 at 9:40 PM, John Clarke <clarkemjj@gmail.com> wrote:
>
> > Hi,
> >
> > I am using Hadoop 0.18.3. I'm trying to get my app to output DEBUG
> messages
> > to the console using a custom conversion pattern.
> >
> > I'm editing the log4j.properties file in the conf folder but the changes
> > don't seem to work. All the log messages are still INFO and higher and
> the
> > pattern is not changing either.
> >
> > I'm currently running as a local Java app in Eclipse rather than in
> Hadoop.
> >
> > Any ideas?
> >
> > Cheers,
> > John
> >
>

--001636c5b7121760470470c708ea--

From common-user-return-16638-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 15:48:03 2009
Return-Path: <common-user-return-16638-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 71426 invoked from network); 10 Aug 2009 15:48:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 15:48:03 -0000
Received: (qmail 30171 invoked by uid 500); 10 Aug 2009 15:48:07 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 30101 invoked by uid 500); 10 Aug 2009 15:48:06 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 30091 invoked by uid 99); 10 Aug 2009 15:48:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 15:48:06 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 15:47:53 +0000
Received: from SNV-EXBH01.ds.corp.yahoo.com (snv-exbh01.ds.corp.yahoo.com [207.126.227.249])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7AFkmZt002103;
	Mon, 10 Aug 2009 08:46:48 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=qtoFsleMrUJCuFa/xq+OowBZBNGYmsVC8ylLSqKtqdy7ncF3dfDinlU7Thzcg8CU
Received: from SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.87]) by SNV-EXBH01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Mon, 10 Aug 2009 08:46:47 -0700
Received: from 10.72.112.117 ([10.72.112.117]) by SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.84]) via Exchange Front-End Server snv-webmail.corp.yahoo.com ([207.126.227.60]) with Microsoft Exchange Server HTTP-DAV ;
 Mon, 10 Aug 2009 15:46:26 +0000
User-Agent: Microsoft-Entourage/12.20.0.090605
Date: Mon, 10 Aug 2009 08:46:25 -0700
Subject: Re: Some tasks fail to report status between the end of the map and 
 the beginning of the merge
From: Koji Noguchi <knoguchi@yahoo-inc.com>
To: <common-user@hadoop.apache.org>, <mathias.demare@gmail.com>,
        Amogh Vasekar <amogh@yahoo-inc.com>
Message-ID: <C6A58EE1.150E2%knoguchi@yahoo-inc.com>
Thread-Topic: Some tasks fail to report status between the end of the map and 
 the beginning of the merge
Thread-Index: AcoZ0bdxpKrYW+RA90OhzcFZKP7FeA==
In-Reply-To: <375c60f40908090218i364a5596hbbd3c42a626882f7@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="ISO-8859-1"
Content-transfer-encoding: quoted-printable
X-OriginalArrivalTime: 10 Aug 2009 15:46:47.0935 (UTC) FILETIME=[C51CF8F0:01CA19D1]
X-Virus-Checked: Checked by ClamAV on apache.org

> but I didn't find a config option
> that allows ignoring tasks that fail.
>
If 0.18,=20
http://hadoop.apache.org/common/docs/r0.18.3/api/org/apache/hadoop/mapred/J=
o
bConf.html#setMaxMapTaskFailuresPercent(int)
(mapred.max.map.failures.percent)


http://hadoop.apache.org/common/docs/r0.18.3/api/org/apache/hadoop/mapred/J=
o
bConf.html#setMaxReduceTaskFailuresPercent(int)
(mapred.max.reduce.failures.percent)


If 0.19 or later, you can also try skipping records.


Koji



On 8/9/09 2:18 AM, "Mathias De Mar=E9" <mathias.demare@gmail.com> wrote:

> I changed the maximum split size to 30000, and now most tasks actually
> succeed.
> However, I still have the failure problem with some tasks (with a job I w=
as
> running yesterday, I got a failure after 1900 tasks).
> The problem is that these very few failures can bring down the entire job=
,
> as they sometimes seem to just keep failing.
> I looked through the mapred-default.xml, but I didn't find a config optio=
n
> that allows ignoring tasks that fail. Is there a way to do this (it seems
> like the only alternative I have, since I can't make the failures stop)?
>=20
> Mathias
>=20
> 2009/8/5 Mathias De Mar=E9 <mathias.demare@gmail.com>
>=20
>>=20
>> On Wed, Aug 5, 2009 at 9:38 AM, Jothi Padmanabhan
>> <jothipn@yahoo-inc.com>wrote:
>>> Hi,
>>>=20
>>> Could you please try setting this parameter
>>> mapred.merge.recordsBeforeProgress to a lower number?
>>> See https://issues.apache.org/jira/browse/HADOOP-4714
>>>=20
>>> Cheers
>>> Jothi
>>=20
>>=20
>> Hm, that bug looks like it's applicable during the merge, but my case is=
 a
>> block right before the merge (but seemingly right after all of the map t=
asks
>> finish).
>> I tried putting mapred.merge.recordsBeforeProgress to 100, and it didn't
>> make a difference.
>>=20
>> On Wed, Aug 5, 2009 at 10:32 AM, Amogh Vasekar <amogh@yahoo-inc.com>wrot=
e:
>>=20
>>> 10 mins reminds me of parameter mapred.task.timeout . This is
>>> configurable. Or alternatively you might just do a sysout to let tracke=
r
>>> know of its existence ( not an ideal solution though )
>>>=20
>>> Thanks,
>>> Amogh
>>=20
>>=20
>> Well, the map tasks take around 30 minutes to run. Letting the task idle
>> for a large number of minutes after that is a lot of useless time, imho.=
 I
>> tried with 20 minutes now, but I still get timeouts.
>>=20
>> I don't know if it's useful, but here are the settings of the map tasks =
at
>> the moment:
>>=20
>> <configuration>
>>   <property>
>>     <name>mapred.job.tracker</name>
>>     <value>localhost:9001</value>
>>   </property>
>>   <property>
>>     <name>io.sort.mb</name>
>>     <value>3</value>
>>     <description>The total amount of buffer memory to use while sorting
>>     files, in megabytes.  By default, gives each merge stream 1MB, which
>>     should minimize seeks.</description>
>>   </property>
>> <property>
>>   <name>mapred.tasktracker.map.tasks.maximum</name>
>>   <value>4</value>
>>   <description>The maximum number of map tasks that will be run
>>   simultaneously by a task tracker.
>>   </description>
>> </property>
>>=20
>> <property>
>>   <name>mapred.tasktracker.reduce.tasks.maximum</name>
>>   <value>4</value>
>>   <description>The maximum number of reduce tasks that will be run
>>   simultaneously by a task tracker.
>>   </description>
>> </property>
>>=20
>> <property>
>>   <name>mapred.max.split.size</name>
>>   <value>1000000</value>
>> </property>
>>=20
>> <property>
>>   <name>mapred.child.java.opts</name>
>>   <value>-Xmx400m</value>
>> </property>
>>=20
>> <property>
>> <name>mapred.merge.recordsBeforeProgress</name>
>> <value>100</value>
>> </property>
>>=20
>> <property>
>> <name>mapred.task.timeout</name>
>> <value>1200000</value>
>> </property>
>>=20
>> </configuration>
>>=20
>> Ideally, I would want to get rid of the delay that causes the timeouts, =
yet
>> also increase the split size somewhat (though I think a larger split siz=
e
>> would increase the delay even more?).
>> The map tasks take around 8000-11000 records as input, and can produce u=
p
>> to 1 000 000 records as output (in case this is relevant).
>>=20
>> Mathias
>>=20
>>=20


From common-user-return-16639-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 15:50:07 2009
Return-Path: <common-user-return-16639-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 72668 invoked from network); 10 Aug 2009 15:50:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 15:50:06 -0000
Received: (qmail 35545 invoked by uid 500); 10 Aug 2009 15:50:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35474 invoked by uid 500); 10 Aug 2009 15:50:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35464 invoked by uid 99); 10 Aug 2009 15:50:10 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 15:50:10 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 15:50:01 +0000
Received: by vws40 with SMTP id 40so2909298vws.2
        for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 08:49:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:from:date
         :message-id:subject:to:content-type:content-transfer-encoding;
        bh=wc1KaqpvjoNfyZJgPN8NhzKDQYmofbPr7v0JC4qzfIs=;
        b=h5jG11n9O0GlChL9Hr0TPhB32Iv4pamj/7mDsICumS2nqdpjSdNn9WMny+SfvC/vNc
         U5y9rXngsMgrMWBWhsQ4gKCqVy0yuj1FvrcM7kYgjK4S/xwMK1Yc/0Kk37oNHUoo43Qe
         E7b0fZ4XQMNQMTnlj7LsdVKYoHvJBaiNI6oqI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:from:date:message-id:subject:to:content-type
         :content-transfer-encoding;
        b=nf54eOtAvafsHIl6XnI/rXeVN78J/XpTLRcomDSRIP1v2C4vNiz9GvQHaaE+TtRS+n
         EIi3g2MCeA4o9BAal2zyTYA6W8AQNVoWr9uO7pHDE22gAPdBAkeBUdUnAuVBG66/DvRF
         SRTddHhW4q83lyDj8pos1artttYpgrHhbaQ/s=
MIME-Version: 1.0
Received: by 10.220.100.140 with SMTP id y12mr5001910vcn.86.1249919380132; 
	Mon, 10 Aug 2009 08:49:40 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Mon, 10 Aug 2009 11:49:20 -0400
Message-ID: <1e7471d50908100849n6eb05207u83e40131b6c3cf4d@mail.gmail.com>
Subject: InputSplits, Serializers in Hadoop 0.20
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,
In my custom inputformat written using the new Hadoop 0.20 API, I get
rhe following error
	at org.apache.hadoop.io.serializer.SerializationFactory.getSerializer(SerializationFactory.java:73)
	at org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:899)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:779)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:432)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:447)


The code in writeNewSplits which causes this is the last line

...
 try {
      if (array.length != 0) {
        DataOutputBuffer buffer = new DataOutputBuffer();
        RawSplit rawSplit = new RawSplit();
        SerializationFactory factory = new SerializationFactory(conf);

        Serializer<T> serializer =
          factory.getSerializer((Class<T>) array[0].getClass());
...

My InputSplit format has the read and write methods, but I can't quite
figure out what is causing this error.

Thank you in advance
Saptarshi

From common-user-return-16640-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 16:11:36 2009
Return-Path: <common-user-return-16640-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80412 invoked from network); 10 Aug 2009 16:11:36 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 16:11:36 -0000
Received: (qmail 82890 invoked by uid 500); 10 Aug 2009 16:11:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82803 invoked by uid 500); 10 Aug 2009 16:11:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82793 invoked by uid 99); 10 Aug 2009 16:11:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 16:11:40 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 16:11:31 +0000
Received: by vws40 with SMTP id 40so2923487vws.2
        for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 09:11:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:content-type
         :content-transfer-encoding;
        bh=yjediBnJ5RFcRcLfnkMi+5JykZc5xaO7N01LNKojTp0=;
        b=nWaKL9gSPn+VpccHCJQaKa6I6F/Fq4axMAZwyBTS93eeeI0b/V7rc1mjWErciTe8kx
         3spQnfmNjEVhvUpAHDnvsNypckDl5/NjDGC9O7UnUNit1b5gT5wMZ9Q35rl+IdThDxIS
         d1ClA0zN45XqwvglYUFKtsaBoW1CFhX1tF77w=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:content-type:content-transfer-encoding;
        b=ATx2wasPpw0ffELQOERF0UBQHVGwlt19JIs+CF9mHDX2QtqFkeVL1C6JIOTeUzCT0F
         FSV0rmhpNT/L8mDog4QjqPT9vSHXOsRfuMW7ec2GdzotabixsNKtMqi+ptz8lM+NuSJs
         S2CjPjYttd9TXEeBuguF2glDmPkIBMThsMKvg=
MIME-Version: 1.0
Received: by 10.220.91.194 with SMTP id o2mr5008616vcm.4.1249920670095; Mon, 
	10 Aug 2009 09:11:10 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
In-Reply-To: <1e7471d50908100849n6eb05207u83e40131b6c3cf4d@mail.gmail.com>
References: <1e7471d50908100849n6eb05207u83e40131b6c3cf4d@mail.gmail.com>
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Mon, 10 Aug 2009 12:10:50 -0400
Message-ID: <1e7471d50908100910g7099be9cmdfb276afe8dd034a@mail.gmail.com>
Subject: Re: InputSplits, Serializers in Hadoop 0.20
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Fixed. InputSplits in 0.20 should implement Writable

On Mon, Aug 10, 2009 at 11:49 AM, Saptarshi
Guha<saptarshi.guha@gmail.com> wrote:
> Hello,
> In my custom inputformat written using the new Hadoop 0.20 API, I get
> rhe following error
> =C2=A0 =C2=A0 =C2=A0 =C2=A0at org.apache.hadoop.io.serializer.Serializati=
onFactory.getSerializer(SerializationFactory.java:73)
> =C2=A0 =C2=A0 =C2=A0 =C2=A0at org.apache.hadoop.mapred.JobClient.writeNew=
Splits(JobClient.java:899)
> =C2=A0 =C2=A0 =C2=A0 =C2=A0at org.apache.hadoop.mapred.JobClient.submitJo=
bInternal(JobClient.java:779)
> =C2=A0 =C2=A0 =C2=A0 =C2=A0at org.apache.hadoop.mapreduce.Job.submit(Job.=
java:432)
> =C2=A0 =C2=A0 =C2=A0 =C2=A0at org.apache.hadoop.mapreduce.Job.waitForComp=
letion(Job.java:447)
>
>
> The code in writeNewSplits which causes this is the last line
>
> ...
> =C2=A0try {
> =C2=A0 =C2=A0 =C2=A0if (array.length !=3D 0) {
> =C2=A0 =C2=A0 =C2=A0 =C2=A0DataOutputBuffer buffer =3D new DataOutputBuff=
er();
> =C2=A0 =C2=A0 =C2=A0 =C2=A0RawSplit rawSplit =3D new RawSplit();
> =C2=A0 =C2=A0 =C2=A0 =C2=A0SerializationFactory factory =3D new Serializa=
tionFactory(conf);
>
> =C2=A0 =C2=A0 =C2=A0 =C2=A0Serializer<T> serializer =3D
> =C2=A0 =C2=A0 =C2=A0 =C2=A0 =C2=A0factory.getSerializer((Class<T>) array[=
0].getClass());
> ...
>
> My InputSplit format has the read and write methods, but I can't quite
> figure out what is causing this error.
>
> Thank you in advance
> Saptarshi
>

From common-user-return-16641-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 17:54:07 2009
Return-Path: <common-user-return-16641-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 23968 invoked from network); 10 Aug 2009 17:54:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 17:54:07 -0000
Received: (qmail 33557 invoked by uid 500); 10 Aug 2009 17:54:12 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 33461 invoked by uid 500); 10 Aug 2009 17:54:12 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 33451 invoked by uid 99); 10 Aug 2009 17:54:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 17:54:12 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 17:54:04 +0000
Received: by qyk26 with SMTP id 26so2799696qyk.5
        for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 10:53:43 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.74.79 with SMTP id t15mr3401091qaj.331.1249926823101; Mon, 
	10 Aug 2009 10:53:43 -0700 (PDT)
In-Reply-To: <773580c10908070826y6a01b281vcecdea43aa8492ec@mail.gmail.com>
References: <773580c10908070806w2a1a3f84x8248af8324c66309@mail.gmail.com> 
	<773580c10908070826y6a01b281vcecdea43aa8492ec@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Mon, 10 Aug 2009 10:53:23 -0700
Message-ID: <d6d7c4410908101053k28532a69x6a099e7f721d2ed4@mail.gmail.com>
Subject: Re: ~ Replacement for MapReduceBase ~
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175d67544946280470cd44ad
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175d67544946280470cd44ad
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Naga,

That's right. In the old API, Mapper and Reducer were just interfaces and
didn't provide default implementations of their code. Thus MapReduceBase.
Now Mapper and Reducer are classes to extend, so no MapReduceBase is needed.

- Aaron

On Fri, Aug 7, 2009 at 8:26 AM, Naga Vijayapuram <nvijayap@gmail.com> wrote:

> Appears we just need to extend the Mapper class and not use
> MapReduceBase anymore (in hadoop-0.20.0)
>
> If that is not the case, I would like to know the recommended approach
> in hadoop-0.20.0
>
> Thanks,
> Naga Vijayapuram
>
>
> On Fri, Aug 7, 2009 at 8:06 AM, Naga Vijayapuram<nvijayap@gmail.com>
> wrote:
> > Hello,
> >
> > I am using hadoop-0.20.0
> >
> > What's the replacement for the deprecated MapReduceBase?
> >
> > Thanks,
> > Naga Vijayapuram
> >
>

--0015175d67544946280470cd44ad--

From common-user-return-16642-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 18:15:29 2009
Return-Path: <common-user-return-16642-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 34164 invoked from network); 10 Aug 2009 18:15:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 18:15:29 -0000
Received: (qmail 64273 invoked by uid 500); 10 Aug 2009 18:15:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 64172 invoked by uid 500); 10 Aug 2009 18:15:33 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 64162 invoked by uid 99); 10 Aug 2009 18:15:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 18:15:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadooprocks@gmail.com designates 209.85.222.189 as permitted sender)
Received: from [209.85.222.189] (HELO mail-pz0-f189.google.com) (209.85.222.189)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 18:15:25 +0000
Received: by pzk27 with SMTP id 27so3274326pzk.2
        for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 11:15:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=IQf4BU60QxHxs4eTUsrgP7oJ+vKM9glCUitw97FcXaI=;
        b=v41LZnQ/OHA4hrNQVk3TJZsHfw0O1x1KSa/HPowAcwb2KBdvUZ0vjgbbUwnAB4Fy24
         3v7bg8eKyDaS/Vewi/gSre7z9HAjtZBTnPcRqeYbnuQRGDBx8Dea0g9BYDZtmSpVplBf
         87hKzS1XpY1qQKNOzSXgog/yXSjefl8qtNTd0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=I7l6tTPx905jak5GiGIV8Anun6wiNK7BmlabMmAq6ssfMcZ/HZcWWsWvhghAufjTu9
         RveZVufJUKSr7ctobHzuRZLJjmDkmfqghHulvzWYS7DtUdJ5l3i1K1bmey0Bl5CoZuI4
         5g70Pxc6p07k03YYUvJIMpZ6Gn/vVW7fd6lks=
MIME-Version: 1.0
Received: by 10.142.157.1 with SMTP id f1mr863290wfe.161.1249928105307; Mon, 
	10 Aug 2009 11:15:05 -0700 (PDT)
Date: Mon, 10 Aug 2009 11:15:05 -0700
Message-ID: <207bdf5a0908101115l2caa48b3v15d8fc7f80ba12bc@mail.gmail.com>
Subject: newbie question
From: hadooprcoks <hadooprocks@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd244f4b62e800470cd90ee
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd244f4b62e800470cd90ee
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,I was looking at the FileSystem API and have couple of quick questions
for experts.
In the FileSystem.create() call two of the parameters are bufferSize and
blockSize.

I understand they correspond to io.file.buffer.size and dfs.block.size
properties in the config files.

My question is - do we expect that applications can provide different values
for them on a per file basis or usually its a cluster wide setting ?

Thanks
-Vineet

--000e0cd244f4b62e800470cd90ee--

From common-user-return-16643-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 18:43:21 2009
Return-Path: <common-user-return-16643-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 53584 invoked from network); 10 Aug 2009 18:43:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 18:43:21 -0000
Received: (qmail 2616 invoked by uid 500); 10 Aug 2009 18:43:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 2533 invoked by uid 500); 10 Aug 2009 18:43:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 2523 invoked by uid 99); 10 Aug 2009 18:43:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 18:43:26 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 18:43:17 +0000
Received: by qyk26 with SMTP id 26so2830928qyk.5
        for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 11:42:55 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.37.147 with SMTP id x19mr2513511qad.120.1249929775297; 
	Mon, 10 Aug 2009 11:42:55 -0700 (PDT)
In-Reply-To: <207bdf5a0908101115l2caa48b3v15d8fc7f80ba12bc@mail.gmail.com>
References: <207bdf5a0908101115l2caa48b3v15d8fc7f80ba12bc@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Mon, 10 Aug 2009 11:42:35 -0700
Message-ID: <d6d7c4410908101142o73106842m181edf403759466f@mail.gmail.com>
Subject: Re: newbie question
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175cb1ca4037100470cdf4a9
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175cb1ca4037100470cdf4a9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

You can set it on a per-file basis if you'd like the control. The data
structures associated with files allow these to be individually controlled.
But there's also a  create() call that only accepts the Path to open as an
argument. This uses the configuration file defaults. This use case is
considerably more common in user applications.

- Aaron

On Mon, Aug 10, 2009 at 11:15 AM, hadooprcoks <hadooprocks@gmail.com> wrote:

> Hi,I was looking at the FileSystem API and have couple of quick questions
> for experts.
> In the FileSystem.create() call two of the parameters are bufferSize and
> blockSize.
>
> I understand they correspond to io.file.buffer.size and dfs.block.size
> properties in the config files.
>
> My question is - do we expect that applications can provide different
> values
> for them on a per file basis or usually its a cluster wide setting ?
>
> Thanks
> -Vineet
>

--0015175cb1ca4037100470cdf4a9--

From common-user-return-16644-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 19:07:30 2009
Return-Path: <common-user-return-16644-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 60157 invoked from network); 10 Aug 2009 19:07:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 19:07:30 -0000
Received: (qmail 42879 invoked by uid 500); 10 Aug 2009 19:07:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 42782 invoked by uid 500); 10 Aug 2009 19:07:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 42772 invoked by uid 99); 10 Aug 2009 19:07:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 19:07:35 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [212.201.18.42] (HELO mout1.fh-giessen.de) (212.201.18.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 19:07:22 +0000
Received: from mx3.fh-giessen.de (mx3.fh-giessen.de [212.201.18.28])
	(using TLSv1 with cipher AES256-SHA (256/256 bits))
	(No client certificate requested)
	by mout1.fh-giessen.de (Postfix) with ESMTPS id 41EAAAC3A9
	for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 21:07:02 +0200 (CEST)
Received: from mailgate.fh-giessen.de ([212.201.18.39])
	by mx3.fh-giessen.de with esmtp (Exim 4.69)
	(envelope-from <joerg.rieger@mni.fh-giessen.de>)
	id 1MaaD0-0004bC-4K
	for common-user@hadoop.apache.org; Mon, 10 Aug 2009 21:07:02 +0200
Received: from gssn-590d2f4c.pool.einsundeins.de ([89.13.47.76] helo=jac.jnet.local)
	by mailgate.fh-giessen.de with esmtpsa (TLSv1:AES128-SHA:128)
	(Exim 4.69)
	(envelope-from <joerg.rieger@mni.fh-giessen.de>)
	id 1MaaCz-0005pc-Le
	for common-user@hadoop.apache.org; Mon, 10 Aug 2009 21:07:01 +0200
Message-Id: <C03AB49A-1641-4452-BF99-7EBA2EE0AB0B@mni.fh-giessen.de>
From: Joerg Rieger <joerg.rieger@mni.fh-giessen.de>
To: common-user@hadoop.apache.org
In-Reply-To: <4b2c7b610907300516k5db15dc0nf08461e92f357c9a@mail.gmail.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: XML files in HDFS
Date: Mon, 10 Aug 2009 21:07:00 +0200
References: <BAY102-W474085CBF74EDC91FD44D8BC130@phx.gbl> <4b2c7b610907300516k5db15dc0nf08461e92f357c9a@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

while flipping through the cloud9 collections, I came across an XML  
InputFormat class:

http://www.umiacs.umd.edu/~jimmylin/cloud9/docs/api/edu/umd/cloud9/collection/XMLInputFormat.html

I haven't used it myself, but It might be worth a try.


Joerg


On 30.07.2009, at 14:16, Hyunsik Choi wrote:

> Hi,
>
> Actually, I don't know there exists any well-made XML InputFormat or
> Record reader.
> To the best of my knowledge, StreamXmlRecordReader (
> http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/streaming/StreamXmlRecordReader.html
> ) of Hadoop streaming is only solution.
>
> Good luck!
>
> --
> Hyunsik Choi
> Database & Information Systems Group, Korea University
> http://diveintodata.org
>
>
>
> On Thu, Jul 30, 2009 at 5:30 PM, Wasim Bari<wasimbari@msn.com> wrote:
>>
>>
>>
>> Hi All,
>>
>>       I am looking to store some real big xml files in HDFS and  
>> then process them using MapReduce.
>>
>>
>>
>> Do we have some utility which uploads the xml files to hdfs making  
>> sure split  up of file in block doen't brake an elemet ( mean half  
>> element on one block and half on someother ) ?
>>
>>
>>
>> Any suggestions to work thos out will  be appreciated greatly.
>>
>>
>>
>> Thanks
>>
>>
>>
>> Bari
>>

-- 




From common-user-return-16645-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 19:38:58 2009
Return-Path: <common-user-return-16645-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 66498 invoked from network); 10 Aug 2009 19:38:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 19:38:58 -0000
Received: (qmail 84135 invoked by uid 500); 10 Aug 2009 19:39:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 84048 invoked by uid 500); 10 Aug 2009 19:39:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 84038 invoked by uid 99); 10 Aug 2009 19:39:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 19:39:02 +0000
X-ASF-Spam-Status: No, hits=-1.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [64.78.17.143] (HELO EXSMTP012-12.exch012.intermedia.net) (64.78.17.143)
    by apache.org (qpsmtpd/0.29) with SMTP; Mon, 10 Aug 2009 19:38:54 +0000
Received: from EXVBE012-14.exch012.intermedia.net ([10.254.2.74]) by EXSMTP012-12.exch012.intermedia.net with Microsoft SMTPSVC(6.0.3790.1830);
	 Mon, 10 Aug 2009 12:38:33 -0700
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
Subject: RE: OutputCommitter for rollbacks?
Date: Mon, 10 Aug 2009 12:37:51 -0700
Message-ID: <FAE2AFC892D2DC43AF29AADCF271940A016A0400@EXVBE012-14.exch012.intermedia.net>
In-Reply-To: <4A7F9C86.7000406@yahoo-inc.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: OutputCommitter for rollbacks?
Thread-Index: AcoZcCe/MGyNiOqsQC2jdGjs+pjJ8wAgSHpA
References: <FAE2AFC892D2DC43AF29AADCF271940A016A01F6@EXVBE012-14.exch012.intermedia.net> <4A7F9C86.7000406@yahoo-inc.com>
From: "Deepika Khera" <deepikak@collarity.com>
To: <common-user@hadoop.apache.org>
X-OriginalArrivalTime: 10 Aug 2009 19:38:33.0910 (UTC) FILETIME=[25B85D60:01CA19F2]
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks Amareshwari for your response.

It seems like a good idea to use the map progress & reduce progress. My
only concern is that in the web interface(jobdetails.jsp) , we see some
of our jobs show 100% map & 100% reduce, while the reduce still seems to
be running(Not sure but maybe it's just a UI thing).=20

But I guess if the job has reached its cleanup, we should be able to
trust these numbers(map progress & reduce progress) and make the call on
commit & rollback?

Thanks again,
Deepika


-----Original Message-----
From: Amareshwari Sriramadasu [mailto:amarsri@yahoo-inc.com]=20
Sent: Sunday, August 09, 2009 9:05 PM
To: common-user@hadoop.apache.org
Subject: Re: OutputCommitter for rollbacks?

Hi Deepika,

You can use the fact that map progress and reduce progress 1.0 for=20
succeeded jobs and is <1.0 for failed or killed jobs.
Hope this helps.

Thanks
Amareshwari

Deepika Khera wrote:
> Hi,
>
> =20
>
> I am trying to use the OutputCommitter.cleanupJob() to commit and
> rollback my job. The cleanup() method is called whether the job was
> successful, killed or failed.
>
> =20
>
> I need to know in the cleanupJob(jobContext) method the status of job
so
> far, especially if it failed or was killed.
>
> =20
>
> The issue is that no matter whether the job failed or was
> killed/successful, the job status in the committer is "running" (which
> makes sense but not what I need). It seems that I can only know the
job
> status when the entire job (including the cleanup task) has finished.=20
>
> =20
>
> I see an open JIRA  which is related , but until we have a resolution
to
> that is there any other  way to achieve this?
>
> =20
>
> http://issues.apache.org/jira/browse/HADOOP-6005
>
> =20
>
> So, what I need is make the decision in the cleanupJob() whether I
> should do  a commit or rollback(Killed/Failed vs Successful).
>
> =20
>
> Would appreciate any help on this.
>
> =20
>
> Thanks,
>
> Deepika
>
>
>  =20


From common-user-return-16646-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 22:08:06 2009
Return-Path: <common-user-return-16646-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 19079 invoked from network); 10 Aug 2009 22:08:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 22:08:06 -0000
Received: (qmail 67293 invoked by uid 500); 10 Aug 2009 22:07:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 67251 invoked by uid 500); 10 Aug 2009 22:07:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 67230 invoked by uid 99); 10 Aug 2009 22:07:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 22:07:46 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [192.139.80.206] (HELO mx1.casalemedia.com) (192.139.80.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 22:07:36 +0000
Received: from exchange.casalemedia.com (unknown [10.3.10.15])
	by mx1.casalemedia.com (Postfix) with ESMTP id 120CE588013
	for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 18:07:16 -0400 (EDT)
Received: from mayuran.casalemedia.com (10.3.10.40) by
 exchange.casalemedia.com (10.3.10.15) with Microsoft SMTP Server id
 8.1.240.5; Mon, 10 Aug 2009 18:07:15 -0400
Message-ID: <4A809A0D.7060704@casalemedia.com>
Date: Mon, 10 Aug 2009 18:07:09 -0400
From: Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: corrupt filesystem
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello all,

What can cause HDFS to become corrupt? I was running some jobs which 
were failing. 
When I checked logs I saw that some files were corrupt so I ran  'hadoop 
fsck /' which
showed that a few files were corrupt:

/user/data/2009-07-01/165_2009-07-01.log: CORRUPT block 
blk_1697509332927954816
/user/data/2009-07-21/060_2009-07-21.log: CORRUPT block 
blk_8841160612810933777
/user/data/2009-07-26/173_2009-07-26.log: CORRUPT block 
blk_-6669973789246139664

I had backups of these files so what I did was delete these and reload 
them, so the file system
is OK now.  What I'm wondering is how these files became corrupt.  There 
are 6 nodes in the
cluster and I have a replication factor of 3.

I had assumed that if a replica became corrupt that it would be replaced 
by a non-corrupt copy.
Is this not the case?

Would there have been some way to recover the files if I didn't have any 
backups ?

Another concern is that I only found out HDFS was corrupt by accident.  
I suppose I should have
a script run every few minutes to parse the results of 'hadoop fsck /' 
and email if anything becomes
corrupt.  How are people currently handling this ?

thank you very much
M

From common-user-return-16647-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 22:38:39 2009
Return-Path: <common-user-return-16647-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 31925 invoked from network); 10 Aug 2009 22:38:39 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 22:38:39 -0000
Received: (qmail 4002 invoked by uid 500); 10 Aug 2009 22:38:43 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 3891 invoked by uid 500); 10 Aug 2009 22:38:43 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 3881 invoked by uid 99); 10 Aug 2009 22:38:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 22:38:43 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 22:38:31 +0000
Received: from [10.72.106.226] (heighthigh-lx.corp.yahoo.com [10.72.106.226])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7AMb2TZ091071
	for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 15:37:02 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=IWqQjMnw9mqKrp9kmjQOkb4apIS9iN5IgxKB8j6mn6uwFF5NZHdnmbGoruczMSbo
Message-ID: <4A80A10E.8010700@yahoo-inc.com>
Date: Mon, 10 Aug 2009 15:37:02 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: corrupt filesystem
References: <4A809A0D.7060704@casalemedia.com>
In-Reply-To: <4A809A0D.7060704@casalemedia.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


 > I had assumed that if a replica became corrupt that it would be replaced
 > by a non-corrupt copy.
 > Is this not the case?

yes it is. Usually some random block might be corrupted for various 
reasons and it gets replaced by another replica of the block.

A block might stay in corrupt state if there are no good replicas left 
or new replicas could not be created. The actual reason might be 
hardware related (say a lot of nodes die) or a real software bug.

If you use Hadoop-0.20 or later, you will notice a warning in red on the 
NameNode front page if some blocks are left with no good replicas. You 
don't need to run FSCK (which could be costly) each time.

If you are interested, you could try to trace one of these block ids in 
NameNode log to see what happened it. We are always eager to hear about 
irrecoverable errors. Please mention hadoop version you are using.

If the data is corrupt (rather than truncated or missing), you can fetch
the data by using "-ignoreCrc" option to 'fs -get'.

Raghu.

Mayuran Yogarajah wrote:
> Hello all,
> 
> What can cause HDFS to become corrupt? I was running some jobs which 
> were failing. When I checked logs I saw that some files were corrupt so 
> I ran  'hadoop fsck /' which
> showed that a few files were corrupt:
> 
> /user/data/2009-07-01/165_2009-07-01.log: CORRUPT block 
> blk_1697509332927954816
> /user/data/2009-07-21/060_2009-07-21.log: CORRUPT block 
> blk_8841160612810933777
> /user/data/2009-07-26/173_2009-07-26.log: CORRUPT block 
> blk_-6669973789246139664
> 
> I had backups of these files so what I did was delete these and reload 
> them, so the file system
> is OK now.  What I'm wondering is how these files became corrupt.  There 
> are 6 nodes in the
> cluster and I have a replication factor of 3.
> 
> I had assumed that if a replica became corrupt that it would be replaced 
> by a non-corrupt copy.
> Is this not the case?
> 
> Would there have been some way to recover the files if I didn't have any 
> backups ?
> 
> Another concern is that I only found out HDFS was corrupt by accident.  
> I suppose I should have
> a script run every few minutes to parse the results of 'hadoop fsck /' 
> and email if anything becomes
> corrupt.  How are people currently handling this ?
> 
> thank you very much
> M


From common-user-return-16648-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 10 23:15:34 2009
Return-Path: <common-user-return-16648-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 40933 invoked from network); 10 Aug 2009 23:15:33 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 10 Aug 2009 23:15:33 -0000
Received: (qmail 39817 invoked by uid 500); 10 Aug 2009 23:15:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 39737 invoked by uid 500); 10 Aug 2009 23:15:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 39727 invoked by uid 99); 10 Aug 2009 23:15:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 23:15:38 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [192.139.80.206] (HELO mx1.casalemedia.com) (192.139.80.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 10 Aug 2009 23:15:29 +0000
Received: from exchange.casalemedia.com (unknown [10.3.10.15])
	by mx1.casalemedia.com (Postfix) with ESMTP id 21D06588014
	for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 19:15:08 -0400 (EDT)
Received: from mayuran.casalemedia.com (10.3.10.40) by
 exchange.casalemedia.com (10.3.10.15) with Microsoft SMTP Server id
 8.1.240.5; Mon, 10 Aug 2009 19:15:07 -0400
Message-ID: <4A80A9F5.9000603@casalemedia.com>
Date: Mon, 10 Aug 2009 19:15:01 -0400
From: Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: Re: corrupt filesystem
References: <4A809A0D.7060704@casalemedia.com> <4A80A10E.8010700@yahoo-inc.com>
In-Reply-To: <4A80A10E.8010700@yahoo-inc.com>
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

> If you are interested, you could try to trace one of these block ids in
> NameNode log to see what happened it. We are always eager to hear about
> irrecoverable errors. Please mention hadoop version you are using.
>
>   
I'm using Hadoop 0.18.3.  I just checked namenode log for one of the bad 
blocks. 
I see entries from Saturday saying:
ask 1.1.1.6:50010 to replicate blk_1697509332927954816_8724 to 
datanode(s) < all other data nodes >

I only loaded this data Saturday, and the .6 data node became full at 
some point.
When data is first loaded into the cluster, does the name node send the 
data to as many nodes as
it can to satisfy the replication factor, or does it send it to one node 
and ask that node send it to others?

If its the latter then its possible that the block became corrupt when I 
first loaded it to .6 (since it was full),
and since it was designated to send the block to other nodes none of the 
nodes would have a non-corrupt
copy.

Raghu, please let me know what you think.

thanks,

M

From common-user-return-16649-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 03:54:19 2009
Return-Path: <common-user-return-16649-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 31374 invoked from network); 11 Aug 2009 03:54:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 03:54:18 -0000
Received: (qmail 26021 invoked by uid 500); 11 Aug 2009 03:54:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25934 invoked by uid 500); 11 Aug 2009 03:54:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25924 invoked by uid 99); 11 Aug 2009 03:54:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 03:54:22 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.20] (HELO mrout1-b.corp.re1.yahoo.com) (69.147.107.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 03:54:10 +0000
Received: from ownstrong-lr.eglbp.corp.yahoo.com (ownstrong-lr.eglbp.corp.yahoo.com [10.66.74.39])
	by mrout1-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7B3qXi5081940
	for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 20:52:35 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=yKzIoSAZLxPR5SxYdm1aDKqm4tWysI3exLG+ebYIM5pHZt1etkLv2ZklF402VNYv
Message-ID: <4A80EAC2.3010606@yahoo-inc.com>
Date: Tue, 11 Aug 2009 09:21:30 +0530
From: Amareshwari Sriramadasu <amarsri@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: OutputCommitter for rollbacks?
References: <FAE2AFC892D2DC43AF29AADCF271940A016A01F6@EXVBE012-14.exch012.intermedia.net> <4A7F9C86.7000406@yahoo-inc.com> <FAE2AFC892D2DC43AF29AADCF271940A016A0400@EXVBE012-14.exch012.intermedia.net>
In-Reply-To: <FAE2AFC892D2DC43AF29AADCF271940A016A0400@EXVBE012-14.exch012.intermedia.net>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Deepika Khera wrote:
> Thanks Amareshwari for your response.
>
> It seems like a good idea to use the map progress & reduce progress. My
> only concern is that in the web interface(jobdetails.jsp) , we see some
> of our jobs show 100% map & 100% reduce, while the reduce still seems to
> be running(Not sure but maybe it's just a UI thing). 
>
> But I guess if the job has reached its cleanup, we should be able to
> trust these numbers(map progress & reduce progress) and make the call on
> commit & rollback?
>
>   
Yes. You can assume that when cleanup is running and reduce progress is 
100%, job is successful.
> Thanks again,
> Deepika
>
>
> -----Original Message-----
> From: Amareshwari Sriramadasu [mailto:amarsri@yahoo-inc.com] 
> Sent: Sunday, August 09, 2009 9:05 PM
> To: common-user@hadoop.apache.org
> Subject: Re: OutputCommitter for rollbacks?
>
> Hi Deepika,
>
> You can use the fact that map progress and reduce progress 1.0 for 
> succeeded jobs and is <1.0 for failed or killed jobs.
> Hope this helps.
>
> Thanks
> Amareshwari
>
> Deepika Khera wrote:
>   
>> Hi,
>>
>>  
>>
>> I am trying to use the OutputCommitter.cleanupJob() to commit and
>> rollback my job. The cleanup() method is called whether the job was
>> successful, killed or failed.
>>
>>  
>>
>> I need to know in the cleanupJob(jobContext) method the status of job
>>     
> so
>   
>> far, especially if it failed or was killed.
>>
>>  
>>
>> The issue is that no matter whether the job failed or was
>> killed/successful, the job status in the committer is "running" (which
>> makes sense but not what I need). It seems that I can only know the
>>     
> job
>   
>> status when the entire job (including the cleanup task) has finished. 
>>
>>  
>>
>> I see an open JIRA  which is related , but until we have a resolution
>>     
> to
>   
>> that is there any other  way to achieve this?
>>
>>  
>>
>> http://issues.apache.org/jira/browse/HADOOP-6005
>>
>>  
>>
>> So, what I need is make the decision in the cleanupJob() whether I
>> should do  a commit or rollback(Killed/Failed vs Successful).
>>
>>  
>>
>> Would appreciate any help on this.
>>
>>  
>>
>> Thanks,
>>
>> Deepika
>>
>>
>>   
>>     
>
>   


From common-user-return-16650-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 05:31:24 2009
Return-Path: <common-user-return-16650-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 46182 invoked from network); 11 Aug 2009 05:31:24 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 05:31:24 -0000
Received: (qmail 83271 invoked by uid 500); 11 Aug 2009 05:31:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 83172 invoked by uid 500); 11 Aug 2009 05:31:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 83162 invoked by uid 99); 11 Aug 2009 05:31:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 05:31:28 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pareekash@gmail.com designates 209.85.222.189 as permitted sender)
Received: from [209.85.222.189] (HELO mail-pz0-f189.google.com) (209.85.222.189)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 05:31:20 +0000
Received: by pzk27 with SMTP id 27so3576443pzk.2
        for <common-user@hadoop.apache.org>; Mon, 10 Aug 2009 22:31:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=6/gdgRVrduHI16Fo+Vy8WYi/hzUNaTgd7KVGI2zy3Wo=;
        b=ZXvasPZiKqXMxigXTPFhiTrOjR0Ic9uhjrgdLNqmDbHtyGrhSRgBTIJaioxCN0OK/v
         Hpvwxdd23mbTBAiZvDeX5MySr11LBavIapGzuhKfQ5MN1/fHvJUZjIaTisUhm3xHGi0B
         lFzMkqNe8skphKEPVXTx1GE9gASksMfGE1V7o=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=muOyKHCErZJAffJ1yHnG9IY4F0PTzHWXgWZWBhCrSNeilUb2TaLz1dPb+k/nrqZRA9
         QciuaOUvE4tICHOgsZ+4wV2BMJvuUqk5WamuIPM/txxxKOYYvYzJLvjwAyYdpdXtwkT+
         Cue6k90VWKN2w2hiTG+Ic7OZiR1llEUseg4zI=
MIME-Version: 1.0
Received: by 10.114.79.13 with SMTP id c13mr7530741wab.149.1249968659995; Mon, 
	10 Aug 2009 22:30:59 -0700 (PDT)
Date: Tue, 11 Aug 2009 11:00:59 +0530
Message-ID: <45d9159d0908102230k4627b999w474281f2db0f98fa@mail.gmail.com>
Subject: Question on file HDFS file system
From: ashish pareek <pareekash@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016364c6815f59ebf0470d70120
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364c6815f59ebf0470d70120
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Everybody,

                   I would like to understand HDFS source code. But basic
question I want to ask is what type of data-structure does HDFS use to store
INode information.  I am interested in knowing what code of HDFS is
responsible with meta-data info of files.
Please can some HDFS-Guru throw some light on this topic and suggest some
way how to understand HDFS source code. :)

Regards,
Ashish

--0016364c6815f59ebf0470d70120--

From common-user-return-16651-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 07:49:26 2009
Return-Path: <common-user-return-16651-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 1902 invoked from network); 11 Aug 2009 07:49:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 07:49:26 -0000
Received: (qmail 16426 invoked by uid 500); 11 Aug 2009 07:49:31 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 16356 invoked by uid 500); 11 Aug 2009 07:49:30 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 16346 invoked by uid 99); 11 Aug 2009 07:49:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 07:49:30 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pallavi.palleti@corp.aol.com designates 205.188.249.129 as permitted sender)
Received: from [205.188.249.129] (HELO omr-d31.mx.aol.com) (205.188.249.129)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 07:49:21 +0000
Received: from AOLDTCMEH01.ad.office.aol.com (aoldtcmeh01.office.aol.com [10.180.121.20]) by omr-d31.mx.aol.com (v117.7) with ESMTP id MAILOMRD312-7e224a8122684; Tue, 11 Aug 2009 03:48:56 -0400
Received: from AOLMTCMEI02.ad.office.aol.com ([10.178.3.19]) by AOLDTCMEH01.ad.office.aol.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Tue, 11 Aug 2009 03:48:57 -0400
Received: from localhost ([10.178.3.11]) by AOLMTCMEI02.ad.office.aol.com over TLS secured channel with Microsoft SMTPSVC(6.0.3790.3959);
	 Tue, 11 Aug 2009 03:48:56 -0400
Date: Tue, 11 Aug 2009 13:18:51 +0530 (GMT+05:30)
From: Pallavi Palleti <pallavi.palleti@corp.aol.com>
To: common-user@hadoop.apache.org
Message-ID: <19745250.321249976926698.JavaMail.pallavi@e1a31053e.in.office.aol.com>
In-Reply-To: <2876901.301249976755609.JavaMail.pallavi@e1a31053e.in.office.aol.com>
Subject: File is closed but data is not visible
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-OriginalArrivalTime: 11 Aug 2009 07:48:56.0810 (UTC) FILETIME=[2E343CA0:01CA1A58]
X-AOL-IP: 10.180.121.20
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

We have an application where we pull logs from an external server(far apart from hadoop cluster) to hadoop cluster. Sometimes, we could see huge delay (of 1 hour or more) in actually seeing the data in HDFS though the file has been closed and the variable is set to null from the external application.I was in the impression that when I close the file, the data gets reflected in hadoop cluster. Now, in this situation, it is even more complicated to handle write failures as it is giving false impression to the client that data has been written to HDFS. Kindly clarify if my perception is correct. If yes, Could some one tell me what is causing the delay in actually showing the data. During those cases, how can we tackle write failures (due to some temporary issues like data node not available, disk is full) as there is no way, we can figure out the failure at the client side?

Thanks
Pallavi

From common-user-return-16652-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 09:47:59 2009
Return-Path: <common-user-return-16652-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 51966 invoked from network); 11 Aug 2009 09:47:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 09:47:58 -0000
Received: (qmail 71413 invoked by uid 500); 11 Aug 2009 09:48:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 71321 invoked by uid 500); 11 Aug 2009 09:48:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 5985 invoked by uid 99); 11 Aug 2009 08:42:38 -0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of avryadav@gmail.com designates 209.85.132.245 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=1zlaWCWRY2mYL4gbDti5RlHUBk31Yyo6shsbCVSUfYo=;
        b=kJvZuWw74sDdLAqsqpynlQAZzfU+ATKDhfMOUCBkS+pl/hEZJarelOjKJNgUncVv7j
         IF6uGVwPqXnQghKMHpf4dOkDAuP5KyYXg+4B06plDrLqrdoA3O6BLtJ3hk8vrdg2c/Ms
         Ib42KXTG70/pIkhpxXQnEk4lYJd2ISpVGlkRU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=lvflI0RokxcnV1wxNUCu/ICMKLk85Zq5j2l6J5cV1E9pPy7Gpmfp19vGBcLWkOjWuY
         svWDFtFp4oUzs9KuqONUZ4/1CG93lQTEMEquYpZ/j3DTXfUQ2vFbgU2pUqalS4IRwcaQ
         vLdc6HhG+aIx+EPE2CPQBIzfZhPx65rQQ8GMo=
MIME-Version: 1.0
Date: Tue, 11 Aug 2009 14:12:09 +0530
Message-ID: <9a65b3c50908110142s54bfeb06p3126553b4c3892ac@mail.gmail.com>
Subject: what is the hadoop version used in both pig2.0 and nutch1.0
From: venkata ramanaiah anneboina <avryadav@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi
 I am using pig 2.0 and nutch 1.0; but it dont have common hadoop verion.
 what is common verion;

 Which version of pig and which version of nutch i need to use (this
brings comman hadoop version only)


please can any one help on this;

thanks
ramana

From common-user-return-16653-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 10:37:32 2009
Return-Path: <common-user-return-16653-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 78002 invoked from network); 11 Aug 2009 10:37:32 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 10:37:32 -0000
Received: (qmail 28079 invoked by uid 500); 11 Aug 2009 10:37:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 27988 invoked by uid 500); 11 Aug 2009 10:37:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 27977 invoked by uid 99); 11 Aug 2009 10:37:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 10:37:37 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [192.6.10.2] (HELO colossus.hpl.hp.com) (192.6.10.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 10:37:25 +0000
Received: from localhost (localhost [127.0.0.1])
	by colossus.hpl.hp.com (Postfix) with ESMTP id B54EB1BA33C
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 11:37:04 +0100 (BST)
X-Virus-Scanned: Debian amavisd-new at hpl.hp.com
Received: from colossus.hpl.hp.com ([127.0.0.1])
	by localhost (colossus.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id 7lXjVVMl1d8M for <common-user@hadoop.apache.org>;
	Tue, 11 Aug 2009 11:37:04 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by colossus.hpl.hp.com (Postfix) with ESMTPS id 4152F1BA2F5
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 11:37:04 +0100 (BST)
MailScanner-NULL-Check: 1250591812.20114@5LvOGiX8JOgvjn1TRuThOQ
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7BAaojh020538
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 11:36:51 +0100 (BST)
Message-ID: <4A8149C2.3090102@apache.org>
Date: Tue, 11 Aug 2009 11:36:50 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: changing logging
References: <4238036a0908070910n16e5a24auc72a187aeea4ef66@mail.gmail.com>	 <73d592f60908071903j5dc036b6qb1e06d2d8c42d8de@mail.gmail.com> <4238036a0908100327x281de118ge3132817fc744ce8@mail.gmail.com>
In-Reply-To: <4238036a0908100327x281de118ge3132817fc744ce8@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7BAaojh020538
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

John Clarke wrote:
> Thanks for the reply. I considered that but I have a lot of threads in my
> application and it's v handy to have log4j output the thread name with the
> log message.
> 
> It's like the log4j.properties file in the conf/ directory is not being used
> as any changes I make seem to have no effect!

Make sure there isn't a log4j. properties file in any JAR you are using; 
it will get picked up first.
You can use Ant's <whichresource> task to find this out for you; give it 
the classpath you are using and it will set a property to the first 
instance of the resource that the classloader finds


From common-user-return-16654-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 10:46:23 2009
Return-Path: <common-user-return-16654-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80036 invoked from network); 11 Aug 2009 10:46:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 10:46:23 -0000
Received: (qmail 35326 invoked by uid 500); 11 Aug 2009 10:46:27 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35235 invoked by uid 500); 11 Aug 2009 10:46:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35225 invoked by uid 99); 11 Aug 2009 10:46:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 10:46:27 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [192.6.10.60] (HELO tobor.hpl.hp.com) (192.6.10.60)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 10:46:16 +0000
Received: from localhost (localhost [127.0.0.1])
	by tobor.hpl.hp.com (Postfix) with ESMTP id 01FF6B7CF4
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 11:45:53 +0100 (BST)
X-Virus-Scanned: amavisd-new at hplb.hpl.hp.com
Received: from tobor.hpl.hp.com ([127.0.0.1])
	by localhost (tobor.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id TkBXCV50SAmc for <common-user@hadoop.apache.org>;
	Tue, 11 Aug 2009 11:45:46 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by tobor.hpl.hp.com (Postfix) with ESMTPS id 7ED87B7CD4
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 11:45:45 +0100 (BST)
MailScanner-NULL-Check: 1250592334.04715@mfKq2047Az0ZFWWqkyWQ/w
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7BAjXov020928
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 11:45:33 +0100 (BST)
Message-ID: <4A814BCD.2060500@apache.org>
Date: Tue, 11 Aug 2009 11:45:33 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: HADOOP-4539 question
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com>	 <4A7BECD9.20303@apache.org> <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com>
In-Reply-To: <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7BAjXov020928
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

Stas Oskin wrote:
> Hi.
> 
> What is the recommended a utility for this?
> 
> Thanks.

for those of us whose hosts are virtual and who have control over the 
infrastructure its fairly simple: bring up a new VM on a different blade 
with the same base image and hostname.

If you have a non-virtual cluster, you need a machine that you can bring 
up with that same hostname; either have something sitting around 
(switched off) waiting for the call of duty, or you rename a node and 
reboot it.

If you own DNS, bring up all the nodes (and the clients) with the JVM 
command-line property networkaddress.cache.ttl to to something low (like 
60s), and then you should be able to bring up a node with the same name 
but a different IPAddress. This is useful if you can't control the 
IPAddr of a node, but you can at least change the DNS entry

> 
> 2009/8/7 Steve Loughran <stevel@apache.org>
> 
>> Stas Oskin wrote:
>>
>>> Hi.
>>>
>>> I checked this ticket and I like what I found.
>>>
>>> Had question about it, and hoped someone can answer it:
>>>
>>> If I have a NN, and BN, and the NN fails, how the DFS clients will know
>>> how
>>> to connect to the new IP?
>>>
>>> It will be a config level setting?
>>>
>>> Or it needs to be achieved via external Linux HA scripts?
>>>
>>> Thanks!
>>>
>>>
>> right now the new NN has to come up with the same hostname and IP address
>> as the original
>>
> 


-- 
Steve Loughran                  http://www.1060.org/blogxter/publish/5
Author: Ant in Action           http://antbook.org/

From common-user-return-16655-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 11:34:31 2009
Return-Path: <common-user-return-16655-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 90542 invoked from network); 11 Aug 2009 11:34:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 11:34:28 -0000
Received: (qmail 86898 invoked by uid 500); 11 Aug 2009 11:34:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 86814 invoked by uid 500); 11 Aug 2009 11:34:31 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 86804 invoked by uid 99); 11 Aug 2009 11:34:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 11:34:31 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.200.170 as permitted sender)
Received: from [209.85.200.170] (HELO wf-out-1314.google.com) (209.85.200.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 11:34:22 +0000
Received: by wf-out-1314.google.com with SMTP id 23so1304408wfg.2
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 04:34:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=BT3QbPb2KJfXQzp351sWMNDboHzErK8Do1DqrEeEXR8=;
        b=Y2D17zCobl8rvi0Azn9GJRzcjB67erxJY4slMNyijVWrhCXmEVmfcGgAAhg+SFZhrg
         dRPUqQK3QDlEv6EWyizvZzqy7V7vIK1lh7ul2q7hnjpp0kuuvc+aGg3inUk02F3XQFXB
         qWPCtc9AGhU5e0n0Zz2Y+fgejTeNFsHFqsTlU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=n8bRa1KvSrJVVxjWFc+0Lz2yIgBJV0/bM1zuWLbIATVJ+Zl8281zBnmqKRNtEmOxrr
         IfP/pUJWtZ+0/pt6csiMzBSJzCImjKSocre2ukYKQiOTyYhS0zHjX8EH8UxztVOOPMkP
         4CzsX/81Ppozu4yiYWYoqIKYd5iIHZzM/rqFM=
MIME-Version: 1.0
Received: by 10.142.157.1 with SMTP id f1mr1030095wfe.85.1249990441098; Tue, 
	11 Aug 2009 04:34:01 -0700 (PDT)
In-Reply-To: <4A80A9F5.9000603@casalemedia.com>
References: <4A809A0D.7060704@casalemedia.com> <4A80A10E.8010700@yahoo-inc.com> 
	<4A80A9F5.9000603@casalemedia.com>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Tue, 11 Aug 2009 17:03:41 +0530
Message-ID: <e01b80590908110433re7585f1u213e9a4601587046@mail.gmail.com>
Subject: Re: corrupt filesystem
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd244f436de070470dc14fc
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd244f436de070470dc14fc
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Tue, Aug 11, 2009 at 4:45 AM, Mayuran Yogarajah <
mayuran.yogarajah@casalemedia.com> wrote:

> Hello,
>
>  If you are interested, you could try to trace one of these block ids in
>> NameNode log to see what happened it. We are always eager to hear about
>> irrecoverable errors. Please mention hadoop version you are using.
>>
>>
>>
> I'm using Hadoop 0.18.3.  I just checked namenode log for one of the bad
> blocks. I see entries from Saturday saying:
> ask 1.1.1.6:50010 to replicate blk_1697509332927954816_8724 to datanode(s)
> < all other data nodes >
>
> I only loaded this data Saturday, and the .6 data node became full at some
> point.
> When data is first loaded into the cluster, does the name node send the
> data to as many nodes as
> it can to satisfy the replication factor, or does it send it to one node
> and ask that node send it to others?
>

A DN is instructed by the NN (this actually happens when the DN sends a
heartbeat to NN) to replicate its block to the first replication target DN.
The NN chooses replication targets based on some logic (2nd replica is
always placed on a node in a different rack; 3rd replica is placed on a DN
in the same rack as the first one).

-- 
Harish Mallipeddi
http://blog.poundbang.in

--000e0cd244f436de070470dc14fc--

From common-user-return-16656-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 12:54:49 2009
Return-Path: <common-user-return-16656-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 30788 invoked from network); 11 Aug 2009 12:54:49 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 12:54:49 -0000
Received: (qmail 1544 invoked by uid 500); 11 Aug 2009 12:54:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 1467 invoked by uid 500); 11 Aug 2009 12:54:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 1457 invoked by uid 99); 11 Aug 2009 12:54:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 12:54:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 12:54:44 +0000
Received: by vws40 with SMTP id 40so3463569vws.2
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 05:54:22 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=DcZW+uQqVBxPvDdarSDFo4lWS6f9Pefvyn+e/pqo0ys=;
        b=hqbmmsc8EN69QoonywfCDlLF+ZwwDm3GT2lJIJlPvbR71Guo0STECLcD+T25MChGTd
         v0XpHQqoDwy8FISkQaZup/MxtGLdKiE8SgB57SqBSeUv1eXHqJa2LNAMtFsH996zz7lf
         RI03ui6o0WZ5wR/Gcpgqvoc62oZzP4C4a6Eo0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=U1C42JhWs0WJQeDTag/Ru+P6pN6Eo+jZLMCkiHmdWp6ecW0eKbNdFpnesIpnC7tmd8
         i/39DupxOViyShEY5ktFlVuntekobmVjnZu45UEMfyJsMckyUvA8mmg8Iykv0WRY+5JR
         KQJcrifEtdT6qRtUKk4cgBk4FpXRPyaeB13aI=
MIME-Version: 1.0
Received: by 10.220.90.210 with SMTP id j18mr6499017vcm.61.1249995262340; Tue, 
	11 Aug 2009 05:54:22 -0700 (PDT)
In-Reply-To: <19745250.321249976926698.JavaMail.pallavi@e1a31053e.in.office.aol.com>
References: <2876901.301249976755609.JavaMail.pallavi@e1a31053e.in.office.aol.com>
	 <19745250.321249976926698.JavaMail.pallavi@e1a31053e.in.office.aol.com>
Date: Tue, 11 Aug 2009 05:54:22 -0700
Message-ID: <314098690908110554i6f4bd416pa299165fc18b3702@mail.gmail.com>
Subject: Re: File is closed but data is not visible
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6469d38953f680470dd3336
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6469d38953f680470dd3336
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Please provide information on what version of hadoop you are using and the
method of opening and closing the file.


On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
pallavi.palleti@corp.aol.com> wrote:

> Hi all,
>
> We have an application where we pull logs from an external server(far apart
> from hadoop cluster) to hadoop cluster. Sometimes, we could see huge delay
> (of 1 hour or more) in actually seeing the data in HDFS though the file has
> been closed and the variable is set to null from the external application.I
> was in the impression that when I close the file, the data gets reflected in
> hadoop cluster. Now, in this situation, it is even more complicated to
> handle write failures as it is giving false impression to the client that
> data has been written to HDFS. Kindly clarify if my perception is correct.
> If yes, Could some one tell me what is causing the delay in actually showing
> the data. During those cases, how can we tackle write failures (due to some
> temporary issues like data node not available, disk is full) as there is no
> way, we can figure out the failure at the client side?
>
> Thanks
> Pallavi
>



-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--0016e6469d38953f680470dd3336--

From common-user-return-16657-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 15:05:16 2009
Return-Path: <common-user-return-16657-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 20193 invoked from network); 11 Aug 2009 15:05:16 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 15:05:16 -0000
Received: (qmail 87648 invoked by uid 500); 11 Aug 2009 15:05:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87600 invoked by uid 500); 11 Aug 2009 15:05:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 67881 invoked by uid 500); 11 Aug 2009 09:40:39 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of avryadav@gmail.com designates 209.85.211.188 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=I10DvxbCL/NhoSrs/w+xPZ5YdMpGqUvPejDcPp8YIbQ=;
        b=mdXJ2tDQ3tkiFEDW7mvEjaYNOAZl37gBLiFSV03pdPZvS8f9hd3Y1Dv6ByIrqsyFqu
         9oZnJRCDGuQvrh68lY6P6iwxbgvpFp4FXsNl54oFelZ244M3MVCaLbevOaFYOVZZQpgZ
         tWbtRL8QAITD6IvhWTjBvC85EodMpuleEN2r8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=B89UECXUwvsVZt0hx45B5QoX42ovTPpVyV9jZ3oAHPLqehijVD0lUVUkNangvevG2X
         YbhnqxlxbqXZKE1uKROQPW3jbcOf3yuX0acW+/ClZq+yVUQRuUYt3r/l/Kdwfk61aILk
         ghoxaRzLM7SEELc8hvljtyQxTl29XEZbH+quk=
MIME-Version: 1.0
In-Reply-To: <9a65b3c50908110142s54bfeb06p3126553b4c3892ac@mail.gmail.com>
References: <9a65b3c50908110142s54bfeb06p3126553b4c3892ac@mail.gmail.com>
Date: Tue, 11 Aug 2009 15:10:10 +0530
Message-ID: <9a65b3c50908110240v59a25560ma15d57b52daae2be@mail.gmail.com>
Subject: what is the hadoop version used in both pig2.0 and nutch1.0
From: venkata ramanaiah anneboina <avryadav@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hi
=A0I am using pig 2.0 and nutch 1.0; but it dont have common hadoop verion.
=A0what is common verion;

=A0Which version of pig and which version of nutch i need to use (this
brings comman hadoop version only)


please can any one help on this;

thanks
ramana

From common-user-return-16658-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 15:05:27 2009
Return-Path: <common-user-return-16658-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 20276 invoked from network); 11 Aug 2009 15:05:27 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 15:05:27 -0000
Received: (qmail 89443 invoked by uid 500); 11 Aug 2009 15:05:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 89377 invoked by uid 500); 11 Aug 2009 15:05:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 22393 invoked by uid 99); 11 Aug 2009 13:08:46 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
X-AuditID: ac120b16-b7b9bae000005d70-b9-4a816d41768b
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01CA1A85.2388829A"
Subject: problem setting  mapred.child.java.opts 
Date: Tue, 11 Aug 2009 06:10:42 -0700
Message-ID: <4B94F7D3090A974E94A9BD23E57BB14302E5F7A1@corpdc-exch01.corp.digimine.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: problem setting  mapred.child.java.opts 
Thread-Index: AcoahSEfBOWPoSVtSCqY0dfPE+eojg==
From: "Yair Even-Zohar" <yaire@audiencescience.com>
To: <common-user@hadoop.apache.org>,
	<hbase-user@hadoop.apache.org>
X-Brightmail-Tracker: AAAAAA==
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01CA1A85.2388829A
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

I'm running a mapreduce using Hbase table as input with some distributed
cache file and all works well.

However, when I set:

c.set("mapred.child.java.opts", "-Xmx512m")     in the java code and
using the exact same input and exact same distributed cache I'm getting
the following:

=20

on the master side:

=20

09/08/11 08:19:05 INFO mapred.JobClient: Task Id :
attempt_200908110722_0016_m_000001_0, Status : FAILED

java.io.IOException: Task process exit with nonzero status of 134.

        at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:418)

=20

09/08/11 08:19:05 WARN mapred.JobClient: Error reading task
outputhttp://domU-12-31-39-02-95-D2.compute-1.internal:50060/tasklog?pla
intext=3Dtrue&taskid=3Dattempt_200908110722_0016_m_000001_0&filter=3Dstdo=
ut

09/08/11 08:19:05 WARN mapred.JobClient: Error reading task
outputhttp://domU-12-31-39-02-95-D2.compute-1.internal:50060/tasklog?pla
intext=3Dtrue&taskid=3Dattempt_200908110722_0016_m_000001_0&filter=3Dstde=
rr

=20

=20

=20

=20

On the slave log I'm getting as if I do not have enough space. But I run
these on EC2 with 4 GB or memory so that's insane.=20

=20

Error occurred during initialization of VM

Could not reserve enough space for object heap

#

# An unexpected error has been detected by Java Runtime Environment:

#

#  SIGSEGV (0xb) at pc=3D0xf7ec40da, pid=3D4948, tid=3D4158831504

#

# Java VM: Java HotSpot(TM) Server VM (10.0-b23 mixed mode linux-x86)

# Problematic frame:

# C  [libc.so.6+0x6d0da]  cfree+0x7a

#

# An error report file with more information is saved as:

#
/mnt/hadoop/mapred/local/taskTracker/jobcache/job_200908110722_0016/atte
mpt_200908110722_0016_m_000001_0/work/hs_err_pid4948.log

#

# If you would like to submit a bug report, please visit:

#   http://java.sun.com/webapps/bugreport/crash.jsp

#

=20

=20

Furthermore, I have checked the job_XXXXXXXXX_YYYY_conf.xml and the only
difference between the two runs (successful and non-successful ) is the
size=20

<
<property><name>mapred.child.java.opts</name><value>-Xmx512m</value></pr
operty>

>
<property><name>mapred.child.java.opts</name><value>-Xmx200m</value></pr
operty>

=20

=20

Any idea regarding this proble is welcome

=20

Thanks

-Yair

=20


------_=_NextPart_001_01CA1A85.2388829A--

From common-user-return-16659-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 15:05:36 2009
Return-Path: <common-user-return-16659-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 20361 invoked from network); 11 Aug 2009 15:05:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 15:05:35 -0000
Received: (qmail 91220 invoked by uid 500); 11 Aug 2009 15:05:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91170 invoked by uid 500); 11 Aug 2009 15:05:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 21330 invoked by uid 99); 11 Aug 2009 14:46:48 -0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
X-AuditID: ac120b16-b7b9bae000005d70-1b-4a81843ae3c9
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
Subject: RE: problem setting  mapred.child.java.opts 
Date: Tue, 11 Aug 2009 07:48:44 -0700
Message-ID: <4B94F7D3090A974E94A9BD23E57BB14302E5F7AC@corpdc-exch01.corp.digimine.com>
In-Reply-To: <4B94F7D3090A974E94A9BD23E57BB14302E5F7A1@corpdc-exch01.corp.digimine.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: problem setting  mapred.child.java.opts 
Thread-Index: AcoahSEfBOWPoSVtSCqY0dfPE+eojgADUWHQ
References: <4B94F7D3090A974E94A9BD23E57BB14302E5F7A1@corpdc-exch01.corp.digimine.com>
From: "Yair Even-Zohar" <yaire@audiencescience.com>
To: <hbase-user@hadoop.apache.org>,
	<common-user@hadoop.apache.org>
X-Brightmail-Tracker: AAAAAA==
X-Virus-Checked: Checked by ClamAV on apache.org

Sorry to bug you guys again but I found the problem.
An old hadoop-site that was in the class path and had limit on the
"mapred.child.ulimit" to 500000

Thanks
-Yair

-----Original Message-----
From: Yair Even-Zohar [mailto:yaire@audiencescience.com]=20
Sent: Tuesday, August 11, 2009 4:11 PM
To: common-user@hadoop.apache.org; hbase-user@hadoop.apache.org
Subject: problem setting mapred.child.java.opts=20

I'm running a mapreduce using Hbase table as input with some distributed
cache file and all works well.

However, when I set:

c.set("mapred.child.java.opts", "-Xmx512m")     in the java code and
using the exact same input and exact same distributed cache I'm getting
the following:

=20

on the master side:

=20

09/08/11 08:19:05 INFO mapred.JobClient: Task Id :
attempt_200908110722_0016_m_000001_0, Status : FAILED

java.io.IOException: Task process exit with nonzero status of 134.

        at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:418)

=20

09/08/11 08:19:05 WARN mapred.JobClient: Error reading task
outputhttp://domU-12-31-39-02-95-D2.compute-1.internal:50060/tasklog?pla
intext=3Dtrue&taskid=3Dattempt_200908110722_0016_m_000001_0&filter=3Dstdo=
ut

09/08/11 08:19:05 WARN mapred.JobClient: Error reading task
outputhttp://domU-12-31-39-02-95-D2.compute-1.internal:50060/tasklog?pla
intext=3Dtrue&taskid=3Dattempt_200908110722_0016_m_000001_0&filter=3Dstde=
rr

=20

=20

=20

=20

On the slave log I'm getting as if I do not have enough space. But I run
these on EC2 with 4 GB or memory so that's insane.=20

=20

Error occurred during initialization of VM

Could not reserve enough space for object heap

#

# An unexpected error has been detected by Java Runtime Environment:

#

#  SIGSEGV (0xb) at pc=3D0xf7ec40da, pid=3D4948, tid=3D4158831504

#

# Java VM: Java HotSpot(TM) Server VM (10.0-b23 mixed mode linux-x86)

# Problematic frame:

# C  [libc.so.6+0x6d0da]  cfree+0x7a

#

# An error report file with more information is saved as:

#
/mnt/hadoop/mapred/local/taskTracker/jobcache/job_200908110722_0016/atte
mpt_200908110722_0016_m_000001_0/work/hs_err_pid4948.log

#

# If you would like to submit a bug report, please visit:

#   http://java.sun.com/webapps/bugreport/crash.jsp

#

=20

=20

Furthermore, I have checked the job_XXXXXXXXX_YYYY_conf.xml and the only
difference between the two runs (successful and non-successful ) is the
size=20

<
<property><name>mapred.child.java.opts</name><value>-Xmx512m</value></pr
operty>

>
<property><name>mapred.child.java.opts</name><value>-Xmx200m</value></pr
operty>

=20

=20

Any idea regarding this proble is welcome

=20

Thanks

-Yair

=20


From common-user-return-16660-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 16:44:21 2009
Return-Path: <common-user-return-16660-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 57879 invoked from network); 11 Aug 2009 16:44:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 16:44:21 -0000
Received: (qmail 13516 invoked by uid 500); 11 Aug 2009 16:34:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 13490 invoked by uid 500); 11 Aug 2009 16:34:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 13480 invoked by uid 99); 11 Aug 2009 16:34:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 16:34:53 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 16:34:41 +0000
Received: from [1.0.0.0] (proxy7.corp.yahoo.com [216.145.48.98])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7BGXHFS098288
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 09:33:18 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=HxG6JUFyXR9HcqpvdFz9AqCb39BcXgexZMGK8T5+nLtxivX/SWolyIrczXhr9URe
Message-ID: <4A819D49.5010504@yahoo-inc.com>
Date: Tue, 11 Aug 2009 09:33:13 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090608)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: corrupt filesystem
References: <4A809A0D.7060704@casalemedia.com> <4A80A10E.8010700@yahoo-inc.com> <4A80A9F5.9000603@casalemedia.com>
In-Reply-To: <4A80A9F5.9000603@casalemedia.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


Note that there are multiple log files (one for each day). Make sure you 
searched all the relevant days. You can also check datanode log for this 
block.

HDFS writes to all three datanodes at the time you write the data. It is 
possible that other two datanodes also encountered errors.

This would result in an error when you tried to copy and such corrupt 
block should not even appear in HDFS. Did you restart the cluster after 
copying? 0.18.3 has various fixes related to handling block replication 
correctly.

Please include the complete log lines (at the end of your response), it 
makes it simpler to interpret. Alternately you file a JIRA and attach 
log files there.

Raghu.

Mayuran Yogarajah wrote:
> Hello,
> 
>> If you are interested, you could try to trace one of these block ids in
>> NameNode log to see what happened it. We are always eager to hear about
>> irrecoverable errors. Please mention hadoop version you are using.
>>
>>   
> I'm using Hadoop 0.18.3.  I just checked namenode log for one of the bad 
> blocks. I see entries from Saturday saying:
> ask 1.1.1.6:50010 to replicate blk_1697509332927954816_8724 to 
> datanode(s) < all other data nodes >
> 
> I only loaded this data Saturday, and the .6 data node became full at 
> some point.
> When data is first loaded into the cluster, does the name node send the 
> data to as many nodes as
> it can to satisfy the replication factor, or does it send it to one node 
> and ask that node send it to others?
> 
> If its the latter then its possible that the block became corrupt when I 
> first loaded it to .6 (since it was full),
> and since it was designated to send the block to other nodes none of the 
> nodes would have a non-corrupt
> copy.
> 
> Raghu, please let me know what you think.
> 
> thanks,
> 
> M


From common-user-return-16661-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 16:52:59 2009
Return-Path: <common-user-return-16661-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63366 invoked from network); 11 Aug 2009 16:52:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 16:52:58 -0000
Received: (qmail 70762 invoked by uid 500); 11 Aug 2009 16:53:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 70674 invoked by uid 500); 11 Aug 2009 16:53:03 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 70664 invoked by uid 99); 11 Aug 2009 16:53:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 16:53:03 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pallavi.palleti@corp.aol.com designates 64.12.143.147 as permitted sender)
Received: from [64.12.143.147] (HELO omr-m35.mx.aol.com) (64.12.143.147)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 16:52:52 +0000
Received: from AOLMTCMEH01.ad.office.aol.com (aolmtcmeh01.office.aol.com [10.178.121.20]) by omr-m35.mx.aol.com (v117.7) with ESMTP id MAILOMRM353-7f3a4a81a1cc399; Tue, 11 Aug 2009 12:52:28 -0400
Received: from EVSBNG01.ad.office.aol.com ([10.146.190.242]) by AOLMTCMEH01.ad.office.aol.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Tue, 11 Aug 2009 12:52:27 -0400
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
Subject: RE: File is closed but data is not visible
Date: Tue, 11 Aug 2009 22:22:23 +0530
Message-ID: <2AAFC2B9E4C5DC4F859F154FB664CF5F061A90A4@EVSBNG01.ad.office.aol.com>
In-Reply-To: <314098690908110554i6f4bd416pa299165fc18b3702@mail.gmail.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: File is closed but data is not visible
Thread-Index: AcoagviqvHqVeqz9TwmZ+edLaMg94gAH/TMQ
References: <2876901.301249976755609.JavaMail.pallavi@e1a31053e.in.office.aol.com> <19745250.321249976926698.JavaMail.pallavi@e1a31053e.in.office.aol.com> <314098690908110554i6f4bd416pa299165fc18b3702@mail.gmail.com>
From: "Palleti, Pallavi" <pallavi.palleti@corp.aol.com>
To: <common-user@hadoop.apache.org>
X-OriginalArrivalTime: 11 Aug 2009 16:52:27.0995 (UTC) FILETIME=[1BFC2AB0:01CA1AA4]
X-AOL-IP: 10.178.121.20
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Jason,

Apologies for missing version information in my previous mail. I am
using hadoop-0.18.3. I am getting FSDataOutputStream object using
fs.create(new Path(some_file_name)), where fs is FileSystem object. And,
I am closing the file using close().=20

Thanks
Pallavi

-----Original Message-----
From: Jason Venner [mailto:jason.hadoop@gmail.com]=20
Sent: Tuesday, August 11, 2009 6:24 PM
To: common-user@hadoop.apache.org
Subject: Re: File is closed but data is not visible

Please provide information on what version of hadoop you are using and
the
method of opening and closing the file.


On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
pallavi.palleti@corp.aol.com> wrote:

> Hi all,
>
> We have an application where we pull logs from an external server(far
apart
> from hadoop cluster) to hadoop cluster. Sometimes, we could see huge
delay
> (of 1 hour or more) in actually seeing the data in HDFS though the
file has
> been closed and the variable is set to null from the external
application.I
> was in the impression that when I close the file, the data gets
reflected in
> hadoop cluster. Now, in this situation, it is even more complicated to
> handle write failures as it is giving false impression to the client
that
> data has been written to HDFS. Kindly clarify if my perception is
correct.
> If yes, Could some one tell me what is causing the delay in actually
showing
> the data. During those cases, how can we tackle write failures (due to
some
> temporary issues like data node not available, disk is full) as there
is no
> way, we can figure out the failure at the client side?
>
> Thanks
> Pallavi
>



--=20
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

From common-user-return-16662-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 17:43:33 2009
Return-Path: <common-user-return-16662-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 92290 invoked from network); 11 Aug 2009 17:43:33 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 17:43:33 -0000
Received: (qmail 25904 invoked by uid 500); 11 Aug 2009 17:43:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25830 invoked by uid 500); 11 Aug 2009 17:43:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25820 invoked by uid 99); 11 Aug 2009 17:43:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 17:43:37 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 17:43:25 +0000
Received: by yxe15 with SMTP id 15so5073932yxe.5
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 10:43:03 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.91.153.15 with SMTP id f15mr119660ago.77.1250012583663; Tue, 
	11 Aug 2009 10:43:03 -0700 (PDT)
In-Reply-To: <4A814BCD.2060500@apache.org>
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com> 
	<4A7BECD9.20303@apache.org> <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com> 
	<4A814BCD.2060500@apache.org>
From: Todd Lipcon <todd@cloudera.com>
Date: Tue, 11 Aug 2009 10:42:43 -0700
Message-ID: <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com>
Subject: Re: HADOOP-4539 question
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64713e203979a0470e13c77
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64713e203979a0470e13c77
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hey Stas,

You can also use a utility like Linux-HA (aka heartbeat) to handle IP
address failover. It will even send gratuitous ARPs to make sure to get the
new mac address registered after a failover. Check out this blog for info
about a setup like this:

http://www.cloudera.com/blog/2009/07/22/hadoop-ha-configuration/

Hope that helps
-Todd

On Tue, Aug 11, 2009 at 3:45 AM, Steve Loughran <stevel@apache.org> wrote:

> Stas Oskin wrote:
>
>> Hi.
>>
>> What is the recommended a utility for this?
>>
>> Thanks.
>>
>
> for those of us whose hosts are virtual and who have control over the
> infrastructure its fairly simple: bring up a new VM on a different blade
> with the same base image and hostname.
>
> If you have a non-virtual cluster, you need a machine that you can bring up
> with that same hostname; either have something sitting around (switched off)
> waiting for the call of duty, or you rename a node and reboot it.
>
> If you own DNS, bring up all the nodes (and the clients) with the JVM
> command-line property networkaddress.cache.ttl to to something low (like
> 60s), and then you should be able to bring up a node with the same name but
> a different IPAddress. This is useful if you can't control the IPAddr of a
> node, but you can at least change the DNS entry
>
>
>
>> 2009/8/7 Steve Loughran <stevel@apache.org>
>>
>>  Stas Oskin wrote:
>>>
>>>  Hi.
>>>>
>>>> I checked this ticket and I like what I found.
>>>>
>>>> Had question about it, and hoped someone can answer it:
>>>>
>>>> If I have a NN, and BN, and the NN fails, how the DFS clients will know
>>>> how
>>>> to connect to the new IP?
>>>>
>>>> It will be a config level setting?
>>>>
>>>> Or it needs to be achieved via external Linux HA scripts?
>>>>
>>>> Thanks!
>>>>
>>>>
>>>>  right now the new NN has to come up with the same hostname and IP
>>> address
>>> as the original
>>>
>>>
>>
>
> --
> Steve Loughran                  http://www.1060.org/blogxter/publish/5
> Author: Ant in Action           http://antbook.org/
>

--0016e64713e203979a0470e13c77--

From common-user-return-16663-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 17:53:04 2009
Return-Path: <common-user-return-16663-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 95887 invoked from network); 11 Aug 2009 17:53:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 17:53:04 -0000
Received: (qmail 42599 invoked by uid 500); 11 Aug 2009 17:48:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 42553 invoked by uid 500); 11 Aug 2009 17:48:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 93341 invoked by uid 500); 11 Aug 2009 17:31:48 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of thkunkel@gmail.com designates 209.85.210.185 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=OVKVfLPb5Vvzkltu3Fj0ij/PJ22wIGirJSVG4HsVGxk=;
        b=H5pbITlwQ1oIS90UI0DWjeyLtMjSgqiBSSnjMhzZe1KJyWnuB9OkvldbmXJlYt8hrF
         jznTEcBHwJ0XHUZvoOp5wKHocV/58b/cxu53bRMUjXN6diiCUaTh5WA7Pqa4s2RvRLqK
         204pXRXZoQNrNQHJRyl2oOLi6tSidu8TGF+RQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=VGV6y6Rggwp/Y7blj+8Mx/KZWqr6D4iPORs0Sz28iF/conHVTRik45eogrCKCAulPx
         DxsmhovmB1iETuwqsxHRXP//EX10oDsc6/zoScOgYmMoMg7+atwMYS7gZYdRTvaXlZlX
         e4O2tfubcKi2voGhY5aFXquiOaEWWgGh1LUsQ=
MIME-Version: 1.0
Date: Tue, 11 Aug 2009 12:31:19 -0500
Message-ID: <8134a2730908111031v7afcdd72i12385d2b40b76aa7@mail.gmail.com>
Subject: FTP into HDFS
From: Turner Kunkel <thkunkel@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163630efc9131a320470e11271
X-Virus-Checked: Checked by ClamAV on apache.org

--00163630efc9131a320470e11271
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Does anyone have any experience with using FTP with HDFS?  I have all the
config files setup correctly and have started the service.
But, when I connect from a remote (Windows) machine: "Connection closed by
remote host."
And on the local (Ubuntu) machine: "412 Service not available... Permission
denied."

I have all my permissions set in the hdfs conf file that came with this
package: https://sites.google.com/a/iponweb.net/hadoop/Home/hdfs-over-ftp

Any help?

Thanks much.

-Turner Kunkel

--00163630efc9131a320470e11271--

From common-user-return-16664-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 18:05:35 2009
Return-Path: <common-user-return-16664-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 5719 invoked from network); 11 Aug 2009 18:05:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 18:05:34 -0000
Received: (qmail 95999 invoked by uid 500); 11 Aug 2009 18:05:39 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95930 invoked by uid 500); 11 Aug 2009 18:05:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95920 invoked by uid 99); 11 Aug 2009 18:05:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 18:05:38 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 18:05:28 +0000
Received: from [10.73.145.24] (travelsoon-lm.corp.yahoo.com [10.73.145.24])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7BI2kDw035523
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 11:02:46 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=d6iWb7sg/dtgpFOoKr2Wn3ailsPNPGgFz/hkysmuRBgu7F2aXchcYSXZthT+yqEt
Message-ID: <4A81B246.4060001@yahoo-inc.com>
Date: Tue, 11 Aug 2009 11:02:46 -0700
From: Jakob Homan <jhoman@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.12 (Macintosh/20080213)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Question on file HDFS file system
References: <45d9159d0908102230k4627b999w474281f2db0f98fa@mail.gmail.com>
In-Reply-To: <45d9159d0908102230k4627b999w474281f2db0f98fa@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Ashish-
    In terms of how overall design architecture of HDFS, I would point 
you to the project documentation: 
http://hadoop.apache.org/common/docs/current/hdfs_design.html
For specific data structures, your first stop should be the INode class 
and its extending classes, located in 
src/java/org/apache/hadoop/hdfs/server/namenode/INode.java (also 
INodeDirectory, INodeFile, etc.)  Looking at how the fsimage file is 
laid out FSImage:LoadFSImage or the OfflineImageViewer classes.

Hope this helps.

-Jakob Homan
HDFS/Yahoo!

ashish pareek wrote:
> Hi Everybody,
> 
>                    I would like to understand HDFS source code. But basic
> question I want to ask is what type of data-structure does HDFS use to store
> INode information.  I am interested in knowing what code of HDFS is
> responsible with meta-data info of files.
> Please can some HDFS-Guru throw some light on this topic and suggest some
> way how to understand HDFS source code. :)
> 
> Regards,
> Ashish
> 


From common-user-return-16665-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 18:09:40 2009
Return-Path: <common-user-return-16665-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7882 invoked from network); 11 Aug 2009 18:09:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 18:09:40 -0000
Received: (qmail 2617 invoked by uid 500); 11 Aug 2009 18:09:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 2535 invoked by uid 500); 11 Aug 2009 18:09:44 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 2525 invoked by uid 99); 11 Aug 2009 18:09:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 18:09:44 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [192.139.80.206] (HELO mx1.casalemedia.com) (192.139.80.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 18:09:35 +0000
Received: from exchange.casalemedia.com (unknown [10.3.10.15])
	by mx1.casalemedia.com (Postfix) with ESMTP id 5DFB058800E
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 14:09:14 -0400 (EDT)
Received: from mayuran.casalemedia.com (10.3.10.40) by
 exchange.casalemedia.com (10.3.10.15) with Microsoft SMTP Server id
 8.1.240.5; Tue, 11 Aug 2009 14:09:14 -0400
Message-ID: <4A81B3C3.3060903@casalemedia.com>
Date: Tue, 11 Aug 2009 14:09:07 -0400
From: Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: NN + secondary got full, even though data nodes had plenty of space
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I have a 6 node cluster running Hadoop 0.18.3.  I'm trying to figure out
how the data was spread out like this:

node001         94.15%
node002         94.16%
node003         48.22%
node004         47.85%
node005         48.12%
node006         43.18% 

Node 001 (NN) and node 002( secondary NN) both got full, while the other
data nodes had more space left.  I had assumed that Hadoop would distribute
more blocks to nodes 3-6 since they had much more space, but it ended up
filling up nodes1 and 2.  Is this expected?

thanks,
M


From common-user-return-16666-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 18:19:08 2009
Return-Path: <common-user-return-16666-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 18806 invoked from network); 11 Aug 2009 18:19:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 18:19:07 -0000
Received: (qmail 35872 invoked by uid 500); 11 Aug 2009 18:19:12 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35776 invoked by uid 500); 11 Aug 2009 18:19:12 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35757 invoked by uid 500); 11 Aug 2009 18:19:12 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 35750 invoked by uid 99); 11 Aug 2009 18:19:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 18:19:11 +0000
X-ASF-Spam-Status: No, hits=1.4 required=10.0
	tests=ASF_LIST_OPS,HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 209.85.211.188 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.211.188] (HELO mail-yw0-f188.google.com) (209.85.211.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 18:19:03 +0000
Received: by ywh26 with SMTP id 26so5229229ywh.5
        for <multiple recipients>; Tue, 11 Aug 2009 11:18:39 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.100.167.20 with SMTP id p20mr5693302ane.80.1250014718785; Tue, 
	11 Aug 2009 11:18:38 -0700 (PDT)
Date: Tue, 11 Aug 2009 11:18:38 -0700
Message-ID: <77f4f8890908111118l247390e0p9623cb876cb04057@mail.gmail.com>
Subject: Class JobStatus
From: Mithila Nagendra <mnagendr@asu.edu>
To: core-user@hadoop.apache.org, core-user-subscribe@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e644d0a246f7c60470e1bb2e
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e644d0a246f7c60470e1bb2e
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello Everyone

I was trying to figure out how the JobStatus class can be used in Hadoop.
Can someone guide me to an example? I want to put the method setRunState()
to use.

Thanks!
Mithila

--0016e644d0a246f7c60470e1bb2e--

From common-user-return-16667-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 18:41:45 2009
Return-Path: <common-user-return-16667-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 34479 invoked from network); 11 Aug 2009 18:41:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 18:41:45 -0000
Received: (qmail 7335 invoked by uid 500); 11 Aug 2009 18:41:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 7255 invoked by uid 500); 11 Aug 2009 18:41:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 7245 invoked by uid 99); 11 Aug 2009 18:41:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 18:41:49 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 18:41:37 +0000
Received: from [10.72.106.226] (heighthigh-lx.corp.yahoo.com [10.72.106.226])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7BIeBbm024969
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 11:40:12 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=P0V17Asd61n79gKDymwlwZkNH7g+qweSf6GcDC2CPzFP8iy9PgR8G8+VjFwqq2a/
Message-ID: <4A81BB0C.6060209@yahoo-inc.com>
Date: Tue, 11 Aug 2009 11:40:12 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: File is closed but data is not visible
References: <2876901.301249976755609.JavaMail.pallavi@e1a31053e.in.office.aol.com> <19745250.321249976926698.JavaMail.pallavi@e1a31053e.in.office.aol.com> <314098690908110554i6f4bd416pa299165fc18b3702@mail.gmail.com> <2AAFC2B9E4C5DC4F859F154FB664CF5F061A90A4@EVSBNG01.ad.office.aol.com>
In-Reply-To: <2AAFC2B9E4C5DC4F859F154FB664CF5F061A90A4@EVSBNG01.ad.office.aol.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


Your assumption is correct. When you close the file, others can read the 
data. There is no delay expected before the data is visible. If there is 
an error either write() or close() would throw an error.

When you say data is not visible do you mean readers can not see the 
file or can not see the data? Is it guaranteed that readers open the 
file _after_ close returns on the writer?

Raghu.

Palleti, Pallavi wrote:
> Hi Jason,
> 
> Apologies for missing version information in my previous mail. I am
> using hadoop-0.18.3. I am getting FSDataOutputStream object using
> fs.create(new Path(some_file_name)), where fs is FileSystem object. And,
> I am closing the file using close(). 
> 
> Thanks
> Pallavi
> 
> -----Original Message-----
> From: Jason Venner [mailto:jason.hadoop@gmail.com] 
> Sent: Tuesday, August 11, 2009 6:24 PM
> To: common-user@hadoop.apache.org
> Subject: Re: File is closed but data is not visible
> 
> Please provide information on what version of hadoop you are using and
> the
> method of opening and closing the file.
> 
> 
> On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
> pallavi.palleti@corp.aol.com> wrote:
> 
>> Hi all,
>>
>> We have an application where we pull logs from an external server(far
> apart
>> from hadoop cluster) to hadoop cluster. Sometimes, we could see huge
> delay
>> (of 1 hour or more) in actually seeing the data in HDFS though the
> file has
>> been closed and the variable is set to null from the external
> application.I
>> was in the impression that when I close the file, the data gets
> reflected in
>> hadoop cluster. Now, in this situation, it is even more complicated to
>> handle write failures as it is giving false impression to the client
> that
>> data has been written to HDFS. Kindly clarify if my perception is
> correct.
>> If yes, Could some one tell me what is causing the delay in actually
> showing
>> the data. During those cases, how can we tackle write failures (due to
> some
>> temporary issues like data node not available, disk is full) as there
> is no
>> way, we can figure out the failure at the client side?
>>
>> Thanks
>> Pallavi
>>
> 
> 
> 


From common-user-return-16668-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 19:53:51 2009
Return-Path: <common-user-return-16668-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 57988 invoked from network); 11 Aug 2009 19:53:51 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 19:53:51 -0000
Received: (qmail 95728 invoked by uid 500); 11 Aug 2009 19:53:55 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95655 invoked by uid 500); 11 Aug 2009 19:53:55 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95645 invoked by uid 99); 11 Aug 2009 19:53:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 19:53:55 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cubicdesign@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 19:53:46 +0000
Received: by ewy26 with SMTP id 26so4087442ewy.29
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 12:53:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:date:from
         :user-agent:mime-version:to:subject:references:in-reply-to
         :content-type:content-transfer-encoding;
        bh=Sguux4SeXI24IwaORkpQkiqRebRtkkmpkiLY+8XnKfE=;
        b=V7Du/6oD3nG5+zgn/rB+gIxKbY5k018ajJnbdNCPP62PJL9FDfoAgtA8Y7TUKG7+yh
         0kYnDdgSD3G10nr7ibYvR2fx0yJKGheIfIsXSib4qyLQzfbxHH5u+jkvJzqbaGHmLbcU
         LKqcTP4KUhV0UaGBLfcKXEVj2lsaxNAw/fyAg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        b=SEhbplv3cyu6DFqBCxqc3MmkEDgGtIpw9Ka1bET5EZcwo5YVV2S6XwhIZPBeRf5XkX
         SOIq7uMnVXV2oUSJ8Mj9M8Omda7LXJ3miG5lMz1PO6j5L3cbxSqggnJ7zRAAKM8MyjVq
         4KTJWzuiOdwy8LECDJdreY6Q+2bCrZVPyQ+a0=
Received: by 10.210.125.11 with SMTP id x11mr524253ebc.46.1250020405170;
        Tue, 11 Aug 2009 12:53:25 -0700 (PDT)
Received: from ?192.168.220.104? (host-091-097-243-209.ewe-ip-backbone.de [91.97.243.209])
        by mx.google.com with ESMTPS id 28sm705325eyg.12.2009.08.11.12.53.23
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Tue, 11 Aug 2009 12:53:24 -0700 (PDT)
Message-ID: <4A81CC30.1020003@Gmail.com>
Date: Tue, 11 Aug 2009 21:53:20 +0200
From: CubicDesign <cubicdesign@gmail.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Need info about "mapred.input.format.skew"
References: <8131791a0907300127n7874c2b1l290b66d08a8a838@mail.gmail.com>	 <4A7191C1.2040503@apache.org> <4A719468.4070602@gmail.com>
In-Reply-To: <4A719468.4070602@gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi.

Can anybody point me to the Apache documentation page for "mapred.input.format.skew" ?
I cannot find the documentation for this parameter.

What does it mean?

Thanks

From common-user-return-16669-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 22:09:09 2009
Return-Path: <common-user-return-16669-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 10577 invoked from network); 11 Aug 2009 22:09:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 22:09:09 -0000
Received: (qmail 48544 invoked by uid 500); 11 Aug 2009 21:59:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 48462 invoked by uid 500); 11 Aug 2009 21:59:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 48449 invoked by uid 500); 11 Aug 2009 21:59:57 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 48443 invoked by uid 99); 11 Aug 2009 21:59:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 21:59:57 +0000
X-ASF-Spam-Status: No, hits=1.4 required=10.0
	tests=ASF_LIST_OPS,HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.210.185 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 21:59:48 +0000
Received: by yxe15 with SMTP id 15so5312417yxe.5
        for <multiple recipients>; Tue, 11 Aug 2009 14:59:25 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.100.111.7 with SMTP id j7mr6033442anc.179.1250027964980; Tue, 
	11 Aug 2009 14:59:24 -0700 (PDT)
Date: Tue, 11 Aug 2009 14:59:24 -0700
Message-ID: <77f4f8890908111459w53ab1a1bq455f1e937409c12a@mail.gmail.com>
Subject: Creating a job
From: Mithila Nagendra <mnagendr@asu.edu>
To: core-user@hadoop.apache.org, core-user-subscribe@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e645ab48cfde470470e4d075
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e645ab48cfde470470e4d075
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello All

How do I create a Job in Hadoop using Class Job? And how do I run it?
Generally JobClient.runJob(conf) is used, but the parameter in not of the
type Job.

Also How do I use the class JobControl? Can I create Threads in a Hadoop
(similar to multithreading in JAVA), where different Threads call diffrent
hadoop jobs? I guess JobControl is connected to all this in some way.

Thanks for you help
Mithila Nagendra

--0016e645ab48cfde470470e4d075--

From common-user-return-16670-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 11 23:02:42 2009
Return-Path: <common-user-return-16670-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 30767 invoked from network); 11 Aug 2009 23:02:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 11 Aug 2009 23:02:42 -0000
Received: (qmail 21081 invoked by uid 500); 11 Aug 2009 23:02:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20994 invoked by uid 500); 11 Aug 2009 23:02:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20984 invoked by uid 99); 11 Aug 2009 23:02:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 23:02:46 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 11 Aug 2009 23:02:36 +0000
Received: by qyk26 with SMTP id 26so3566978qyk.5
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 16:02:14 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.74.79 with SMTP id t15mr4477259qaj.331.1250031734131; Tue, 
	11 Aug 2009 16:02:14 -0700 (PDT)
In-Reply-To: <C03AB49A-1641-4452-BF99-7EBA2EE0AB0B@mni.fh-giessen.de>
References: <BAY102-W474085CBF74EDC91FD44D8BC130@phx.gbl> <4b2c7b610907300516k5db15dc0nf08461e92f357c9a@mail.gmail.com> 
	<C03AB49A-1641-4452-BF99-7EBA2EE0AB0B@mni.fh-giessen.de>
From: Aaron Kimball <aaron@cloudera.com>
Date: Tue, 11 Aug 2009 16:01:54 -0700
Message-ID: <d6d7c4410908111601i3578ca09n60895abc17cbdc08@mail.gmail.com>
Subject: Re: XML files in HDFS
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175d6754788c6b0470e5b1eb
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175d6754788c6b0470e5b1eb
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Wasim,

RecordReader implementations should never require that elements not be
spread across multiple blocks. The start and end offsets into a file in an
InputSplit are taken as soft limits, not hard ones. The RecordReader
implementations that come with Hadoop perform this way, and any that you
author should do the same. If a logical record continues past its end
offset, it will continue to read the data from the next block until it finds
the end of the record. Similarly, if a RecordReader has a start offset > 0,
then it scans forward til the first end-of-record followed by any
beginning-of-record marker, ignoring this data (as it was processed by the
previous inputsplit), and only then does it begin reading records into its
map task.

- Aaron


On Mon, Aug 10, 2009 at 12:07 PM, Joerg Rieger <
joerg.rieger@mni.fh-giessen.de> wrote:

> Hello,
>
> while flipping through the cloud9 collections, I came across an XML
> InputFormat class:
>
>
> http://www.umiacs.umd.edu/~jimmylin/cloud9/docs/api/edu/umd/cloud9/collection/XMLInputFormat.html<http://www.umiacs.umd.edu/%7Ejimmylin/cloud9/docs/api/edu/umd/cloud9/collection/XMLInputFormat.html>
>
> I haven't used it myself, but It might be worth a try.
>
>
> Joerg
>
>
>
> On 30.07.2009, at 14:16, Hyunsik Choi wrote:
>
>  Hi,
>>
>> Actually, I don't know there exists any well-made XML InputFormat or
>> Record reader.
>> To the best of my knowledge, StreamXmlRecordReader (
>>
>> http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/streaming/StreamXmlRecordReader.html
>> ) of Hadoop streaming is only solution.
>>
>> Good luck!
>>
>> --
>> Hyunsik Choi
>> Database & Information Systems Group, Korea University
>> http://diveintodata.org
>>
>>
>>
>> On Thu, Jul 30, 2009 at 5:30 PM, Wasim Bari<wasimbari@msn.com> wrote:
>>
>>>
>>>
>>>
>>> Hi All,
>>>
>>>      I am looking to store some real big xml files in HDFS and then
>>> process them using MapReduce.
>>>
>>>
>>>
>>> Do we have some utility which uploads the xml files to hdfs making sure
>>> split  up of file in block doen't brake an elemet ( mean half element on one
>>> block and half on someother ) ?
>>>
>>>
>>>
>>> Any suggestions to work thos out will  be appreciated greatly.
>>>
>>>
>>>
>>> Thanks
>>>
>>>
>>>
>>> Bari
>>>
>>>
> --
>
>
>
>

--0015175d6754788c6b0470e5b1eb--

From common-user-return-16671-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 00:30:27 2009
Return-Path: <common-user-return-16671-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 58488 invoked from network); 12 Aug 2009 00:30:27 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 00:30:27 -0000
Received: (qmail 80073 invoked by uid 500); 12 Aug 2009 00:05:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 79663 invoked by uid 500); 12 Aug 2009 00:05:58 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 78731 invoked by uid 99); 12 Aug 2009 00:02:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 00:02:21 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 00:02:10 +0000
Received: from [172.21.149.106] (wlanvpn-mc2e-247-106.corp.yahoo.com [172.21.149.106])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7BNxONK088198
	for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 16:59:25 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=mHJCW9iugGD4+1vebvYDse01tZPAhrU/oiVhLejlZKhwPp0Mh0DLhjtZNpIVyvZL
Message-ID: <4A8205DC.3040907@yahoo-inc.com>
Date: Tue, 11 Aug 2009 16:59:24 -0700
From: Jakob Homan <jhoman@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.12 (Macintosh/20080213)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Creating a job
References: <77f4f8890908111459w53ab1a1bq455f1e937409c12a@mail.gmail.com>
In-Reply-To: <77f4f8890908111459w53ab1a1bq455f1e937409c12a@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Mithila-
    I would point you to the WordCount example 
(http://hadoop.apache.org/common/docs/current/mapred_tutorial.html) for 
a basic example of how jobs are created by supplying a JobConf to the 
JobClient.  This will submit your conf to the cluster which will create 
and run the job.

The JobControl class is to manager a series of jobs that are dependent 
on each other. Is this a situation you're facing? If not, the job 
submission strategy in the WordCount example should be sufficient.

Regarding threading: Writing multi-thread apps is generally not needed, 
as Hadoop provides parallelization via MapReduce.  However, there is a 
MultithreadedMapper for situations where you may not be maxing out the 
CPU in a specific Mapper.

It sounds like it may be helpful to check out the job submission 
documentation: 
http://hadoop.apache.org/common/docs/current/mapred_tutorial.html#Job+Submission+and+Monitoring 
  Let us know if anything is unclear after that.

Thanks,

Jakob Homan
Yahoo!

Mithila Nagendra wrote:
> Hello All
> 
> How do I create a Job in Hadoop using Class Job? And how do I run it?
> Generally JobClient.runJob(conf) is used, but the parameter in not of the
> type Job.
> 
> Also How do I use the class JobControl? Can I create Threads in a Hadoop
> (similar to multithreading in JAVA), where different Threads call diffrent
> hadoop jobs? I guess JobControl is connected to all this in some way.
> 
> Thanks for you help
> Mithila Nagendra
> 


From common-user-return-16672-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 01:34:17 2009
Return-Path: <common-user-return-16672-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 85669 invoked from network); 12 Aug 2009 01:34:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 01:34:17 -0000
Received: (qmail 36692 invoked by uid 500); 12 Aug 2009 01:34:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 36605 invoked by uid 500); 12 Aug 2009 01:34:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 36595 invoked by uid 99); 12 Aug 2009 01:34:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 01:34:21 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 209.85.211.188 is neither permitted nor denied by domain of kjirapinyo@biz360.com)
Received: from [209.85.211.188] (HELO mail-yw0-f188.google.com) (209.85.211.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 01:34:13 +0000
Received: by ywh26 with SMTP id 26so5576580ywh.5
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 18:33:52 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.127.20 with SMTP id z20mr284509agc.118.1250040832113; Tue, 
	11 Aug 2009 18:33:52 -0700 (PDT)
From: Kris Jirapinyo <kjirapinyo@biz360.com>
Date: Tue, 11 Aug 2009 18:33:32 -0700
Message-ID: <42a1925b0908111833t40ac91ecx7e0b7206f4efbfae@mail.gmail.com>
Subject: Extra 4 bytes at beginning of serialized file
To: common-user <common-user@hadoop.apache.org>
Content-Type: multipart/alternative; boundary=0016361e89ecc0bbd90470e7cf99
X-Virus-Checked: Checked by ClamAV on apache.org

--0016361e89ecc0bbd90470e7cf99
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi all,
   I was wondering if anyone's encountered 4 extra bytes at the beginning of
the serialized object file using MultipleOutputFormat.  Basically, I am
using BytesWritable to write the serialized byte arrays in the reducer
phase.  My writer is a generic one:

public class GenericOutputFormat extends FileOutputFormat<Writable,
Writable>  {

    @Override
    public RecordWriter<Writable, Writable> getRecordWriter(FileSystem
ignored, JobConf job, String name, Progressable progress)
        throws IOException {
          Path file = FileOutputFormat.getTaskOutputPath(job, name);
          FileSystem fs = file.getFileSystem(job);
          FSDataOutputStream fileOut = fs.create(file, progress);
        return new GenericWriter(fileOut);
    }

    static class GenericWriter implements RecordWriter<Writable, Writable> {
        protected DataOutputStream out;

        GenericWriter(DataOutputStream out) {
            this.out = out;
        }

        @Override
        public synchronized void close(Reporter reporter) throws IOException
{
            out.close();
        }

        @Override
        public synchronized void write(Writable key, Writable value) throws
IOException {
            key.write(out);
        }
    }
}

Basically, it'll just write out whatever is in the DataOutputStream.  When i
debugged, I printed out the size of the byte array in the BytesWritable, and
the resulting file is always 4 bytes larger than that number.  Any ideas?

-- Kris.

--0016361e89ecc0bbd90470e7cf99--

From common-user-return-16673-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 02:14:14 2009
Return-Path: <common-user-return-16673-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 2591 invoked from network); 12 Aug 2009 02:14:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 02:14:14 -0000
Received: (qmail 20388 invoked by uid 500); 12 Aug 2009 02:04:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20359 invoked by uid 500); 12 Aug 2009 02:04:31 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20349 invoked by uid 99); 12 Aug 2009 02:04:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 02:04:31 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.211.188] (HELO mail-yw0-f188.google.com) (209.85.211.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 02:04:22 +0000
Received: by ywh26 with SMTP id 26so5595926ywh.5
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 19:04:00 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.75.9 with SMTP id x9mr5363005aga.71.1250042640387; Tue, 11 
	Aug 2009 19:04:00 -0700 (PDT)
In-Reply-To: <42a1925b0908111833t40ac91ecx7e0b7206f4efbfae@mail.gmail.com>
References: <42a1925b0908111833t40ac91ecx7e0b7206f4efbfae@mail.gmail.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Tue, 11 Aug 2009 19:03:39 -0700
Message-ID: <45f85f70908111903q45c65019m74f3451a213e6909@mail.gmail.com>
Subject: Re: Extra 4 bytes at beginning of serialized file
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016362836a088d06c0470e83b3a
X-Virus-Checked: Checked by ClamAV on apache.org

--0016362836a088d06c0470e83b3a
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

BytesWritable serializes itself by first outputting the array length, and
then outputting the array itself. The 4 bytes at the top of the file are the
length of the value itself.

Hope that helps
-Todd

On Tue, Aug 11, 2009 at 6:33 PM, Kris Jirapinyo <kjirapinyo@biz360.com>wrote:

> Hi all,
>   I was wondering if anyone's encountered 4 extra bytes at the beginning of
> the serialized object file using MultipleOutputFormat.  Basically, I am
> using BytesWritable to write the serialized byte arrays in the reducer
> phase.  My writer is a generic one:
>
> public class GenericOutputFormat extends FileOutputFormat<Writable,
> Writable>  {
>
>    @Override
>    public RecordWriter<Writable, Writable> getRecordWriter(FileSystem
> ignored, JobConf job, String name, Progressable progress)
>        throws IOException {
>          Path file = FileOutputFormat.getTaskOutputPath(job, name);
>          FileSystem fs = file.getFileSystem(job);
>          FSDataOutputStream fileOut = fs.create(file, progress);
>        return new GenericWriter(fileOut);
>    }
>
>    static class GenericWriter implements RecordWriter<Writable, Writable> {
>        protected DataOutputStream out;
>
>        GenericWriter(DataOutputStream out) {
>            this.out = out;
>        }
>
>        @Override
>        public synchronized void close(Reporter reporter) throws IOException
> {
>            out.close();
>        }
>
>        @Override
>        public synchronized void write(Writable key, Writable value) throws
> IOException {
>            key.write(out);
>        }
>    }
> }
>
> Basically, it'll just write out whatever is in the DataOutputStream.  When
> i
> debugged, I printed out the size of the byte array in the BytesWritable,
> and
> the resulting file is always 4 bytes larger than that number.  Any ideas?
>
> -- Kris.
>

--0016362836a088d06c0470e83b3a--

From common-user-return-16674-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 02:24:28 2009
Return-Path: <common-user-return-16674-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 6424 invoked from network); 12 Aug 2009 02:24:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 02:24:28 -0000
Received: (qmail 86102 invoked by uid 500); 12 Aug 2009 02:24:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 86037 invoked by uid 500); 12 Aug 2009 02:24:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 85945 invoked by uid 99); 12 Aug 2009 02:24:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 02:24:32 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.210.185 is neither permitted nor denied by domain of kjirapinyo@biz360.com)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 02:24:22 +0000
Received: by yxe15 with SMTP id 15so5491642yxe.5
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 19:24:01 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.93.13 with SMTP id q13mr5378451agb.27.1250043841219; Tue, 
	11 Aug 2009 19:24:01 -0700 (PDT)
In-Reply-To: <45f85f70908111903q45c65019m74f3451a213e6909@mail.gmail.com>
References: <42a1925b0908111833t40ac91ecx7e0b7206f4efbfae@mail.gmail.com> 
	<45f85f70908111903q45c65019m74f3451a213e6909@mail.gmail.com>
From: Kris Jirapinyo <kris.jirapinyo@biz360.com>
Date: Tue, 11 Aug 2009 19:23:41 -0700
Message-ID: <42a1925b0908111923g3e3c5dbctded4c81001cce8e0@mail.gmail.com>
Subject: Re: Extra 4 bytes at beginning of serialized file
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163630f2411c0ec80470e883b2
X-Virus-Checked: Checked by ClamAV on apache.org

--00163630f2411c0ec80470e883b2
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Ah that explains it, thanks Todd.  Is there a way to serialize an object
without using BytesWritable, or some way I can have a "perfect" serialized
file so I won't have to keep discarding the first 4 bytes of the files?

-- Kris.

On Tue, Aug 11, 2009 at 7:03 PM, Todd Lipcon <todd@cloudera.com> wrote:

> BytesWritable serializes itself by first outputting the array length, and
> then outputting the array itself. The 4 bytes at the top of the file are
> the
> length of the value itself.
>
> Hope that helps
> -Todd
>
> On Tue, Aug 11, 2009 at 6:33 PM, Kris Jirapinyo <kjirapinyo@biz360.com
> >wrote:
>
> > Hi all,
> >   I was wondering if anyone's encountered 4 extra bytes at the beginning
> of
> > the serialized object file using MultipleOutputFormat.  Basically, I am
> > using BytesWritable to write the serialized byte arrays in the reducer
> > phase.  My writer is a generic one:
> >
> > public class GenericOutputFormat extends FileOutputFormat<Writable,
> > Writable>  {
> >
> >    @Override
> >    public RecordWriter<Writable, Writable> getRecordWriter(FileSystem
> > ignored, JobConf job, String name, Progressable progress)
> >        throws IOException {
> >          Path file = FileOutputFormat.getTaskOutputPath(job, name);
> >          FileSystem fs = file.getFileSystem(job);
> >          FSDataOutputStream fileOut = fs.create(file, progress);
> >        return new GenericWriter(fileOut);
> >    }
> >
> >    static class GenericWriter implements RecordWriter<Writable, Writable>
> {
> >        protected DataOutputStream out;
> >
> >        GenericWriter(DataOutputStream out) {
> >            this.out = out;
> >        }
> >
> >        @Override
> >        public synchronized void close(Reporter reporter) throws
> IOException
> > {
> >            out.close();
> >        }
> >
> >        @Override
> >        public synchronized void write(Writable key, Writable value)
> throws
> > IOException {
> >            key.write(out);
> >        }
> >    }
> > }
> >
> > Basically, it'll just write out whatever is in the DataOutputStream.
>  When
> > i
> > debugged, I printed out the size of the byte array in the BytesWritable,
> > and
> > the resulting file is always 4 bytes larger than that number.  Any ideas?
> >
> > -- Kris.
> >
>

--00163630f2411c0ec80470e883b2--

From common-user-return-16675-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 02:43:03 2009
Return-Path: <common-user-return-16675-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 13305 invoked from network); 12 Aug 2009 02:43:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 02:43:03 -0000
Received: (qmail 37044 invoked by uid 500); 12 Aug 2009 02:43:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 36959 invoked by uid 500); 12 Aug 2009 02:43:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 36944 invoked by uid 99); 12 Aug 2009 02:43:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 02:43:08 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 02:42:58 +0000
Received: by gxk18 with SMTP id 18so5145941gxk.5
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 19:42:37 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.245.16 with SMTP id s16mr309497agh.44.1250044957538; Tue, 
	11 Aug 2009 19:42:37 -0700 (PDT)
In-Reply-To: <42a1925b0908111923g3e3c5dbctded4c81001cce8e0@mail.gmail.com>
References: <42a1925b0908111833t40ac91ecx7e0b7206f4efbfae@mail.gmail.com> 
	<45f85f70908111903q45c65019m74f3451a213e6909@mail.gmail.com> 
	<42a1925b0908111923g3e3c5dbctded4c81001cce8e0@mail.gmail.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Tue, 11 Aug 2009 19:42:17 -0700
Message-ID: <45f85f70908111942n5646e098s6fc8586236955b0@mail.gmail.com>
Subject: Re: Extra 4 bytes at beginning of serialized file
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163628421ea5b9240470e8c5ec
X-Virus-Checked: Checked by ClamAV on apache.org

--00163628421ea5b9240470e8c5ec
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

If you know you'll only have one object in the file, you could write your
own Writable implementation which doesn't write its length. The problem is
that you'll never be able to *read* it, since writables only get an input
stream and thus don't know the file size.

If you choose to do this, just model it after BytesWritable but drop the 4
byte length header.

-Todd

On Tue, Aug 11, 2009 at 7:23 PM, Kris Jirapinyo
<kris.jirapinyo@biz360.com>wrote:

> Ah that explains it, thanks Todd.  Is there a way to serialize an object
> without using BytesWritable, or some way I can have a "perfect" serialized
> file so I won't have to keep discarding the first 4 bytes of the files?
>
> -- Kris.
>
> On Tue, Aug 11, 2009 at 7:03 PM, Todd Lipcon <todd@cloudera.com> wrote:
>
> > BytesWritable serializes itself by first outputting the array length, and
> > then outputting the array itself. The 4 bytes at the top of the file are
> > the
> > length of the value itself.
> >
> > Hope that helps
> > -Todd
> >
> > On Tue, Aug 11, 2009 at 6:33 PM, Kris Jirapinyo <kjirapinyo@biz360.com
> > >wrote:
> >
> > > Hi all,
> > >   I was wondering if anyone's encountered 4 extra bytes at the
> beginning
> > of
> > > the serialized object file using MultipleOutputFormat.  Basically, I am
> > > using BytesWritable to write the serialized byte arrays in the reducer
> > > phase.  My writer is a generic one:
> > >
> > > public class GenericOutputFormat extends FileOutputFormat<Writable,
> > > Writable>  {
> > >
> > >    @Override
> > >    public RecordWriter<Writable, Writable> getRecordWriter(FileSystem
> > > ignored, JobConf job, String name, Progressable progress)
> > >        throws IOException {
> > >          Path file = FileOutputFormat.getTaskOutputPath(job, name);
> > >          FileSystem fs = file.getFileSystem(job);
> > >          FSDataOutputStream fileOut = fs.create(file, progress);
> > >        return new GenericWriter(fileOut);
> > >    }
> > >
> > >    static class GenericWriter implements RecordWriter<Writable,
> Writable>
> > {
> > >        protected DataOutputStream out;
> > >
> > >        GenericWriter(DataOutputStream out) {
> > >            this.out = out;
> > >        }
> > >
> > >        @Override
> > >        public synchronized void close(Reporter reporter) throws
> > IOException
> > > {
> > >            out.close();
> > >        }
> > >
> > >        @Override
> > >        public synchronized void write(Writable key, Writable value)
> > throws
> > > IOException {
> > >            key.write(out);
> > >        }
> > >    }
> > > }
> > >
> > > Basically, it'll just write out whatever is in the DataOutputStream.
> >  When
> > > i
> > > debugged, I printed out the size of the byte array in the
> BytesWritable,
> > > and
> > > the resulting file is always 4 bytes larger than that number.  Any
> ideas?
> > >
> > > -- Kris.
> > >
> >
>

--00163628421ea5b9240470e8c5ec--

From common-user-return-16676-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 03:42:54 2009
Return-Path: <common-user-return-16676-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 32001 invoked from network); 12 Aug 2009 03:42:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 03:42:54 -0000
Received: (qmail 65447 invoked by uid 500); 12 Aug 2009 03:42:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 65366 invoked by uid 500); 12 Aug 2009 03:42:58 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 65356 invoked by uid 99); 12 Aug 2009 03:42:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 03:42:58 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pareekash@gmail.com designates 209.85.222.189 as permitted sender)
Received: from [209.85.222.189] (HELO mail-pz0-f189.google.com) (209.85.222.189)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 03:42:49 +0000
Received: by pzk27 with SMTP id 27so4162366pzk.2
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 20:42:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=W6USz5Gve9c7UjOsyFnS2uv7eSG7uKbaUzcqAGlxxM8=;
        b=o72qHzqPWCcWJfPHyykcN82aQnrIFqp772k79ZmEJAZfhoT6aVGOrgcSCYL0T3Atbn
         gkrpKFgt6mSsBNnI6IjbXE0a5dT4q7BYS8SziyL0ZDHIqL7RU20AGHsQg9fScVuIrMLG
         mwCovz/3jd4T0qqmK5iNbku4I7mS/ngfTH6po=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=r7dFSHkMl3Ffqi4x8Ah0saX6plOMewLeQje4eBYcmcBNn41yyF5FiCCeGatnISKdQk
         SMpkjTPwrQMxOEjz5DbnGW/8QegUUS23V6oU/bOspiLRMmKzE++qKtEQewobjgA2Vf3W
         VRGLz0NcneFnAe15Y+qpoLFwTT6KtqT98Jjfw=
MIME-Version: 1.0
Received: by 10.114.27.15 with SMTP id a15mr9354959waa.16.1250048543660; Tue, 
	11 Aug 2009 20:42:23 -0700 (PDT)
In-Reply-To: <4A81B246.4060001@yahoo-inc.com>
References: <45d9159d0908102230k4627b999w474281f2db0f98fa@mail.gmail.com>
	 <4A81B246.4060001@yahoo-inc.com>
Date: Wed, 12 Aug 2009 09:12:23 +0530
Message-ID: <45d9159d0908112042h3e049661v1ed088ca547a3af5@mail.gmail.com>
Subject: Re: Question on file HDFS file system
From: ashish pareek <pareekash@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636417859659c720470e99bda
X-Virus-Checked: Checked by ClamAV on apache.org

--001636417859659c720470e99bda
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Everybody,
                   I am already tracing through source code and trying to
figure out things. Any way thanks for all your suggestions.

Regards,
Ashish


On Tue, Aug 11, 2009 at 11:32 PM, Jakob Homan <jhoman@yahoo-inc.com> wrote:

> Hey Ashish-
>   In terms of how overall design architecture of HDFS, I would point you to
> the project documentation:
> http://hadoop.apache.org/common/docs/current/hdfs_design.html
> For specific data structures, your first stop should be the INode class and
> its extending classes, located in
> src/java/org/apache/hadoop/hdfs/server/namenode/INode.java (also
> INodeDirectory, INodeFile, etc.)  Looking at how the fsimage file is laid
> out FSImage:LoadFSImage or the OfflineImageViewer classes.
>
> Hope this helps.
>
> -Jakob Homan
> HDFS/Yahoo!
>
>
> ashish pareek wrote:
>
>> Hi Everybody,
>>
>>                   I would like to understand HDFS source code. But basic
>> question I want to ask is what type of data-structure does HDFS use to
>> store
>> INode information.  I am interested in knowing what code of HDFS is
>> responsible with meta-data info of files.
>> Please can some HDFS-Guru throw some light on this topic and suggest some
>> way how to understand HDFS source code. :)
>>
>> Regards,
>> Ashish
>>
>>
>

--001636417859659c720470e99bda--

From common-user-return-16677-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 04:00:57 2009
Return-Path: <common-user-return-16677-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 36957 invoked from network); 12 Aug 2009 04:00:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 04:00:56 -0000
Received: (qmail 84238 invoked by uid 500); 12 Aug 2009 04:01:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 84143 invoked by uid 500); 12 Aug 2009 04:01:01 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 84133 invoked by uid 99); 12 Aug 2009 04:01:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 04:01:01 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pallavi.palleti@corp.aol.com designates 205.188.249.129 as permitted sender)
Received: from [205.188.249.129] (HELO omr-d31.mx.aol.com) (205.188.249.129)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 04:00:51 +0000
Received: from AOLMTCMEH01.ad.office.aol.com (aolmtcmeh01.office.aol.com [10.178.121.20]) by omr-d31.mx.aol.com (v117.7) with ESMTP id MAILOMRD311-7e214a823e5a3da; Wed, 12 Aug 2009 00:00:26 -0400
Received: from AOLMTCMEI02.ad.office.aol.com ([10.178.3.19]) by AOLMTCMEH01.ad.office.aol.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Wed, 12 Aug 2009 00:00:25 -0400
Received: from localhost ([10.178.3.11]) by AOLMTCMEI02.ad.office.aol.com over TLS secured channel with Microsoft SMTPSVC(6.0.3790.3959);
	 Wed, 12 Aug 2009 00:00:25 -0400
Date: Wed, 12 Aug 2009 09:30:20 +0530 (GMT+05:30)
From: Pallavi Palleti <pallavi.palleti@corp.aol.com>
To: common-user@hadoop.apache.org
Message-ID: <18070014.481250049615899.JavaMail.pallavi@e1a31053e.in.office.aol.com>
In-Reply-To: <31565010.461250045532801.JavaMail.pallavi@e1a31053e.in.office.aol.com>
Subject: Re: File is closed but data is not visible
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-OriginalArrivalTime: 12 Aug 2009 04:00:25.0895 (UTC) FILETIME=[6C466370:01CA1B01]
X-AOL-IP: 10.178.121.20
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Raghu,

The file doesn't appear in the cluster when I saw it from Namenode UI. Also, I have a monitor at cluster side which checks whether file is created and throws an exception when it is not created. And, it threw an exception saying "File not found".

Thanks
Pallavi
----- Original Message -----
From: "Raghu Angadi" <rangadi@yahoo-inc.com>
To: common-user@hadoop.apache.org
Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai, Kolkata, Mumbai, New Delhi
Subject: Re: File is closed but data is not visible


Your assumption is correct. When you close the file, others can read the 
data. There is no delay expected before the data is visible. If there is 
an error either write() or close() would throw an error.

When you say data is not visible do you mean readers can not see the 
file or can not see the data? Is it guaranteed that readers open the 
file _after_ close returns on the writer?

Raghu.

Palleti, Pallavi wrote:
> Hi Jason,
> 
> Apologies for missing version information in my previous mail. I am
> using hadoop-0.18.3. I am getting FSDataOutputStream object using
> fs.create(new Path(some_file_name)), where fs is FileSystem object. And,
> I am closing the file using close(). 
> 
> Thanks
> Pallavi
> 
> -----Original Message-----
> From: Jason Venner [mailto:jason.hadoop@gmail.com] 
> Sent: Tuesday, August 11, 2009 6:24 PM
> To: common-user@hadoop.apache.org
> Subject: Re: File is closed but data is not visible
> 
> Please provide information on what version of hadoop you are using and
> the
> method of opening and closing the file.
> 
> 
> On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
> pallavi.palleti@corp.aol.com> wrote:
> 
>> Hi all,
>>
>> We have an application where we pull logs from an external server(far
> apart
>> from hadoop cluster) to hadoop cluster. Sometimes, we could see huge
> delay
>> (of 1 hour or more) in actually seeing the data in HDFS though the
> file has
>> been closed and the variable is set to null from the external
> application.I
>> was in the impression that when I close the file, the data gets
> reflected in
>> hadoop cluster. Now, in this situation, it is even more complicated to
>> handle write failures as it is giving false impression to the client
> that
>> data has been written to HDFS. Kindly clarify if my perception is
> correct.
>> If yes, Could some one tell me what is causing the delay in actually
> showing
>> the data. During those cases, how can we tackle write failures (due to
> some
>> temporary issues like data node not available, disk is full) as there
> is no
>> way, we can figure out the failure at the client side?
>>
>> Thanks
>> Pallavi
>>
> 
> 
> 


From common-user-return-16678-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 04:08:50 2009
Return-Path: <common-user-return-16678-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 38485 invoked from network); 12 Aug 2009 04:08:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 04:08:50 -0000
Received: (qmail 91969 invoked by uid 500); 12 Aug 2009 04:08:55 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91858 invoked by uid 500); 12 Aug 2009 04:08:55 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91848 invoked by uid 99); 12 Aug 2009 04:08:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 04:08:55 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.210.185 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 04:08:45 +0000
Received: by yxe15 with SMTP id 15so5551785yxe.5
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 21:08:22 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.100.252.13 with SMTP id z13mr6402455anh.24.1250050102840; Tue, 
	11 Aug 2009 21:08:22 -0700 (PDT)
In-Reply-To: <4A8205DC.3040907@yahoo-inc.com>
References: <77f4f8890908111459w53ab1a1bq455f1e937409c12a@mail.gmail.com>
	 <4A8205DC.3040907@yahoo-inc.com>
Date: Tue, 11 Aug 2009 21:08:22 -0700
Message-ID: <77f4f8890908112108w1461872ay9040bb3575413aa6@mail.gmail.com>
Subject: Re: Creating a job
From: Mithila Nagendra <mnagendr@asu.edu>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016369fa25054cf860470e9f8fe
X-Virus-Checked: Checked by ClamAV on apache.org

--0016369fa25054cf860470e9f8fe
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello Jakob

Yes I have gone through the Job Submission strategy in Hadoop, that is
helpful. But I was looking at interdependent jobs, I was trying to switch
the state of a running job to waiting. I was looking at Jobcontrol for that
reason.

I have gone through the document you pointed out, was wondering if there is
a more comprehensive guide out there.

Thanks!
Mithila



On Tue, Aug 11, 2009 at 4:59 PM, Jakob Homan <jhoman@yahoo-inc.com> wrote:

> Hey Mithila-
>   I would point you to the WordCount example (
> http://hadoop.apache.org/common/docs/current/mapred_tutorial.html) for a
> basic example of how jobs are created by supplying a JobConf to the
> JobClient.  This will submit your conf to the cluster which will create and
> run the job.
>
> The JobControl class is to manager a series of jobs that are dependent on
> each other. Is this a situation you're facing? If not, the job submission
> strategy in the WordCount example should be sufficient.
>
> Regarding threading: Writing multi-thread apps is generally not needed, as
> Hadoop provides parallelization via MapReduce.  However, there is a
> MultithreadedMapper for situations where you may not be maxing out the CPU
> in a specific Mapper.
>
> It sounds like it may be helpful to check out the job submission
> documentation:
> http://hadoop.apache.org/common/docs/current/mapred_tutorial.html#Job+Submission+and+Monitoring Let us know if anything is unclear after that.
>
> Thanks,
>
> Jakob Homan
> Yahoo!
>
>
> Mithila Nagendra wrote:
>
>> Hello All
>>
>> How do I create a Job in Hadoop using Class Job? And how do I run it?
>> Generally JobClient.runJob(conf) is used, but the parameter in not of the
>> type Job.
>>
>> Also How do I use the class JobControl? Can I create Threads in a Hadoop
>> (similar to multithreading in JAVA), where different Threads call diffrent
>> hadoop jobs? I guess JobControl is connected to all this in some way.
>>
>> Thanks for you help
>> Mithila Nagendra
>>
>>
>

--0016369fa25054cf860470e9f8fe--

From common-user-return-16679-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 04:56:41 2009
Return-Path: <common-user-return-16679-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 47528 invoked from network); 12 Aug 2009 04:56:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 04:56:41 -0000
Received: (qmail 38343 invoked by uid 500); 12 Aug 2009 04:56:45 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 38257 invoked by uid 500); 12 Aug 2009 04:56:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 38243 invoked by uid 99); 12 Aug 2009 04:56:45 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 04:56:45 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jddhok@gmail.com designates 209.85.222.189 as permitted sender)
Received: from [209.85.222.189] (HELO mail-pz0-f189.google.com) (209.85.222.189)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 04:56:33 +0000
Received: by pzk27 with SMTP id 27so4196073pzk.2
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 21:56:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=ZHbK3p2WA12h7+xduVLaaIAjkgn8N72FeFNBDFxZTOg=;
        b=OPv6eItSEnumTsuuT19iS+gDd/ntavLWdPlI6zxprx+FOD5zk2zWh4VfGThY4Kv0C6
         z4GOiNt7A84mUt9+wSlAimIHjjlqQYOg9IPy+zucioixzF06zmaCO2VaRJcixJZsaY11
         0nMm7Y07ELs2gQoasRsJejGrYNs2JbCCXlKxQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=wDo7YP5l+U0d1iD8AcdyzrF6zAcDy67RbJQx9XlOYdheAjJuVCJz1Mj5jX8/aPVfRc
         N4ScJ8Qpv2/+K/Ph+BBvV0XzUPrE3MPG2jJAjWMYnyCjPmzsq7VNKA30olHon87L5Q4a
         W5/B1qGFqnt3kpBZyfywz2UR32uF/zbu1bGk0=
MIME-Version: 1.0
Received: by 10.142.232.12 with SMTP id e12mr1530100wfh.197.1250052971468; 
	Tue, 11 Aug 2009 21:56:11 -0700 (PDT)
In-Reply-To: <45f11e410908091927y550d5f35ua77fec5c1c0721a2@mail.gmail.com>
References: <45f11e410908090841p6a8e7342t9c00cabd539226ee@mail.gmail.com>
	 <31a243e70908090853s7a6bc23dr33410dfbd1f6a7fb@mail.gmail.com>
	 <45f11e410908091927y550d5f35ua77fec5c1c0721a2@mail.gmail.com>
Date: Wed, 12 Aug 2009 10:26:11 +0530
Message-ID: <eaccdf0b0908112156y36fe0673qddfcd239750b2d83@mail.gmail.com>
Subject: Re: hdfs and small file size
From: jaideep dhok <jddhok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

There's an interview with one of the GFS engineers on ACM Queue that
might be of interest to you. Its related to GFS, but I think the
underlying issues are the same in HDFS. There is lot of discussion on
dealing with large number of files. Here's the link:
http://queue.acm.org/detail.cfm?id=1594206
-
Jaideep
On Mon, Aug 10, 2009 at 7:57 AM, Budianto Lie<popo6190@gmail.com> wrote:
> Thanks
>
> On 8/9/09, Jean-Daniel Cryans <jdcryans@apache.org> wrote:
>> Have a look at
>> http://www.cloudera.com/blog/2009/02/02/the-small-files-problem/
>>
>> J-D
>>
>> On Sun, Aug 9, 2009 at 8:41 AM, Budianto Lie<popo6190@gmail.com> wrote:
>>> Hello,
>>> As we know the block size of hdfs is big (64M).
>>> If I've large amount of files but the average file size is small (less
>>> than
>>> 50kb). And they are stored into hdfs.
>>> What's the performance, compare with storing a big files?
>>>
>>> Thanks,
>>> Budianto
>>>
>>
>



-- 
- JDD

From common-user-return-16680-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 05:12:16 2009
Return-Path: <common-user-return-16680-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 52909 invoked from network); 12 Aug 2009 05:12:16 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 05:12:16 -0000
Received: (qmail 50471 invoked by uid 500); 12 Aug 2009 05:12:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 50377 invoked by uid 500); 12 Aug 2009 05:12:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 50367 invoked by uid 99); 12 Aug 2009 05:12:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 05:12:19 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pvssvikas@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 05:12:10 +0000
Received: by gxk18 with SMTP id 18so5219934gxk.5
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 22:11:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=DMoMVb/+Fen9FwFbmWQw4HFjaWag3aRtD05kBGHy+/U=;
        b=L3XTqBgaB1m5mYj87/hgsz8rPsaO6Niz9YAXmR8mAnqnzIHoiK5lUWGCFxCEw3Yr+o
         3ybc5omPBm5flJBLmAVPo0NuCAEyADIgPK8WNSvw5kXo2YuuotBpwBiU+SjW8P/JXUjL
         NiqAlkDYZP7KjsmJLiRBJk4dnarLotlxTVW30=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=B7+LnF4p0o8WvDtWJsym5IrLYdvxpMfrdrgEKR7gj9PSdDHc3X8gj2Zn8mhr9fQHdA
         On2Sqd3xyWhrW7Z8TPDmPjUVfaaHBOBKhZf2MM3e1lzorFNLYUts8FZSd7SzlpVRLyST
         pm6kii9kNzlSMpLaLzbIAukIvCF5ZCavtRrDc=
MIME-Version: 1.0
Received: by 10.90.32.4 with SMTP id f4mr5440012agf.7.1250053909217; Tue, 11 
	Aug 2009 22:11:49 -0700 (PDT)
In-Reply-To: <9a65b3c50908110142s54bfeb06p3126553b4c3892ac@mail.gmail.com>
References: <9a65b3c50908110142s54bfeb06p3126553b4c3892ac@mail.gmail.com>
Date: Wed, 12 Aug 2009 10:41:49 +0530
Message-ID: <6cbf6c150908112211x2baa32fcn819ed444f1323bbe@mail.gmail.com>
Subject: Re: what is the hadoop version used in both pig2.0 and nutch1.0
From: vikas <pvssvikas@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016364edad43586120470eadbc4
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364edad43586120470eadbc4
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

Please check out the below links,

http://mail-archives.apache.org/mod_mbox/hadoop-pig-user/200904.mbox/%3C004f01c9c6f2$b1222500$13666f00$@com%3E

http://wiki.apache.org/nutch/Upgrading_Hadoop

If you find any issues in upgrading Hadoop version with Nutch probably
getting in touch with Nutch mailing lists should help the situation.

Thanks,
-Vikas.

On Tue, Aug 11, 2009 at 2:12 PM, venkata ramanaiah anneboina <
avryadav@gmail.com> wrote:

> Hi
>  I am using pig 2.0 and nutch 1.0; but it dont have common hadoop verion.
>  what is common verion;
>
>  Which version of pig and which version of nutch i need to use (this
> brings comman hadoop version only)
>
>
> please can any one help on this;
>
> thanks
> ramana
>

--0016364edad43586120470eadbc4--

From common-user-return-16682-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 05:56:11 2009
Return-Path: <common-user-return-16682-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 73675 invoked from network); 12 Aug 2009 05:56:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 05:56:11 -0000
Received: (qmail 80269 invoked by uid 500); 12 Aug 2009 05:56:12 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80114 invoked by uid 500); 12 Aug 2009 05:56:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 80101 invoked by uid 500); 12 Aug 2009 05:56:11 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 80088 invoked by uid 99); 12 Aug 2009 05:56:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 05:56:11 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of avryadav@gmail.com designates 209.85.211.188 as permitted sender)
Received: from [209.85.211.188] (HELO mail-yw0-f188.google.com) (209.85.211.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 05:56:02 +0000
Received: by ywh26 with SMTP id 26so5714878ywh.5
        for <multiple recipients>; Tue, 11 Aug 2009 22:55:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=3FOIIvQkPkJMHuvQzqTk9gdynRhh/ZP44LRi4X6hLMo=;
        b=M2F7sDoCKIfcitHXdgr7MhOr2NEihivr+BNYaTE3EKB0nJVG5ndHF0dkz63Ntcd4Yo
         Y+PWWmA6RyhSwVCDaSksXED/WiYU0SAsF3/mhJPFnUqBJHeBwI+gVpdI0BeAQ4E5rEHm
         s2jGIpAtjYZITo8wG/0G/Y3TUsYeyL2Cd64gk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=goyNdZgbhJUWTSH6dYBR9HCelQz4L+74auWFyH0Exo7A+90K6BuFCbmfzTK7EZTAx3
         Mz3ylODnmkSGnNfOkrcGmcu4DTbJPk3pcsrA2YH/CzsBA9bOZanrETg3YQACpwpUxaSn
         202ndIxanETGcHDYZ5pNhMA8biJdy0wxT72Sc=
MIME-Version: 1.0
Received: by 10.100.239.11 with SMTP id m11mr6437668anh.12.1250056541335; Tue, 
	11 Aug 2009 22:55:41 -0700 (PDT)
Date: Wed, 12 Aug 2009 11:25:41 +0530
Message-ID: <9a65b3c50908112255g51a3984axb670891147960c74@mail.gmail.com>
Subject: which versions of pig,nutch and hadoop are requeired to run at once
From: venkata ramanaiah anneboina <avryadav@gmail.com>
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org, 
	pig-user@hadoop.apache.org, nutch-user@lucene.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

 Hi
 I am using pig 2.0 and nutch 1.0; but it dont have common hadoop verion.
 what is common hadoop verion for both pig and hadoop;
GIVE the pig version, nutch version and hadoo


please can any one help on this


thanks
ramanaiah

From common-user-return-16681-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 05:56:11 2009
Return-Path: <common-user-return-16681-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 73664 invoked from network); 12 Aug 2009 05:56:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 05:56:10 -0000
Received: (qmail 80233 invoked by uid 500); 12 Aug 2009 05:56:12 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80112 invoked by uid 500); 12 Aug 2009 05:56:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 80088 invoked by uid 99); 12 Aug 2009 05:56:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 05:56:11 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of avryadav@gmail.com designates 209.85.211.188 as permitted sender)
Received: from [209.85.211.188] (HELO mail-yw0-f188.google.com) (209.85.211.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 05:56:02 +0000
Received: by ywh26 with SMTP id 26so5714878ywh.5
        for <multiple recipients>; Tue, 11 Aug 2009 22:55:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=3FOIIvQkPkJMHuvQzqTk9gdynRhh/ZP44LRi4X6hLMo=;
        b=M2F7sDoCKIfcitHXdgr7MhOr2NEihivr+BNYaTE3EKB0nJVG5ndHF0dkz63Ntcd4Yo
         Y+PWWmA6RyhSwVCDaSksXED/WiYU0SAsF3/mhJPFnUqBJHeBwI+gVpdI0BeAQ4E5rEHm
         s2jGIpAtjYZITo8wG/0G/Y3TUsYeyL2Cd64gk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=goyNdZgbhJUWTSH6dYBR9HCelQz4L+74auWFyH0Exo7A+90K6BuFCbmfzTK7EZTAx3
         Mz3ylODnmkSGnNfOkrcGmcu4DTbJPk3pcsrA2YH/CzsBA9bOZanrETg3YQACpwpUxaSn
         202ndIxanETGcHDYZ5pNhMA8biJdy0wxT72Sc=
MIME-Version: 1.0
Received: by 10.100.239.11 with SMTP id m11mr6437668anh.12.1250056541335; Tue, 
	11 Aug 2009 22:55:41 -0700 (PDT)
Date: Wed, 12 Aug 2009 11:25:41 +0530
Message-ID: <9a65b3c50908112255g51a3984axb670891147960c74@mail.gmail.com>
Subject: which versions of pig,nutch and hadoop are requeired to run at once
From: venkata ramanaiah anneboina <avryadav@gmail.com>
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org, 
	pig-user@hadoop.apache.org, nutch-user@lucene.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

 Hi
 I am using pig 2.0 and nutch 1.0; but it dont have common hadoop verion.
 what is common hadoop verion for both pig and hadoop;
GIVE the pig version, nutch version and hadoo


please can any one help on this


thanks
ramanaiah

From common-user-return-16683-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 06:01:09 2009
Return-Path: <common-user-return-16683-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75566 invoked from network); 12 Aug 2009 06:01:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 06:01:09 -0000
Received: (qmail 85864 invoked by uid 500); 12 Aug 2009 06:01:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 85770 invoked by uid 500); 12 Aug 2009 06:01:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 85760 invoked by uid 99); 12 Aug 2009 06:01:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 06:01:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.198.239 as permitted sender)
Received: from [209.85.198.239] (HELO rv-out-0506.google.com) (209.85.198.239)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 06:01:05 +0000
Received: by rv-out-0506.google.com with SMTP id k40so1290032rvb.29
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 23:00:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=yRFrYtPc4/P9B5CVLsF+7agP8ou3nr2bT0o8h0WUzL0=;
        b=gt5EoYaUL1W3Nc/oM0zQh3XCtRu8/F1vztgYj21cJoCze+RtSbphtas43j8tynmlJa
         gPfo53Nr2WiXhz9gpv4uq3RmQ/e7P345oc+crrwFtCeK1H0GA3pDyXllK4f8mFvESgby
         s7mZMhmUREr3xd2LqtC23iWJN7qOkODbMMqaE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=gdaqqdOHOcwLwmUNwhIvhDvbOeiYFXQv6s2o8DygoG73PB37OczbOUh9g3FLhujqsl
         KWYveTiUyIKdklTiHKlEA+HJAERcbWd0co3s1YSxnfpG7Kboyqsphilhyobe3g8dWHcL
         ztFRTMxrhnvmw+p5XohBSwZ9Rvk0R5l8KOOO8=
MIME-Version: 1.0
Received: by 10.141.1.19 with SMTP id d19mr1600469rvi.128.1250056845318; Tue, 
	11 Aug 2009 23:00:45 -0700 (PDT)
Date: Wed, 12 Aug 2009 14:00:45 +0800
Message-ID: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com>
Subject: What will we encounter if we add a lot of nodes into the current 
	cluster?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd1107c36dc9f0470eb8ad1
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd1107c36dc9f0470eb8ad1
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Dear all
    I'm sorry to disturb you.
    Our cluster has 200 nodes now. In order to improve its ability, we hope
to add 60 nodes into the current cluster. However, we all don't know what
will happen if we add so many nodes at the same time. Could you give me some
tips and notes? During the process, which part shall we pay much attention
on?
    Thank you!

    P.S. Our environment is hadoop-0.19.1, jdk1.6.0_06, linux redhat
enterprise 4.0

--000e0cd1107c36dc9f0470eb8ad1--

From common-user-return-16684-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 06:28:29 2009
Return-Path: <common-user-return-16684-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 95501 invoked from network); 12 Aug 2009 06:28:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 06:28:29 -0000
Received: (qmail 12481 invoked by uid 500); 12 Aug 2009 06:28:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 12408 invoked by uid 500); 12 Aug 2009 06:28:33 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 12398 invoked by uid 99); 12 Aug 2009 06:28:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 06:28:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 06:28:24 +0000
Received: by gxk18 with SMTP id 18so5249978gxk.5
        for <common-user@hadoop.apache.org>; Tue, 11 Aug 2009 23:28:03 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=dGkYcY7kPHY+aYyjxmZqvMRzy1sH3tE1TAPhT3pV4N0=;
        b=RIx3dAyna+tqmGxNLLgQRF4whfIRi1CGVpg4VFXRl2vidMiCcpx0pdFNApfVOHmz2s
         38grCyM27oOLL9UUZcczcZu9LNNRxzC4vrXF6p5p1NMaayGmHB22r0CgRWahaOA431F8
         O4prjbFOTiiytDrOaUz49kNnOvNphcdz94UpA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=ZAJ75P56GQBI4NmA9TxvQRyy253U+LQ2TOJo7cuC0RopI/zymgYvA0H5r/CRLiXGLt
         cadTQloVHGYYIt13BY/M/RJu4F82qU5mSUxUD7qU9+4Dtg/WBNqn43vM6ElBlPxloGba
         2nBozrrIH8wG2OjFKC9+kFpF4j1/nNKdFfDeQ=
MIME-Version: 1.0
Received: by 10.151.108.10 with SMTP id k10mr8576194ybm.107.1250058483053; 
	Tue, 11 Aug 2009 23:28:03 -0700 (PDT)
In-Reply-To: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com>
References: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Tue, 11 Aug 2009 23:27:43 -0700
Message-ID: <c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com>
Subject: Re: What will we encounter if we add a lot of nodes into the current 
	cluster?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001517573e08d4b64b0470ebebdf
X-Virus-Checked: Checked by ClamAV on apache.org

--001517573e08d4b64b0470ebebdf
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

If you add these nodes, data will be put on them as you add data to the
cluster.

Soon after adding the nodes you should rebalance the storage to avoid age
related surprises in how files are arranged in your cluster.

Other than that, your addition should cause little in the way of surprises.

On Tue, Aug 11, 2009 at 11:00 PM, yang song <hadoop.inifok@gmail.com> wrote:

> Dear all
>    I'm sorry to disturb you.
>    Our cluster has 200 nodes now. In order to improve its ability, we hope
> to add 60 nodes into the current cluster. However, we all don't know what
> will happen if we add so many nodes at the same time. Could you give me
> some
> tips and notes? During the process, which part shall we pay much attention
> on?
>    Thank you!
>
>    P.S. Our environment is hadoop-0.19.1, jdk1.6.0_06, linux redhat
> enterprise 4.0
>



-- 
Ted Dunning, CTO
DeepDyve

--001517573e08d4b64b0470ebebdf--

From common-user-return-16685-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 07:39:52 2009
Return-Path: <common-user-return-16685-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 16625 invoked from network); 12 Aug 2009 07:39:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 07:39:52 -0000
Received: (qmail 73024 invoked by uid 500); 12 Aug 2009 07:39:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 72935 invoked by uid 500); 12 Aug 2009 07:39:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 72918 invoked by uid 99); 12 Aug 2009 07:39:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 07:39:56 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mathias.demare@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 07:39:48 +0000
Received: by fxm24 with SMTP id 24so4724039fxm.36
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 00:39:27 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:cc:content-type;
        bh=1FlVwiA7aFs0yREwgknw4KOmOveMUVbs5tir2CtN410=;
        b=x0YsgHbZHt0SB1vUmSkHx9UxfW0YUqCHIlcj3DdkZ2eTn1QzP1BEaHnMBN1lDA/nK1
         Fgoht49nSsQ92vQ7x7SWTLq2LJm4DzeBWPzEg1yAxAq6Blbx+uTLYxaNMeLn+iWh9BHt
         3ZWt3iREx9fYdi3RCJ8bjo7LeR1nusf741BvM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        b=uAY0OsRrKZatrFAhmK5TcBUasckdBrliJHZ+73fQkUfMA3IXWLFF1bpoKNltYGLpCQ
         Y6DmEwqpif7x1p8vh1ZeUBqv0+n7od1zhTqkgDhhA6h5F8uG17l+taL6b9wxxpXqXu6t
         7l64miqMHGq0H6wO4+0HFXmFoe/OLcFqUwO+M=
MIME-Version: 1.0
Received: by 10.204.113.208 with SMTP id b16mr6607866bkq.57.1250062767250; 
	Wed, 12 Aug 2009 00:39:27 -0700 (PDT)
Reply-To: mathias.demare@gmail.com
In-Reply-To: <C6A58EE1.150E2%knoguchi@yahoo-inc.com>
References: <375c60f40908090218i364a5596hbbd3c42a626882f7@mail.gmail.com> 
	<C6A58EE1.150E2%knoguchi@yahoo-inc.com>
From: =?UTF-8?Q?Mathias_De_Mar=C3=A9?= <mathias.demare@gmail.com>
Date: Wed, 12 Aug 2009 09:39:07 +0200
Message-ID: <375c60f40908120039n2f2eb88ekbefc62b1335410ed@mail.gmail.com>
Subject: Re: Some tasks fail to report status between the end of the map and 
	the beginning of the merge
To: Koji Noguchi <knoguchi@yahoo-inc.com>
Cc: common-user@hadoop.apache.org, Amogh Vasekar <amogh@yahoo-inc.com>
Content-Type: multipart/alternative; boundary=0016e6d59d1d305e170470ecebb1
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6d59d1d305e170470ecebb1
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Thank you, that's very useful.
In addition, I changed the way the tasks work, so they store their data in
HBase now (since it's more suited for handling small files).
I'm not 100% sure yet if the problems have been resolved (still doing
extensive testing), but I think I might have gotten rid of them (and I'll
add the 'skipping records' option in case I do get a failure).

Mathias

On Mon, Aug 10, 2009 at 5:46 PM, Koji Noguchi <knoguchi@yahoo-inc.com>wrote:

> > but I didn't find a config option
> > that allows ignoring tasks that fail.
> >
> If 0.18,
>
> http://hadoop.apache.org/common/docs/r0.18.3/api/org/apache/hadoop/mapred/Jo
> bConf.html#setMaxMapTaskFailuresPercent(int)<http://hadoop.apache.org/common/docs/r0.18.3/api/org/apache/hadoop/mapred/Jo%0AbConf.html#setMaxMapTaskFailuresPercent%28int%29>
> (mapred.max.map.failures.percent)
>
>
>
> http://hadoop.apache.org/common/docs/r0.18.3/api/org/apache/hadoop/mapred/Jo
> bConf.html#setMaxReduceTaskFailuresPercent(int)<http://hadoop.apache.org/common/docs/r0.18.3/api/org/apache/hadoop/mapred/Jo%0AbConf.html#setMaxReduceTaskFailuresPercent%28int%29>
> (mapred.max.reduce.failures.percent)
>
>
> If 0.19 or later, you can also try skipping records.
>
>
> Koji
>

--0016e6d59d1d305e170470ecebb1--

From common-user-return-16686-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 08:39:05 2009
Return-Path: <common-user-return-16686-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 29739 invoked from network); 12 Aug 2009 08:39:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 08:39:05 -0000
Received: (qmail 25987 invoked by uid 500); 12 Aug 2009 08:39:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25880 invoked by uid 500); 12 Aug 2009 08:39:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25869 invoked by uid 99); 12 Aug 2009 08:39:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 08:39:09 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of amansk@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 08:39:02 +0000
Received: by yxe15 with SMTP id 15so5661770yxe.5
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 01:38:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=0iBirXjwsr8wOuHjgFGLZQECHX1Q66lZ/ATAeg2t6EQ=;
        b=hwaY/RnrGsr9HZhxHwz4ijWpOQNl2NBdxmzTeJwDxq9OzzVtkj1M7k3gJKul01ZdyQ
         VsoONf1tcnQDvWOMAj1/wv1gwikBtWeLif4N5HH9ZercJ9OyieqMhwvDBULFWP86aNW7
         p1SfC1CUnKcsV6mJa9bkiz07od8ceAMPXXqEo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=QYEw+KG7z8GD3V410G/B6rXZ3wMQ1Wf9YKj+bKu4Uvq+04T6jEBAkkrmX3rKi6fxK+
         MWKMaHrdEVJ/AKV00pK86yipt9j/JRqYuUHpxu1brcSzhxjiSgvMYXp6CvBuJ3bxZFLF
         ei14Wpj5GCP48LHp8tsUvVzuSUn0+avSx0Gjk=
MIME-Version: 1.0
Received: by 10.100.178.2 with SMTP id a2mr6635995anf.2.1250066321091; Wed, 12 
	Aug 2009 01:38:41 -0700 (PDT)
In-Reply-To: <4A81B3C3.3060903@casalemedia.com>
References: <4A81B3C3.3060903@casalemedia.com>
Date: Wed, 12 Aug 2009 01:38:41 -0700
Message-ID: <35a22e220908120138s7ee2da9r1b4080462de6c7db@mail.gmail.com>
Subject: Re: NN + secondary got full, even though data nodes had plenty of 
	space
From: Amandeep Khurana <amansk@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Is your NN doubling up as a DN? If its not, I wonder how the NN is full...

On 8/11/09, Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com> wrote:
> I have a 6 node cluster running Hadoop 0.18.3.  I'm trying to figure out
> how the data was spread out like this:
>
> node001         94.15%
> node002         94.16%
> node003         48.22%
> node004         47.85%
> node005         48.12%
> node006         43.18%
>
> Node 001 (NN) and node 002( secondary NN) both got full, while the other
> data nodes had more space left.  I had assumed that Hadoop would distribute
> more blocks to nodes 3-6 since they had much more space, but it ended up
> filling up nodes1 and 2.  Is this expected?
>
> thanks,
> M
>
>


-- 


Amandeep Khurana
Computer Science Graduate Student
University of California, Santa Cruz

From common-user-return-16687-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 10:42:28 2009
Return-Path: <common-user-return-16687-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 5057 invoked from network); 12 Aug 2009 10:42:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 10:42:28 -0000
Received: (qmail 85619 invoked by uid 500); 12 Aug 2009 10:42:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 85537 invoked by uid 500); 12 Aug 2009 10:42:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 85527 invoked by uid 99); 12 Aug 2009 10:42:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 10:42:32 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of stas.oskin@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 10:42:21 +0000
Received: by bwz10 with SMTP id 10so2345825bwz.29
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 03:42:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=HpNE2UwpexOrUPw/ZBg+GKWX+4Ysh1rpDdbJdKtANTE=;
        b=JsKcsHBIkuF5tcLSKnGiW9SEWQaeUwVYeFVWTwIXp6fPCXNm7DuyQBb8WWAcLn+8ti
         Cqcj4qSQw4pjOx8FCdc5IJ2B0rPpN4t3j2285TaSNJ3iNtIV6cdVI5UaiAaPLAuzZtVi
         xmnnm48kuOZp2LM6p9WbSJZqkbafJJVoYIZYQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=gqkmbJz2uBH1ZUA45cQZ2dmbCr8Pq/z3wvyOnDlVBFviwVW5AKMLOH1ajFvAoTjYh5
         qaW4wnT+uaOQGsKnxsueY1qkYZ+zPQyzowZNoN7gtFrwmvmmHPf/MKjumwCh5CrGS86p
         od2RX9M3joqhuq+rwyMwpevMbolKBKBUMxsE4=
MIME-Version: 1.0
Received: by 10.223.125.207 with SMTP id z15mr189far.7.1250073721033; Wed, 12 
	Aug 2009 03:42:01 -0700 (PDT)
In-Reply-To: <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com>
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com>
	 <4A7BECD9.20303@apache.org>
	 <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com>
	 <4A814BCD.2060500@apache.org>
	 <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com>
Date: Wed, 12 Aug 2009 13:42:00 +0300
Message-ID: <77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com>
Subject: Re: HADOOP-4539 question
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c5b41515d4d60470ef7800
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c5b41515d4d60470ef7800
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.


> You can also use a utility like Linux-HA (aka heartbeat) to handle IP
> address failover. It will even send gratuitous ARPs to make sure to get the
> new mac address registered after a failover. Check out this blog for info
> about a setup like this:
>
> http://www.cloudera.com/blog/2009/07/22/hadoop-ha-configuration/
>
> Hope that helps
>

Thanks, exactly what I looked for :).

 I presume that with the coming BB node, there won't be need for DRBD, am I
correct?

Regards.

--001636c5b41515d4d60470ef7800--

From common-user-return-16688-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 11:05:36 2009
Return-Path: <common-user-return-16688-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 9372 invoked from network); 12 Aug 2009 11:05:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 11:05:35 -0000
Received: (qmail 8345 invoked by uid 500); 12 Aug 2009 11:05:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 8258 invoked by uid 500); 12 Aug 2009 11:05:39 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 8247 invoked by uid 99); 12 Aug 2009 11:05:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 11:05:39 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of timrobertson100@gmail.com designates 74.125.78.26 as permitted sender)
Received: from [74.125.78.26] (HELO ey-out-2122.google.com) (74.125.78.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 11:05:31 +0000
Received: by ey-out-2122.google.com with SMTP id 22so18580eye.35
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 04:05:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=tyHt17uWHtx68r+tIGJ+9MoK/ypxDfRUbF1R0/BuVOw=;
        b=eK/wITEm0swMrk5uB34wX7Yf0sgZbveTK5eAP0pbCJ0DrpP1aMgbfFUmhe8bmY2sbP
         bS0Q5F+tHF2KVjWD9E1n2SNO0JfoHWmGnNn+YKQ+Z7KRghvS9EKSEDhVJ5pTjLpuGYVU
         EIsnAm18Jw5HZ27q+oMK7aI1JpNl1ELAS2d8E=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=ja+zXqm0vBvGihrEgcHlJW99RFBg4kb/Hdo465bSVul6yV1iOwU0z0EVjLXVwqHGv/
         LA+d6jeLVEKfageIOMW1CfIO9jJVaE4Mc0xQ4Q6V+ErB+agXeSuNMnzzwLN60k/pbbb9
         BDy5Jqxm/znoE/ITLGvl+G5ti2ykGqo6nBnNQ=
MIME-Version: 1.0
Received: by 10.216.53.133 with SMTP id g5mr1441835wec.160.1250075110674; Wed, 
	12 Aug 2009 04:05:10 -0700 (PDT)
Date: Wed, 12 Aug 2009 13:05:10 +0200
Message-ID: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
Subject: What OS?
From: tim robertson <timrobertson100@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

Is fedora a decent choice of OS for a new hadoop cluster?  All our
other stuff is fedora, but is there was a strong case to move to
something else?

Cheers

Tim

From common-user-return-16689-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 11:59:07 2009
Return-Path: <common-user-return-16689-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 28971 invoked from network); 12 Aug 2009 11:59:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 11:59:07 -0000
Received: (qmail 10222 invoked by uid 500); 12 Aug 2009 11:59:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10139 invoked by uid 500); 12 Aug 2009 11:59:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10129 invoked by uid 99); 12 Aug 2009 11:59:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 11:59:11 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bogdan.maryniuk@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 11:59:02 +0000
Received: by fxm24 with SMTP id 24so4849476fxm.36
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 04:58:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=W5Nm3KfSNc3wHxPhMwaG6PPXj8o6AOZ6RhJYfY8SVdw=;
        b=B0tzdS9I2CFN15dZ3rfbwTMqYmn0CQBSwD4gxSuijh+M7M3hOtSI3kcmZOJECwY4iY
         m52J4NJUNN3Q1Y4dXVRHDGwBMvuqSOb8xhUvTjTd0PQlgDifW7DZ2AtvBFeCWls2Dd4C
         xdG0JQkkrJ3OmgOg40e47cz5/vDFTXCglROZ4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=j+Kl8NooiloWZL5Gdr+ma+nemlU1V8bHSmwCnLJ3Kvemf+slS3eTFHiRM1jBBrxjFc
         tj+XMvRi9mhldFfPTvgmalC5r8W3iwZUhbtaL4jDl6cRKbgZVYeev5CBXoewBtgoBtsM
         SZYYxE2PibIkCiNit6hCpHdJzihhkodhFD64w=
MIME-Version: 1.0
Received: by 10.223.123.208 with SMTP id q16mr17166far.36.1250078321433; Wed, 
	12 Aug 2009 04:58:41 -0700 (PDT)
In-Reply-To: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
Date: Wed, 12 Aug 2009 20:58:41 +0900
Message-ID: <fa561940908120458l2b2fe671uabae729ff7eca9a5@mail.gmail.com>
Subject: Re: What OS?
From: "Bogdan M. Maryniuk" <bogdan.maryniuk@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Wed, Aug 12, 2009 at 8:05 PM, tim robertson<timrobertson100@gmail.com> w=
rote:
> Is fedora a decent choice of OS for a new hadoop cluster? =C2=A0All our
> other stuff is fedora, but is there was a strong case to move to
> something else?

Not that is known to the world. For example, I am using OpenSolaris
and running Hadoop on zones. No problems other than zone should point
to a real device.

--=20
Kind regards, BM

Things, that are stupid at the beginning, rarely ends up wisely.

From common-user-return-16690-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 12:04:28 2009
Return-Path: <common-user-return-16690-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 31099 invoked from network); 12 Aug 2009 12:04:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 12:04:28 -0000
Received: (qmail 21717 invoked by uid 500); 12 Aug 2009 12:04:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21628 invoked by uid 500); 12 Aug 2009 12:04:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21618 invoked by uid 99); 12 Aug 2009 12:04:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 12:04:32 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 12:04:21 +0000
Received: from [192.168.0.102] (user-0cdvqhn.cable.mindspring.com [24.223.234.55])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7CC3umD016143
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 07:03:59 -0500
Message-Id: <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
Content-Type: multipart/signed; boundary=Apple-Mail-1--958987731; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v935.3)
Subject: Re: What OS?
Date: Wed, 12 Aug 2009 07:03:55 -0500
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
X-Mailer: Apple Mail (2.935.3)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-1--958987731
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Hey Tim,

One consideration is "how long is this OS version going to be  
receiving updates?" or "Do I do the operations team any favor by  
having them upgrade every 6 months?"

Personally, I'd avoid Fedora for a production cluster because the lack  
of long-lived releases means that you'll be spending extra effort on  
upgrading the OS.

Brian

On Aug 12, 2009, at 6:05 AM, tim robertson wrote:

> Hi all,
>
> Is fedora a decent choice of OS for a new hadoop cluster?  All our
> other stuff is fedora, but is there was a strong case to move to
> something else?
>
> Cheers
>
> Tim


--Apple-Mail-1--958987731
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-1--958987731--

From common-user-return-16691-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 12:33:10 2009
Return-Path: <common-user-return-16691-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 49755 invoked from network); 12 Aug 2009 12:33:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 12:33:09 -0000
Received: (qmail 62925 invoked by uid 500); 12 Aug 2009 12:33:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 62832 invoked by uid 500); 12 Aug 2009 12:33:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 62822 invoked by uid 99); 12 Aug 2009 12:33:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 12:33:14 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 12:33:03 +0000
Received: by vws40 with SMTP id 40so4099556vws.2
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 05:32:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=wdyh7t2VoDk1Vi0SCC7N5WlDc+N5RYpDBnk2wJtDP2E=;
        b=XLuQAsFcBdk0ffKrUxsYQg+EaugLyncKTN6W3uHZ8XoQJGm85eLyj/HD2fmewdxeXi
         rsxBkFeu09JtUSXb7hXZuBJnx5bHTzJfltsXty3avCOXKM/6p6v3euC8RUyttqx50FcT
         3l3MKTUZHd4dLUydyvkaZVXHuqDS2XFqOxSHw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=c2sPtOp8GKJFEGnnz2X94kwXw/uAiln94HgT6uUKFJQpqnj38Xp1L7JS20X7/yxO1H
         oYQ6b+3uMYX4iE5UlrKkXv5vLUXcyi5uwY/64kboKjX5OmXZkzZ93pl7y+gF+2ldDE0/
         uwov/gRTCGIqhsUm0rxqcYIp/nKvusTvs+vSo=
MIME-Version: 1.0
Received: by 10.220.15.208 with SMTP id l16mr75961vca.64.1250080360945; Wed, 
	12 Aug 2009 05:32:40 -0700 (PDT)
In-Reply-To: <18070014.481250049615899.JavaMail.pallavi@e1a31053e.in.office.aol.com>
References: <31565010.461250045532801.JavaMail.pallavi@e1a31053e.in.office.aol.com>
	 <18070014.481250049615899.JavaMail.pallavi@e1a31053e.in.office.aol.com>
Date: Wed, 12 Aug 2009 05:32:40 -0700
Message-ID: <314098690908120532p799e81d7rbc416782e58e27df@mail.gmail.com>
Subject: Re: File is closed but data is not visible
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64aee22dada900470f1038b
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64aee22dada900470f1038b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Is it possible that your application is caching some data and not refreshing
it when you expect?
The HDFS file visibility semantics are well understood, and your case does
not fit with that understanding.
A factor that hints strongly at this is that your file is visible via the
Namenode UI, there is nothing special about that UI

On Tue, Aug 11, 2009 at 9:00 PM, Pallavi Palleti <
pallavi.palleti@corp.aol.com> wrote:

> Hi Raghu,
>
> The file doesn't appear in the cluster when I saw it from Namenode UI.
> Also, I have a monitor at cluster side which checks whether file is created
> and throws an exception when it is not created. And, it threw an exception
> saying "File not found".
>
> Thanks
> Pallavi
> ----- Original Message -----
> From: "Raghu Angadi" <rangadi@yahoo-inc.com>
> To: common-user@hadoop.apache.org
> Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai, Kolkata,
> Mumbai, New Delhi
> Subject: Re: File is closed but data is not visible
>
>
> Your assumption is correct. When you close the file, others can read the
> data. There is no delay expected before the data is visible. If there is
> an error either write() or close() would throw an error.
>
> When you say data is not visible do you mean readers can not see the
> file or can not see the data? Is it guaranteed that readers open the
> file _after_ close returns on the writer?
>
> Raghu.
>
> Palleti, Pallavi wrote:
> > Hi Jason,
> >
> > Apologies for missing version information in my previous mail. I am
> > using hadoop-0.18.3. I am getting FSDataOutputStream object using
> > fs.create(new Path(some_file_name)), where fs is FileSystem object. And,
> > I am closing the file using close().
> >
> > Thanks
> > Pallavi
> >
> > -----Original Message-----
> > From: Jason Venner [mailto:jason.hadoop@gmail.com]
> > Sent: Tuesday, August 11, 2009 6:24 PM
> > To: common-user@hadoop.apache.org
> > Subject: Re: File is closed but data is not visible
> >
> > Please provide information on what version of hadoop you are using and
> > the
> > method of opening and closing the file.
> >
> >
> > On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
> > pallavi.palleti@corp.aol.com> wrote:
> >
> >> Hi all,
> >>
> >> We have an application where we pull logs from an external server(far
> > apart
> >> from hadoop cluster) to hadoop cluster. Sometimes, we could see huge
> > delay
> >> (of 1 hour or more) in actually seeing the data in HDFS though the
> > file has
> >> been closed and the variable is set to null from the external
> > application.I
> >> was in the impression that when I close the file, the data gets
> > reflected in
> >> hadoop cluster. Now, in this situation, it is even more complicated to
> >> handle write failures as it is giving false impression to the client
> > that
> >> data has been written to HDFS. Kindly clarify if my perception is
> > correct.
> >> If yes, Could some one tell me what is causing the delay in actually
> > showing
> >> the data. During those cases, how can we tackle write failures (due to
> > some
> >> temporary issues like data node not available, disk is full) as there
> > is no
> >> way, we can figure out the failure at the client side?
> >>
> >> Thanks
> >> Pallavi
> >>
> >
> >
> >
>
>


-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--0016e64aee22dada900470f1038b--

From common-user-return-16692-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 12:57:41 2009
Return-Path: <common-user-return-16692-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61137 invoked from network); 12 Aug 2009 12:57:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 12:57:41 -0000
Received: (qmail 96594 invoked by uid 500); 12 Aug 2009 12:57:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 96502 invoked by uid 500); 12 Aug 2009 12:57:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 96491 invoked by uid 99); 12 Aug 2009 12:57:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 12:57:46 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pallavi.palleti@corp.aol.com designates 64.12.143.147 as permitted sender)
Received: from [64.12.143.147] (HELO omr-m35.mx.aol.com) (64.12.143.147)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 12:57:36 +0000
Received: from AOLMTCMEH01.ad.office.aol.com (aolmtcmeh01.office.aol.com [10.178.121.20]) by omr-m35.mx.aol.com (v117.7) with ESMTP id MAILOMRM354-7f3b4a82bc283ba; Wed, 12 Aug 2009 08:57:12 -0400
Received: from EVSBNG01.ad.office.aol.com ([10.146.190.242]) by AOLMTCMEH01.ad.office.aol.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Wed, 12 Aug 2009 08:57:12 -0400
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
Subject: RE: File is closed but data is not visible
Date: Wed, 12 Aug 2009 18:27:08 +0530
Message-ID: <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D157@EVSBNG01.ad.office.aol.com>
In-Reply-To: <314098690908120532p799e81d7rbc416782e58e27df@mail.gmail.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: File is closed but data is not visible
Thread-Index: AcobSSCnM+ZuBOxwRhy7UMm7kso1cAAAUfzw
References: <31565010.461250045532801.JavaMail.pallavi@e1a31053e.in.office.aol.com> <18070014.481250049615899.JavaMail.pallavi@e1a31053e.in.office.aol.com> <314098690908120532p799e81d7rbc416782e58e27df@mail.gmail.com>
From: "Palleti, Pallavi" <pallavi.palleti@corp.aol.com>
To: <common-user@hadoop.apache.org>
X-OriginalArrivalTime: 12 Aug 2009 12:57:12.0050 (UTC) FILETIME=[68A3A520:01CA1B4C]
X-AOL-IP: 10.178.121.20
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Jason,

The file is neither visible via Namenode UI nor via program(checking
whether a file exists).

There is no caching happening at the application level. The application
is pretty simple. We are taking apache logs and trying to put into
timely buckets based on the logged time of records. We are creating 4
files(one for every 15 minutes) for every hour. So, at the client side,
we are looking into the logs and see if the data belongs to the current
interval, then we are writing into the currently opened HDFS file. If it
belongs to new interval, the old file is closed and new file is created.
I have been logging the time at which the file is being created and at
which the file is being closed at my client side. And, I could see that
the file is getting closed at expected time period. But, when I look for
the same file in hadoop cluster, it is still not created and if I wait
for another 1 to 2 hours, I could see the file.=20

Thanks
Pallavi


-----Original Message-----
From: Jason Venner [mailto:jason.hadoop@gmail.com]=20
Sent: Wednesday, August 12, 2009 6:03 PM
To: common-user@hadoop.apache.org
Subject: Re: File is closed but data is not visible

Is it possible that your application is caching some data and not
refreshing
it when you expect?
The HDFS file visibility semantics are well understood, and your case
does
not fit with that understanding.
A factor that hints strongly at this is that your file is visible via
the
Namenode UI, there is nothing special about that UI

On Tue, Aug 11, 2009 at 9:00 PM, Pallavi Palleti <
pallavi.palleti@corp.aol.com> wrote:

> Hi Raghu,
>
> The file doesn't appear in the cluster when I saw it from Namenode UI.
> Also, I have a monitor at cluster side which checks whether file is
created
> and throws an exception when it is not created. And, it threw an
exception
> saying "File not found".
>
> Thanks
> Pallavi
> ----- Original Message -----
> From: "Raghu Angadi" <rangadi@yahoo-inc.com>
> To: common-user@hadoop.apache.org
> Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai,
Kolkata,
> Mumbai, New Delhi
> Subject: Re: File is closed but data is not visible
>
>
> Your assumption is correct. When you close the file, others can read
the
> data. There is no delay expected before the data is visible. If there
is
> an error either write() or close() would throw an error.
>
> When you say data is not visible do you mean readers can not see the
> file or can not see the data? Is it guaranteed that readers open the
> file _after_ close returns on the writer?
>
> Raghu.
>
> Palleti, Pallavi wrote:
> > Hi Jason,
> >
> > Apologies for missing version information in my previous mail. I am
> > using hadoop-0.18.3. I am getting FSDataOutputStream object using
> > fs.create(new Path(some_file_name)), where fs is FileSystem object.
And,
> > I am closing the file using close().
> >
> > Thanks
> > Pallavi
> >
> > -----Original Message-----
> > From: Jason Venner [mailto:jason.hadoop@gmail.com]
> > Sent: Tuesday, August 11, 2009 6:24 PM
> > To: common-user@hadoop.apache.org
> > Subject: Re: File is closed but data is not visible
> >
> > Please provide information on what version of hadoop you are using
and
> > the
> > method of opening and closing the file.
> >
> >
> > On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
> > pallavi.palleti@corp.aol.com> wrote:
> >
> >> Hi all,
> >>
> >> We have an application where we pull logs from an external
server(far
> > apart
> >> from hadoop cluster) to hadoop cluster. Sometimes, we could see
huge
> > delay
> >> (of 1 hour or more) in actually seeing the data in HDFS though the
> > file has
> >> been closed and the variable is set to null from the external
> > application.I
> >> was in the impression that when I close the file, the data gets
> > reflected in
> >> hadoop cluster. Now, in this situation, it is even more complicated
to
> >> handle write failures as it is giving false impression to the
client
> > that
> >> data has been written to HDFS. Kindly clarify if my perception is
> > correct.
> >> If yes, Could some one tell me what is causing the delay in
actually
> > showing
> >> the data. During those cases, how can we tackle write failures (due
to
> > some
> >> temporary issues like data node not available, disk is full) as
there
> > is no
> >> way, we can figure out the failure at the client side?
> >>
> >> Thanks
> >> Pallavi
> >>
> >
> >
> >
>
>


--=20
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

From common-user-return-16693-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 13:05:35 2009
Return-Path: <common-user-return-16693-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 65212 invoked from network); 12 Aug 2009 13:05:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 13:05:35 -0000
Received: (qmail 11028 invoked by uid 500); 12 Aug 2009 13:05:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10916 invoked by uid 500); 12 Aug 2009 13:05:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10782 invoked by uid 99); 12 Aug 2009 13:05:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 13:05:37 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 13:05:25 +0000
Received: by vws40 with SMTP id 40so4114647vws.2
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 06:05:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=S9hkzOpm0zdoUKO+cde762tEO5Xs39hDDdhEylG/R2o=;
        b=PelvDdTHrcQR2oKcwUO6fk8YIhxX8aB9oPo2KOPMUm0cGH9mejr2lXhET8O/fy/djF
         +rFKAmuvtS56qjmB+sxXMh1oGp9wAmPU8+rbkM0npen/05zJhBphxivLSWwKvzv2lHO7
         051eGr5TNQVIFaEcM/q4fy9jOr/AZ1oc4vMzk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=ZP8wSeio/CXHC1gduzxH6v2XY5I/+U2y9Yq9Lm/hf58PolskeVIoeZoM5ecAjGthNB
         5FvjriN3UrKMtEFOy2FDRbQvEp/fCsvAMNArxTEUmI341Sp/RTS5/fAjyvRQGwRguvW4
         3fappenP2/fvfXli5kcgMMEBnDww85YB/jR3g=
MIME-Version: 1.0
Received: by 10.220.45.198 with SMTP id g6mr114864vcf.46.1250082303892; Wed, 
	12 Aug 2009 06:05:03 -0700 (PDT)
In-Reply-To: <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D157@EVSBNG01.ad.office.aol.com>
References: <31565010.461250045532801.JavaMail.pallavi@e1a31053e.in.office.aol.com>
	 <18070014.481250049615899.JavaMail.pallavi@e1a31053e.in.office.aol.com>
	 <314098690908120532p799e81d7rbc416782e58e27df@mail.gmail.com>
	 <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D157@EVSBNG01.ad.office.aol.com>
Date: Wed, 12 Aug 2009 06:05:03 -0700
Message-ID: <314098690908120605m783e77d4ue8c9ebbf584af64f@mail.gmail.com>
Subject: Re: File is closed but data is not visible
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016363b85b0a9deae0470f17776
X-Virus-Checked: Checked by ClamAV on apache.org

--0016363b85b0a9deae0470f17776
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Are you explicitly calling close on the FSDataOutputStream that you received
from the FileSystem.create method?
It sounds like the close is actually happening in the finalizer method on
the object.

Can you post the relevant code, or provide a cut down demonstrator?

On Wed, Aug 12, 2009 at 5:57 AM, Palleti, Pallavi <
pallavi.palleti@corp.aol.com> wrote:

> Hi Jason,
>
> The file is neither visible via Namenode UI nor via program(checking
> whether a file exists).
>
> There is no caching happening at the application level. The application
> is pretty simple. We are taking apache logs and trying to put into
> timely buckets based on the logged time of records. We are creating 4
> files(one for every 15 minutes) for every hour. So, at the client side,
> we are looking into the logs and see if the data belongs to the current
> interval, then we are writing into the currently opened HDFS file. If it
> belongs to new interval, the old file is closed and new file is created.
> I have been logging the time at which the file is being created and at
> which the file is being closed at my client side. And, I could see that
> the file is getting closed at expected time period. But, when I look for
> the same file in hadoop cluster, it is still not created and if I wait
> for another 1 to 2 hours, I could see the file.
>
> Thanks
> Pallavi
>
>
> -----Original Message-----
> From: Jason Venner [mailto:jason.hadoop@gmail.com]
> Sent: Wednesday, August 12, 2009 6:03 PM
> To: common-user@hadoop.apache.org
> Subject: Re: File is closed but data is not visible
>
> Is it possible that your application is caching some data and not
> refreshing
> it when you expect?
> The HDFS file visibility semantics are well understood, and your case
> does
> not fit with that understanding.
> A factor that hints strongly at this is that your file is visible via
> the
> Namenode UI, there is nothing special about that UI
>
> On Tue, Aug 11, 2009 at 9:00 PM, Pallavi Palleti <
> pallavi.palleti@corp.aol.com> wrote:
>
> > Hi Raghu,
> >
> > The file doesn't appear in the cluster when I saw it from Namenode UI.
> > Also, I have a monitor at cluster side which checks whether file is
> created
> > and throws an exception when it is not created. And, it threw an
> exception
> > saying "File not found".
> >
> > Thanks
> > Pallavi
> > ----- Original Message -----
> > From: "Raghu Angadi" <rangadi@yahoo-inc.com>
> > To: common-user@hadoop.apache.org
> > Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai,
> Kolkata,
> > Mumbai, New Delhi
> > Subject: Re: File is closed but data is not visible
> >
> >
> > Your assumption is correct. When you close the file, others can read
> the
> > data. There is no delay expected before the data is visible. If there
> is
> > an error either write() or close() would throw an error.
> >
> > When you say data is not visible do you mean readers can not see the
> > file or can not see the data? Is it guaranteed that readers open the
> > file _after_ close returns on the writer?
> >
> > Raghu.
> >
> > Palleti, Pallavi wrote:
> > > Hi Jason,
> > >
> > > Apologies for missing version information in my previous mail. I am
> > > using hadoop-0.18.3. I am getting FSDataOutputStream object using
> > > fs.create(new Path(some_file_name)), where fs is FileSystem object.
> And,
> > > I am closing the file using close().
> > >
> > > Thanks
> > > Pallavi
> > >
> > > -----Original Message-----
> > > From: Jason Venner [mailto:jason.hadoop@gmail.com]
> > > Sent: Tuesday, August 11, 2009 6:24 PM
> > > To: common-user@hadoop.apache.org
> > > Subject: Re: File is closed but data is not visible
> > >
> > > Please provide information on what version of hadoop you are using
> and
> > > the
> > > method of opening and closing the file.
> > >
> > >
> > > On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
> > > pallavi.palleti@corp.aol.com> wrote:
> > >
> > >> Hi all,
> > >>
> > >> We have an application where we pull logs from an external
> server(far
> > > apart
> > >> from hadoop cluster) to hadoop cluster. Sometimes, we could see
> huge
> > > delay
> > >> (of 1 hour or more) in actually seeing the data in HDFS though the
> > > file has
> > >> been closed and the variable is set to null from the external
> > > application.I
> > >> was in the impression that when I close the file, the data gets
> > > reflected in
> > >> hadoop cluster. Now, in this situation, it is even more complicated
> to
> > >> handle write failures as it is giving false impression to the
> client
> > > that
> > >> data has been written to HDFS. Kindly clarify if my perception is
> > > correct.
> > >> If yes, Could some one tell me what is causing the delay in
> actually
> > > showing
> > >> the data. During those cases, how can we tackle write failures (due
> to
> > > some
> > >> temporary issues like data node not available, disk is full) as
> there
> > > is no
> > >> way, we can figure out the failure at the client side?
> > >>
> > >> Thanks
> > >> Pallavi
> > >>
> > >
> > >
> > >
> >
> >
>
>
> --
> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> http://www.amazon.com/dp/1430219424?tag=jewlerymall
> www.prohadoopbook.com a community for Hadoop Professionals
>



-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--0016363b85b0a9deae0470f17776--

From common-user-return-16694-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 13:24:58 2009
Return-Path: <common-user-return-16694-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 71975 invoked from network); 12 Aug 2009 13:24:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 13:24:58 -0000
Received: (qmail 50205 invoked by uid 500); 12 Aug 2009 13:25:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 50110 invoked by uid 500); 12 Aug 2009 13:25:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 50100 invoked by uid 99); 12 Aug 2009 13:25:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 13:25:02 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pallavi.palleti@corp.aol.com designates 64.12.143.147 as permitted sender)
Received: from [64.12.143.147] (HELO omr-m35.mx.aol.com) (64.12.143.147)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 13:24:51 +0000
Received: from AOLMTCMEH01.ad.office.aol.com (aolmtcmeh01.office.aol.com [10.178.121.20]) by omr-m35.mx.aol.com (v117.7) with ESMTP id MAILOMRM353-7f3a4a82c2893ca; Wed, 12 Aug 2009 09:24:25 -0400
Received: from EVSBNG01.ad.office.aol.com ([10.146.190.242]) by AOLMTCMEH01.ad.office.aol.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Wed, 12 Aug 2009 09:24:24 -0400
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01CA1B50.3454B5DB"
Subject: RE: File is closed but data is not visible
Date: Wed, 12 Aug 2009 18:54:21 +0530
Message-ID: <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D15C@EVSBNG01.ad.office.aol.com>
In-Reply-To: <314098690908120605m783e77d4ue8c9ebbf584af64f@mail.gmail.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: File is closed but data is not visible
Thread-Index: AcobTaTLw9aJszWIR2Cm00dqN+bWBQAAQSdg
References: <31565010.461250045532801.JavaMail.pallavi@e1a31053e.in.office.aol.com> <18070014.481250049615899.JavaMail.pallavi@e1a31053e.in.office.aol.com> <314098690908120532p799e81d7rbc416782e58e27df@mail.gmail.com> <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D157@EVSBNG01.ad.office.aol.com> <314098690908120605m783e77d4ue8c9ebbf584af64f@mail.gmail.com>
From: "Palleti, Pallavi" <pallavi.palleti@corp.aol.com>
To: <common-user@hadoop.apache.org>
X-OriginalArrivalTime: 12 Aug 2009 13:24:24.0680 (UTC) FILETIME=[35C33680:01CA1B50]
X-AOL-IP: 10.178.121.20
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01CA1B50.3454B5DB
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Hi Jason,

Kindly find the snippet of code which creates and close file.

Variables passed to the method:FSDataOutputStream out,ParamWrapper
paramWrapper=20

Snippet:

    String inputLine =3D null;
    int status =3D 0;

    BufferedReader reader =3D null;

    try {
      reader =3D new BufferedReader(new InputStreamReader(....); =
//reader
initialization

      while ((inputLine =3D reader.readLine()) !=3D null) {

        Date date =3D getLoggedDate(inputLine); // process the line to =
get
input and if it is wrong
        if (date =3D=3D null) // if input data is wrong, don't write
        {
          continue;
        }
        Calendar cal =3D Calendar.getInstance();
        cal.setTime(date);
        int hour =3D cal.get(Calendar.HOUR_OF_DAY); // get input hour
        int minutes =3D cal.get(Calendar.MINUTE); // get input minute

        int outputMinute =3D minutes / timePeriod + 1; // compute the =
slot

        if (paramWrapper.prevHour !=3D hour
            || paramWrapper.prevMin !=3D outputMinute) // if it is a new
slot
        {

          if (out !=3D null) // if any output stream opened previously ,
close it
          {
            logger.info("Closing writer of -" +
paramWrapper.getOutFileStr());
            out.close();
            out =3D null;
          }
          String outFileStr =3D generateFileName(rootDir,
hdfsOutFile,outputMinute, date); // generate file name ex:
location/year/month/day/hour/_1.txt
          Path outFile =3D new Path(outFileStr);

          paramWrapper.setOutFileStr(outFileStr);
          logger.info("Creating outFile:" + outFileStr);

          out =3D fs.create(outFile); // create new file and get
          // output stream
          paramWrapper.setPrevHour(hour);
          paramWrapper.setPrevMin(outputMinute);
        }
        StringBuilder outLineStr =3D new StringBuilder();
        outLineStr.append(inputLine).append("\n");
        out.write(outLineStr.toString().getBytes());
      }
    } catch (IOException ioe) {
      logger.error("Main: IO Exception while writing to HDFS, exiting...
", ioe);
      // before exiting do the cleanup
      close(reader);
      System.exit(-1);

    } catch (Exception e) {
      logger.error("Unexpected error while writing to HDFS, exiting
...", e);
      // before exiting do the cleanup
      close(reader);

      System.exit(-1);
    } finally {
      close(reader);
    }
   =20
Thanks
Pallavi


-----Original Message-----
From: Jason Venner [mailto:jason.hadoop@gmail.com]=20
Sent: Wednesday, August 12, 2009 6:35 PM
To: common-user@hadoop.apache.org
Subject: Re: File is closed but data is not visible

Are you explicitly calling close on the FSDataOutputStream that you
received
from the FileSystem.create method?
It sounds like the close is actually happening in the finalizer method
on
the object.

Can you post the relevant code, or provide a cut down demonstrator?

On Wed, Aug 12, 2009 at 5:57 AM, Palleti, Pallavi <
pallavi.palleti@corp.aol.com> wrote:

> Hi Jason,
>
> The file is neither visible via Namenode UI nor via program(checking
> whether a file exists).
>
> There is no caching happening at the application level. The
application
> is pretty simple. We are taking apache logs and trying to put into
> timely buckets based on the logged time of records. We are creating 4
> files(one for every 15 minutes) for every hour. So, at the client
side,
> we are looking into the logs and see if the data belongs to the
current
> interval, then we are writing into the currently opened HDFS file. If
it
> belongs to new interval, the old file is closed and new file is
created.
> I have been logging the time at which the file is being created and at
> which the file is being closed at my client side. And, I could see
that
> the file is getting closed at expected time period. But, when I look
for
> the same file in hadoop cluster, it is still not created and if I wait
> for another 1 to 2 hours, I could see the file.
>
> Thanks
> Pallavi
>
>
> -----Original Message-----
> From: Jason Venner [mailto:jason.hadoop@gmail.com]
> Sent: Wednesday, August 12, 2009 6:03 PM
> To: common-user@hadoop.apache.org
> Subject: Re: File is closed but data is not visible
>
> Is it possible that your application is caching some data and not
> refreshing
> it when you expect?
> The HDFS file visibility semantics are well understood, and your case
> does
> not fit with that understanding.
> A factor that hints strongly at this is that your file is visible via
> the
> Namenode UI, there is nothing special about that UI
>
> On Tue, Aug 11, 2009 at 9:00 PM, Pallavi Palleti <
> pallavi.palleti@corp.aol.com> wrote:
>
> > Hi Raghu,
> >
> > The file doesn't appear in the cluster when I saw it from Namenode
UI.
> > Also, I have a monitor at cluster side which checks whether file is
> created
> > and throws an exception when it is not created. And, it threw an
> exception
> > saying "File not found".
> >
> > Thanks
> > Pallavi
> > ----- Original Message -----
> > From: "Raghu Angadi" <rangadi@yahoo-inc.com>
> > To: common-user@hadoop.apache.org
> > Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai,
> Kolkata,
> > Mumbai, New Delhi
> > Subject: Re: File is closed but data is not visible
> >
> >
> > Your assumption is correct. When you close the file, others can read
> the
> > data. There is no delay expected before the data is visible. If
there
> is
> > an error either write() or close() would throw an error.
> >
> > When you say data is not visible do you mean readers can not see the
> > file or can not see the data? Is it guaranteed that readers open the
> > file _after_ close returns on the writer?
> >
> > Raghu.
> >
> > Palleti, Pallavi wrote:
> > > Hi Jason,
> > >
> > > Apologies for missing version information in my previous mail. I
am
> > > using hadoop-0.18.3. I am getting FSDataOutputStream object using
> > > fs.create(new Path(some_file_name)), where fs is FileSystem
object.
> And,
> > > I am closing the file using close().
> > >
> > > Thanks
> > > Pallavi
> > >
> > > -----Original Message-----
> > > From: Jason Venner [mailto:jason.hadoop@gmail.com]
> > > Sent: Tuesday, August 11, 2009 6:24 PM
> > > To: common-user@hadoop.apache.org
> > > Subject: Re: File is closed but data is not visible
> > >
> > > Please provide information on what version of hadoop you are using
> and
> > > the
> > > method of opening and closing the file.
> > >
> > >
> > > On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
> > > pallavi.palleti@corp.aol.com> wrote:
> > >
> > >> Hi all,
> > >>
> > >> We have an application where we pull logs from an external
> server(far
> > > apart
> > >> from hadoop cluster) to hadoop cluster. Sometimes, we could see
> huge
> > > delay
> > >> (of 1 hour or more) in actually seeing the data in HDFS though
the
> > > file has
> > >> been closed and the variable is set to null from the external
> > > application.I
> > >> was in the impression that when I close the file, the data gets
> > > reflected in
> > >> hadoop cluster. Now, in this situation, it is even more
complicated
> to
> > >> handle write failures as it is giving false impression to the
> client
> > > that
> > >> data has been written to HDFS. Kindly clarify if my perception is
> > > correct.
> > >> If yes, Could some one tell me what is causing the delay in
> actually
> > > showing
> > >> the data. During those cases, how can we tackle write failures
(due
> to
> > > some
> > >> temporary issues like data node not available, disk is full) as
> there
> > > is no
> > >> way, we can figure out the failure at the client side?
> > >>
> > >> Thanks
> > >> Pallavi
> > >>
> > >
> > >
> > >
> >
> >
>
>
> --
> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
> www.prohadoopbook.com a community for Hadoop Professionals
>



--=20
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

------_=_NextPart_001_01CA1B50.3454B5DB--

From common-user-return-16695-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 14:01:35 2009
Return-Path: <common-user-return-16695-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 96520 invoked from network); 12 Aug 2009 14:01:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 14:01:35 -0000
Received: (qmail 20491 invoked by uid 500); 12 Aug 2009 14:01:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20434 invoked by uid 500); 12 Aug 2009 14:01:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20424 invoked by uid 99); 12 Aug 2009 14:01:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 14:01:38 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 14:01:25 +0000
Received: by vws40 with SMTP id 40so24971vws.2
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 07:01:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=I0bCnqVrT1ZbXT4B5cugb3OEKQjSXjvHzJMYn1VhnM0=;
        b=Zp9DJ1uUTyXZlyzk6FwVmPOe/c+BBvf25yZDsRToPTOVZtbQbjrmuDB/zFAaOGuoMI
         +ap5dwVZKu3u468jipvh1zD1Cc2PYvHwC/CwDjFng12Q+otPaQ/l5ftFoejTPPcimR5f
         tBOifgDZKDxruRLzyQBO/7BUIWxlY5eEZ50sc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=JgxsL7SLmK3JW9fYlPuIrAb0fuworbzYidPNt+0WAaeawVY1W+wPni1uYPOohOkaRP
         evX5D5nGxV/kmV8NCMxEAScf+k8LwL9iXa67+fEgaZCJmv3bSuSL2ItbHnnkMQW0BA8J
         CYdjohMcxvutHILXH5S4lP7f/fFFut/0T0RPA=
MIME-Version: 1.0
Received: by 10.220.71.85 with SMTP id g21mr181660vcj.12.1250085663218; Wed, 
	12 Aug 2009 07:01:03 -0700 (PDT)
In-Reply-To: <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D15C@EVSBNG01.ad.office.aol.com>
References: <31565010.461250045532801.JavaMail.pallavi@e1a31053e.in.office.aol.com>
	 <18070014.481250049615899.JavaMail.pallavi@e1a31053e.in.office.aol.com>
	 <314098690908120532p799e81d7rbc416782e58e27df@mail.gmail.com>
	 <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D157@EVSBNG01.ad.office.aol.com>
	 <314098690908120605m783e77d4ue8c9ebbf584af64f@mail.gmail.com>
	 <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D15C@EVSBNG01.ad.office.aol.com>
Date: Wed, 12 Aug 2009 07:01:03 -0700
Message-ID: <314098690908120701g4604db8cqfab097d0c5329282@mail.gmail.com>
Subject: Re: File is closed but data is not visible
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6469bc2e51c070470f23feb
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6469bc2e51c070470f23feb
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

You do not appear to close out, except when an exception occurs.
The finally block only closes the reader.

On Wed, Aug 12, 2009 at 6:24 AM, Palleti, Pallavi <
pallavi.palleti@corp.aol.com> wrote:

> Hi Jason,
>
> Kindly find the snippet of code which creates and close file.
>
> Variables passed to the method:FSDataOutputStream out,ParamWrapper
> paramWrapper
>
> Snippet:
>
>    String inputLine = null;
>    int status = 0;
>
>    BufferedReader reader = null;
>
>    try {
>      reader = new BufferedReader(new InputStreamReader(....); //reader
> initialization
>
>      while ((inputLine = reader.readLine()) != null) {
>
>        Date date = getLoggedDate(inputLine); // process the line to get
> input and if it is wrong
>        if (date == null) // if input data is wrong, don't write
>        {
>          continue;
>        }
>        Calendar cal = Calendar.getInstance();
>        cal.setTime(date);
>        int hour = cal.get(Calendar.HOUR_OF_DAY); // get input hour
>        int minutes = cal.get(Calendar.MINUTE); // get input minute
>
>        int outputMinute = minutes / timePeriod + 1; // compute the slot
>
>        if (paramWrapper.prevHour != hour
>            || paramWrapper.prevMin != outputMinute) // if it is a new
> slot
>        {
>
>          if (out != null) // if any output stream opened previously ,
> close it
>          {
>            logger.info("Closing writer of -" +
> paramWrapper.getOutFileStr());
>            out.close();
>            out = null;
>          }
>          String outFileStr = generateFileName(rootDir,
> hdfsOutFile,outputMinute, date); // generate file name ex:
> location/year/month/day/hour/_1.txt
>          Path outFile = new Path(outFileStr);
>
>          paramWrapper.setOutFileStr(outFileStr);
>          logger.info("Creating outFile:" + outFileStr);
>
>          out = fs.create(outFile); // create new file and get
>          // output stream
>          paramWrapper.setPrevHour(hour);
>          paramWrapper.setPrevMin(outputMinute);
>        }
>        StringBuilder outLineStr = new StringBuilder();
>        outLineStr.append(inputLine).append("\n");
>        out.write(outLineStr.toString().getBytes());
>      }
>    } catch (IOException ioe) {
>      logger.error("Main: IO Exception while writing to HDFS, exiting...
> ", ioe);
>      // before exiting do the cleanup
>      close(reader);
>      System.exit(-1);
>
>    } catch (Exception e) {
>      logger.error("Unexpected error while writing to HDFS, exiting
> ...", e);
>      // before exiting do the cleanup
>      close(reader);
>
>      System.exit(-1);
>    } finally {
>      close(reader);
>     }
>
> Thanks
> Pallavi
>
>
> -----Original Message-----
> From: Jason Venner [mailto:jason.hadoop@gmail.com]
> Sent: Wednesday, August 12, 2009 6:35 PM
> To: common-user@hadoop.apache.org
> Subject: Re: File is closed but data is not visible
>
> Are you explicitly calling close on the FSDataOutputStream that you
> received
> from the FileSystem.create method?
> It sounds like the close is actually happening in the finalizer method
> on
> the object.
>
> Can you post the relevant code, or provide a cut down demonstrator?
>
> On Wed, Aug 12, 2009 at 5:57 AM, Palleti, Pallavi <
> pallavi.palleti@corp.aol.com> wrote:
>
> > Hi Jason,
> >
> > The file is neither visible via Namenode UI nor via program(checking
> > whether a file exists).
> >
> > There is no caching happening at the application level. The
> application
> > is pretty simple. We are taking apache logs and trying to put into
> > timely buckets based on the logged time of records. We are creating 4
> > files(one for every 15 minutes) for every hour. So, at the client
> side,
> > we are looking into the logs and see if the data belongs to the
> current
> > interval, then we are writing into the currently opened HDFS file. If
> it
> > belongs to new interval, the old file is closed and new file is
> created.
> > I have been logging the time at which the file is being created and at
> > which the file is being closed at my client side. And, I could see
> that
> > the file is getting closed at expected time period. But, when I look
> for
> > the same file in hadoop cluster, it is still not created and if I wait
> > for another 1 to 2 hours, I could see the file.
> >
> > Thanks
> > Pallavi
> >
> >
> > -----Original Message-----
> > From: Jason Venner [mailto:jason.hadoop@gmail.com]
> > Sent: Wednesday, August 12, 2009 6:03 PM
> > To: common-user@hadoop.apache.org
> > Subject: Re: File is closed but data is not visible
> >
> > Is it possible that your application is caching some data and not
> > refreshing
> > it when you expect?
> > The HDFS file visibility semantics are well understood, and your case
> > does
> > not fit with that understanding.
> > A factor that hints strongly at this is that your file is visible via
> > the
> > Namenode UI, there is nothing special about that UI
> >
> > On Tue, Aug 11, 2009 at 9:00 PM, Pallavi Palleti <
> > pallavi.palleti@corp.aol.com> wrote:
> >
> > > Hi Raghu,
> > >
> > > The file doesn't appear in the cluster when I saw it from Namenode
> UI.
> > > Also, I have a monitor at cluster side which checks whether file is
> > created
> > > and throws an exception when it is not created. And, it threw an
> > exception
> > > saying "File not found".
> > >
> > > Thanks
> > > Pallavi
> > > ----- Original Message -----
> > > From: "Raghu Angadi" <rangadi@yahoo-inc.com>
> > > To: common-user@hadoop.apache.org
> > > Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai,
> > Kolkata,
> > > Mumbai, New Delhi
> > > Subject: Re: File is closed but data is not visible
> > >
> > >
> > > Your assumption is correct. When you close the file, others can read
> > the
> > > data. There is no delay expected before the data is visible. If
> there
> > is
> > > an error either write() or close() would throw an error.
> > >
> > > When you say data is not visible do you mean readers can not see the
> > > file or can not see the data? Is it guaranteed that readers open the
> > > file _after_ close returns on the writer?
> > >
> > > Raghu.
> > >
> > > Palleti, Pallavi wrote:
> > > > Hi Jason,
> > > >
> > > > Apologies for missing version information in my previous mail. I
> am
> > > > using hadoop-0.18.3. I am getting FSDataOutputStream object using
> > > > fs.create(new Path(some_file_name)), where fs is FileSystem
> object.
> > And,
> > > > I am closing the file using close().
> > > >
> > > > Thanks
> > > > Pallavi
> > > >
> > > > -----Original Message-----
> > > > From: Jason Venner [mailto:jason.hadoop@gmail.com]
> > > > Sent: Tuesday, August 11, 2009 6:24 PM
> > > > To: common-user@hadoop.apache.org
> > > > Subject: Re: File is closed but data is not visible
> > > >
> > > > Please provide information on what version of hadoop you are using
> > and
> > > > the
> > > > method of opening and closing the file.
> > > >
> > > >
> > > > On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
> > > > pallavi.palleti@corp.aol.com> wrote:
> > > >
> > > >> Hi all,
> > > >>
> > > >> We have an application where we pull logs from an external
> > server(far
> > > > apart
> > > >> from hadoop cluster) to hadoop cluster. Sometimes, we could see
> > huge
> > > > delay
> > > >> (of 1 hour or more) in actually seeing the data in HDFS though
> the
> > > > file has
> > > >> been closed and the variable is set to null from the external
> > > > application.I
> > > >> was in the impression that when I close the file, the data gets
> > > > reflected in
> > > >> hadoop cluster. Now, in this situation, it is even more
> complicated
> > to
> > > >> handle write failures as it is giving false impression to the
> > client
> > > > that
> > > >> data has been written to HDFS. Kindly clarify if my perception is
> > > > correct.
> > > >> If yes, Could some one tell me what is causing the delay in
> > actually
> > > > showing
> > > >> the data. During those cases, how can we tackle write failures
> (due
> > to
> > > > some
> > > >> temporary issues like data node not available, disk is full) as
> > there
> > > > is no
> > > >> way, we can figure out the failure at the client side?
> > > >>
> > > >> Thanks
> > > >> Pallavi
> > > >>
> > > >
> > > >
> > > >
> > >
> > >
> >
> >
> > --
> > Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> > http://www.amazon.com/dp/1430219424?tag=jewlerymall
> > www.prohadoopbook.com a community for Hadoop Professionals
> >
>
>
>
> --
> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> http://www.amazon.com/dp/1430219424?tag=jewlerymall
> www.prohadoopbook.com a community for Hadoop Professionals
>



-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--0016e6469bc2e51c070470f23feb--

From common-user-return-16696-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 14:05:05 2009
Return-Path: <common-user-return-16696-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 98059 invoked from network); 12 Aug 2009 14:05:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 14:05:05 -0000
Received: (qmail 29079 invoked by uid 500); 12 Aug 2009 14:05:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 28969 invoked by uid 500); 12 Aug 2009 14:05:09 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 28959 invoked by uid 99); 12 Aug 2009 14:05:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 14:05:09 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pallavi.palleti@corp.aol.com designates 64.12.143.147 as permitted sender)
Received: from [64.12.143.147] (HELO omr-m35.mx.aol.com) (64.12.143.147)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 14:04:57 +0000
Received: from AOLMTCMEH01.ad.office.aol.com (aolmtcmeh01.office.aol.com [10.178.121.20]) by omr-m35.mx.aol.com (v117.7) with ESMTP id MAILOMRM352-7f394a82cbf132a; Wed, 12 Aug 2009 10:04:33 -0400
Received: from EVSBNG01.ad.office.aol.com ([10.146.190.242]) by AOLMTCMEH01.ad.office.aol.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Wed, 12 Aug 2009 10:04:32 -0400
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01CA1B55.CFA34EBB"
Subject: RE: File is closed but data is not visible
Date: Wed, 12 Aug 2009 19:34:29 +0530
Message-ID: <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D16C@EVSBNG01.ad.office.aol.com>
In-Reply-To: <314098690908120701g4604db8cqfab097d0c5329282@mail.gmail.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: File is closed but data is not visible
Thread-Index: AcobVX9f1/uIaec3RnaN3CvXKMbxUwAADNuQ
References: <31565010.461250045532801.JavaMail.pallavi@e1a31053e.in.office.aol.com> <18070014.481250049615899.JavaMail.pallavi@e1a31053e.in.office.aol.com> <314098690908120532p799e81d7rbc416782e58e27df@mail.gmail.com> <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D157@EVSBNG01.ad.office.aol.com> <314098690908120605m783e77d4ue8c9ebbf584af64f@mail.gmail.com> <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D15C@EVSBNG01.ad.office.aol.com> <314098690908120701g4604db8cqfab097d0c5329282@mail.gmail.com>
From: "Palleti, Pallavi" <pallavi.palleti@corp.aol.com>
To: <common-user@hadoop.apache.org>
X-OriginalArrivalTime: 12 Aug 2009 14:04:32.0617 (UTC) FILETIME=[D1013D90:01CA1B55]
X-AOL-IP: 10.178.121.20
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01CA1B55.CFA34EBB
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

No. I am closing it before opening a new one

if (out !=3D null) // if any output stream opened previously ,  close it
          {
            logger.info("Closing writer of -" +=20
 paramWrapper.getOutFileStr());
            out.close();
            out =3D null;
          }

Thanks
Pallavi

-----Original Message-----
From: Jason Venner [mailto:jason.hadoop@gmail.com]=20
Sent: Wednesday, August 12, 2009 7:31 PM
To: common-user@hadoop.apache.org
Subject: Re: File is closed but data is not visible

You do not appear to close out, except when an exception occurs.
The finally block only closes the reader.

On Wed, Aug 12, 2009 at 6:24 AM, Palleti, Pallavi <
pallavi.palleti@corp.aol.com> wrote:

> Hi Jason,
>
> Kindly find the snippet of code which creates and close file.
>
> Variables passed to the method:FSDataOutputStream out,ParamWrapper
> paramWrapper
>
> Snippet:
>
>    String inputLine =3D null;
>    int status =3D 0;
>
>    BufferedReader reader =3D null;
>
>    try {
>      reader =3D new BufferedReader(new InputStreamReader(....); =
//reader
> initialization
>
>      while ((inputLine =3D reader.readLine()) !=3D null) {
>
>        Date date =3D getLoggedDate(inputLine); // process the line to
get
> input and if it is wrong
>        if (date =3D=3D null) // if input data is wrong, don't write
>        {
>          continue;
>        }
>        Calendar cal =3D Calendar.getInstance();
>        cal.setTime(date);
>        int hour =3D cal.get(Calendar.HOUR_OF_DAY); // get input hour
>        int minutes =3D cal.get(Calendar.MINUTE); // get input minute
>
>        int outputMinute =3D minutes / timePeriod + 1; // compute the
slot
>
>        if (paramWrapper.prevHour !=3D hour
>            || paramWrapper.prevMin !=3D outputMinute) // if it is a =
new
> slot
>        {
>
>          if (out !=3D null) // if any output stream opened previously =
,
> close it
>          {
>            logger.info("Closing writer of -" +
> paramWrapper.getOutFileStr());
>            out.close();
>            out =3D null;
>          }
>          String outFileStr =3D generateFileName(rootDir,
> hdfsOutFile,outputMinute, date); // generate file name ex:
> location/year/month/day/hour/_1.txt
>          Path outFile =3D new Path(outFileStr);
>
>          paramWrapper.setOutFileStr(outFileStr);
>          logger.info("Creating outFile:" + outFileStr);
>
>          out =3D fs.create(outFile); // create new file and get
>          // output stream
>          paramWrapper.setPrevHour(hour);
>          paramWrapper.setPrevMin(outputMinute);
>        }
>        StringBuilder outLineStr =3D new StringBuilder();
>        outLineStr.append(inputLine).append("\n");
>        out.write(outLineStr.toString().getBytes());
>      }
>    } catch (IOException ioe) {
>      logger.error("Main: IO Exception while writing to HDFS,
exiting...
> ", ioe);
>      // before exiting do the cleanup
>      close(reader);
>      System.exit(-1);
>
>    } catch (Exception e) {
>      logger.error("Unexpected error while writing to HDFS, exiting
> ...", e);
>      // before exiting do the cleanup
>      close(reader);
>
>      System.exit(-1);
>    } finally {
>      close(reader);
>     }
>
> Thanks
> Pallavi
>
>
> -----Original Message-----
> From: Jason Venner [mailto:jason.hadoop@gmail.com]
> Sent: Wednesday, August 12, 2009 6:35 PM
> To: common-user@hadoop.apache.org
> Subject: Re: File is closed but data is not visible
>
> Are you explicitly calling close on the FSDataOutputStream that you
> received
> from the FileSystem.create method?
> It sounds like the close is actually happening in the finalizer method
> on
> the object.
>
> Can you post the relevant code, or provide a cut down demonstrator?
>
> On Wed, Aug 12, 2009 at 5:57 AM, Palleti, Pallavi <
> pallavi.palleti@corp.aol.com> wrote:
>
> > Hi Jason,
> >
> > The file is neither visible via Namenode UI nor via program(checking
> > whether a file exists).
> >
> > There is no caching happening at the application level. The
> application
> > is pretty simple. We are taking apache logs and trying to put into
> > timely buckets based on the logged time of records. We are creating
4
> > files(one for every 15 minutes) for every hour. So, at the client
> side,
> > we are looking into the logs and see if the data belongs to the
> current
> > interval, then we are writing into the currently opened HDFS file.
If
> it
> > belongs to new interval, the old file is closed and new file is
> created.
> > I have been logging the time at which the file is being created and
at
> > which the file is being closed at my client side. And, I could see
> that
> > the file is getting closed at expected time period. But, when I look
> for
> > the same file in hadoop cluster, it is still not created and if I
wait
> > for another 1 to 2 hours, I could see the file.
> >
> > Thanks
> > Pallavi
> >
> >
> > -----Original Message-----
> > From: Jason Venner [mailto:jason.hadoop@gmail.com]
> > Sent: Wednesday, August 12, 2009 6:03 PM
> > To: common-user@hadoop.apache.org
> > Subject: Re: File is closed but data is not visible
> >
> > Is it possible that your application is caching some data and not
> > refreshing
> > it when you expect?
> > The HDFS file visibility semantics are well understood, and your
case
> > does
> > not fit with that understanding.
> > A factor that hints strongly at this is that your file is visible
via
> > the
> > Namenode UI, there is nothing special about that UI
> >
> > On Tue, Aug 11, 2009 at 9:00 PM, Pallavi Palleti <
> > pallavi.palleti@corp.aol.com> wrote:
> >
> > > Hi Raghu,
> > >
> > > The file doesn't appear in the cluster when I saw it from Namenode
> UI.
> > > Also, I have a monitor at cluster side which checks whether file
is
> > created
> > > and throws an exception when it is not created. And, it threw an
> > exception
> > > saying "File not found".
> > >
> > > Thanks
> > > Pallavi
> > > ----- Original Message -----
> > > From: "Raghu Angadi" <rangadi@yahoo-inc.com>
> > > To: common-user@hadoop.apache.org
> > > Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai,
> > Kolkata,
> > > Mumbai, New Delhi
> > > Subject: Re: File is closed but data is not visible
> > >
> > >
> > > Your assumption is correct. When you close the file, others can
read
> > the
> > > data. There is no delay expected before the data is visible. If
> there
> > is
> > > an error either write() or close() would throw an error.
> > >
> > > When you say data is not visible do you mean readers can not see
the
> > > file or can not see the data? Is it guaranteed that readers open
the
> > > file _after_ close returns on the writer?
> > >
> > > Raghu.
> > >
> > > Palleti, Pallavi wrote:
> > > > Hi Jason,
> > > >
> > > > Apologies for missing version information in my previous mail. I
> am
> > > > using hadoop-0.18.3. I am getting FSDataOutputStream object
using
> > > > fs.create(new Path(some_file_name)), where fs is FileSystem
> object.
> > And,
> > > > I am closing the file using close().
> > > >
> > > > Thanks
> > > > Pallavi
> > > >
> > > > -----Original Message-----
> > > > From: Jason Venner [mailto:jason.hadoop@gmail.com]
> > > > Sent: Tuesday, August 11, 2009 6:24 PM
> > > > To: common-user@hadoop.apache.org
> > > > Subject: Re: File is closed but data is not visible
> > > >
> > > > Please provide information on what version of hadoop you are
using
> > and
> > > > the
> > > > method of opening and closing the file.
> > > >
> > > >
> > > > On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
> > > > pallavi.palleti@corp.aol.com> wrote:
> > > >
> > > >> Hi all,
> > > >>
> > > >> We have an application where we pull logs from an external
> > server(far
> > > > apart
> > > >> from hadoop cluster) to hadoop cluster. Sometimes, we could see
> > huge
> > > > delay
> > > >> (of 1 hour or more) in actually seeing the data in HDFS though
> the
> > > > file has
> > > >> been closed and the variable is set to null from the external
> > > > application.I
> > > >> was in the impression that when I close the file, the data gets
> > > > reflected in
> > > >> hadoop cluster. Now, in this situation, it is even more
> complicated
> > to
> > > >> handle write failures as it is giving false impression to the
> > client
> > > > that
> > > >> data has been written to HDFS. Kindly clarify if my perception
is
> > > > correct.
> > > >> If yes, Could some one tell me what is causing the delay in
> > actually
> > > > showing
> > > >> the data. During those cases, how can we tackle write failures
> (due
> > to
> > > > some
> > > >> temporary issues like data node not available, disk is full) as
> > there
> > > > is no
> > > >> way, we can figure out the failure at the client side?
> > > >>
> > > >> Thanks
> > > >> Pallavi
> > > >>
> > > >
> > > >
> > > >
> > >
> > >
> >
> >
> > --
> > Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> > http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
> > www.prohadoopbook.com a community for Hadoop Professionals
> >
>
>
>
> --
> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
> www.prohadoopbook.com a community for Hadoop Professionals
>



--=20
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

------_=_NextPart_001_01CA1B55.CFA34EBB--

From common-user-return-16697-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 14:37:16 2009
Return-Path: <common-user-return-16697-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 18203 invoked from network); 12 Aug 2009 14:37:16 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 14:37:16 -0000
Received: (qmail 4548 invoked by uid 500); 12 Aug 2009 14:37:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 4467 invoked by uid 500); 12 Aug 2009 14:37:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 4457 invoked by uid 99); 12 Aug 2009 14:37:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 14:37:20 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of edlinuxguru@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 14:37:11 +0000
Received: by fxm24 with SMTP id 24so45635fxm.36
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 07:36:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=0kEtkwyG3BwMRQzT0Odn6T3vDYB+QzYk9/YB2lC/ZPA=;
        b=bYsxw08pYG6KQcIHcLCeDrtVotKF9ecDuLfucX7YI+Qp7ruxsB6Hg+he+MCbsd5br3
         dhKs6HUaIAB6cqMrBSBclRUtNOWzBQXc5gGIAw8rw9kUCICgfsWztPluJ/rfMPwx6LGy
         0e8z2e0141WLOKt9IhSfok504su4g5htzihZA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=Rhzt/pHAA7UucdC+cFez1PzC6jm1/RFhHaOZzJlf59JskRJ0+1pnsiHi53fTlkYm/J
         D66hdC2gPQiT8id/tT5C2BDLYwCi/wNXIdK5INtqeL2CkO54uOTrCMVyfkHvrnSaN3zC
         xcVC65KeLeUrEsnDVbO/FKDXNfQR0m7zLwtLM=
MIME-Version: 1.0
Received: by 10.239.155.10 with SMTP id g10mr12256hbc.20.1250087810838; Wed, 
	12 Aug 2009 07:36:50 -0700 (PDT)
In-Reply-To: <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu>
Date: Wed, 12 Aug 2009 10:36:50 -0400
Message-ID: <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com>
Subject: Re: What OS?
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Wed, Aug 12, 2009 at 8:03 AM, Brian Bockelman<bbockelm@cse.unl.edu> wrot=
e:
> Hey Tim,
>
> One consideration is "how long is this OS version going to be receiving
> updates?" or "Do I do the operations team any favor by having them upgrad=
e
> every 6 months?"
>
> Personally, I'd avoid Fedora for a production cluster because the lack of
> long-lived releases means that you'll be spending extra effort on upgradi=
ng
> the OS.
>
> Brian
>
> On Aug 12, 2009, at 6:05 AM, tim robertson wrote:
>
>> Hi all,
>>
>> Is fedora a decent choice of OS for a new hadoop cluster? =A0All our
>> other stuff is fedora, but is there was a strong case to move to
>> something else?
>>
>> Cheers
>>
>> Tim
>
>

CentOS and Scientific Linux are Red Hat Enterprise Linux clones. I
advice people to go with them. Most of this is based on the fact that
CentOS is very compatible with RHEL. This is important because
packaged, but not open source software, is typically targeted at RHEL.
You can read about someone trying to install WebSphere on say Fedora
Core and see the hard aches. As mentioned above support life is an
issue. RHEL/CENT 5 will be supported until 2014.

http://www.redhat.com/security/updates/errata/

The Fedora line typically has support life of a few months. So your
package support dries up fast and then you have to get good with
RPM-build fast :)

From common-user-return-16698-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 14:46:40 2009
Return-Path: <common-user-return-16698-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 22842 invoked from network); 12 Aug 2009 14:46:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 14:46:35 -0000
Received: (qmail 22833 invoked by uid 500); 12 Aug 2009 14:46:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21906 invoked by uid 500); 12 Aug 2009 14:46:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21851 invoked by uid 99); 12 Aug 2009 14:46:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 14:46:19 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of timrobertson100@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 14:46:10 +0000
Received: by ewy26 with SMTP id 26so62556ewy.29
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 07:45:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=VEXh3EGQ6plPTGimqrICWcYaLkhB5EbT7U18FAU4G88=;
        b=RnaQOplZ2FRrQoQq3lfWD5yS6sYVDbSUyCb0wt84h5OdyruwX4cxgcttnNsFDLM3xn
         BmVqpFQlak+P0q9PDbiOE9BAlF0Zf9wYQuBCkGy/FmxSm9FKR1MbHEyWQ7zpcp1Dl7zf
         W+f4s9GRxySoUXy6AOBsy+lXWPy5JsY4wY9aw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=jc/sp2jaXJw/Hv9lCVFolnrYaMkg4q3KkPykImb6HPjHerDkSWjLLGVyqRMBp95zDQ
         CtFBoPcIFnf/fmhRrxgAYjk0zmC5GJ6Ah8YgFzx1XNY5fh36198Ns5YlsmzjAV+NLMuR
         R2I3h1gPmmtyhHL3DYIbvs/mcINUhB7pieGwc=
MIME-Version: 1.0
Received: by 10.216.8.65 with SMTP id 43mr30784weq.168.1250088350199; Wed, 12 
	Aug 2009 07:45:50 -0700 (PDT)
In-Reply-To: <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu>
	 <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com>
Date: Wed, 12 Aug 2009 16:45:50 +0200
Message-ID: <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>
Subject: Re: What OS?
From: tim robertson <timrobertson100@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks guys.  I'll chat with sys admin and see what he thinks.
We knew fedora would require a 6 month rebuild


On Wed, Aug 12, 2009 at 4:36 PM, Edward Capriolo<edlinuxguru@gmail.com> wro=
te:
> On Wed, Aug 12, 2009 at 8:03 AM, Brian Bockelman<bbockelm@cse.unl.edu> wr=
ote:
>> Hey Tim,
>>
>> One consideration is "how long is this OS version going to be receiving
>> updates?" or "Do I do the operations team any favor by having them upgra=
de
>> every 6 months?"
>>
>> Personally, I'd avoid Fedora for a production cluster because the lack o=
f
>> long-lived releases means that you'll be spending extra effort on upgrad=
ing
>> the OS.
>>
>> Brian
>>
>> On Aug 12, 2009, at 6:05 AM, tim robertson wrote:
>>
>>> Hi all,
>>>
>>> Is fedora a decent choice of OS for a new hadoop cluster? =A0All our
>>> other stuff is fedora, but is there was a strong case to move to
>>> something else?
>>>
>>> Cheers
>>>
>>> Tim
>>
>>
>
> CentOS and Scientific Linux are Red Hat Enterprise Linux clones. I
> advice people to go with them. Most of this is based on the fact that
> CentOS is very compatible with RHEL. This is important because
> packaged, but not open source software, is typically targeted at RHEL.
> You can read about someone trying to install WebSphere on say Fedora
> Core and see the hard aches. As mentioned above support life is an
> issue. RHEL/CENT 5 will be supported until 2014.
>
> http://www.redhat.com/security/updates/errata/
>
> The Fedora line typically has support life of a few months. So your
> package support dries up fast and then you have to get good with
> RPM-build fast :)
>

From common-user-return-16699-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 15:22:38 2009
Return-Path: <common-user-return-16699-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 37036 invoked from network); 12 Aug 2009 15:22:38 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 15:22:38 -0000
Received: (qmail 8969 invoked by uid 500); 12 Aug 2009 15:22:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 8892 invoked by uid 500); 12 Aug 2009 15:22:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 8882 invoked by uid 99); 12 Aug 2009 15:22:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 15:22:42 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 15:22:32 +0000
Received: by yxe15 with SMTP id 15so122481yxe.5
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 08:22:11 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.56.17 with SMTP id e17mr95362aga.42.1250090531147; Wed, 12 
	Aug 2009 08:22:11 -0700 (PDT)
In-Reply-To: <77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com>
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com> 
	<4A7BECD9.20303@apache.org> <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com> 
	<4A814BCD.2060500@apache.org> <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com> 
	<77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Wed, 12 Aug 2009 08:21:51 -0700
Message-ID: <45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com>
Subject: Re: HADOOP-4539 question
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016362838280bd0950470f3622c
X-Virus-Checked: Checked by ClamAV on apache.org

--0016362838280bd0950470f3622c
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Wed, Aug 12, 2009 at 3:42 AM, Stas Oskin <stas.oskin@gmail.com> wrote:

> Hi.
>
>
> > You can also use a utility like Linux-HA (aka heartbeat) to handle IP
> > address failover. It will even send gratuitous ARPs to make sure to get
> the
> > new mac address registered after a failover. Check out this blog for info
> > about a setup like this:
> >
> > http://www.cloudera.com/blog/2009/07/22/hadoop-ha-configuration/
> >
> > Hope that helps
> >
>
> Thanks, exactly what I looked for :).
>
>  I presume that with the coming BB node, there won't be need for DRBD, am I
> correct?
>

I haven't followed that development closely, but I believe that's the case.
The BackupNode will stream the FSEditLog writes as they occur while
replaying them into its own FSNamesystem. Then during a failover a real
NameNode starts on that FSNamesystem "ready to go". As for how the
BackupNode keeps track of block locations, I'm not sure - is there a
replication stream between BlockManagers too? Or is the cluster in a broken
state until all of the DNs have processed new block reports?

-Todd

--0016362838280bd0950470f3622c--

From common-user-return-16700-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 15:24:15 2009
Return-Path: <common-user-return-16700-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 37531 invoked from network); 12 Aug 2009 15:24:15 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 15:24:15 -0000
Received: (qmail 19440 invoked by uid 500); 12 Aug 2009 15:24:19 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 19360 invoked by uid 500); 12 Aug 2009 15:24:19 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 19350 invoked by uid 99); 12 Aug 2009 15:24:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 15:24:19 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 15:24:11 +0000
Received: by yxe15 with SMTP id 15so124183yxe.5
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 08:23:50 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.35.9 with SMTP id i9mr87497agi.87.1250090630214; Wed, 12 
	Aug 2009 08:23:50 -0700 (PDT)
In-Reply-To: <4A81B3C3.3060903@casalemedia.com>
References: <4A81B3C3.3060903@casalemedia.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Wed, 12 Aug 2009 08:23:30 -0700
Message-ID: <45f85f70908120823h1dc26130ncd6ce1b700035f1a@mail.gmail.com>
Subject: Re: NN + secondary got full, even though data nodes had plenty of 
	space
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64f51aef374fa0470f367ab
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64f51aef374fa0470f367ab
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Mayuran,

Do you do all of your uploads of data into your Hadoop cluster from node001
and node002?

If so, keep in mind that one of your replicas will always be written on
localhost in the case that it is part of the cluster.

You should consider running the rebalancer to even up your space usage.

-Todd

On Tue, Aug 11, 2009 at 11:09 AM, Mayuran Yogarajah <
mayuran.yogarajah@casalemedia.com> wrote:

> I have a 6 node cluster running Hadoop 0.18.3.  I'm trying to figure out
> how the data was spread out like this:
>
> node001         94.15%
> node002         94.16%
> node003         48.22%
> node004         47.85%
> node005         48.12%
> node006         43.18%
> Node 001 (NN) and node 002( secondary NN) both got full, while the other
> data nodes had more space left.  I had assumed that Hadoop would distribute
> more blocks to nodes 3-6 since they had much more space, but it ended up
> filling up nodes1 and 2.  Is this expected?
>
> thanks,
> M
>
>

--0016e64f51aef374fa0470f367ab--

From common-user-return-16701-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 15:31:09 2009
Return-Path: <common-user-return-16701-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 40247 invoked from network); 12 Aug 2009 15:31:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 15:31:09 -0000
Received: (qmail 27360 invoked by uid 500); 12 Aug 2009 15:31:12 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 27288 invoked by uid 500); 12 Aug 2009 15:31:12 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 27278 invoked by uid 99); 12 Aug 2009 15:31:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 15:31:12 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cubicdesign@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 15:31:02 +0000
Received: by ewy26 with SMTP id 26so97713ewy.29
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 08:30:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:date:from
         :user-agent:mime-version:to:subject:references:in-reply-to
         :content-type:content-transfer-encoding;
        bh=gu67y9Wc6sEtPBR0rbqVYIz2SIwn9/Je0EVpYQ+SnjA=;
        b=xy80MXEitUFBP62HawU7C/9dFVw1D0eI8H1Zyq+g7+znxOBZlJmf74Bpv8FgkR8Xsq
         hxN3VUF4Kyl9WLcPrGkLMFBLBF9UtGEKuyZudh9tj43/Fl9WFl0bIwPVRqx2a88Tss/+
         ZIgtNa15PULQ5EBOdAQzAvaQ09HBWlkHXplVE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        b=NmNU76cB6Y2RKk+7lTvLO033iXQbMMDPRXhZ+iuZOzYsXVNVx5cJOyIEX0tL3vA8Px
         Wruywc2MeWHzSk7Fl1f7iK512/DSrvdgmQu30fWLv+UTJk6xbnPDkdIx21XVlWaKuQ9r
         H7c+ldJJ1JWz3kG+eBxzsyuWd2eGTAKFrQnjY=
Received: by 10.210.116.17 with SMTP id o17mr308396ebc.33.1250091041756;
        Wed, 12 Aug 2009 08:30:41 -0700 (PDT)
Received: from ?192.168.220.104? (host-091-097-246-041.ewe-ip-backbone.de [91.97.246.41])
        by mx.google.com with ESMTPS id 10sm2817275eyz.51.2009.08.12.08.30.41
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Wed, 12 Aug 2009 08:30:41 -0700 (PDT)
Message-ID: <4A82E01D.4000100@Gmail.com>
Date: Wed, 12 Aug 2009 17:30:37 +0200
From: CubicDesign <cubicdesign@gmail.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Need info about "mapred.input.format.skew" - solved
References: <8131791a0907300127n7874c2b1l290b66d08a8a838@mail.gmail.com>	 <4A7191C1.2040503@apache.org> <4A719468.4070602@gmail.com>
In-Reply-To: <4A719468.4070602@gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Solved.

It was a custom function. This is what happens when the user (me) uses a system build in 
Java while he has absolutely no knowledge of Java :)

From common-user-return-16702-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 16:18:26 2009
Return-Path: <common-user-return-16702-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 54808 invoked from network); 12 Aug 2009 16:18:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 16:18:26 -0000
Received: (qmail 97338 invoked by uid 500); 12 Aug 2009 16:06:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 97310 invoked by uid 500); 12 Aug 2009 16:06:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 97300 invoked by uid 99); 12 Aug 2009 16:06:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 16:06:25 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of roman.wsmo@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 16:06:17 +0000
Received: by bwz19 with SMTP id 19so94002bwz.37
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 09:05:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=xIovFKVpqcdhyo9CARhgIY1Hka2m/Af8ftLv3SWTr2Y=;
        b=JzPdBKBCzgU9cXzx1b6Kg5WZiRORgiithaab70LZ1WxhxeAxRStVcKlogpPsWkhyLB
         u6YqjBQ46UcGIM6xxyTWu+Z78zPZJ4on9PegSvuM9O6tGFx+bKlwsibCJrJ80pQAUBl7
         syehCT+pZipnqzmfAZsNM5IUJkaiN0s4dSyrg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=rQEjoNqitXE2hPg/gpPV1SVCesh16n5cgFby06SnPtzOFA5ksFHbQM0t3kfhGLwNA6
         9/CK6WIcFLW9sm0HnheBm4mSS07OJ5l0jPzvauL660bD0MXyV9QgijE5R97i8vw8M96W
         Zp06nGPm6hsaBfhN8nlBE99KILAPAZMFMvt9E=
MIME-Version: 1.0
Received: by 10.223.144.207 with SMTP id a15mr93438fav.63.1250093156281; Wed, 
	12 Aug 2009 09:05:56 -0700 (PDT)
Date: Wed, 12 Aug 2009 17:05:56 +0100
Message-ID: <597eea000908120905h7702679fl43684231ee500d6d@mail.gmail.com>
Subject: How to easily build and deploy Hadoop
From: roman kolcun <roman.wsmo@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0023545bd84c842d520470f3fe37
X-Virus-Checked: Checked by ClamAV on apache.org

--0023545bd84c842d520470f3fe37
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello everyone,
I would like to ask what is the easiest way to build and deploy Hadoop. I am
trying to add some new features to the Hadoop but every time I make any
small change (while debugging) I have to execute:

ant clean compile jar

than upload the build/hadoop-0.20.1-dev-core.jar file to the cluster and
distribute it to every node. This already takes approx 2 minutes.
In addition the Hadoop does not pick up the new core file and I have to
reboot the whole cluster. And rebooting the whole cluster takes several
minutes.
So it is very frustrating when after 5+ minutes I got some stupid
NullPointerException and I need to fix it and wait another 5+ minutes to see
another Exception.
Is there any other way how to speed up the process?

Thank you for every comment.

Roman

PS: I am using Hadoop 0.20.0

--0023545bd84c842d520470f3fe37--

From common-user-return-16703-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 16:34:01 2009
Return-Path: <common-user-return-16703-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 67007 invoked from network); 12 Aug 2009 16:34:01 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 16:34:01 -0000
Received: (qmail 40924 invoked by uid 500); 12 Aug 2009 16:34:05 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 40861 invoked by uid 500); 12 Aug 2009 16:34:05 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 40851 invoked by uid 99); 12 Aug 2009 16:34:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 16:34:05 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of edlinuxguru@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 16:33:57 +0000
Received: by bwz19 with SMTP id 19so112197bwz.37
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 09:33:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=GKwMB5qUwE5Dz83f2ZLjK0WYGGVQEgcSlL6huLZT1g0=;
        b=aDNoSXH1oirSQ2fcAzb0KAFh8ndTGtfn6G58dDgXmbdIJ2nTyFjUSH9DoKc8aGpTIm
         Dn+Eah/YTT+v3DCSBjw9uegm68rTgcR0iWxWjjvqjGLd0+nTWeQHaHOh5RNaR6MD+EjB
         fuNjnh1lWQFHXvKUkAYZu0/FcyLbwKqeTLuBs=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=ZcJJE/f8eeNvH0POZ0ER/N3pYMciBDs+vZbhKpn9tOfvMnZitjz8d2STcMMW/VAhv1
         moScE1VKEMbMNpbqF+kLKf+nfRQCrSQF6pTb8/TIdiCcSt4t6sMXvgAa5QU8def4mQjT
         okgS2ypT515DQRdUqf5NQCRKVwZ/Dw6/ctxkk=
MIME-Version: 1.0
Received: by 10.239.139.156 with SMTP id t28mr21172hbt.33.1250094815829; Wed, 
	12 Aug 2009 09:33:35 -0700 (PDT)
In-Reply-To: <597eea000908120905h7702679fl43684231ee500d6d@mail.gmail.com>
References: <597eea000908120905h7702679fl43684231ee500d6d@mail.gmail.com>
Date: Wed, 12 Aug 2009 12:33:35 -0400
Message-ID: <cbbf4b570908120933s18ada45had7056914b8c10a8@mail.gmail.com>
Subject: Re: How to easily build and deploy Hadoop
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

On Wed, Aug 12, 2009 at 12:05 PM, roman kolcun<roman.wsmo@gmail.com> wrote:
> Hello everyone,
> I would like to ask what is the easiest way to build and deploy Hadoop. I am
> trying to add some new features to the Hadoop but every time I make any
> small change (while debugging) I have to execute:
>
> ant clean compile jar
>
> than upload the build/hadoop-0.20.1-dev-core.jar file to the cluster and
> distribute it to every node. This already takes approx 2 minutes.
> In addition the Hadoop does not pick up the new core file and I have to
> reboot the whole cluster. And rebooting the whole cluster takes several
> minutes.
> So it is very frustrating when after 5+ minutes I got some stupid
> NullPointerException and I need to fix it and wait another 5+ minutes to see
> another Exception.
> Is there any other way how to speed up the process?
>
> Thank you for every comment.
>
> Roman
>
> PS: I am using Hadoop 0.20.0
>

Roman,

You should really take advantage of the TestCase infrastructure. While
developing TestCases can be time consuming at first, once you get into
a good flow you realize you can not live without it.

For example, I contributed the web Inferface to Hadoop Hive. Initially
I tried to get by without a strong test case. I would have to kick up
a web interface and fill out several web forms to test my process, but
I came to realize doing the TestCase work up front saves time in the
long run.

Hive/Hadoop is slightly different but the same principals apply. I can test:

ant -Dhadoop.version='0.18.3' -Dtestcase=TestHWISessionManager test

http://svn.apache.org/viewvc/hadoop/hive/trunk/hwi/src/test/org/apache/hadoop/hive/hwi/TestHWISessionManager.java?revision=758836

With this test case I can make sure the underlying features work before deploy.

From common-user-return-16704-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 16:43:43 2009
Return-Path: <common-user-return-16704-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70172 invoked from network); 12 Aug 2009 16:43:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 16:43:43 -0000
Received: (qmail 58254 invoked by uid 500); 12 Aug 2009 16:43:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 58171 invoked by uid 500); 12 Aug 2009 16:43:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 58161 invoked by uid 99); 12 Aug 2009 16:43:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 16:43:47 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.20] (HELO mrout1-b.corp.re1.yahoo.com) (69.147.107.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 16:43:35 +0000
Received: from [1.0.0.0] (proxy7.corp.yahoo.com [216.145.48.98])
	by mrout1-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7CGdxJu085776
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 09:40:00 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=s1qSncoCvijBkfBuyGOKqks31V7E3/ZqEzt98sp3XjAqIWwqaw5JbtQ9eMSsc3bc
Message-ID: <4A82F05B.6030009@yahoo-inc.com>
Date: Wed, 12 Aug 2009 09:39:55 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090608)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: File is closed but data is not visible
References: <31565010.461250045532801.JavaMail.pallavi@e1a31053e.in.office.aol.com> <18070014.481250049615899.JavaMail.pallavi@e1a31053e.in.office.aol.com> <314098690908120532p799e81d7rbc416782e58e27df@mail.gmail.com> <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D157@EVSBNG01.ad.office.aol.com> <314098690908120605m783e77d4ue8c9ebbf584af64f@mail.gmail.com> <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D15C@EVSBNG01.ad.office.aol.com> <314098690908120701g4604db8cqfab097d0c5329282@mail.gmail.com> <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D16C@EVSBNG01.ad.office.aol.com>
In-Reply-To: <2AAFC2B9E4C5DC4F859F154FB664CF5F0629D16C@EVSBNG01.ad.office.aol.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


What happens when the while loop ends? Is 'out' closed then?

Palleti, Pallavi wrote:
> No. I am closing it before opening a new one
> 
> if (out != null) // if any output stream opened previously ,  close it
>           {
>             logger.info("Closing writer of -" + 
>  paramWrapper.getOutFileStr());
>             out.close();
>             out = null;
>           }
> 
> Thanks
> Pallavi
> 
> -----Original Message-----
> From: Jason Venner [mailto:jason.hadoop@gmail.com] 
> Sent: Wednesday, August 12, 2009 7:31 PM
> To: common-user@hadoop.apache.org
> Subject: Re: File is closed but data is not visible
> 
> You do not appear to close out, except when an exception occurs.
> The finally block only closes the reader.
> 
> On Wed, Aug 12, 2009 at 6:24 AM, Palleti, Pallavi <
> pallavi.palleti@corp.aol.com> wrote:
> 
>> Hi Jason,
>>
>> Kindly find the snippet of code which creates and close file.
>>
>> Variables passed to the method:FSDataOutputStream out,ParamWrapper
>> paramWrapper
>>
>> Snippet:
>>
>>    String inputLine = null;
>>    int status = 0;
>>
>>    BufferedReader reader = null;
>>
>>    try {
>>      reader = new BufferedReader(new InputStreamReader(....); //reader
>> initialization
>>
>>      while ((inputLine = reader.readLine()) != null) {
>>
>>        Date date = getLoggedDate(inputLine); // process the line to
> get
>> input and if it is wrong
>>        if (date == null) // if input data is wrong, don't write
>>        {
>>          continue;
>>        }
>>        Calendar cal = Calendar.getInstance();
>>        cal.setTime(date);
>>        int hour = cal.get(Calendar.HOUR_OF_DAY); // get input hour
>>        int minutes = cal.get(Calendar.MINUTE); // get input minute
>>
>>        int outputMinute = minutes / timePeriod + 1; // compute the
> slot
>>        if (paramWrapper.prevHour != hour
>>            || paramWrapper.prevMin != outputMinute) // if it is a new
>> slot
>>        {
>>
>>          if (out != null) // if any output stream opened previously ,
>> close it
>>          {
>>            logger.info("Closing writer of -" +
>> paramWrapper.getOutFileStr());
>>            out.close();
>>            out = null;
>>          }
>>          String outFileStr = generateFileName(rootDir,
>> hdfsOutFile,outputMinute, date); // generate file name ex:
>> location/year/month/day/hour/_1.txt
>>          Path outFile = new Path(outFileStr);
>>
>>          paramWrapper.setOutFileStr(outFileStr);
>>          logger.info("Creating outFile:" + outFileStr);
>>
>>          out = fs.create(outFile); // create new file and get
>>          // output stream
>>          paramWrapper.setPrevHour(hour);
>>          paramWrapper.setPrevMin(outputMinute);
>>        }
>>        StringBuilder outLineStr = new StringBuilder();
>>        outLineStr.append(inputLine).append("\n");
>>        out.write(outLineStr.toString().getBytes());
>>      }
>>    } catch (IOException ioe) {
>>      logger.error("Main: IO Exception while writing to HDFS,
> exiting...
>> ", ioe);
>>      // before exiting do the cleanup
>>      close(reader);
>>      System.exit(-1);
>>
>>    } catch (Exception e) {
>>      logger.error("Unexpected error while writing to HDFS, exiting
>> ...", e);
>>      // before exiting do the cleanup
>>      close(reader);
>>
>>      System.exit(-1);
>>    } finally {
>>      close(reader);
>>     }
>>
>> Thanks
>> Pallavi
>>
>>
>> -----Original Message-----
>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>> Sent: Wednesday, August 12, 2009 6:35 PM
>> To: common-user@hadoop.apache.org
>> Subject: Re: File is closed but data is not visible
>>
>> Are you explicitly calling close on the FSDataOutputStream that you
>> received
>> from the FileSystem.create method?
>> It sounds like the close is actually happening in the finalizer method
>> on
>> the object.
>>
>> Can you post the relevant code, or provide a cut down demonstrator?
>>
>> On Wed, Aug 12, 2009 at 5:57 AM, Palleti, Pallavi <
>> pallavi.palleti@corp.aol.com> wrote:
>>
>>> Hi Jason,
>>>
>>> The file is neither visible via Namenode UI nor via program(checking
>>> whether a file exists).
>>>
>>> There is no caching happening at the application level. The
>> application
>>> is pretty simple. We are taking apache logs and trying to put into
>>> timely buckets based on the logged time of records. We are creating
> 4
>>> files(one for every 15 minutes) for every hour. So, at the client
>> side,
>>> we are looking into the logs and see if the data belongs to the
>> current
>>> interval, then we are writing into the currently opened HDFS file.
> If
>> it
>>> belongs to new interval, the old file is closed and new file is
>> created.
>>> I have been logging the time at which the file is being created and
> at
>>> which the file is being closed at my client side. And, I could see
>> that
>>> the file is getting closed at expected time period. But, when I look
>> for
>>> the same file in hadoop cluster, it is still not created and if I
> wait
>>> for another 1 to 2 hours, I could see the file.
>>>
>>> Thanks
>>> Pallavi
>>>
>>>
>>> -----Original Message-----
>>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>>> Sent: Wednesday, August 12, 2009 6:03 PM
>>> To: common-user@hadoop.apache.org
>>> Subject: Re: File is closed but data is not visible
>>>
>>> Is it possible that your application is caching some data and not
>>> refreshing
>>> it when you expect?
>>> The HDFS file visibility semantics are well understood, and your
> case
>>> does
>>> not fit with that understanding.
>>> A factor that hints strongly at this is that your file is visible
> via
>>> the
>>> Namenode UI, there is nothing special about that UI
>>>
>>> On Tue, Aug 11, 2009 at 9:00 PM, Pallavi Palleti <
>>> pallavi.palleti@corp.aol.com> wrote:
>>>
>>>> Hi Raghu,
>>>>
>>>> The file doesn't appear in the cluster when I saw it from Namenode
>> UI.
>>>> Also, I have a monitor at cluster side which checks whether file
> is
>>> created
>>>> and throws an exception when it is not created. And, it threw an
>>> exception
>>>> saying "File not found".
>>>>
>>>> Thanks
>>>> Pallavi
>>>> ----- Original Message -----
>>>> From: "Raghu Angadi" <rangadi@yahoo-inc.com>
>>>> To: common-user@hadoop.apache.org
>>>> Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai,
>>> Kolkata,
>>>> Mumbai, New Delhi
>>>> Subject: Re: File is closed but data is not visible
>>>>
>>>>
>>>> Your assumption is correct. When you close the file, others can
> read
>>> the
>>>> data. There is no delay expected before the data is visible. If
>> there
>>> is
>>>> an error either write() or close() would throw an error.
>>>>
>>>> When you say data is not visible do you mean readers can not see
> the
>>>> file or can not see the data? Is it guaranteed that readers open
> the
>>>> file _after_ close returns on the writer?
>>>>
>>>> Raghu.
>>>>
>>>> Palleti, Pallavi wrote:
>>>>> Hi Jason,
>>>>>
>>>>> Apologies for missing version information in my previous mail. I
>> am
>>>>> using hadoop-0.18.3. I am getting FSDataOutputStream object
> using
>>>>> fs.create(new Path(some_file_name)), where fs is FileSystem
>> object.
>>> And,
>>>>> I am closing the file using close().
>>>>>
>>>>> Thanks
>>>>> Pallavi
>>>>>
>>>>> -----Original Message-----
>>>>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>>>>> Sent: Tuesday, August 11, 2009 6:24 PM
>>>>> To: common-user@hadoop.apache.org
>>>>> Subject: Re: File is closed but data is not visible
>>>>>
>>>>> Please provide information on what version of hadoop you are
> using
>>> and
>>>>> the
>>>>> method of opening and closing the file.
>>>>>
>>>>>
>>>>> On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
>>>>> pallavi.palleti@corp.aol.com> wrote:
>>>>>
>>>>>> Hi all,
>>>>>>
>>>>>> We have an application where we pull logs from an external
>>> server(far
>>>>> apart
>>>>>> from hadoop cluster) to hadoop cluster. Sometimes, we could see
>>> huge
>>>>> delay
>>>>>> (of 1 hour or more) in actually seeing the data in HDFS though
>> the
>>>>> file has
>>>>>> been closed and the variable is set to null from the external
>>>>> application.I
>>>>>> was in the impression that when I close the file, the data gets
>>>>> reflected in
>>>>>> hadoop cluster. Now, in this situation, it is even more
>> complicated
>>> to
>>>>>> handle write failures as it is giving false impression to the
>>> client
>>>>> that
>>>>>> data has been written to HDFS. Kindly clarify if my perception
> is
>>>>> correct.
>>>>>> If yes, Could some one tell me what is causing the delay in
>>> actually
>>>>> showing
>>>>>> the data. During those cases, how can we tackle write failures
>> (due
>>> to
>>>>> some
>>>>>> temporary issues like data node not available, disk is full) as
>>> there
>>>>> is no
>>>>>> way, we can figure out the failure at the client side?
>>>>>>
>>>>>> Thanks
>>>>>> Pallavi
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>> --
>>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>>> http://www.amazon.com/dp/1430219424?tag=jewlerymall
>>> www.prohadoopbook.com a community for Hadoop Professionals
>>>
>>
>>
>> --
>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>> http://www.amazon.com/dp/1430219424?tag=jewlerymall
>> www.prohadoopbook.com a community for Hadoop Professionals
>>
> 
> 
> 


From common-user-return-16705-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 17:01:10 2009
Return-Path: <common-user-return-16705-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 74615 invoked from network); 12 Aug 2009 17:01:10 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 17:01:10 -0000
Received: (qmail 82130 invoked by uid 500); 12 Aug 2009 17:01:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82037 invoked by uid 500); 12 Aug 2009 17:01:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82027 invoked by uid 99); 12 Aug 2009 17:01:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 17:01:14 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [192.139.80.206] (HELO mx1.casalemedia.com) (192.139.80.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 17:01:05 +0000
Received: from exchange.casalemedia.com (unknown [10.3.10.15])
	by mx1.casalemedia.com (Postfix) with ESMTP id 4D3D5588011
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 13:00:44 -0400 (EDT)
Received: from mayuran.casalemedia.com (10.3.10.40) by
 exchange.casalemedia.com (10.3.10.15) with Microsoft SMTP Server id
 8.1.240.5; Wed, 12 Aug 2009 13:00:44 -0400
Message-ID: <4A82F535.9070905@casalemedia.com>
Date: Wed, 12 Aug 2009 13:00:37 -0400
From: Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: Re: NN + secondary got full, even though data nodes had plenty of
 	space
References: <4A81B3C3.3060903@casalemedia.com> <35a22e220908120138s7ee2da9r1b4080462de6c7db@mail.gmail.com>
In-Reply-To: <35a22e220908120138s7ee2da9r1b4080462de6c7db@mail.gmail.com>
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Amandeep Khurana wrote:
> Is your NN doubling up as a DN? If its not, I wonder how the NN is full...
>   
Yes both NN and secondary are doubling as DN, sorry I should have mentioned
this earlier.

M
> On 8/11/09, Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com> wrote:
>   
>> I have a 6 node cluster running Hadoop 0.18.3.  I'm trying to figure out
>> how the data was spread out like this:
>>
>> node001         94.15%
>> node002         94.16%
>> node003         48.22%
>> node004         47.85%
>> node005         48.12%
>> node006         43.18%
>>
>> Node 001 (NN) and node 002( secondary NN) both got full, while the other
>> data nodes had more space left.  I had assumed that Hadoop would distribute
>> more blocks to nodes 3-6 since they had much more space, but it ended up
>> filling up nodes1 and 2.  Is this expected?
>>
>> thanks,
>> M
>>
>>
>>     
>
>
> --
>
>
> Amandeep Khurana
> Computer Science Graduate Student
> University of California, Santa Cruz
>   


From common-user-return-16706-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 17:02:16 2009
Return-Path: <common-user-return-16706-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 74908 invoked from network); 12 Aug 2009 17:02:16 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 17:02:16 -0000
Received: (qmail 84955 invoked by uid 500); 12 Aug 2009 17:02:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 84886 invoked by uid 500); 12 Aug 2009 17:02:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 84876 invoked by uid 99); 12 Aug 2009 17:02:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 17:02:20 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [192.139.80.206] (HELO mx1.casalemedia.com) (192.139.80.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 17:02:11 +0000
Received: from exchange.casalemedia.com (unknown [10.3.10.15])
	by mx1.casalemedia.com (Postfix) with ESMTP id DD93B588013
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 13:01:50 -0400 (EDT)
Received: from mayuran.casalemedia.com (10.3.10.40) by
 exchange.casalemedia.com (10.3.10.15) with Microsoft SMTP Server id
 8.1.240.5; Wed, 12 Aug 2009 13:01:50 -0400
Message-ID: <4A82F578.7050309@casalemedia.com>
Date: Wed, 12 Aug 2009 13:01:44 -0400
From: Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: Re: NN + secondary got full, even though data nodes had plenty of
 	space
References: <4A81B3C3.3060903@casalemedia.com> <45f85f70908120823h1dc26130ncd6ce1b700035f1a@mail.gmail.com>
In-Reply-To: <45f85f70908120823h1dc26130ncd6ce1b700035f1a@mail.gmail.com>
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Todd Lipcon wrote:
> Hi Mayuran,
>
> Do you do all of your uploads of data into your Hadoop cluster from node001
> and node002?
>
> If so, keep in mind that one of your replicas will always be written on
> localhost in the case that it is part of the cluster.
>
> You should consider running the rebalancer to even up your space usage.
>
> -Todd
>
>   
Actually yes I have been doing this.  I'll try rebalancer, thanks for 
your help.

M


> On Tue, Aug 11, 2009 at 11:09 AM, Mayuran Yogarajah <
> mayuran.yogarajah@casalemedia.com> wrote:
>
>   
>> I have a 6 node cluster running Hadoop 0.18.3.  I'm trying to figure out
>> how the data was spread out like this:
>>
>> node001         94.15%
>> node002         94.16%
>> node003         48.22%
>> node004         47.85%
>> node005         48.12%
>> node006         43.18%
>> Node 001 (NN) and node 002( secondary NN) both got full, while the other
>> data nodes had more space left.  I had assumed that Hadoop would distribute
>> more blocks to nodes 3-6 since they had much more space, but it ended up
>> filling up nodes1 and 2.  Is this expected?
>>
>> thanks,
>> M
>>
>>
>>     


From common-user-return-16707-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 18:02:38 2009
Return-Path: <common-user-return-16707-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 6112 invoked from network); 12 Aug 2009 18:02:38 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 18:02:38 -0000
Received: (qmail 94867 invoked by uid 500); 12 Aug 2009 18:02:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 94790 invoked by uid 500); 12 Aug 2009 18:02:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 94780 invoked by uid 99); 12 Aug 2009 18:02:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 18:02:42 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 18:02:31 +0000
Received: from pineapple-lm.corp.yahoo.com (pineapple-lm.corp.yahoo.com [10.72.122.24])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7CI0GHp093861
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 11:00:16 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:from:to:in-reply-to:content-type:
	content-transfer-encoding:mime-version:subject:date:references:x-mailer;
	b=rjGVWHdS1bdfsuKAQP5ssE5b+/CtXi0GB5lwlHV1pR5OeU5kNA+Ds2W/etMAOWp+
Message-Id: <6B05C5BF-048D-425E-9BFA-1D77C578E6DA@yahoo-inc.com>
From: Chris Douglas <chrisdo@yahoo-inc.com>
To: common-user@hadoop.apache.org
In-Reply-To: <45f85f70908111942n5646e098s6fc8586236955b0@mail.gmail.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: Extra 4 bytes at beginning of serialized file
Date: Wed, 12 Aug 2009 11:00:16 -0700
References: <42a1925b0908111833t40ac91ecx7e0b7206f4efbfae@mail.gmail.com>  <45f85f70908111903q45c65019m74f3451a213e6909@mail.gmail.com>  <42a1925b0908111923g3e3c5dbctded4c81001cce8e0@mail.gmail.com> <45f85f70908111942n5646e098s6fc8586236955b0@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

Rather than calling key.write(out), use out.write(key.getBytes(), 0,  
key.getLength()) in your OutputFormat. You'll need to specify that the  
keytype is BytesWritable or BinaryComparable, rather than Writable  
(for maintainers, "generic" may not be the best way to describe this  
output format, btw).

As Todd points out, whether the output data are legible is entirely up  
to your application. -C

On Aug 11, 2009, at 7:42 PM, Todd Lipcon wrote:

> If you know you'll only have one object in the file, you could write  
> your
> own Writable implementation which doesn't write its length. The  
> problem is
> that you'll never be able to *read* it, since writables only get an  
> input
> stream and thus don't know the file size.
>
> If you choose to do this, just model it after BytesWritable but drop  
> the 4
> byte length header.
>
> -Todd
>
> On Tue, Aug 11, 2009 at 7:23 PM, Kris Jirapinyo
> <kris.jirapinyo@biz360.com>wrote:
>
>> Ah that explains it, thanks Todd.  Is there a way to serialize an  
>> object
>> without using BytesWritable, or some way I can have a "perfect"  
>> serialized
>> file so I won't have to keep discarding the first 4 bytes of the  
>> files?
>>
>> -- Kris.
>>
>> On Tue, Aug 11, 2009 at 7:03 PM, Todd Lipcon <todd@cloudera.com>  
>> wrote:
>>
>>> BytesWritable serializes itself by first outputting the array  
>>> length, and
>>> then outputting the array itself. The 4 bytes at the top of the  
>>> file are
>>> the
>>> length of the value itself.
>>>
>>> Hope that helps
>>> -Todd
>>>
>>> On Tue, Aug 11, 2009 at 6:33 PM, Kris Jirapinyo <kjirapinyo@biz360.com
>>>> wrote:
>>>
>>>> Hi all,
>>>>  I was wondering if anyone's encountered 4 extra bytes at the
>> beginning
>>> of
>>>> the serialized object file using MultipleOutputFormat.   
>>>> Basically, I am
>>>> using BytesWritable to write the serialized byte arrays in the  
>>>> reducer
>>>> phase.  My writer is a generic one:
>>>>
>>>> public class GenericOutputFormat extends FileOutputFormat<Writable,
>>>> Writable>  {
>>>>
>>>>   @Override
>>>>   public RecordWriter<Writable, Writable>  
>>>> getRecordWriter(FileSystem
>>>> ignored, JobConf job, String name, Progressable progress)
>>>>       throws IOException {
>>>>         Path file = FileOutputFormat.getTaskOutputPath(job, name);
>>>>         FileSystem fs = file.getFileSystem(job);
>>>>         FSDataOutputStream fileOut = fs.create(file, progress);
>>>>       return new GenericWriter(fileOut);
>>>>   }
>>>>
>>>>   static class GenericWriter implements RecordWriter<Writable,
>> Writable>
>>> {
>>>>       protected DataOutputStream out;
>>>>
>>>>       GenericWriter(DataOutputStream out) {
>>>>           this.out = out;
>>>>       }
>>>>
>>>>       @Override
>>>>       public synchronized void close(Reporter reporter) throws
>>> IOException
>>>> {
>>>>           out.close();
>>>>       }
>>>>
>>>>       @Override
>>>>       public synchronized void write(Writable key, Writable value)
>>> throws
>>>> IOException {
>>>>           key.write(out);
>>>>       }
>>>>   }
>>>> }
>>>>
>>>> Basically, it'll just write out whatever is in the  
>>>> DataOutputStream.
>>> When
>>>> i
>>>> debugged, I printed out the size of the byte array in the
>> BytesWritable,
>>>> and
>>>> the resulting file is always 4 bytes larger than that number.  Any
>> ideas?
>>>>
>>>> -- Kris.
>>>>
>>>
>>


From common-user-return-16708-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 18:35:37 2009
Return-Path: <common-user-return-16708-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 34072 invoked from network); 12 Aug 2009 18:35:37 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 18:35:37 -0000
Received: (qmail 55922 invoked by uid 500); 12 Aug 2009 18:35:41 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 55847 invoked by uid 500); 12 Aug 2009 18:35:41 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 55837 invoked by uid 99); 12 Aug 2009 18:35:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 18:35:41 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.210.185 is neither permitted nor denied by domain of kjirapinyo@biz360.com)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 18:35:31 +0000
Received: by yxe15 with SMTP id 15so308010yxe.5
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 11:35:10 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.100.3.20 with SMTP id 20mr343960anc.32.1250102110202; Wed, 12 
	Aug 2009 11:35:10 -0700 (PDT)
In-Reply-To: <6B05C5BF-048D-425E-9BFA-1D77C578E6DA@yahoo-inc.com>
References: <42a1925b0908111833t40ac91ecx7e0b7206f4efbfae@mail.gmail.com> 
	<45f85f70908111903q45c65019m74f3451a213e6909@mail.gmail.com> 
	<42a1925b0908111923g3e3c5dbctded4c81001cce8e0@mail.gmail.com> 
	<45f85f70908111942n5646e098s6fc8586236955b0@mail.gmail.com> 
	<6B05C5BF-048D-425E-9BFA-1D77C578E6DA@yahoo-inc.com>
From: Kris Jirapinyo <kris.jirapinyo@biz360.com>
Date: Wed, 12 Aug 2009 11:34:49 -0700
Message-ID: <42a1925b0908121134h32cff10dq8381387950d5c983@mail.gmail.com>
Subject: Re: Extra 4 bytes at beginning of serialized file
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e645b878362d590470f6140c
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e645b878362d590470f6140c
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Haha yes, I agree...the only thing generic about this Writer is it accepts
any Writable...this is a pretty specific case that I need anyways, so I will
just go with using MultipleFileOutput<BytesWritable, Writable>.  It's
probably easier to do this than to try override BytesWritable.

Thanks!
Kris.

On Wed, Aug 12, 2009 at 11:00 AM, Chris Douglas <chrisdo@yahoo-inc.com>wrote:

> Rather than calling key.write(out), use out.write(key.getBytes(), 0,
> key.getLength()) in your OutputFormat. You'll need to specify that the
> keytype is BytesWritable or BinaryComparable, rather than Writable (for
> maintainers, "generic" may not be the best way to describe this output
> format, btw).
>
> As Todd points out, whether the output data are legible is entirely up to
> your application. -C
>
>
> On Aug 11, 2009, at 7:42 PM, Todd Lipcon wrote:
>
>  If you know you'll only have one object in the file, you could write your
>> own Writable implementation which doesn't write its length. The problem is
>> that you'll never be able to *read* it, since writables only get an input
>> stream and thus don't know the file size.
>>
>> If you choose to do this, just model it after BytesWritable but drop the 4
>> byte length header.
>>
>> -Todd
>>
>> On Tue, Aug 11, 2009 at 7:23 PM, Kris Jirapinyo
>> <kris.jirapinyo@biz360.com>wrote:
>>
>>  Ah that explains it, thanks Todd.  Is there a way to serialize an object
>>> without using BytesWritable, or some way I can have a "perfect"
>>> serialized
>>> file so I won't have to keep discarding the first 4 bytes of the files?
>>>
>>> -- Kris.
>>>
>>> On Tue, Aug 11, 2009 at 7:03 PM, Todd Lipcon <todd@cloudera.com> wrote:
>>>
>>>  BytesWritable serializes itself by first outputting the array length,
>>>> and
>>>> then outputting the array itself. The 4 bytes at the top of the file are
>>>> the
>>>> length of the value itself.
>>>>
>>>> Hope that helps
>>>> -Todd
>>>>
>>>> On Tue, Aug 11, 2009 at 6:33 PM, Kris Jirapinyo <kjirapinyo@biz360.com
>>>>
>>>>> wrote:
>>>>>
>>>>
>>>>  Hi all,
>>>>>  I was wondering if anyone's encountered 4 extra bytes at the
>>>>>
>>>> beginning
>>>
>>>> of
>>>>
>>>>> the serialized object file using MultipleOutputFormat.  Basically, I am
>>>>> using BytesWritable to write the serialized byte arrays in the reducer
>>>>> phase.  My writer is a generic one:
>>>>>
>>>>> public class GenericOutputFormat extends FileOutputFormat<Writable,
>>>>> Writable>  {
>>>>>
>>>>>  @Override
>>>>>  public RecordWriter<Writable, Writable> getRecordWriter(FileSystem
>>>>> ignored, JobConf job, String name, Progressable progress)
>>>>>      throws IOException {
>>>>>        Path file = FileOutputFormat.getTaskOutputPath(job, name);
>>>>>        FileSystem fs = file.getFileSystem(job);
>>>>>        FSDataOutputStream fileOut = fs.create(file, progress);
>>>>>      return new GenericWriter(fileOut);
>>>>>  }
>>>>>
>>>>>  static class GenericWriter implements RecordWriter<Writable,
>>>>>
>>>> Writable>
>>>
>>>> {
>>>>
>>>>>      protected DataOutputStream out;
>>>>>
>>>>>      GenericWriter(DataOutputStream out) {
>>>>>          this.out = out;
>>>>>      }
>>>>>
>>>>>      @Override
>>>>>      public synchronized void close(Reporter reporter) throws
>>>>>
>>>> IOException
>>>>
>>>>> {
>>>>>          out.close();
>>>>>      }
>>>>>
>>>>>      @Override
>>>>>      public synchronized void write(Writable key, Writable value)
>>>>>
>>>> throws
>>>>
>>>>> IOException {
>>>>>          key.write(out);
>>>>>      }
>>>>>  }
>>>>> }
>>>>>
>>>>> Basically, it'll just write out whatever is in the DataOutputStream.
>>>>>
>>>> When
>>>>
>>>>> i
>>>>> debugged, I printed out the size of the byte array in the
>>>>>
>>>> BytesWritable,
>>>
>>>> and
>>>>> the resulting file is always 4 bytes larger than that number.  Any
>>>>>
>>>> ideas?
>>>
>>>>
>>>>> -- Kris.
>>>>>
>>>>>
>>>>
>>>
>

--0016e645b878362d590470f6140c--

From common-user-return-16709-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 18:43:20 2009
Return-Path: <common-user-return-16709-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 35909 invoked from network); 12 Aug 2009 18:43:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 18:43:20 -0000
Received: (qmail 70940 invoked by uid 500); 12 Aug 2009 18:43:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 70839 invoked by uid 500); 12 Aug 2009 18:43:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 70829 invoked by uid 99); 12 Aug 2009 18:43:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 18:43:25 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=FS_REPLICA,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rkhatwani@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 18:43:17 +0000
Received: by yxe15 with SMTP id 15so314998yxe.5
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 11:42:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=1ki1nPunl+QCS3Rw0m2ibU9XxHbj+6JaemFHH+Nx6ko=;
        b=hnxzervVfP7Fw0rFPNsUwkcrVNfwo3PiY5bWjaej1s5n+UT+qbQcTzvOJW8c5PX5GP
         uVDVgtxJwLbDbXUBC5HUzVMxO3N0/JpRNlShXa1onbXXyE4pmrmSILbOy4S9O6LujQPY
         FqJuoOxDWXE24nvFmxhxjeaIvS4gtc+A0j3w0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=Df6BN7r0NxfBVK7g58kL3QEXAfnS/Igah9DYaySzWGaRU0dTt6km7diFN1w55sC6TK
         4c8FNo+5EUgENWqCMoRwhFbxa/VwxAceFwKoedhcN0KuB1NpfHYM7QeWWwi1ELjtuVGz
         lBCQeduC6NdjDR5HPyyAr5D4xnUEcqAn8AiGE=
MIME-Version: 1.0
Received: by 10.231.18.69 with SMTP id v5mr590115iba.26.1250102575985; Wed, 12 
	Aug 2009 11:42:55 -0700 (PDT)
Date: Thu, 13 Aug 2009 00:12:55 +0530
Message-ID: <2aa3aff80908121142r8d45025r39317d8e596d19b@mail.gmail.com>
Subject: Doubt regarding Replication Factor
From: Rakhi Khatwani <rkhatwani@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221504666ff976c90470f62f4c
X-Virus-Checked: Checked by ClamAV on apache.org

--00221504666ff976c90470f62f4c
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,
   I just wanted to know what if we have set the replication factor greater
than the number of nodes in the cluster.
for example, i have only 3 nodes in my cluster but i set the replication
factor to 5.

will it create 3 copies and save it in each node, or can it create more than
one copy per node?

Regards,
Raakhi Khatwani

--00221504666ff976c90470f62f4c--

From common-user-return-16710-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 18:50:23 2009
Return-Path: <common-user-return-16710-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 37995 invoked from network); 12 Aug 2009 18:50:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 18:50:23 -0000
Received: (qmail 90727 invoked by uid 500); 12 Aug 2009 18:50:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 90636 invoked by uid 500); 12 Aug 2009 18:50:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 90617 invoked by uid 99); 12 Aug 2009 18:50:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 18:50:26 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rkhatwani@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 18:50:18 +0000
Received: by gxk18 with SMTP id 18so169091gxk.5
        for <multiple recipients>; Wed, 12 Aug 2009 11:49:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=Ae8wf5mWakXCByDJoiNFuANuZjDLu41rBVpJGEosyfY=;
        b=wH2IvkO0WfiOwKfcjEU3kjYPXbxyJESjpeYSEMWYBVitpxyMKDvExPlmIGkyyN+ao0
         1gccMGWaJ1XL6302xz1tkWWWMG3juiLNsPH4keawxaHWIR3s0BvMBFvJuRN+j4TNbEyd
         fsbAP/SL4+UpI/F2UbujkCg0xyg5pJk0ryvD4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=lQyN7bwWtCuze9GuLETdHZAxZ4uUH47Jw6vNqRb4+9t0F2KHoc1L622plzJ9NW/ppu
         0NIqYygSVQ/R+dS/k/B7YrJZlDY6aifa+JlCyEl926RQxi60ktGVhO/V79QMOXojKx2b
         5/41DM7BBKgqBJ0c8/gbGoE/Ub3PgSUhPP5mA=
MIME-Version: 1.0
Received: by 10.231.34.3 with SMTP id j3mr590871ibd.43.1250102997174; Wed, 12 
	Aug 2009 11:49:57 -0700 (PDT)
Date: Thu, 13 Aug 2009 00:19:57 +0530
Message-ID: <2aa3aff80908121149g606792b0l8e8fbc0a62fd8214@mail.gmail.com>
Subject: Doubt regarding mem cache.
From: Rakhi Khatwani <rkhatwani@gmail.com>
To: hbase-user@hadoop.apache.org, common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221532cda4144aa20470f649ac
X-Virus-Checked: Checked by ClamAV on apache.org

--00221532cda4144aa20470f649ac
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,
I am not very clear as to how does the mem cache thing works.

1. When you set memcache to say 1MB, does hbase write all the table
information into some cache memory and when the size reaches IMB, it writes
into hadoop and after that the replication takes place???

2. Is there any minimum limit on the mem cache property in hbase site??

Regards,
Raakhi

--00221532cda4144aa20470f649ac--

From common-user-return-16711-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 19:20:41 2009
Return-Path: <common-user-return-16711-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 48369 invoked from network); 12 Aug 2009 19:20:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 19:20:40 -0000
Received: (qmail 32281 invoked by uid 500); 12 Aug 2009 19:07:56 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 32251 invoked by uid 500); 12 Aug 2009 19:07:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 32241 invoked by uid 99); 12 Aug 2009 19:07:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 19:07:56 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 19:07:45 +0000
Received: from [10.72.185.127] (gentlepaint-lx.corp.yahoo.com [10.72.185.127])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7CJ6jXc021797
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 12:06:45 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=0dVlE4PIXc3fkuxsSSSmT5gZPSt98AacXXBlvNX5uJx/xQaMc+fWUnm7dSWu//nt
Message-ID: <4A8312C5.9080307@yahoo-inc.com>
Date: Wed, 12 Aug 2009 12:06:45 -0700
From: Konstantin Shvachko <shv@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: HADOOP-4539 question
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com> 	<4A7BECD9.20303@apache.org> <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com> 	<4A814BCD.2060500@apache.org> <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com> 	<77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com> <45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com>
In-Reply-To: <45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Stas,

There is no HA solution currently for Hadoop.
You can do things like Cloudera describes.
Their solution works with 2 real name-nodes.
No Backup node involved.

As for Backup node, I don't really understand Todd's comment
but the fact is that Backup node (BN) is not a standby
node. The failover procedure is not implemented for BN,
so neither clients nor data-node don't fail-over anywhere
when the main name-node (NN) dies, they don't have a clue.

The purpose of the BN is
1) to keep an up-to-date image of the namespace in memory.
This does not include block locations.
BN does not know where file blocks are.
2) to make periodic checkpoints, like SecondaryNameNode did,
but more efficiently, since BN does not need to load image
and edits from NN, its namespace is already up-to-date.

There is provision to transform BN to a real standby node,
with failover, but it has not been implemented yet.

Hope this clarifies things.

Thanks,
--Konstantin


Todd Lipcon wrote:
> On Wed, Aug 12, 2009 at 3:42 AM, Stas Oskin <stas.oskin@gmail.com> wrote:
> 
>> Hi.
>>
>>
>>> You can also use a utility like Linux-HA (aka heartbeat) to handle IP
>>> address failover. It will even send gratuitous ARPs to make sure to get
>> the
>>> new mac address registered after a failover. Check out this blog for info
>>> about a setup like this:
>>>
>>> http://www.cloudera.com/blog/2009/07/22/hadoop-ha-configuration/
>>>
>>> Hope that helps
>>>
>> Thanks, exactly what I looked for :).
>>
>>  I presume that with the coming BB node, there won't be need for DRBD, am I
>> correct?
>>
> 
> I haven't followed that development closely, but I believe that's the case.
> The BackupNode will stream the FSEditLog writes as they occur while
> replaying them into its own FSNamesystem. Then during a failover a real
> NameNode starts on that FSNamesystem "ready to go". As for how the
> BackupNode keeps track of block locations, I'm not sure - is there a
> replication stream between BlockManagers too? Or is the cluster in a broken
> state until all of the DNs have processed new block reports?
> 
> -Todd
> 

From common-user-return-16712-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 19:20:53 2009
Return-Path: <common-user-return-16712-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 48900 invoked from network); 12 Aug 2009 19:20:53 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 19:20:53 -0000
Received: (qmail 32819 invoked by uid 500); 12 Aug 2009 19:11:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 32788 invoked by uid 500); 12 Aug 2009 19:11:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 32778 invoked by uid 500); 12 Aug 2009 19:11:10 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 32775 invoked by uid 99); 12 Aug 2009 19:11:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 19:11:10 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of thkunkel@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 19:11:02 +0000
Received: by yxe15 with SMTP id 15so340316yxe.5
        for <core-user@hadoop.apache.org>; Wed, 12 Aug 2009 12:10:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=gU2KInz+OM9sc0yw99oJmsAGodzojppJftTx9wiqTso=;
        b=QdLy2dLifD0WsO8seAn6yEyI1YquXjYzrbKdMl2Qhc4AAY2hdYPdJ1yzPIQcWElwrH
         W+Jb8iYErlIP0hSZ7PTchvFhAjYkfURZhroD/30CuF9YQ1e6PR2unMYN1EnTFuzYtI4E
         2QNKakj0jkLjhggDZH9Hfjt6X3fAM8aJO+uow=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=b+QPt7C98kDG0wLbVtPrjrk+Bvk7pAA5EoZhs8qnfacz48eJ9ioPEiwvj4GDBwWiWN
         2UWLMUtOKrZC+RR/5p1haEQPWuz5luE2b53cNCkEcM8JreOYBFewagA7aca+I1/cLEYU
         Zwd1xljeFvxEe4DVqmJqBXeZ8RouwE6FY6x9U=
MIME-Version: 1.0
Received: by 10.90.54.5 with SMTP id c5mr172592aga.73.1250104241625; Wed, 12 
	Aug 2009 12:10:41 -0700 (PDT)
Date: Wed, 12 Aug 2009 14:10:41 -0500
Message-ID: <8134a2730908121210n6e343836mcab77dbc0f8fb00e@mail.gmail.com>
Subject: Direct ftp into hdfs
From: Turner Kunkel <thkunkel@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636164497411bf70470f69334
X-Virus-Checked: Checked by ClamAV on apache.org

--001636164497411bf70470f69334
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Can anyone tell me how to directly ftp into hdfs?  I've been trying for a
while and can't get it to work.

Thanks.

--001636164497411bf70470f69334--

From common-user-return-16713-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 19:21:02 2009
Return-Path: <common-user-return-16713-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 49390 invoked from network); 12 Aug 2009 19:21:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 19:21:02 -0000
Received: (qmail 33319 invoked by uid 500); 12 Aug 2009 19:14:34 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 33293 invoked by uid 500); 12 Aug 2009 19:14:34 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 33283 invoked by uid 99); 12 Aug 2009 19:14:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 19:14:34 +0000
X-ASF-Spam-Status: No, hits=2.4 required=10.0
	tests=FS_REPLICA,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 19:14:22 +0000
Received: from [10.72.185.127] (gentlepaint-lx.corp.yahoo.com [10.72.185.127])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7CJBu7t024017
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 12:11:56 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=WTya7s16qhQYtgn4Xh8XZk4pyGcimUkAj5GjKat/BqsyH013P3b/dTgorq9b7s2m
Message-ID: <4A8313FC.90506@yahoo-inc.com>
Date: Wed, 12 Aug 2009 12:11:56 -0700
From: Konstantin Shvachko <shv@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Doubt regarding Replication Factor
References: <2aa3aff80908121142r8d45025r39317d8e596d19b@mail.gmail.com>
In-Reply-To: <2aa3aff80908121142r8d45025r39317d8e596d19b@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

You can try it: start a 3 node cluster and create a file with replication 5.

The answer is that each data-node can store only one replica of a block.
So in your case you will get an exception on close() saying the file cannot
be fully replicated.

Thanks,
--Konstantin

Rakhi Khatwani wrote:
> Hi,
>    I just wanted to know what if we have set the replication factor greater
> than the number of nodes in the cluster.
> for example, i have only 3 nodes in my cluster but i set the replication
> factor to 5.
> 
> will it create 3 copies and save it in each node, or can it create more than
> one copy per node?
> 
> Regards,
> Raakhi Khatwani
> 

From common-user-return-16714-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 19:27:52 2009
Return-Path: <common-user-return-16714-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 53035 invoked from network); 12 Aug 2009 19:27:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 19:27:52 -0000
Received: (qmail 66185 invoked by uid 500); 12 Aug 2009 19:27:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 66112 invoked by uid 500); 12 Aug 2009 19:27:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 66093 invoked by uid 99); 12 Aug 2009 19:27:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 19:27:56 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [209.85.222.189] (HELO mail-pz0-f189.google.com) (209.85.222.189)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 19:27:46 +0000
Received: by pzk27 with SMTP id 27so170847pzk.2
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 12:27:26 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.235.16 with SMTP id i16mr330208wah.28.1250105246163; Wed, 
	12 Aug 2009 12:27:26 -0700 (PDT)
In-Reply-To: <4A8312C5.9080307@yahoo-inc.com>
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com> 
	<4A7BECD9.20303@apache.org> <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com> 
	<4A814BCD.2060500@apache.org> <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com> 
	<77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com> 
	<45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com> 
	<4A8312C5.9080307@yahoo-inc.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Wed, 12 Aug 2009 12:27:06 -0700
Message-ID: <45f85f70908121227o679f4887l9ec1c053270af40a@mail.gmail.com>
Subject: Re: HADOOP-4539 question
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163645812e2124690470f6cf55
X-Virus-Checked: Checked by ClamAV on apache.org

--00163645812e2124690470f6cf55
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Wed, Aug 12, 2009 at 12:06 PM, Konstantin Shvachko <shv@yahoo-inc.com>wrote:

> Stas,
>
> There is no HA solution currently for Hadoop.
> You can do things like Cloudera describes.
> Their solution works with 2 real name-nodes.
> No Backup node involved.
>
> As for Backup node, I don't really understand Todd's comment
> but the fact is that Backup node (BN) is not a standby
> node. The failover procedure is not implemented for BN,
> so neither clients nor data-node don't fail-over anywhere
> when the main name-node (NN) dies, they don't have a clue.
>

Gotcha - I thought the long term goal for the BN was to eventually have it
work as a "warm standby" that could convert into a NN without restart.

My mistake

-Todd


>
> The purpose of the BN is
> 1) to keep an up-to-date image of the namespace in memory.
> This does not include block locations.
> BN does not know where file blocks are.
> 2) to make periodic checkpoints, like SecondaryNameNode did,
> but more efficiently, since BN does not need to load image
> and edits from NN, its namespace is already up-to-date.
>
> There is provision to transform BN to a real standby node,
> with failover, but it has not been implemented yet.
>
> Hope this clarifies things.
>
> Thanks,
> --Konstantin
>
>
>
> Todd Lipcon wrote:
>
>> On Wed, Aug 12, 2009 at 3:42 AM, Stas Oskin <stas.oskin@gmail.com> wrote:
>>
>>  Hi.
>>>
>>>
>>>  You can also use a utility like Linux-HA (aka heartbeat) to handle IP
>>>> address failover. It will even send gratuitous ARPs to make sure to get
>>>>
>>> the
>>>
>>>> new mac address registered after a failover. Check out this blog for
>>>> info
>>>> about a setup like this:
>>>>
>>>> http://www.cloudera.com/blog/2009/07/22/hadoop-ha-configuration/
>>>>
>>>> Hope that helps
>>>>
>>>>  Thanks, exactly what I looked for :).
>>>
>>>  I presume that with the coming BB node, there won't be need for DRBD, am
>>> I
>>> correct?
>>>
>>>
>> I haven't followed that development closely, but I believe that's the
>> case.
>> The BackupNode will stream the FSEditLog writes as they occur while
>> replaying them into its own FSNamesystem. Then during a failover a real
>> NameNode starts on that FSNamesystem "ready to go". As for how the
>> BackupNode keeps track of block locations, I'm not sure - is there a
>> replication stream between BlockManagers too? Or is the cluster in a
>> broken
>> state until all of the DNs have processed new block reports?
>>
>> -Todd
>>
>>

--00163645812e2124690470f6cf55--

From common-user-return-16715-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:07:23 2009
Return-Path: <common-user-return-16715-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 68851 invoked from network); 12 Aug 2009 20:07:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:07:17 -0000
Received: (qmail 96565 invoked by uid 500); 12 Aug 2009 19:56:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 96539 invoked by uid 500); 12 Aug 2009 19:56:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 96525 invoked by uid 99); 12 Aug 2009 19:56:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 19:56:13 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=FS_REPLICA,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tarandeep@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 19:56:05 +0000
Received: by ewy26 with SMTP id 26so281040ewy.29
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 12:55:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=FT6PIOo9u4tcSw3uIhnfTJUckYKWfmor3LpY5n4K1jw=;
        b=kT6vJTfA3/Wb+RLxmrP6mNf1uDYVm5HydcT4HA0y4RjVfoQdIpiqsYF6Ud8K8nwKWJ
         hvfdWt3HjHyMiGiZ3SptLpC82FJ3izWSrl/4CobW3aLnLjzjlWAvBuXGp37XbCl2qfI2
         pTffMGiQ4MRb3QcAn87jZe5CeF65vYCbJ2hNM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=Cgvk97N2ksBmlnjNbSRbbwSwGMVIrOC7SQ1mz0TBxjd9ZU0q02StEGIHwxr2n5Uo2b
         fSXPYmkBfjOo4cgB3LH8VGV1zHSVV03GF6J949Iwbnmth+l/MClM8O8DzaSztH7KODGB
         vnV9iqGTa2HqlFHFARrGslRsaicaM0wgIp1vA=
MIME-Version: 1.0
Received: by 10.210.44.12 with SMTP id r12mr628760ebr.24.1250106943652; Wed, 
	12 Aug 2009 12:55:43 -0700 (PDT)
In-Reply-To: <4A8313FC.90506@yahoo-inc.com>
References: <2aa3aff80908121142r8d45025r39317d8e596d19b@mail.gmail.com> 
	<4A8313FC.90506@yahoo-inc.com>
From: Tarandeep Singh <tarandeep@gmail.com>
Date: Wed, 12 Aug 2009 12:55:22 -0700
Message-ID: <e75c02ef0908121255w2b3f1976k4d7c536c32bd0ea4@mail.gmail.com>
Subject: Re: Doubt regarding Replication Factor
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015174c0fa84ec30a0470f734dc
X-Virus-Checked: Checked by ClamAV on apache.org

--0015174c0fa84ec30a0470f734dc
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

A similar question-

If in an N node cluster, a file's replication is set to N (replicate on each
node) and later if a node goes down, will HDFS throw an exception since the
file's replication has gone down below the specified number ?

Thanks,
Tarandeep

On Wed, Aug 12, 2009 at 12:11 PM, Konstantin Shvachko <shv@yahoo-inc.com>wrote:

> You can try it: start a 3 node cluster and create a file with replication
> 5.
>
> The answer is that each data-node can store only one replica of a block.
> So in your case you will get an exception on close() saying the file cannot
> be fully replicated.
>
> Thanks,
> --Konstantin
>
>
> Rakhi Khatwani wrote:
>
>> Hi,
>>   I just wanted to know what if we have set the replication factor greater
>> than the number of nodes in the cluster.
>> for example, i have only 3 nodes in my cluster but i set the replication
>> factor to 5.
>>
>> will it create 3 copies and save it in each node, or can it create more
>> than
>> one copy per node?
>>
>> Regards,
>> Raakhi Khatwani
>>
>>

--0015174c0fa84ec30a0470f734dc--

From common-user-return-16716-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:07:55 2009
Return-Path: <common-user-return-16716-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 71623 invoked from network); 12 Aug 2009 20:07:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:07:54 -0000
Received: (qmail 99552 invoked by uid 500); 12 Aug 2009 20:07:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 99077 invoked by uid 500); 12 Aug 2009 20:07:06 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 98020 invoked by uid 99); 12 Aug 2009 20:06:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:06:40 +0000
X-ASF-Spam-Status: No, hits=1.4 required=10.0
	tests=FS_REPLICA,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:06:31 +0000
Received: from pcp088961pcs.unl.edu (pcp088961pcs.unl.edu [129.93.158.76])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7CK64CN024749
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 15:06:06 -0500
Message-Id: <576200FF-0A56-45D7-9420-55D02173CD6C@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <4A8313FC.90506@yahoo-inc.com>
Content-Type: multipart/signed; boundary=Apple-Mail-13--930058956; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: Doubt regarding Replication Factor
Date: Wed, 12 Aug 2009 15:06:04 -0500
References: <2aa3aff80908121142r8d45025r39317d8e596d19b@mail.gmail.com> <4A8313FC.90506@yahoo-inc.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-13--930058956
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit


On Aug 12, 2009, at 2:11 PM, Konstantin Shvachko wrote:

> You can try it: start a 3 node cluster and create a file with  
> replication 5.
>
> The answer is that each data-node can store only one replica of a  
> block.
> So in your case you will get an exception on close() saying the file  
> cannot
> be fully replicated.
>

I'm not sure if that's true.  You only get an exception if the system  
cannot provide the minimum replication factor.

I.e, if you ask for 5 replicas and the minimum replicas is 3, then you  
only get an exception if HDFS can't meet 3 replicas.

Am I recalling this wrong?  We have "discovered" this fact at least  
once :)

Brian

> Thanks,
> --Konstantin
>
> Rakhi Khatwani wrote:
>> Hi,
>>   I just wanted to know what if we have set the replication factor  
>> greater
>> than the number of nodes in the cluster.
>> for example, i have only 3 nodes in my cluster but i set the  
>> replication
>> factor to 5.
>> will it create 3 copies and save it in each node, or can it create  
>> more than
>> one copy per node?
>> Regards,
>> Raakhi Khatwani


--Apple-Mail-13--930058956
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-13--930058956--

From common-user-return-16717-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:15:59 2009
Return-Path: <common-user-return-16717-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 74576 invoked from network); 12 Aug 2009 20:15:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:15:59 -0000
Received: (qmail 30190 invoked by uid 500); 12 Aug 2009 20:16:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 30123 invoked by uid 500); 12 Aug 2009 20:16:03 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 30028 invoked by uid 99); 12 Aug 2009 20:16:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:16:03 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [192.139.80.206] (HELO mx1.casalemedia.com) (192.139.80.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:15:54 +0000
Received: from exchange.casalemedia.com (unknown [10.3.10.15])
	by mx1.casalemedia.com (Postfix) with ESMTP id 680A9588011
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 16:15:33 -0400 (EDT)
Received: from mayuran.casalemedia.com (10.3.10.40) by
 exchange.casalemedia.com (10.3.10.15) with Microsoft SMTP Server id
 8.1.240.5; Wed, 12 Aug 2009 16:15:33 -0400
Message-ID: <4A8322DE.4050003@casalemedia.com>
Date: Wed, 12 Aug 2009 16:15:26 -0400
From: Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: I've probably hit some system limits
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I had 3 jobs running and I saw something a bit odd.  Two of the tasks
are reducing, one of them is using all the reducers so the other is
waiting, this is OK.  However the 3rd job is still in the mapping phase
and even though the web interface shows map capacity at 96 I only
see about 7-12 mappers actually running.  I'm wondering if theres
some setting I need to change, perhaps I've hit some system limit.  Can
someone point me in the right direction please?

The other thing was that with the two jobs that are in the reducing phase,
the reducer for one job wouldn't actually start until all the mappers of the
_other_ job completed which seems kind of odd.  Is this expected ?

thanks,
M

From common-user-return-16718-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:19:56 2009
Return-Path: <common-user-return-16718-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75365 invoked from network); 12 Aug 2009 20:19:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:19:56 -0000
Received: (qmail 33581 invoked by uid 500); 12 Aug 2009 20:20:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 33493 invoked by uid 500); 12 Aug 2009 20:20:01 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 33483 invoked by uid 99); 12 Aug 2009 20:20:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:20:01 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of amansk@gmail.com designates 209.85.211.188 as permitted sender)
Received: from [209.85.211.188] (HELO mail-yw0-f188.google.com) (209.85.211.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:19:53 +0000
Received: by ywh26 with SMTP id 26so404859ywh.5
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 13:19:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=w5dOxKyeDxzuK4TrGOJyxSAbvcNcpjFsiymQ8HapDFA=;
        b=E9j+G8fFQ/QrdqERRynWTuNg350zLMhDWDHgTDvflrishgxzDOcQmVhulRXi4B2fcE
         tm709nU0ied5OQx97saVjGW3t1gXlTjNWfuvjmXlE0ocG79g4naLgLjHSbc3WW/BComr
         Kqa6MckgKy4sRV+TNbtDNJVXv0ehLc3BZJ7Os=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=CUIG/kpbBDrCX5UJHu/54/IEwvpzgNGIjFnhUR0SgVrpcMiqcpumVMQjSRIGGpHbl0
         hgYKwk4gZm0C70upNDUtueVXWDhAfjXwFYXK5TmgnCucDawR4+Gl2iTRyfobv8hlWcBr
         USxKqgKlWH9jKsK+tXxPDfM3z3zQC9f/Srzaw=
MIME-Version: 1.0
Received: by 10.100.241.8 with SMTP id o8mr404118anh.102.1250108372220; Wed, 
	12 Aug 2009 13:19:32 -0700 (PDT)
In-Reply-To: <4A8322DE.4050003@casalemedia.com>
References: <4A8322DE.4050003@casalemedia.com>
From: Amandeep Khurana <amansk@gmail.com>
Date: Wed, 12 Aug 2009 13:19:12 -0700
Message-ID: <35a22e220908121319q26ba5c1q7c1e8ea2c5bfdb92@mail.gmail.com>
Subject: Re: I've probably hit some system limits
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016368e2589750a270470f789b8
X-Virus-Checked: Checked by ClamAV on apache.org

--0016368e2589750a270470f789b8
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Wed, Aug 12, 2009 at 1:15 PM, Mayuran Yogarajah <
mayuran.yogarajah@casalemedia.com> wrote:

> I had 3 jobs running and I saw something a bit odd.  Two of the tasks
> are reducing, one of them is using all the reducers so the other is
> waiting, this is OK.  However the 3rd job is still in the mapping phase
> and even though the web interface shows map capacity at 96 I only
> see about 7-12 mappers actually running.  I'm wondering if theres
> some setting I need to change, perhaps I've hit some system limit.  Can
> someone point me in the right direction please?
>

Are there any pending mappers remaining? Are you using any scheduler?


>
> The other thing was that with the two jobs that are in the reducing phase,
> the reducer for one job wouldn't actually start until all the mappers of
> the
> _other_ job completed which seems kind of odd.  Is this expected ?
>

Reducers dont really start the "reduce" phase till the mappers are
completed. However, the process gets spawned off and the copying of the
intermediate keys from the mapper starts off.


> thanks,
> M
>

--0016368e2589750a270470f789b8--

From common-user-return-16719-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:25:26 2009
Return-Path: <common-user-return-16719-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 77339 invoked from network); 12 Aug 2009 20:25:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:25:26 -0000
Received: (qmail 40270 invoked by uid 500); 12 Aug 2009 20:25:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 40186 invoked by uid 500); 12 Aug 2009 20:25:30 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 40176 invoked by uid 99); 12 Aug 2009 20:25:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:25:30 +0000
X-ASF-Spam-Status: No, hits=2.4 required=10.0
	tests=FS_REPLICA,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:25:17 +0000
Received: from SNV-EXBH01.ds.corp.yahoo.com (snv-exbh01.ds.corp.yahoo.com [207.126.227.249])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7CKOQH7053238
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 13:24:27 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=LJX99b3PT40WDnP2o8ECARmSWRS/7sZmw/N761ek2G06UEEm3IH2N7R9EPoe1LZ+
Received: from SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.87]) by SNV-EXBH01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Wed, 12 Aug 2009 13:24:26 -0700
Received: from 10.72.112.100 ([10.72.112.100]) by SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.84]) via Exchange Front-End Server snv-webmail.corp.yahoo.com ([207.126.227.60]) with Microsoft Exchange Server HTTP-DAV ;
 Wed, 12 Aug 2009 20:23:51 +0000
User-Agent: Microsoft-Entourage/12.20.0.090605
Date: Wed, 12 Aug 2009 13:23:51 -0700
Subject: Re: Doubt regarding Replication Factor
From: Hairong Kuang <hairong@yahoo-inc.com>
To: <common-user@hadoop.apache.org>
Message-ID: <C6A872E7.16302%hairong@yahoo-inc.com>
Thread-Topic: Doubt regarding Replication Factor
Thread-Index: Acobis4O6PqQmd7N6UGDaOCqnHPJHw==
In-Reply-To: <e75c02ef0908121255w2b3f1976k4d7c536c32bd0ea4@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-OriginalArrivalTime: 12 Aug 2009 20:24:26.0638 (UTC) FILETIME=[E34CD2E0:01CA1B8A]
X-Virus-Checked: Checked by ClamAV on apache.org

If the number of replicas meets the minimum replication factor, no exception
will be thrown. The default replication factor is 1.

So as long as your cluster has at least one node with available space, file
creations should be fine.

Hairong


On 8/12/09 12:55 PM, "Tarandeep Singh" <tarandeep@gmail.com> wrote:

> A similar question-
> 
> If in an N node cluster, a file's replication is set to N (replicate on each
> node) and later if a node goes down, will HDFS throw an exception since the
> file's replication has gone down below the specified number ?
> 
> Thanks,
> Tarandeep
> 
> On Wed, Aug 12, 2009 at 12:11 PM, Konstantin Shvachko
> <shv@yahoo-inc.com>wrote:
> 
>> You can try it: start a 3 node cluster and create a file with replication
>> 5.
>> 
>> The answer is that each data-node can store only one replica of a block.
>> So in your case you will get an exception on close() saying the file cannot
>> be fully replicated.
>> 
>> Thanks,
>> --Konstantin
>> 
>> 
>> Rakhi Khatwani wrote:
>> 
>>> Hi,
>>>   I just wanted to know what if we have set the replication factor greater
>>> than the number of nodes in the cluster.
>>> for example, i have only 3 nodes in my cluster but i set the replication
>>> factor to 5.
>>> 
>>> will it create 3 copies and save it in each node, or can it create more
>>> than
>>> one copy per node?
>>> 
>>> Regards,
>>> Raakhi Khatwani
>>> 
>>> 


From common-user-return-16720-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:28:09 2009
Return-Path: <common-user-return-16720-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 78271 invoked from network); 12 Aug 2009 20:28:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:28:09 -0000
Received: (qmail 45851 invoked by uid 500); 12 Aug 2009 20:28:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 45749 invoked by uid 500); 12 Aug 2009 20:28:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 45739 invoked by uid 99); 12 Aug 2009 20:28:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:28:14 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [192.139.80.206] (HELO mx1.casalemedia.com) (192.139.80.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:28:06 +0000
Received: from exchange.casalemedia.com (unknown [10.3.10.15])
	by mx1.casalemedia.com (Postfix) with ESMTP id 7E5A3588011
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 16:27:45 -0400 (EDT)
Received: from mayuran.casalemedia.com (10.3.10.40) by
 exchange.casalemedia.com (10.3.10.15) with Microsoft SMTP Server id
 8.1.240.5; Wed, 12 Aug 2009 16:27:45 -0400
Message-ID: <4A8325BA.5030701@casalemedia.com>
Date: Wed, 12 Aug 2009 16:27:38 -0400
From: Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: Re: I've probably hit some system limits
References: <4A8322DE.4050003@casalemedia.com> <35a22e220908121319q26ba5c1q7c1e8ea2c5bfdb92@mail.gmail.com>
In-Reply-To: <35a22e220908121319q26ba5c1q7c1e8ea2c5bfdb92@mail.gmail.com>
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

Amandeep Khurana wrote:
> On Wed, Aug 12, 2009 at 1:15 PM, Mayuran Yogarajah <
> mayuran.yogarajah@casalemedia.com> wrote:
>
>   
>> I had 3 jobs running and I saw something a bit odd.  Two of the tasks
>> are reducing, one of them is using all the reducers so the other is
>> waiting, this is OK.  However the 3rd job is still in the mapping phase
>> and even though the web interface shows map capacity at 96 I only
>> see about 7-12 mappers actually running.  I'm wondering if theres
>> some setting I need to change, perhaps I've hit some system limit.  Can
>> someone point me in the right direction please?
>>
>>     
>
> Are there any pending mappers remaining? Are you using any scheduler?
>
>   
Yes there were pending mappers remaining, I'm not using any scheduler.
>   
>> The other thing was that with the two jobs that are in the reducing phase,
>> the reducer for one job wouldn't actually start until all the mappers of
>> the
>> _other_ job completed which seems kind of odd.  Is this expected ?
>>
>>     
>
> Reducers dont really start the "reduce" phase till the mappers are
> completed. However, the process gets spawned off and the copying of the
> intermediate keys from the mapper starts off.
>
>
>   
That was my understanding for the same job but this was across two 
different jobs.  There
were no reduce tasks running from job #2 until all of the map jobs of 
job #1 completed.

On a side note I just saw this in the task tracker log, I don't know if 
its related:
INFO org.mortbay.http.SocketListener: LOW ON THREADS ((40-40+0)<1) on 
SocketListener0@0.0.0.0:50060
WARN org.mortbay.http.SocketListener: OUT OF THREADS: 
SocketListener0@0.0.0.0:50060


thanks,
M


From common-user-return-16721-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:31:19 2009
Return-Path: <common-user-return-16721-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 79402 invoked from network); 12 Aug 2009 20:31:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:31:19 -0000
Received: (qmail 49421 invoked by uid 500); 12 Aug 2009 20:31:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 49329 invoked by uid 500); 12 Aug 2009 20:31:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 49319 invoked by uid 99); 12 Aug 2009 20:31:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:31:23 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:31:12 +0000
Received: from [10.72.185.127] (gentlepaint-lx.corp.yahoo.com [10.72.185.127])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7CKSnCq077250
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 13:28:49 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=E9EgYRhmEZkNfzL8BHslTXNlA9PXe9dRZtQHbbrE7U3jy/oAP7NoOG0jBYvvaTSc
Message-ID: <4A832601.1030001@yahoo-inc.com>
Date: Wed, 12 Aug 2009 13:28:49 -0700
From: Konstantin Shvachko <shv@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: HADOOP-4539 question
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com> 	<4A7BECD9.20303@apache.org> <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com> 	<4A814BCD.2060500@apache.org> <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com> 	<77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com> 	<45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com> 	<4A8312C5.9080307@yahoo-inc.com> <45f85f70908121227o679f4887l9ec1c053270af40a@mail.gmail.com>
In-Reply-To: <45f85f70908121227o679f4887l9ec1c053270af40a@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

 > Gotcha - I thought the long term goal for the BN was to eventually have it
 > work as a "warm standby" that could convert into a NN without restart.

This is exactly the goal (long term). To evolve BN into StandbyNode,
which will be able to take over when main NN dies without restarting anything else.
And the only remaining step is to implement fail-over mechanism.

--Konstantin

Todd Lipcon wrote:
> On Wed, Aug 12, 2009 at 12:06 PM, Konstantin Shvachko <shv@yahoo-inc.com>wrote:
> 
>> Stas,
>>
>> There is no HA solution currently for Hadoop.
>> You can do things like Cloudera describes.
>> Their solution works with 2 real name-nodes.
>> No Backup node involved.
>>
>> As for Backup node, I don't really understand Todd's comment
>> but the fact is that Backup node (BN) is not a standby
>> node. The failover procedure is not implemented for BN,
>> so neither clients nor data-node don't fail-over anywhere
>> when the main name-node (NN) dies, they don't have a clue.
>>
> 
> Gotcha - I thought the long term goal for the BN was to eventually have it
> work as a "warm standby" that could convert into a NN without restart.
> 
> My mistake
> 
> -Todd
> 
> 
>> The purpose of the BN is
>> 1) to keep an up-to-date image of the namespace in memory.
>> This does not include block locations.
>> BN does not know where file blocks are.
>> 2) to make periodic checkpoints, like SecondaryNameNode did,
>> but more efficiently, since BN does not need to load image
>> and edits from NN, its namespace is already up-to-date.
>>
>> There is provision to transform BN to a real standby node,
>> with failover, but it has not been implemented yet.
>>
>> Hope this clarifies things.
>>
>> Thanks,
>> --Konstantin
>>
>>
>>
>> Todd Lipcon wrote:
>>
>>> On Wed, Aug 12, 2009 at 3:42 AM, Stas Oskin <stas.oskin@gmail.com> wrote:
>>>
>>>  Hi.
>>>>
>>>>  You can also use a utility like Linux-HA (aka heartbeat) to handle IP
>>>>> address failover. It will even send gratuitous ARPs to make sure to get
>>>>>
>>>> the
>>>>
>>>>> new mac address registered after a failover. Check out this blog for
>>>>> info
>>>>> about a setup like this:
>>>>>
>>>>> http://www.cloudera.com/blog/2009/07/22/hadoop-ha-configuration/
>>>>>
>>>>> Hope that helps
>>>>>
>>>>>  Thanks, exactly what I looked for :).
>>>>  I presume that with the coming BB node, there won't be need for DRBD, am
>>>> I
>>>> correct?
>>>>
>>>>
>>> I haven't followed that development closely, but I believe that's the
>>> case.
>>> The BackupNode will stream the FSEditLog writes as they occur while
>>> replaying them into its own FSNamesystem. Then during a failover a real
>>> NameNode starts on that FSNamesystem "ready to go". As for how the
>>> BackupNode keeps track of block locations, I'm not sure - is there a
>>> replication stream between BlockManagers too? Or is the cluster in a
>>> broken
>>> state until all of the DNs have processed new block reports?
>>>
>>> -Todd
>>>
>>>
> 

From common-user-return-16722-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:32:04 2009
Return-Path: <common-user-return-16722-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 79786 invoked from network); 12 Aug 2009 20:32:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:32:03 -0000
Received: (qmail 52144 invoked by uid 500); 12 Aug 2009 20:32:07 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52055 invoked by uid 500); 12 Aug 2009 20:32:07 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52045 invoked by uid 99); 12 Aug 2009 20:32:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:32:07 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of amansk@gmail.com designates 209.85.132.241 as permitted sender)
Received: from [209.85.132.241] (HELO an-out-0708.google.com) (209.85.132.241)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:31:59 +0000
Received: by an-out-0708.google.com with SMTP id c38so128889ana.29
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 13:31:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=WRw2djE2x2ntQ/RGzi1p2m6MY8M3x72h8SgOFiX8axg=;
        b=cRB0VSPoa5Hqt9Je6DI+eWaYpDCnXySZAI0N5c08R1Xpuy6Oi8DnNfDaztc5zYeUcK
         0pxTJ3SOaqS+NK5pQ839VJD+IKqspm+gjVppafulTpD8aiI9zmMYy+sgrBN/CSmTx67E
         VbiFRpRVa3ocHof7ow8Y+WLn/u19Hb+8ZKvjw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=FJ7MubscZItgqcYGITQGRknkL6FdwvUP6h0wD/vYm55Gmh18k2V+zoQXWFE20e+Noj
         HN202oFVZB+lnjvhEe0mX++eK4WdpM3tWmCAZBqymW8mGeva+YNdhrhluMTsM5dump4M
         BMh7LXsqa3ISKqhZx3pTBKNPMhaaB4aGhGcSg=
MIME-Version: 1.0
Received: by 10.101.59.5 with SMTP id m5mr418234ank.67.1250109098227; Wed, 12 
	Aug 2009 13:31:38 -0700 (PDT)
In-Reply-To: <4A8325BA.5030701@casalemedia.com>
References: <4A8322DE.4050003@casalemedia.com> <35a22e220908121319q26ba5c1q7c1e8ea2c5bfdb92@mail.gmail.com> 
	<4A8325BA.5030701@casalemedia.com>
From: Amandeep Khurana <amansk@gmail.com>
Date: Wed, 12 Aug 2009 13:31:18 -0700
Message-ID: <35a22e220908121331i5942874eu3076d5890122783@mail.gmail.com>
Subject: Re: I've probably hit some system limits
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636ed7465baf9200470f7b45c
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed7465baf9200470f7b45c
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Wed, Aug 12, 2009 at 1:27 PM, Mayuran Yogarajah <
mayuran.yogarajah@casalemedia.com> wrote:

> Hello,
>
> Amandeep Khurana wrote:
>
>> On Wed, Aug 12, 2009 at 1:15 PM, Mayuran Yogarajah <
>> mayuran.yogarajah@casalemedia.com> wrote:
>>
>>
>>
>>> I had 3 jobs running and I saw something a bit odd.  Two of the tasks
>>> are reducing, one of them is using all the reducers so the other is
>>> waiting, this is OK.  However the 3rd job is still in the mapping phase
>>> and even though the web interface shows map capacity at 96 I only
>>> see about 7-12 mappers actually running.  I'm wondering if theres
>>> some setting I need to change, perhaps I've hit some system limit.  Can
>>> someone point me in the right direction please?
>>>
>>>
>>>
>>
>> Are there any pending mappers remaining? Are you using any scheduler?
>>
>>
>>
> Yes there were pending mappers remaining, I'm not using any scheduler.
>

>
>>
>>> The other thing was that with the two jobs that are in the reducing
>>> phase,
>>> the reducer for one job wouldn't actually start until all the mappers of
>>> the
>>> _other_ job completed which seems kind of odd.  Is this expected ?
>>>
>>>
>>>
>>
>> Reducers dont really start the "reduce" phase till the mappers are
>> completed. However, the process gets spawned off and the copying of the
>> intermediate keys from the mapper starts off.
>>
>>
>>
>>
> That was my understanding for the same job but this was across two
> different jobs.  There
> were no reduce tasks running from job #2 until all of the map jobs of job
> #1 completed.
>
> On a side note I just saw this in the task tracker log, I don't know if its
> related:
> INFO org.mortbay.http.SocketListener: LOW ON THREADS ((40-40+0)<1) on
> SocketListener0@0.0.0.0:50060
> WARN org.mortbay.http.SocketListener: OUT OF THREADS:
> SocketListener0@0.0.0.0:50060
>

Ah.. That might be the issue.. I dont know the solution to this.. Wait for
someone else to answer. The mappers not starting could be because of this as
well.

Whats your cluster configuration? How many cpu's, RAM etc...?


>
>
> thanks,
> M
>
>

--001636ed7465baf9200470f7b45c--

From common-user-return-16723-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:34:38 2009
Return-Path: <common-user-return-16723-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81698 invoked from network); 12 Aug 2009 20:34:37 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:34:37 -0000
Received: (qmail 60094 invoked by uid 500); 12 Aug 2009 20:34:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 60016 invoked by uid 500); 12 Aug 2009 20:34:41 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 60006 invoked by uid 99); 12 Aug 2009 20:34:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:34:41 +0000
X-ASF-Spam-Status: No, hits=2.4 required=10.0
	tests=FS_REPLICA,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:34:31 +0000
Received: from [10.72.185.127] (gentlepaint-lx.corp.yahoo.com [10.72.185.127])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7CKX2d4079038
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 13:33:02 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=AQHatHukrfEEpMaPoWzV0d/edt+gLfbV35mWB37hb7i+asGjHp/m9yn1W/xQjxQh
Message-ID: <4A8326FE.5090107@yahoo-inc.com>
Date: Wed, 12 Aug 2009 13:33:02 -0700
From: Konstantin Shvachko <shv@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Doubt regarding Replication Factor
References: <2aa3aff80908121142r8d45025r39317d8e596d19b@mail.gmail.com> <4A8313FC.90506@yahoo-inc.com> <576200FF-0A56-45D7-9420-55D02173CD6C@cse.unl.edu>
In-Reply-To: <576200FF-0A56-45D7-9420-55D02173CD6C@cse.unl.edu>
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

This exactly true.
Thanks for correcting, Brian.

--Konstantin

Brian Bockelman wrote:
> 
> On Aug 12, 2009, at 2:11 PM, Konstantin Shvachko wrote:
> 
>> You can try it: start a 3 node cluster and create a file with 
>> replication 5.
>>
>> The answer is that each data-node can store only one replica of a block.
>> So in your case you will get an exception on close() saying the file 
>> cannot
>> be fully replicated.
>>
> 
> I'm not sure if that's true.  You only get an exception if the system 
> cannot provide the minimum replication factor.
> 
> I.e, if you ask for 5 replicas and the minimum replicas is 3, then you 
> only get an exception if HDFS can't meet 3 replicas.
> 
> Am I recalling this wrong?  We have "discovered" this fact at least once :)
> 
> Brian
> 
>> Thanks,
>> --Konstantin
>>
>> Rakhi Khatwani wrote:
>>> Hi,
>>>   I just wanted to know what if we have set the replication factor 
>>> greater
>>> than the number of nodes in the cluster.
>>> for example, i have only 3 nodes in my cluster but i set the replication
>>> factor to 5.
>>> will it create 3 copies and save it in each node, or can it create 
>>> more than
>>> one copy per node?
>>> Regards,
>>> Raakhi Khatwani
> 

From common-user-return-16724-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:37:09 2009
Return-Path: <common-user-return-16724-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 83882 invoked from network); 12 Aug 2009 20:37:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:37:09 -0000
Received: (qmail 67041 invoked by uid 500); 12 Aug 2009 20:37:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 66963 invoked by uid 500); 12 Aug 2009 20:37:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 66953 invoked by uid 99); 12 Aug 2009 20:37:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:37:14 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [192.139.80.206] (HELO mx1.casalemedia.com) (192.139.80.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:37:04 +0000
Received: from exchange.casalemedia.com (unknown [10.3.10.15])
	by mx1.casalemedia.com (Postfix) with ESMTP id 503FB588011
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 16:36:44 -0400 (EDT)
Received: from mayuran.casalemedia.com (10.3.10.40) by
 exchange.casalemedia.com (10.3.10.15) with Microsoft SMTP Server id
 8.1.240.5; Wed, 12 Aug 2009 16:36:44 -0400
Message-ID: <4A8327D5.6030107@casalemedia.com>
Date: Wed, 12 Aug 2009 16:36:37 -0400
From: Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: Re: I've probably hit some system limits
References: <4A8322DE.4050003@casalemedia.com> <35a22e220908121319q26ba5c1q7c1e8ea2c5bfdb92@mail.gmail.com> 	<4A8325BA.5030701@casalemedia.com> <35a22e220908121331i5942874eu3076d5890122783@mail.gmail.com>
In-Reply-To: <35a22e220908121331i5942874eu3076d5890122783@mail.gmail.com>
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Amandeep Khurana wrote:
>
> Ah.. That might be the issue.. I dont know the solution to this.. Wait for
> someone else to answer. The mappers not starting could be because of this as
> well.
>
> Whats your cluster configuration? How many cpu's, RAM etc...?
>
>   
There are 6 servers in the cluster, they're all the same hardware 
cpu/ram wise: 2xquad core
and 6gigs of ram.

thanks,
M



From common-user-return-16725-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:43:30 2009
Return-Path: <common-user-return-16725-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 86550 invoked from network); 12 Aug 2009 20:43:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:43:29 -0000
Received: (qmail 81825 invoked by uid 500); 12 Aug 2009 20:43:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 81735 invoked by uid 500); 12 Aug 2009 20:43:33 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 81725 invoked by uid 99); 12 Aug 2009 20:43:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:43:33 +0000
X-ASF-Spam-Status: No, hits=-4.0 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bbansal@linkedin.com designates 69.28.149.25 as permitted sender)
Received: from [69.28.149.25] (HELO esv4-mav03.corp.linkedin.com) (69.28.149.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:43:22 +0000
DomainKey-Signature: s=prod; d=linkedin.com; c=nofws; q=dns;
  h=X-IronPort-AV:Received:User-Agent:Date:Subject:From:To:
   Message-ID:Thread-Topic:Thread-Index:In-Reply-To:
   Mime-version:Content-type:Content-transfer-encoding;
  b=rze62y4Ccae5QDNxNNwzgXQzd5eAU5LIDZnqT4L7upa/qgFAeNAt7Mlx
   StojiT4rLQDM/3slMvljE1ZLK83LFsc+6zVYZxlnJHpAuRoxEmShCoQfH
   0OdLbGMctqL1WY5;
DKIM-Signature: v=1; a=rsa-sha256; c=simple/simple;
  d=linkedin.com; i=bbansal@linkedin.com; q=dns/txt;
  s=proddkim; t=1250109802; x=1281645802;
  h=from:sender:reply-to:subject:date:message-id:to:cc:
   mime-version:content-transfer-encoding:content-id:
   content-description:resent-date:resent-from:resent-sender:
   resent-to:resent-cc:resent-message-id:in-reply-to:
   references:list-id:list-help:list-unsubscribe:
   list-subscribe:list-post:list-owner:list-archive;
  z=From:=20Bhupesh=20Bansal=20<bbansal@linkedin.com>
   |Subject:=20Re:=20I've=20probably=20hit=20some=20system
   =20limits|Date:=20Wed,=2012=20Aug=202009=2013:41:05=20-07
   00|Message-ID:=20<C6A876F1.248DC%bbansal@linkedin.com>
   |To:=20<common-user@hadoop.apache.org>|Mime-version:=201.
   0|Content-transfer-encoding:=207bit|In-Reply-To:=20<4A832
   7D5.6030107@casalemedia.com>;
  bh=wBPY1IF1VUU4Fi+guxNBbRK3oJ2s4TCk9I3wcdi5luU=;
  b=pZ9VphnVjIiC+c3oxZWoBrm9L6sl4NTzlsuvmyC1jsCP5usBOqeMcIqr
   6XszML6lyLGAt1LvFCBA+NQwRY1tjUFlPVulTnYqntZ65UtovoH1qM05z
   ad4anmdAYFFQ2KY;
X-IronPort-AV: E=Sophos;i="4.43,370,1246863600"; 
   d="scan'208";a="8128438"
Received: from 172.16.20.217 ([172.16.20.217]) by CORP-MAIL.linkedin.biz ([172.18.46.135]) via Exchange Front-End Server mail-access.linkedin.biz ([172.18.46.133]) with Microsoft Exchange Server HTTP-DAV ;
 Wed, 12 Aug 2009 20:42:27 +0000
User-Agent: Microsoft-Entourage/11.4.0.080122
Date: Wed, 12 Aug 2009 13:41:05 -0700
Subject: Re: I've probably hit some system limits
From: Bhupesh Bansal <bbansal@linkedin.com>
To: <common-user@hadoop.apache.org>
Message-ID: <C6A876F1.248DC%bbansal@linkedin.com>
Thread-Topic: I've probably hit some system limits
Thread-Index: AcobjTZedQbA/oeAEd6DbAAj3+AmKA==
In-Reply-To: <4A8327D5.6030107@casalemedia.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Mayuran, 

One reason might be that the input data is available only on few nodes and
Hence only that node is being used for mappers .. You should be able to run
A dfs fsck and see for the input path how many actual replicas do you have.


Otherwise go to the slaves and take a thread-dump for all java child
processes ?? (kill -3) The threaddump will go into hadoop logs and you can
look them through hadoop UI if the mappers are getting stuck somewhere.

Best
Bhupesh


On 8/12/09 1:36 PM, "Mayuran Yogarajah" <mayuran.yogarajah@casalemedia.com>
wrote:

> Amandeep Khurana wrote:
>> 
>> Ah.. That might be the issue.. I dont know the solution to this.. Wait for
>> someone else to answer. The mappers not starting could be because of this as
>> well.
>> 
>> Whats your cluster configuration? How many cpu's, RAM etc...?
>> 
>>   
> There are 6 servers in the cluster, they're all the same hardware
> cpu/ram wise: 2xquad core
> and 6gigs of ram.
> 
> thanks,
> M
> 
> 


From common-user-return-16726-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 20:44:37 2009
Return-Path: <common-user-return-16726-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 86910 invoked from network); 12 Aug 2009 20:44:37 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 20:44:37 -0000
Received: (qmail 86810 invoked by uid 500); 12 Aug 2009 20:44:41 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 86725 invoked by uid 500); 12 Aug 2009 20:44:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 86649 invoked by uid 99); 12 Aug 2009 20:44:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:44:40 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of amansk@gmail.com designates 209.85.211.188 as permitted sender)
Received: from [209.85.211.188] (HELO mail-yw0-f188.google.com) (209.85.211.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 20:44:31 +0000
Received: by ywh26 with SMTP id 26so428303ywh.5
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 13:44:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=EQOp+e6bALbQyd5+YP5q/nci6StatezVN8xLAno5XQQ=;
        b=msoBwtz8JCpO5RHNIpnd5/4TFygQX+WqO3/v5ZpE6pclnPs7fJryTS8sVIDJMI5wgZ
         BH+PeFLHQTk8PQAj21V6j2dQ2EUcIH7mPvtAXRukDVKP9lSZPyp5NKmFeIjxK4bbbFfT
         NeboTU29dWbv3FVlLsYVMy96dF/lsN6jQM2UM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=F0Qi9my7yfKMT0DaaRbhtDo6+zlWPZup5J9dCfhCAFmTeYSwRRDWAeTcMI2Cgn3QE9
         mDMXF5/NV3hP0CpvcYQpXKGF2xgrr1VGBz2zbwaX+zpf3Gyo8yqXxLLhataMhET846dS
         z1lZcaX+8T0VG0RusPRLdF9dZJR8q8vXjhyZs=
MIME-Version: 1.0
Received: by 10.100.141.10 with SMTP id o10mr429390and.82.1250109850863; Wed, 
	12 Aug 2009 13:44:10 -0700 (PDT)
In-Reply-To: <4A8327D5.6030107@casalemedia.com>
References: <4A8322DE.4050003@casalemedia.com>
	 <35a22e220908121319q26ba5c1q7c1e8ea2c5bfdb92@mail.gmail.com>
	 <4A8325BA.5030701@casalemedia.com>
	 <35a22e220908121331i5942874eu3076d5890122783@mail.gmail.com>
	 <4A8327D5.6030107@casalemedia.com>
Date: Wed, 12 Aug 2009 13:44:10 -0700
Message-ID: <35a22e220908121344h68f8bce2jeb98f298a75d9d36@mail.gmail.com>
Subject: Re: I've probably hit some system limits
From: Amandeep Khurana <amansk@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

So you are running 16 map tasks per node? Plus 2 reducers?
I think that's high. With 6gb RAM, you should be looking at around 2
map tasks plus 1 reducer...
I have 9 nodes with quad core + 8gb RAM and I run 2M+1R on each node..

How much heap size have you given your hadoop instance?

Also, is there a lot of processing going on in the mappers and reducers?

On 8/12/09, Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com> wrote:
> Amandeep Khurana wrote:
>>
>> Ah.. That might be the issue.. I dont know the solution to this.. Wait for
>> someone else to answer. The mappers not starting could be because of this
>> as
>> well.
>>
>> Whats your cluster configuration? How many cpu's, RAM etc...?
>>
>>
> There are 6 servers in the cluster, they're all the same hardware
> cpu/ram wise: 2xquad core
> and 6gigs of ram.
>
> thanks,
> M
>
>
>


-- 


Amandeep Khurana
Computer Science Graduate Student
University of California, Santa Cruz

From common-user-return-16727-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 21:02:28 2009
Return-Path: <common-user-return-16727-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 92518 invoked from network); 12 Aug 2009 21:02:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 21:02:28 -0000
Received: (qmail 2896 invoked by uid 500); 12 Aug 2009 21:02:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 2801 invoked by uid 500); 12 Aug 2009 21:02:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 2791 invoked by uid 99); 12 Aug 2009 21:02:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 21:02:32 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 21:02:23 +0000
Received: by qw-out-2122.google.com with SMTP id 8so113601qwh.35
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 14:02:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.66.136 with SMTP id n8mr637360qai.328.1250110922190; Wed, 
	12 Aug 2009 14:02:02 -0700 (PDT)
In-Reply-To: <4A81CC30.1020003@Gmail.com>
References: <8131791a0907300127n7874c2b1l290b66d08a8a838@mail.gmail.com> 
	<4A7191C1.2040503@apache.org> <4A719468.4070602@gmail.com> 
	<4A81CC30.1020003@Gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 12 Aug 2009 14:01:42 -0700
Message-ID: <d6d7c4410908121401v6601a687h1ceb7a5503331b9b@mail.gmail.com>
Subject: Re: Need info about "mapred.input.format.skew"
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00c09f88d0fb7270f50470f8211c
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09f88d0fb7270f50470f8211c
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Cubic,

I don't see that string appear anywhere in the MapReduce trunk source.
Where'd you come across this?
- Aaron

On Tue, Aug 11, 2009 at 12:53 PM, CubicDesign <cubicdesign@gmail.com> wrote:

> Hi.
>
> Can anybody point me to the Apache documentation page for
> "mapred.input.format.skew" ?
> I cannot find the documentation for this parameter.
>
> What does it mean?
>
> Thanks
>

--00c09f88d0fb7270f50470f8211c--

From common-user-return-16728-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 21:04:18 2009
Return-Path: <common-user-return-16728-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 93361 invoked from network); 12 Aug 2009 21:04:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 21:04:17 -0000
Received: (qmail 7275 invoked by uid 500); 12 Aug 2009 21:04:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 7180 invoked by uid 500); 12 Aug 2009 21:04:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 7169 invoked by uid 99); 12 Aug 2009 21:04:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 21:04:22 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 21:04:12 +0000
Received: by qyk26 with SMTP id 26so288562qyk.5
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 14:03:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.83.21 with SMTP id d21mr659039qal.10.1250111031253; Wed, 
	12 Aug 2009 14:03:51 -0700 (PDT)
In-Reply-To: <c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com>
References: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com> 
	<c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 12 Aug 2009 14:03:30 -0700
Message-ID: <d6d7c4410908121403y96ce158k87408df8d9ab11cc@mail.gmail.com>
Subject: Re: What will we encounter if we add a lot of nodes into the current 
	cluster?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000feaf10899f3e5930470f827a5
X-Virus-Checked: Checked by ClamAV on apache.org

--000feaf10899f3e5930470f827a5
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Also, if you haven't yet configured rack awareness, now's a good time to
start :)
- Aaron

On Tue, Aug 11, 2009 at 11:27 PM, Ted Dunning <ted.dunning@gmail.com> wrote:

> If you add these nodes, data will be put on them as you add data to the
> cluster.
>
> Soon after adding the nodes you should rebalance the storage to avoid age
> related surprises in how files are arranged in your cluster.
>
> Other than that, your addition should cause little in the way of surprises.
>
> On Tue, Aug 11, 2009 at 11:00 PM, yang song <hadoop.inifok@gmail.com>
> wrote:
>
> > Dear all
> >    I'm sorry to disturb you.
> >    Our cluster has 200 nodes now. In order to improve its ability, we
> hope
> > to add 60 nodes into the current cluster. However, we all don't know what
> > will happen if we add so many nodes at the same time. Could you give me
> > some
> > tips and notes? During the process, which part shall we pay much
> attention
> > on?
> >    Thank you!
> >
> >    P.S. Our environment is hadoop-0.19.1, jdk1.6.0_06, linux redhat
> > enterprise 4.0
> >
>
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>

--000feaf10899f3e5930470f827a5--

From common-user-return-16729-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 21:15:25 2009
Return-Path: <common-user-return-16729-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 99640 invoked from network); 12 Aug 2009 21:15:24 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 21:15:24 -0000
Received: (qmail 27172 invoked by uid 500); 12 Aug 2009 21:15:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 27068 invoked by uid 500); 12 Aug 2009 21:15:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 27058 invoked by uid 99); 12 Aug 2009 21:15:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 21:15:29 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [192.139.80.206] (HELO mx1.casalemedia.com) (192.139.80.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 21:15:21 +0000
Received: from exchange.casalemedia.com (unknown [10.3.10.15])
	by mx1.casalemedia.com (Postfix) with ESMTP id 6F99F440001
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 17:15:00 -0400 (EDT)
Received: from mayuran.casalemedia.com (10.3.10.40) by
 exchange.casalemedia.com (10.3.10.15) with Microsoft SMTP Server id
 8.1.240.5; Wed, 12 Aug 2009 17:15:00 -0400
Message-ID: <4A8330CD.9070805@casalemedia.com>
Date: Wed, 12 Aug 2009 17:14:53 -0400
From: Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: Re: I've probably hit some system limits
References: <4A8322DE.4050003@casalemedia.com>	 <35a22e220908121319q26ba5c1q7c1e8ea2c5bfdb92@mail.gmail.com>	 <4A8325BA.5030701@casalemedia.com>	 <35a22e220908121331i5942874eu3076d5890122783@mail.gmail.com>	 <4A8327D5.6030107@casalemedia.com> <35a22e220908121344h68f8bce2jeb98f298a75d9d36@mail.gmail.com>
In-Reply-To: <35a22e220908121344h68f8bce2jeb98f298a75d9d36@mail.gmail.com>
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

Amandeep Khurana wrote:
> So you are running 16 map tasks per node? Plus 2 reducers?
>   
Thats correct.
> I think that's high. With 6gb RAM, you should be looking at around 2
> map tasks plus 1 reducer...
> I have 9 nodes with quad core + 8gb RAM and I run 2M+1R on each node..
>
>   
I thought the number of maps should be set to 1/2 - 2 * number of cpus, 
thats why
we set it so high.  Right now I've set:
mapred.tasktracker.map.tasks.maximum = 16
mapred.tasktracker.reduce.tasks.maximum = 16

So the max mappers/reducers is 96/96.

> How much heap size have you given your hadoop instance?
>
> Also, is there a lot of processing going on in the mappers and reducers?
>
>   
Yes these are pretty intensive jobs.

thanks,
M

From common-user-return-16730-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 12 22:24:45 2009
Return-Path: <common-user-return-16730-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 41691 invoked from network); 12 Aug 2009 22:24:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 12 Aug 2009 22:24:45 -0000
Received: (qmail 10973 invoked by uid 500); 12 Aug 2009 22:24:50 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10870 invoked by uid 500); 12 Aug 2009 22:24:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10860 invoked by uid 99); 12 Aug 2009 22:24:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 22:24:49 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of amansk@gmail.com designates 209.85.211.188 as permitted sender)
Received: from [209.85.211.188] (HELO mail-yw0-f188.google.com) (209.85.211.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 12 Aug 2009 22:24:40 +0000
Received: by ywh26 with SMTP id 26so512928ywh.5
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 15:24:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=IDqXfdHdV/c2mW4GYYSKbBQ4tTZxxYz958nbkCKplyU=;
        b=aSajtDr3NoA4n43xnQ4nEZYapVcVKcDyWhNsYX69lxg0j8rrldzrPJRr7qEAwvLNfj
         +D97a3RvDutRKhqVCRj8WxHXua5Zu4pQqOtX+la06R08VgXgXwNa66iWgx4n7zMLg39h
         1kL2fke+lrAATXOtfXWVvWUDSXt35KhPqZYJQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=G3J3jW8aI8Ec7QpsI0NM7ygIdXlt4Wy+0lQ4M32Ls5K3loSYj4OnOPZxl9bvc6QYRP
         O2D43LLUVo2lfzXRB+AOe4QebmTOob+czuwvDycw/hf90LUX4VB/AWxe6oppm9Ywhbvf
         5is/1d8mMlNGEzTzFBJgP2kLY8p9GNjWpkhKE=
MIME-Version: 1.0
Received: by 10.100.172.18 with SMTP id u18mr513978ane.23.1250115859156; Wed, 
	12 Aug 2009 15:24:19 -0700 (PDT)
In-Reply-To: <4A8330CD.9070805@casalemedia.com>
References: <4A8322DE.4050003@casalemedia.com> <35a22e220908121319q26ba5c1q7c1e8ea2c5bfdb92@mail.gmail.com> 
	<4A8325BA.5030701@casalemedia.com> <35a22e220908121331i5942874eu3076d5890122783@mail.gmail.com> 
	<4A8327D5.6030107@casalemedia.com> <35a22e220908121344h68f8bce2jeb98f298a75d9d36@mail.gmail.com> 
	<4A8330CD.9070805@casalemedia.com>
From: Amandeep Khurana <amansk@gmail.com>
Date: Wed, 12 Aug 2009 15:23:59 -0700
Message-ID: <35a22e220908121523r55de762cq90e7eb2745211c9@mail.gmail.com>
Subject: Re: I've probably hit some system limits
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016368e1a96b6901e0470f947ee
X-Virus-Checked: Checked by ClamAV on apache.org

--0016368e1a96b6901e0470f947ee
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Wed, Aug 12, 2009 at 2:14 PM, Mayuran Yogarajah <
mayuran.yogarajah@casalemedia.com> wrote:

> Hello,
>
> Amandeep Khurana wrote:
>
>> So you are running 16 map tasks per node? Plus 2 reducers?
>>
>>
> Thats correct.
>
>> I think that's high. With 6gb RAM, you should be looking at around 2
>> map tasks plus 1 reducer...
>> I have 9 nodes with quad core + 8gb RAM and I run 2M+1R on each node..
>>
>>
>>
> I thought the number of maps should be set to 1/2 - 2 * number of cpus,
> thats why
> we set it so high.  Right now I've set:
> mapred.tasktracker.map.tasks.maximum = 16
> mapred.tasktracker.reduce.tasks.maximum = 16
>

Its 2*number of nodes
Moreover, its not only the CPU's, but also the RAM that matters.. Plus I/O..
Now, I'm not sure if you are I/O bound on this job or not, but thats also a
consideration.

Reduce the number to 2+1 and see how it goes. Once things work stably,
increase the mapper by 2 and see.. You'll have to try a few times before
you'll find out the optimal number for your setup.



>
> So the max mappers/reducers is 96/96.
>
>  How much heap size have you given your hadoop instance?
>>
>> Also, is there a lot of processing going on in the mappers and reducers?
>>
>>
>>
> Yes these are pretty intensive jobs.
>
> thanks,
> M
>

--0016368e1a96b6901e0470f947ee--

From common-user-return-16731-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 02:36:57 2009
Return-Path: <common-user-return-16731-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 14921 invoked from network); 13 Aug 2009 02:36:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 02:36:56 -0000
Received: (qmail 20316 invoked by uid 500); 13 Aug 2009 02:37:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20256 invoked by uid 500); 13 Aug 2009 02:37:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20246 invoked by uid 99); 13 Aug 2009 02:37:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 02:37:00 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.211.172 as permitted sender)
Received: from [209.85.211.172] (HELO mail-yw0-f172.google.com) (209.85.211.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 02:36:52 +0000
Received: by ywh2 with SMTP id 2so708144ywh.2
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 19:36:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=tHuAl5jkBCrqAJJmwpckWKUjwcE/igXhFhMFG2KV7/Y=;
        b=bb9dMVqf6dooYeHrhX7XFy+rj7TN6fZ5pNFH72lgouzkWTn37e+OKddi5RoHmOIhEe
         g2mVOE993YkNF8/el7T4KnV5oPDkQETPMWLCat1bSRU/t6fOYG+0qQ63qyJh4/DQhDng
         odFDWxOyqlWJnNYY2rrd2ouTbWdgd2w8oi88Y=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=cvsihxK18vzZYLTbzxnIYu0inWe61UhnTDPbpRYeLdQlz4k9Px6rqtHRvUliC9ejpV
         x14Z1Zj5OdCvKxnH0T61Ynww7PwKSNyLcjtKzq6o/GYYnOb2kv9eHEV0XKedFm87NcFk
         dhYcpG50wEsolsEOV2rsY+Lb3HVx0agLJjC0E=
MIME-Version: 1.0
Received: by 10.100.56.19 with SMTP id e19mr618188ana.6.1250130991902; Wed, 12 
	Aug 2009 19:36:31 -0700 (PDT)
In-Reply-To: <c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com>
References: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com>
	 <c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com>
Date: Thu, 13 Aug 2009 10:36:31 +0800
Message-ID: <3b1311780908121936h5895a966r264a2bbd76a2c82e@mail.gmail.com>
Subject: Re: What will we encounter if we add a lot of nodes into the current 
	cluster?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6475b02b1efc40470fccda6
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6475b02b1efc40470fccda6
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thank you for teaching me that.

I'm trying to use the balance tool(bin/hadoop balancer -t xxx). However, the
data transfer is so slow that it will take a long long time.
Is there a good method to solve it?

What's more, I have a puzzle. The situation is we rarely use the existed
data in the cluster. That means to rebalance existed data is not that worth.
So, I intend to not rebalance the data. Is my opinion right?

Thank you.

2009/8/12 Ted Dunning <ted.dunning@gmail.com>

> If you add these nodes, data will be put on them as you add data to the
> cluster.
>
> Soon after adding the nodes you should rebalance the storage to avoid age
> related surprises in how files are arranged in your cluster.
>
> Other than that, your addition should cause little in the way of surprises.
>
> On Tue, Aug 11, 2009 at 11:00 PM, yang song <hadoop.inifok@gmail.com>
> wrote:
>
> > Dear all
> >    I'm sorry to disturb you.
> >    Our cluster has 200 nodes now. In order to improve its ability, we
> hope
> > to add 60 nodes into the current cluster. However, we all don't know what
> > will happen if we add so many nodes at the same time. Could you give me
> > some
> > tips and notes? During the process, which part shall we pay much
> attention
> > on?
> >    Thank you!
> >
> >    P.S. Our environment is hadoop-0.19.1, jdk1.6.0_06, linux redhat
> > enterprise 4.0
> >
>
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>

--0016e6475b02b1efc40470fccda6--

From common-user-return-16732-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 04:15:21 2009
Return-Path: <common-user-return-16732-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 32199 invoked from network); 13 Aug 2009 04:15:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 04:15:21 -0000
Received: (qmail 82468 invoked by uid 500); 13 Aug 2009 04:15:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82380 invoked by uid 500); 13 Aug 2009 04:15:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82370 invoked by uid 99); 13 Aug 2009 04:15:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 04:15:26 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.200.170 as permitted sender)
Received: from [209.85.200.170] (HELO wf-out-1314.google.com) (209.85.200.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 04:15:17 +0000
Received: by wf-out-1314.google.com with SMTP id 23so145700wfg.2
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 21:14:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=T3myi0+wkgMSSgxHRFCWVxIE/lV0HhfafrYC+SpbB/w=;
        b=QGt3JGGghx5d5a9x8to7D3mQL62cT5ossJjLnZBR8hc4vfsg0nrpyaH/NdNvDdmnQS
         epi6j85NMUAXMerNdTEYokQhot8MvP7Aq8PA/kFaocd/ccrI31IdpkN4t/oJjLGkzu9d
         p7TmrIn+P6eFlKDKOqxm9od3DpSEHUlki1Jk0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=HXrT+CPXmJ8fC2zNNoPnmksC+8K/dE+1VpTjg82rkbyn+B+vxsSoBfv0niBN+EOGmM
         MytGQYiZYFEebT0TLMDEEUDx3cVLolLuBgAixRGiwgOYiJejwLSjZlHhruW6pB5nm6PG
         MJUEhRWenB6pG2MSz4GHab9UAUUN8SWpnYWno=
MIME-Version: 1.0
Received: by 10.142.208.14 with SMTP id f14mr112431wfg.252.1250136896124; Wed, 
	12 Aug 2009 21:14:56 -0700 (PDT)
In-Reply-To: <3b1311780908121936h5895a966r264a2bbd76a2c82e@mail.gmail.com>
References: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com> 
	<c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com> 
	<3b1311780908121936h5895a966r264a2bbd76a2c82e@mail.gmail.com>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Thu, 13 Aug 2009 09:44:36 +0530
Message-ID: <e01b80590908122114i71903a73r163dff1d148dfa75@mail.gmail.com>
Subject: Re: What will we encounter if we add a lot of nodes into the current 
	cluster?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd29c809d38b10470fe2d52
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd29c809d38b10470fe2d52
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 13, 2009 at 8:06 AM, yang song <hadoop.inifok@gmail.com> wrote:

> Thank you for teaching me that.
>
> I'm trying to use the balance tool(bin/hadoop balancer -t xxx). However,
> the
> data transfer is so slow that it will take a long long time.
> Is there a good method to solve it?
>
> What's more, I have a puzzle. The situation is we rarely use the existed
> data in the cluster. That means to rebalance existed data is not that
> worth.
> So, I intend to not rebalance the data. Is my opinion right?
>
>
I think after you add new nodes to the cluster and if you don't rebalance,
hadoop is probably going to pick the new nodes over the older ones for all
the new data that you write into HDFS. As a result even your new data is
probably going to be not balanced evenly across the cluster. If you're going
to run m/r jobs on this new data, then it's a good idea to have that spread
across the cluster evenly.

-- 
Harish Mallipeddi
http://blog.poundbang.in

--000e0cd29c809d38b10470fe2d52--

From common-user-return-16733-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 04:16:28 2009
Return-Path: <common-user-return-16733-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 32325 invoked from network); 13 Aug 2009 04:16:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 04:16:28 -0000
Received: (qmail 84369 invoked by uid 500); 13 Aug 2009 04:16:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 84272 invoked by uid 500); 13 Aug 2009 04:16:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 84258 invoked by uid 99); 13 Aug 2009 04:16:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 04:16:32 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pallavi.palleti@corp.aol.com designates 64.12.143.147 as permitted sender)
Received: from [64.12.143.147] (HELO omr-m35.mx.aol.com) (64.12.143.147)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 04:16:22 +0000
Received: from AOLMTCMEH01.ad.office.aol.com (aolmtcmeh01.office.aol.com [10.178.121.20]) by omr-m35.mx.aol.com (v117.7) with ESMTP id MAILOMRM354-7f3b4a83937e26e; Thu, 13 Aug 2009 00:15:58 -0400
Received: from AOLMTCMEI02.ad.office.aol.com ([10.178.3.19]) by AOLMTCMEH01.ad.office.aol.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Thu, 13 Aug 2009 00:15:58 -0400
Received: from localhost ([10.178.3.11]) by AOLMTCMEI02.ad.office.aol.com over TLS secured channel with Microsoft SMTPSVC(6.0.3790.3959);
	 Thu, 13 Aug 2009 00:15:57 -0400
Date: Thu, 13 Aug 2009 09:45:51 +0530 (GMT+05:30)
From: Pallavi Palleti <pallavi.palleti@corp.aol.com>
To: common-user@hadoop.apache.org
Message-ID: <24282036.661250136946160.JavaMail.pallavi@e1a31053e.in.office.aol.com>
In-Reply-To: <4A82F05B.6030009@yahoo-inc.com>
Subject: Re: File is closed but data is not visible
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-OriginalArrivalTime: 13 Aug 2009 04:15:58.0200 (UTC) FILETIME=[C2629780:01CA1BCC]
X-AOL-IP: 10.178.121.20
X-Virus-Checked: Checked by ClamAV on apache.org

yes.
----- Original Message -----
From: "Raghu Angadi" <rangadi@yahoo-inc.com>
To: common-user@hadoop.apache.org
Sent: Wednesday, August 12, 2009 10:09:55 PM GMT +05:30 Chennai, Kolkata, Mumbai, New Delhi
Subject: Re: File is closed but data is not visible


What happens when the while loop ends? Is 'out' closed then?

Palleti, Pallavi wrote:
> No. I am closing it before opening a new one
> 
> if (out != null) // if any output stream opened previously ,  close it
>           {
>             logger.info("Closing writer of -" + 
>  paramWrapper.getOutFileStr());
>             out.close();
>             out = null;
>           }
> 
> Thanks
> Pallavi
> 
> -----Original Message-----
> From: Jason Venner [mailto:jason.hadoop@gmail.com] 
> Sent: Wednesday, August 12, 2009 7:31 PM
> To: common-user@hadoop.apache.org
> Subject: Re: File is closed but data is not visible
> 
> You do not appear to close out, except when an exception occurs.
> The finally block only closes the reader.
> 
> On Wed, Aug 12, 2009 at 6:24 AM, Palleti, Pallavi <
> pallavi.palleti@corp.aol.com> wrote:
> 
>> Hi Jason,
>>
>> Kindly find the snippet of code which creates and close file.
>>
>> Variables passed to the method:FSDataOutputStream out,ParamWrapper
>> paramWrapper
>>
>> Snippet:
>>
>>    String inputLine = null;
>>    int status = 0;
>>
>>    BufferedReader reader = null;
>>
>>    try {
>>      reader = new BufferedReader(new InputStreamReader(....); //reader
>> initialization
>>
>>      while ((inputLine = reader.readLine()) != null) {
>>
>>        Date date = getLoggedDate(inputLine); // process the line to
> get
>> input and if it is wrong
>>        if (date == null) // if input data is wrong, don't write
>>        {
>>          continue;
>>        }
>>        Calendar cal = Calendar.getInstance();
>>        cal.setTime(date);
>>        int hour = cal.get(Calendar.HOUR_OF_DAY); // get input hour
>>        int minutes = cal.get(Calendar.MINUTE); // get input minute
>>
>>        int outputMinute = minutes / timePeriod + 1; // compute the
> slot
>>        if (paramWrapper.prevHour != hour
>>            || paramWrapper.prevMin != outputMinute) // if it is a new
>> slot
>>        {
>>
>>          if (out != null) // if any output stream opened previously ,
>> close it
>>          {
>>            logger.info("Closing writer of -" +
>> paramWrapper.getOutFileStr());
>>            out.close();
>>            out = null;
>>          }
>>          String outFileStr = generateFileName(rootDir,
>> hdfsOutFile,outputMinute, date); // generate file name ex:
>> location/year/month/day/hour/_1.txt
>>          Path outFile = new Path(outFileStr);
>>
>>          paramWrapper.setOutFileStr(outFileStr);
>>          logger.info("Creating outFile:" + outFileStr);
>>
>>          out = fs.create(outFile); // create new file and get
>>          // output stream
>>          paramWrapper.setPrevHour(hour);
>>          paramWrapper.setPrevMin(outputMinute);
>>        }
>>        StringBuilder outLineStr = new StringBuilder();
>>        outLineStr.append(inputLine).append("\n");
>>        out.write(outLineStr.toString().getBytes());
>>      }
>>    } catch (IOException ioe) {
>>      logger.error("Main: IO Exception while writing to HDFS,
> exiting...
>> ", ioe);
>>      // before exiting do the cleanup
>>      close(reader);
>>      System.exit(-1);
>>
>>    } catch (Exception e) {
>>      logger.error("Unexpected error while writing to HDFS, exiting
>> ...", e);
>>      // before exiting do the cleanup
>>      close(reader);
>>
>>      System.exit(-1);
>>    } finally {
>>      close(reader);
>>     }
>>
>> Thanks
>> Pallavi
>>
>>
>> -----Original Message-----
>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>> Sent: Wednesday, August 12, 2009 6:35 PM
>> To: common-user@hadoop.apache.org
>> Subject: Re: File is closed but data is not visible
>>
>> Are you explicitly calling close on the FSDataOutputStream that you
>> received
>> from the FileSystem.create method?
>> It sounds like the close is actually happening in the finalizer method
>> on
>> the object.
>>
>> Can you post the relevant code, or provide a cut down demonstrator?
>>
>> On Wed, Aug 12, 2009 at 5:57 AM, Palleti, Pallavi <
>> pallavi.palleti@corp.aol.com> wrote:
>>
>>> Hi Jason,
>>>
>>> The file is neither visible via Namenode UI nor via program(checking
>>> whether a file exists).
>>>
>>> There is no caching happening at the application level. The
>> application
>>> is pretty simple. We are taking apache logs and trying to put into
>>> timely buckets based on the logged time of records. We are creating
> 4
>>> files(one for every 15 minutes) for every hour. So, at the client
>> side,
>>> we are looking into the logs and see if the data belongs to the
>> current
>>> interval, then we are writing into the currently opened HDFS file.
> If
>> it
>>> belongs to new interval, the old file is closed and new file is
>> created.
>>> I have been logging the time at which the file is being created and
> at
>>> which the file is being closed at my client side. And, I could see
>> that
>>> the file is getting closed at expected time period. But, when I look
>> for
>>> the same file in hadoop cluster, it is still not created and if I
> wait
>>> for another 1 to 2 hours, I could see the file.
>>>
>>> Thanks
>>> Pallavi
>>>
>>>
>>> -----Original Message-----
>>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>>> Sent: Wednesday, August 12, 2009 6:03 PM
>>> To: common-user@hadoop.apache.org
>>> Subject: Re: File is closed but data is not visible
>>>
>>> Is it possible that your application is caching some data and not
>>> refreshing
>>> it when you expect?
>>> The HDFS file visibility semantics are well understood, and your
> case
>>> does
>>> not fit with that understanding.
>>> A factor that hints strongly at this is that your file is visible
> via
>>> the
>>> Namenode UI, there is nothing special about that UI
>>>
>>> On Tue, Aug 11, 2009 at 9:00 PM, Pallavi Palleti <
>>> pallavi.palleti@corp.aol.com> wrote:
>>>
>>>> Hi Raghu,
>>>>
>>>> The file doesn't appear in the cluster when I saw it from Namenode
>> UI.
>>>> Also, I have a monitor at cluster side which checks whether file
> is
>>> created
>>>> and throws an exception when it is not created. And, it threw an
>>> exception
>>>> saying "File not found".
>>>>
>>>> Thanks
>>>> Pallavi
>>>> ----- Original Message -----
>>>> From: "Raghu Angadi" <rangadi@yahoo-inc.com>
>>>> To: common-user@hadoop.apache.org
>>>> Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai,
>>> Kolkata,
>>>> Mumbai, New Delhi
>>>> Subject: Re: File is closed but data is not visible
>>>>
>>>>
>>>> Your assumption is correct. When you close the file, others can
> read
>>> the
>>>> data. There is no delay expected before the data is visible. If
>> there
>>> is
>>>> an error either write() or close() would throw an error.
>>>>
>>>> When you say data is not visible do you mean readers can not see
> the
>>>> file or can not see the data? Is it guaranteed that readers open
> the
>>>> file _after_ close returns on the writer?
>>>>
>>>> Raghu.
>>>>
>>>> Palleti, Pallavi wrote:
>>>>> Hi Jason,
>>>>>
>>>>> Apologies for missing version information in my previous mail. I
>> am
>>>>> using hadoop-0.18.3. I am getting FSDataOutputStream object
> using
>>>>> fs.create(new Path(some_file_name)), where fs is FileSystem
>> object.
>>> And,
>>>>> I am closing the file using close().
>>>>>
>>>>> Thanks
>>>>> Pallavi
>>>>>
>>>>> -----Original Message-----
>>>>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>>>>> Sent: Tuesday, August 11, 2009 6:24 PM
>>>>> To: common-user@hadoop.apache.org
>>>>> Subject: Re: File is closed but data is not visible
>>>>>
>>>>> Please provide information on what version of hadoop you are
> using
>>> and
>>>>> the
>>>>> method of opening and closing the file.
>>>>>
>>>>>
>>>>> On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
>>>>> pallavi.palleti@corp.aol.com> wrote:
>>>>>
>>>>>> Hi all,
>>>>>>
>>>>>> We have an application where we pull logs from an external
>>> server(far
>>>>> apart
>>>>>> from hadoop cluster) to hadoop cluster. Sometimes, we could see
>>> huge
>>>>> delay
>>>>>> (of 1 hour or more) in actually seeing the data in HDFS though
>> the
>>>>> file has
>>>>>> been closed and the variable is set to null from the external
>>>>> application.I
>>>>>> was in the impression that when I close the file, the data gets
>>>>> reflected in
>>>>>> hadoop cluster. Now, in this situation, it is even more
>> complicated
>>> to
>>>>>> handle write failures as it is giving false impression to the
>>> client
>>>>> that
>>>>>> data has been written to HDFS. Kindly clarify if my perception
> is
>>>>> correct.
>>>>>> If yes, Could some one tell me what is causing the delay in
>>> actually
>>>>> showing
>>>>>> the data. During those cases, how can we tackle write failures
>> (due
>>> to
>>>>> some
>>>>>> temporary issues like data node not available, disk is full) as
>>> there
>>>>> is no
>>>>>> way, we can figure out the failure at the client side?
>>>>>>
>>>>>> Thanks
>>>>>> Pallavi
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>> --
>>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>>> http://www.amazon.com/dp/1430219424?tag=jewlerymall
>>> www.prohadoopbook.com a community for Hadoop Professionals
>>>
>>
>>
>> --
>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>> http://www.amazon.com/dp/1430219424?tag=jewlerymall
>> www.prohadoopbook.com a community for Hadoop Professionals
>>
> 
> 
> 


From common-user-return-16734-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 04:36:04 2009
Return-Path: <common-user-return-16734-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 34146 invoked from network); 13 Aug 2009 04:36:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 04:36:03 -0000
Received: (qmail 92813 invoked by uid 500); 13 Aug 2009 04:36:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 92719 invoked by uid 500); 13 Aug 2009 04:36:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 92709 invoked by uid 99); 13 Aug 2009 04:36:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 04:36:08 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 04:35:56 +0000
Received: from [216.145.54.158] (socks1.corp.yahoo.com [216.145.54.158])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7D4Yisb028767
	for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 21:34:45 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=nmSMxFjQCO9l9/0/gLvceoWAxQ1Wy0WFBJiWJkXBEJHwbPNuJHbK7iOKilc+3FFY
Message-ID: <4A8397E7.9010709@yahoo-inc.com>
Date: Wed, 12 Aug 2009 21:34:47 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: File is closed but data is not visible
References: <24282036.661250136946160.JavaMail.pallavi@e1a31053e.in.office.aol.com>
In-Reply-To: <24282036.661250136946160.JavaMail.pallavi@e1a31053e.in.office.aol.com>
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Pallavi Palleti wrote:
> yes.

Then you can check NameNode log for such a file name. If it is closed 
then you will notice 'completeFile...' message with the filename. This 
will also show if there was anything odd with the file.

Raghu.

> ----- Original Message -----
> From: "Raghu Angadi" <rangadi@yahoo-inc.com>
> To: common-user@hadoop.apache.org
> Sent: Wednesday, August 12, 2009 10:09:55 PM GMT +05:30 Chennai, Kolkata, Mumbai, New Delhi
> Subject: Re: File is closed but data is not visible
> 
> 
> What happens when the while loop ends? Is 'out' closed then?
> 
> Palleti, Pallavi wrote:
>> No. I am closing it before opening a new one
>>
>> if (out != null) // if any output stream opened previously ,  close it
>>           {
>>             logger.info("Closing writer of -" + 
>>  paramWrapper.getOutFileStr());
>>             out.close();
>>             out = null;
>>           }
>>
>> Thanks
>> Pallavi
>>
>> -----Original Message-----
>> From: Jason Venner [mailto:jason.hadoop@gmail.com] 
>> Sent: Wednesday, August 12, 2009 7:31 PM
>> To: common-user@hadoop.apache.org
>> Subject: Re: File is closed but data is not visible
>>
>> You do not appear to close out, except when an exception occurs.
>> The finally block only closes the reader.
>>
>> On Wed, Aug 12, 2009 at 6:24 AM, Palleti, Pallavi <
>> pallavi.palleti@corp.aol.com> wrote:
>>
>>> Hi Jason,
>>>
>>> Kindly find the snippet of code which creates and close file.
>>>
>>> Variables passed to the method:FSDataOutputStream out,ParamWrapper
>>> paramWrapper
>>>
>>> Snippet:
>>>
>>>    String inputLine = null;
>>>    int status = 0;
>>>
>>>    BufferedReader reader = null;
>>>
>>>    try {
>>>      reader = new BufferedReader(new InputStreamReader(....); //reader
>>> initialization
>>>
>>>      while ((inputLine = reader.readLine()) != null) {
>>>
>>>        Date date = getLoggedDate(inputLine); // process the line to
>> get
>>> input and if it is wrong
>>>        if (date == null) // if input data is wrong, don't write
>>>        {
>>>          continue;
>>>        }
>>>        Calendar cal = Calendar.getInstance();
>>>        cal.setTime(date);
>>>        int hour = cal.get(Calendar.HOUR_OF_DAY); // get input hour
>>>        int minutes = cal.get(Calendar.MINUTE); // get input minute
>>>
>>>        int outputMinute = minutes / timePeriod + 1; // compute the
>> slot
>>>        if (paramWrapper.prevHour != hour
>>>            || paramWrapper.prevMin != outputMinute) // if it is a new
>>> slot
>>>        {
>>>
>>>          if (out != null) // if any output stream opened previously ,
>>> close it
>>>          {
>>>            logger.info("Closing writer of -" +
>>> paramWrapper.getOutFileStr());
>>>            out.close();
>>>            out = null;
>>>          }
>>>          String outFileStr = generateFileName(rootDir,
>>> hdfsOutFile,outputMinute, date); // generate file name ex:
>>> location/year/month/day/hour/_1.txt
>>>          Path outFile = new Path(outFileStr);
>>>
>>>          paramWrapper.setOutFileStr(outFileStr);
>>>          logger.info("Creating outFile:" + outFileStr);
>>>
>>>          out = fs.create(outFile); // create new file and get
>>>          // output stream
>>>          paramWrapper.setPrevHour(hour);
>>>          paramWrapper.setPrevMin(outputMinute);
>>>        }
>>>        StringBuilder outLineStr = new StringBuilder();
>>>        outLineStr.append(inputLine).append("\n");
>>>        out.write(outLineStr.toString().getBytes());
>>>      }
>>>    } catch (IOException ioe) {
>>>      logger.error("Main: IO Exception while writing to HDFS,
>> exiting...
>>> ", ioe);
>>>      // before exiting do the cleanup
>>>      close(reader);
>>>      System.exit(-1);
>>>
>>>    } catch (Exception e) {
>>>      logger.error("Unexpected error while writing to HDFS, exiting
>>> ...", e);
>>>      // before exiting do the cleanup
>>>      close(reader);
>>>
>>>      System.exit(-1);
>>>    } finally {
>>>      close(reader);
>>>     }
>>>
>>> Thanks
>>> Pallavi
>>>
>>>
>>> -----Original Message-----
>>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>>> Sent: Wednesday, August 12, 2009 6:35 PM
>>> To: common-user@hadoop.apache.org
>>> Subject: Re: File is closed but data is not visible
>>>
>>> Are you explicitly calling close on the FSDataOutputStream that you
>>> received
>>> from the FileSystem.create method?
>>> It sounds like the close is actually happening in the finalizer method
>>> on
>>> the object.
>>>
>>> Can you post the relevant code, or provide a cut down demonstrator?
>>>
>>> On Wed, Aug 12, 2009 at 5:57 AM, Palleti, Pallavi <
>>> pallavi.palleti@corp.aol.com> wrote:
>>>
>>>> Hi Jason,
>>>>
>>>> The file is neither visible via Namenode UI nor via program(checking
>>>> whether a file exists).
>>>>
>>>> There is no caching happening at the application level. The
>>> application
>>>> is pretty simple. We are taking apache logs and trying to put into
>>>> timely buckets based on the logged time of records. We are creating
>> 4
>>>> files(one for every 15 minutes) for every hour. So, at the client
>>> side,
>>>> we are looking into the logs and see if the data belongs to the
>>> current
>>>> interval, then we are writing into the currently opened HDFS file.
>> If
>>> it
>>>> belongs to new interval, the old file is closed and new file is
>>> created.
>>>> I have been logging the time at which the file is being created and
>> at
>>>> which the file is being closed at my client side. And, I could see
>>> that
>>>> the file is getting closed at expected time period. But, when I look
>>> for
>>>> the same file in hadoop cluster, it is still not created and if I
>> wait
>>>> for another 1 to 2 hours, I could see the file.
>>>>
>>>> Thanks
>>>> Pallavi
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>>>> Sent: Wednesday, August 12, 2009 6:03 PM
>>>> To: common-user@hadoop.apache.org
>>>> Subject: Re: File is closed but data is not visible
>>>>
>>>> Is it possible that your application is caching some data and not
>>>> refreshing
>>>> it when you expect?
>>>> The HDFS file visibility semantics are well understood, and your
>> case
>>>> does
>>>> not fit with that understanding.
>>>> A factor that hints strongly at this is that your file is visible
>> via
>>>> the
>>>> Namenode UI, there is nothing special about that UI
>>>>
>>>> On Tue, Aug 11, 2009 at 9:00 PM, Pallavi Palleti <
>>>> pallavi.palleti@corp.aol.com> wrote:
>>>>
>>>>> Hi Raghu,
>>>>>
>>>>> The file doesn't appear in the cluster when I saw it from Namenode
>>> UI.
>>>>> Also, I have a monitor at cluster side which checks whether file
>> is
>>>> created
>>>>> and throws an exception when it is not created. And, it threw an
>>>> exception
>>>>> saying "File not found".
>>>>>
>>>>> Thanks
>>>>> Pallavi
>>>>> ----- Original Message -----
>>>>> From: "Raghu Angadi" <rangadi@yahoo-inc.com>
>>>>> To: common-user@hadoop.apache.org
>>>>> Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai,
>>>> Kolkata,
>>>>> Mumbai, New Delhi
>>>>> Subject: Re: File is closed but data is not visible
>>>>>
>>>>>
>>>>> Your assumption is correct. When you close the file, others can
>> read
>>>> the
>>>>> data. There is no delay expected before the data is visible. If
>>> there
>>>> is
>>>>> an error either write() or close() would throw an error.
>>>>>
>>>>> When you say data is not visible do you mean readers can not see
>> the
>>>>> file or can not see the data? Is it guaranteed that readers open
>> the
>>>>> file _after_ close returns on the writer?
>>>>>
>>>>> Raghu.
>>>>>
>>>>> Palleti, Pallavi wrote:
>>>>>> Hi Jason,
>>>>>>
>>>>>> Apologies for missing version information in my previous mail. I
>>> am
>>>>>> using hadoop-0.18.3. I am getting FSDataOutputStream object
>> using
>>>>>> fs.create(new Path(some_file_name)), where fs is FileSystem
>>> object.
>>>> And,
>>>>>> I am closing the file using close().
>>>>>>
>>>>>> Thanks
>>>>>> Pallavi
>>>>>>
>>>>>> -----Original Message-----
>>>>>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>>>>>> Sent: Tuesday, August 11, 2009 6:24 PM
>>>>>> To: common-user@hadoop.apache.org
>>>>>> Subject: Re: File is closed but data is not visible
>>>>>>
>>>>>> Please provide information on what version of hadoop you are
>> using
>>>> and
>>>>>> the
>>>>>> method of opening and closing the file.
>>>>>>
>>>>>>
>>>>>> On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
>>>>>> pallavi.palleti@corp.aol.com> wrote:
>>>>>>
>>>>>>> Hi all,
>>>>>>>
>>>>>>> We have an application where we pull logs from an external
>>>> server(far
>>>>>> apart
>>>>>>> from hadoop cluster) to hadoop cluster. Sometimes, we could see
>>>> huge
>>>>>> delay
>>>>>>> (of 1 hour or more) in actually seeing the data in HDFS though
>>> the
>>>>>> file has
>>>>>>> been closed and the variable is set to null from the external
>>>>>> application.I
>>>>>>> was in the impression that when I close the file, the data gets
>>>>>> reflected in
>>>>>>> hadoop cluster. Now, in this situation, it is even more
>>> complicated
>>>> to
>>>>>>> handle write failures as it is giving false impression to the
>>>> client
>>>>>> that
>>>>>>> data has been written to HDFS. Kindly clarify if my perception
>> is
>>>>>> correct.
>>>>>>> If yes, Could some one tell me what is causing the delay in
>>>> actually
>>>>>> showing
>>>>>>> the data. During those cases, how can we tackle write failures
>>> (due
>>>> to
>>>>>> some
>>>>>>> temporary issues like data node not available, disk is full) as
>>>> there
>>>>>> is no
>>>>>>> way, we can figure out the failure at the client side?
>>>>>>>
>>>>>>> Thanks
>>>>>>> Pallavi
>>>>>>>
>>>>>>
>>>> --
>>>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>>>> http://www.amazon.com/dp/1430219424?tag=jewlerymall
>>>> www.prohadoopbook.com a community for Hadoop Professionals
>>>>
>>>
>>> --
>>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>>> http://www.amazon.com/dp/1430219424?tag=jewlerymall
>>> www.prohadoopbook.com a community for Hadoop Professionals
>>>
>>
>>
> 


From common-user-return-16735-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 05:25:55 2009
Return-Path: <common-user-return-16735-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 43957 invoked from network); 13 Aug 2009 05:25:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 05:25:55 -0000
Received: (qmail 32096 invoked by uid 500); 13 Aug 2009 05:26:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 32009 invoked by uid 500); 13 Aug 2009 05:26:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 31999 invoked by uid 99); 13 Aug 2009 05:26:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 05:26:00 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.217.218 as permitted sender)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 05:25:50 +0000
Received: by gxk18 with SMTP id 18so587340gxk.5
        for <common-user@hadoop.apache.org>; Wed, 12 Aug 2009 22:25:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=sybqaqtJq77z8lwYKrRhiBiyZs+buBCMcVsinSdlrAw=;
        b=fwxLSMSpztG+P6wSRrZHreafKmJSUZ+FNarVtoQ8Mek/H9TmLPJBIVDx7z35L0V/pt
         TUkz5ehFuMLzJVnE3GuKBfNswjXdXdXiOmag6pFMdUnuPn4LdMzCkuze/XsBIrz+QiR6
         pu8kWmIhRJ3kVXyYA7cxf/WL9QUa7VrgFboVU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=qi0lE4WKlBnaPinJHXrGuyD7N5zthWzVPPbb+d/NwvwQCnhR2zk2tHQlonkgJGEo8d
         D4/NfRSySncECL3a/+Znh8SGCkX5KB4pFpM1WOe9sR7jXZqFbQ3fSQNGdYmaa8lutlG+
         vUlLqqw+DJDx4HMNrWyVYgxH5KvLdEWtwPiWk=
MIME-Version: 1.0
Received: by 10.151.84.5 with SMTP id m5mr1062748ybl.132.1250141130090; Wed, 
	12 Aug 2009 22:25:30 -0700 (PDT)
In-Reply-To: <3b1311780908121936h5895a966r264a2bbd76a2c82e@mail.gmail.com>
References: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com> 
	<c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com> 
	<3b1311780908121936h5895a966r264a2bbd76a2c82e@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Wed, 12 Aug 2009 22:25:10 -0700
Message-ID: <c7d45fc70908122225o7f2a5981r110432bd1938b903@mail.gmail.com>
Subject: Re: What will we encounter if we add a lot of nodes into the current 
	cluster?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd56af8fa695b0470ff29d6
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd56af8fa695b0470ff29d6
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

There is a parameter (dfs.balance.bandwidthPerSec) that limits the
rebalancing bandwidth.  The default is rather low.

See http://developer.yahoo.com/hadoop/tutorial/module2.html#rebalancing

On Wed, Aug 12, 2009 at 7:36 PM, yang song <hadoop.inifok@gmail.com> wrote:

> I'm trying to use the balance tool(bin/hadoop balancer -t xxx). However,
> the
> data transfer is so slow that it will take a long long time.
> Is there a good method to solve it?
>



-- 
Ted Dunning, CTO
DeepDyve

--000e0cd56af8fa695b0470ff29d6--

From common-user-return-16736-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 07:04:50 2009
Return-Path: <common-user-return-16736-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 85538 invoked from network); 13 Aug 2009 07:04:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 07:04:50 -0000
Received: (qmail 17628 invoked by uid 500); 13 Aug 2009 07:04:55 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 17550 invoked by uid 500); 13 Aug 2009 07:04:55 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 17540 invoked by uid 500); 13 Aug 2009 07:04:55 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 17537 invoked by uid 99); 13 Aug 2009 07:04:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 07:04:54 +0000
X-ASF-Spam-Status: No, hits=-1.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jo@nttdocomo.com designates 202.19.227.74 as permitted sender)
Received: from [202.19.227.74] (HELO zcsg-mailro11.is.nttdocomo.co.jp) (202.19.227.74)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 07:04:45 +0000
Received: from zcsg-mailmt12.is.nttdocomo.co.jp (zcsg-mailmt10.is.nttdocomo.co.jp [10.160.86.41])
	by zcsg-mailro11.is.nttdocomo.co.jp (Postfix) with ESMTP id C805834025
	for <core-user@hadoop.apache.org>; Thu, 13 Aug 2009 16:04:22 +0900 (JST)
Received: from smtp_saver-daemon.zcsg-mailmt12.is.nttdocomo.co.jp by
 zcsg-mailmt12.is.nttdocomo.co.jp (NTT DoCoMo Mail System)
 id <0KOA00NSDZNA8300@NTTDoCoMo.co.jp> for core-user@hadoop.apache.org; Thu,
 13 Aug 2009 16:04:22 +0900 (JST)
Received: from zcsg-mailmi12.is.nttdocomo.co.jp
 (zcsg-mailmi10.is.nttdocomo.co.jp [10.160.86.49])
 by zcsg-mailmt12.is.nttdocomo.co.jp (NTT DoCoMo Mail System)
 with SMTP id <0KOA0082GZNAHS60@NTTDoCoMo.co.jp> for
 core-user@hadoop.apache.org; Thu, 13 Aug 2009 16:04:22 +0900 (JST)
Received: from unknown (HELO zcsg-mailvs13.is.nttdocomo.co.jp) (10.160.86.48)
 by 0 with SMTP; Thu, 13 Aug 2009 16:04:22 +0900
Received: from zcsg-mailvs13.is.nttdocomo.co.jp (localhost [127.0.0.1])
	by localhost.nttdocomo.co.jp (Postfix) with ESMTP id A2F948C003	for
 <core-user@hadoop.apache.org>; Thu, 13 Aug 2009 16:04:22 +0900 (JST)
Received: from zcsg-mailsa11.is.nttdocomo.co.jp
 (zcsg-mailsa10.is.nttdocomo.co.jp [10.160.86.46])
	by zcsg-mailvs13.is.nttdocomo.co.jp (Postfix) with ESMTP id 97DF88C002	for
 <core-user@hadoop.apache.org>; Thu, 13 Aug 2009 16:04:22 +0900 (JST)
Received: from gc_check-daemon.zcsg-mailsa11.is.nttdocomo.co.jp by
 zcsg-mailsa11.is.nttdocomo.co.jp (NTT DoCoMo Mail System)
 id <0KOA00E6RZNABF00@NTTDoCoMo.co.jp> for core-user@hadoop.apache.org; Thu,
 13 Aug 2009 16:04:22 +0900 (JST)
Received: from aknetlab20 (aknetlab20.docomo.docomogr.net [10.19.78.76])
 by zcsg-mailsa11.is.nttdocomo.co.jp (NTT DoCoMo Mail System)
 with ESMTPA id <0KOA00EWVZN9QT60@NTTDoCoMo.co.jp> for
 core-user@hadoop.apache.org; Thu, 13 Aug 2009 16:04:22 +0900 (JST)
Date: Thu, 13 Aug 2009 16:04:21 +0900
From: Manhee Jo <jo@nttdocomo.com>
Subject: fuse-dfs then samba mount
To: core-user@hadoop.apache.org
Message-id: <786D52F1E5C343E89523E2CFBE54DF27@docomo.docomogr.net>
MIME-version: 1.0
X-MIMEOLE: Produced By Microsoft MimeOLE V6.00.2900.5579
X-Mailer: Microsoft Outlook Express 6.00.2900.5512
Content-type: text/plain; format=flowed; charset=Windows-1252;
 reply-type=response
Content-transfer-encoding: 7bit
X-Priority: 3
X-MSMail-priority: Normal
X-DoCoMo: ZCSG
References: <BLU119-W21A28C79A3F1C979E75EECA2350@phx.gbl>
 <4B66AF92-2C09-4245-AE3B-7FA0FCF09144@cse.unl.edu>
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

I've succeeded in sharing hdfs files from windows xp through fuse-dfs then 
samba mount.
When I tried to copy (read and write) 1GB text file from fuse-dfs over 
samba, it took around 50 secs.
Then, I tried "dfs get" the same file to a data node's local file system and 
tried to copy the file
from the data node (without fuse-dfs this time) over samba, again, which 
took around 30 seconds.
Since the disk reads are paralleled and distributed, should it be faster 
then reading from one node?
Well, I know it must depend on the file size. So then, here is my question.
What is actually happening in fuse-dfs read? and samba?
What is the threshold of the file size when fuse-dfs might win?


Thanks,
Manhee








From common-user-return-16737-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 07:13:04 2009
Return-Path: <common-user-return-16737-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 86921 invoked from network); 13 Aug 2009 07:13:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 07:13:03 -0000
Received: (qmail 28412 invoked by uid 500); 13 Aug 2009 07:13:07 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 28323 invoked by uid 500); 13 Aug 2009 07:13:07 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 28313 invoked by uid 99); 13 Aug 2009 07:13:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 07:13:07 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.217.218] (HELO mail-gx0-f218.google.com) (209.85.217.218)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 07:12:59 +0000
Received: by gxk18 with SMTP id 18so627522gxk.5
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 00:12:38 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.242.1 with SMTP id p1mr464212agh.105.1250147558245; Thu, 13 
	Aug 2009 00:12:38 -0700 (PDT)
In-Reply-To: <786D52F1E5C343E89523E2CFBE54DF27@docomo.docomogr.net>
References: <BLU119-W21A28C79A3F1C979E75EECA2350@phx.gbl> <4B66AF92-2C09-4245-AE3B-7FA0FCF09144@cse.unl.edu> 
	<786D52F1E5C343E89523E2CFBE54DF27@docomo.docomogr.net>
From: Todd Lipcon <todd@cloudera.com>
Date: Thu, 13 Aug 2009 00:12:18 -0700
Message-ID: <45f85f70908130012s5d335a7etf943c663efd621d2@mail.gmail.com>
Subject: Re: fuse-dfs then samba mount
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636284f282044dd047100a924
X-Virus-Checked: Checked by ClamAV on apache.org

--001636284f282044dd047100a924
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 13, 2009 at 12:04 AM, Manhee Jo <jo@nttdocomo.com> wrote:

> Hi all,
>
> I've succeeded in sharing hdfs files from windows xp through fuse-dfs then
> samba mount.
> When I tried to copy (read and write) 1GB text file from fuse-dfs over
> samba, it took around 50 secs.
> Then, I tried "dfs get" the same file to a data node's local file system
> and tried to copy the file
> from the data node (without fuse-dfs this time) over samba, again, which
> took around 30 seconds.
> Since the disk reads are paralleled and distributed, should it be faster
> then reading from one node?


Nope - the file is stored distributed, but a single reader (using dfs -get
or the DFSClient API from Java) won't do a parallel read from multiple
replicas. What you've seen seems about right - there's a measurable overhead
of going through the datanode compared to just using local disk.


>
> Well, I know it must depend on the file size. So then, here is my question.
> What is actually happening in fuse-dfs read? and samba?


It's a single connection to one datanode at a time. At the end of each
block, it connects to the DN that stores the next block and reads from that
one. At no time does it transfer in parallel from multiple replicas. Some
people have mentioned this as a feature request but it hasn't been
prioritized high yet for a multitude of reasons.

-Todd

--001636284f282044dd047100a924--

From common-user-return-16738-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 09:01:24 2009
Return-Path: <common-user-return-16738-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 17924 invoked from network); 13 Aug 2009 09:01:24 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 09:01:24 -0000
Received: (qmail 73585 invoked by uid 500); 13 Aug 2009 09:01:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 73506 invoked by uid 500); 13 Aug 2009 09:01:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 73496 invoked by uid 99); 13 Aug 2009 09:01:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 09:01:28 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pallavi.palleti@corp.aol.com designates 64.12.143.146 as permitted sender)
Received: from [64.12.143.146] (HELO omr-m34.mx.aol.com) (64.12.143.146)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 09:01:16 +0000
Received: from AOLDTCMEH01.ad.office.aol.com (aoldtcmeh01.office.aol.com [10.180.121.20]) by omr-m34.mx.aol.com (v117.7) with ESMTP id MAILOMRM347-7f324a83d6453e1; Thu, 13 Aug 2009 05:00:53 -0400
Received: from AOLMTCMEI02.ad.office.aol.com ([10.178.3.19]) by AOLDTCMEH01.ad.office.aol.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Thu, 13 Aug 2009 05:00:53 -0400
Received: from localhost ([10.178.3.10]) by AOLMTCMEI02.ad.office.aol.com over TLS secured channel with Microsoft SMTPSVC(6.0.3790.3959);
	 Thu, 13 Aug 2009 05:00:53 -0400
Date: Thu, 13 Aug 2009 14:30:47 +0530 (GMT+05:30)
From: Pallavi Palleti <pallavi.palleti@corp.aol.com>
To: common-user@hadoop.apache.org
Message-ID: <19765151.1061250154040265.JavaMail.pallavi@e1a31053e.in.office.aol.com>
In-Reply-To: <20915040.1041250153975174.JavaMail.pallavi@e1a31053e.in.office.aol.com>
Subject: Re: File is closed but data is not visible
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-OriginalArrivalTime: 13 Aug 2009 09:00:53.0760 (UTC) FILETIME=[90220800:01CA1BF4]
X-AOL-IP: 10.180.121.20
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Raghu and Jason,

Thanks for your help. Due to some confusion at our end, I was looking into a different output log file. Right now, I could see the consistency in timing between output log file and namenode log file though the problem is not resolved completely. I will seek your help in case it is needed and apologies for the confusion.
 
Thanks
Pallavi

 
----- Original Message -----
From: "Raghu Angadi" <rangadi@yahoo-inc.com>
To: common-user@hadoop.apache.org
Sent: Thursday, August 13, 2009 10:04:47 AM GMT +05:30 Chennai, Kolkata, Mumbai, New Delhi
Subject: Re: File is closed but data is not visible

Pallavi Palleti wrote:
> yes.

Then you can check NameNode log for such a file name. If it is closed 
then you will notice 'completeFile...' message with the filename. This 
will also show if there was anything odd with the file.

Raghu.

> ----- Original Message -----
> From: "Raghu Angadi" <rangadi@yahoo-inc.com>
> To: common-user@hadoop.apache.org
> Sent: Wednesday, August 12, 2009 10:09:55 PM GMT +05:30 Chennai, Kolkata, Mumbai, New Delhi
> Subject: Re: File is closed but data is not visible
> 
> 
> What happens when the while loop ends? Is 'out' closed then?
> 
> Palleti, Pallavi wrote:
>> No. I am closing it before opening a new one
>>
>> if (out != null) // if any output stream opened previously ,  close it
>>           {
>>             logger.info("Closing writer of -" + 
>>  paramWrapper.getOutFileStr());
>>             out.close();
>>             out = null;
>>           }
>>
>> Thanks
>> Pallavi
>>
>> -----Original Message-----
>> From: Jason Venner [mailto:jason.hadoop@gmail.com] 
>> Sent: Wednesday, August 12, 2009 7:31 PM
>> To: common-user@hadoop.apache.org
>> Subject: Re: File is closed but data is not visible
>>
>> You do not appear to close out, except when an exception occurs.
>> The finally block only closes the reader.
>>
>> On Wed, Aug 12, 2009 at 6:24 AM, Palleti, Pallavi <
>> pallavi.palleti@corp.aol.com> wrote:
>>
>>> Hi Jason,
>>>
>>> Kindly find the snippet of code which creates and close file.
>>>
>>> Variables passed to the method:FSDataOutputStream out,ParamWrapper
>>> paramWrapper
>>>
>>> Snippet:
>>>
>>>    String inputLine = null;
>>>    int status = 0;
>>>
>>>    BufferedReader reader = null;
>>>
>>>    try {
>>>      reader = new BufferedReader(new InputStreamReader(....); //reader
>>> initialization
>>>
>>>      while ((inputLine = reader.readLine()) != null) {
>>>
>>>        Date date = getLoggedDate(inputLine); // process the line to
>> get
>>> input and if it is wrong
>>>        if (date == null) // if input data is wrong, don't write
>>>        {
>>>          continue;
>>>        }
>>>        Calendar cal = Calendar.getInstance();
>>>        cal.setTime(date);
>>>        int hour = cal.get(Calendar.HOUR_OF_DAY); // get input hour
>>>        int minutes = cal.get(Calendar.MINUTE); // get input minute
>>>
>>>        int outputMinute = minutes / timePeriod + 1; // compute the
>> slot
>>>        if (paramWrapper.prevHour != hour
>>>            || paramWrapper.prevMin != outputMinute) // if it is a new
>>> slot
>>>        {
>>>
>>>          if (out != null) // if any output stream opened previously ,
>>> close it
>>>          {
>>>            logger.info("Closing writer of -" +
>>> paramWrapper.getOutFileStr());
>>>            out.close();
>>>            out = null;
>>>          }
>>>          String outFileStr = generateFileName(rootDir,
>>> hdfsOutFile,outputMinute, date); // generate file name ex:
>>> location/year/month/day/hour/_1.txt
>>>          Path outFile = new Path(outFileStr);
>>>
>>>          paramWrapper.setOutFileStr(outFileStr);
>>>          logger.info("Creating outFile:" + outFileStr);
>>>
>>>          out = fs.create(outFile); // create new file and get
>>>          // output stream
>>>          paramWrapper.setPrevHour(hour);
>>>          paramWrapper.setPrevMin(outputMinute);
>>>        }
>>>        StringBuilder outLineStr = new StringBuilder();
>>>        outLineStr.append(inputLine).append("\n");
>>>        out.write(outLineStr.toString().getBytes());
>>>      }
>>>    } catch (IOException ioe) {
>>>      logger.error("Main: IO Exception while writing to HDFS,
>> exiting...
>>> ", ioe);
>>>      // before exiting do the cleanup
>>>      close(reader);
>>>      System.exit(-1);
>>>
>>>    } catch (Exception e) {
>>>      logger.error("Unexpected error while writing to HDFS, exiting
>>> ...", e);
>>>      // before exiting do the cleanup
>>>      close(reader);
>>>
>>>      System.exit(-1);
>>>    } finally {
>>>      close(reader);
>>>     }
>>>
>>> Thanks
>>> Pallavi
>>>
>>>
>>> -----Original Message-----
>>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>>> Sent: Wednesday, August 12, 2009 6:35 PM
>>> To: common-user@hadoop.apache.org
>>> Subject: Re: File is closed but data is not visible
>>>
>>> Are you explicitly calling close on the FSDataOutputStream that you
>>> received
>>> from the FileSystem.create method?
>>> It sounds like the close is actually happening in the finalizer method
>>> on
>>> the object.
>>>
>>> Can you post the relevant code, or provide a cut down demonstrator?
>>>
>>> On Wed, Aug 12, 2009 at 5:57 AM, Palleti, Pallavi <
>>> pallavi.palleti@corp.aol.com> wrote:
>>>
>>>> Hi Jason,
>>>>
>>>> The file is neither visible via Namenode UI nor via program(checking
>>>> whether a file exists).
>>>>
>>>> There is no caching happening at the application level. The
>>> application
>>>> is pretty simple. We are taking apache logs and trying to put into
>>>> timely buckets based on the logged time of records. We are creating
>> 4
>>>> files(one for every 15 minutes) for every hour. So, at the client
>>> side,
>>>> we are looking into the logs and see if the data belongs to the
>>> current
>>>> interval, then we are writing into the currently opened HDFS file.
>> If
>>> it
>>>> belongs to new interval, the old file is closed and new file is
>>> created.
>>>> I have been logging the time at which the file is being created and
>> at
>>>> which the file is being closed at my client side. And, I could see
>>> that
>>>> the file is getting closed at expected time period. But, when I look
>>> for
>>>> the same file in hadoop cluster, it is still not created and if I
>> wait
>>>> for another 1 to 2 hours, I could see the file.
>>>>
>>>> Thanks
>>>> Pallavi
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>>>> Sent: Wednesday, August 12, 2009 6:03 PM
>>>> To: common-user@hadoop.apache.org
>>>> Subject: Re: File is closed but data is not visible
>>>>
>>>> Is it possible that your application is caching some data and not
>>>> refreshing
>>>> it when you expect?
>>>> The HDFS file visibility semantics are well understood, and your
>> case
>>>> does
>>>> not fit with that understanding.
>>>> A factor that hints strongly at this is that your file is visible
>> via
>>>> the
>>>> Namenode UI, there is nothing special about that UI
>>>>
>>>> On Tue, Aug 11, 2009 at 9:00 PM, Pallavi Palleti <
>>>> pallavi.palleti@corp.aol.com> wrote:
>>>>
>>>>> Hi Raghu,
>>>>>
>>>>> The file doesn't appear in the cluster when I saw it from Namenode
>>> UI.
>>>>> Also, I have a monitor at cluster side which checks whether file
>> is
>>>> created
>>>>> and throws an exception when it is not created. And, it threw an
>>>> exception
>>>>> saying "File not found".
>>>>>
>>>>> Thanks
>>>>> Pallavi
>>>>> ----- Original Message -----
>>>>> From: "Raghu Angadi" <rangadi@yahoo-inc.com>
>>>>> To: common-user@hadoop.apache.org
>>>>> Sent: Wednesday, August 12, 2009 12:10:12 AM GMT +05:30 Chennai,
>>>> Kolkata,
>>>>> Mumbai, New Delhi
>>>>> Subject: Re: File is closed but data is not visible
>>>>>
>>>>>
>>>>> Your assumption is correct. When you close the file, others can
>> read
>>>> the
>>>>> data. There is no delay expected before the data is visible. If
>>> there
>>>> is
>>>>> an error either write() or close() would throw an error.
>>>>>
>>>>> When you say data is not visible do you mean readers can not see
>> the
>>>>> file or can not see the data? Is it guaranteed that readers open
>> the
>>>>> file _after_ close returns on the writer?
>>>>>
>>>>> Raghu.
>>>>>
>>>>> Palleti, Pallavi wrote:
>>>>>> Hi Jason,
>>>>>>
>>>>>> Apologies for missing version information in my previous mail. I
>>> am
>>>>>> using hadoop-0.18.3. I am getting FSDataOutputStream object
>> using
>>>>>> fs.create(new Path(some_file_name)), where fs is FileSystem
>>> object.
>>>> And,
>>>>>> I am closing the file using close().
>>>>>>
>>>>>> Thanks
>>>>>> Pallavi
>>>>>>
>>>>>> -----Original Message-----
>>>>>> From: Jason Venner [mailto:jason.hadoop@gmail.com]
>>>>>> Sent: Tuesday, August 11, 2009 6:24 PM
>>>>>> To: common-user@hadoop.apache.org
>>>>>> Subject: Re: File is closed but data is not visible
>>>>>>
>>>>>> Please provide information on what version of hadoop you are
>> using
>>>> and
>>>>>> the
>>>>>> method of opening and closing the file.
>>>>>>
>>>>>>
>>>>>> On Tue, Aug 11, 2009 at 12:48 AM, Pallavi Palleti <
>>>>>> pallavi.palleti@corp.aol.com> wrote:
>>>>>>
>>>>>>> Hi all,
>>>>>>>
>>>>>>> We have an application where we pull logs from an external
>>>> server(far
>>>>>> apart
>>>>>>> from hadoop cluster) to hadoop cluster. Sometimes, we could see
>>>> huge
>>>>>> delay
>>>>>>> (of 1 hour or more) in actually seeing the data in HDFS though
>>> the
>>>>>> file has
>>>>>>> been closed and the variable is set to null from the external
>>>>>> application.I
>>>>>>> was in the impression that when I close the file, the data gets
>>>>>> reflected in
>>>>>>> hadoop cluster. Now, in this situation, it is even more
>>> complicated
>>>> to
>>>>>>> handle write failures as it is giving false impression to the
>>>> client
>>>>>> that
>>>>>>> data has been written to HDFS. Kindly clarify if my perception
>> is
>>>>>> correct.
>>>>>>> If yes, Could some one tell me what is causing the delay in
>>>> actually
>>>>>> showing
>>>>>>> the data. During those cases, how can we tackle write failures
>>> (due
>>>> to
>>>>>> some
>>>>>>> temporary issues like data node not available, disk is full) as
>>>> there
>>>>>> is no
>>>>>>> way, we can figure out the failure at the client side?
>>>>>>>
>>>>>>> Thanks
>>>>>>> Pallavi
>>>>>>>
>>>>>>
>>>> --
>>>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>>>> http://www.amazon.com/dp/1430219424?tag=jewlerymall
>>>> www.prohadoopbook.com a community for Hadoop Professionals
>>>>
>>>
>>> --
>>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>>> http://www.amazon.com/dp/1430219424?tag=jewlerymall
>>> www.prohadoopbook.com a community for Hadoop Professionals
>>>
>>
>>
> 


From common-user-return-16739-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 10:55:53 2009
Return-Path: <common-user-return-16739-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81834 invoked from network); 13 Aug 2009 10:55:53 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 10:55:53 -0000
Received: (qmail 22380 invoked by uid 500); 13 Aug 2009 10:55:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 22297 invoked by uid 500); 13 Aug 2009 10:55:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 22287 invoked by uid 99); 13 Aug 2009 10:55:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 10:55:57 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 10:55:48 +0000
Received: by fxm24 with SMTP id 24so701870fxm.36
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 03:55:27 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=rb0Jq0uZO/E5oJCQmyjKteobyucS7RZNJ6LX3uHMg4g=;
        b=Pme+TNXq4Z5P6HepY6o+QfPRU8gNCbFFCuxmtSeYxbf/Yzw4fiuhAq/FNkJC76YHX6
         6F0TVoTJzvz52GZ+3HOAu1wWZcvaeaGfBWGUij3/H6eqFQsfVaLeSXc8/cYskwdgF2Od
         DRyPYfhrkfY1Gf/C8Z65INEuoYqPKtuncP0T8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=RXRmgWl4YwhkU7/xDrt2lWmnCws0FCe6tJFpn9sKWMknQOgwuo7jixIWEaFYj8Uprs
         F8wm3ah7I90B+lbM8h7cVPKgQeWBo1ih0hykUtIMcmqkxAanjLcossBpJx56GUiwxrnR
         RXud4hY1sSJgK0q+/1sHK31qTwkLhTgHEM4+g=
MIME-Version: 1.0
Received: by 10.223.143.79 with SMTP id t15mr254545fau.2.1250160927791; Thu, 
	13 Aug 2009 03:55:27 -0700 (PDT)
In-Reply-To: <4A832601.1030001@yahoo-inc.com>
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com>
	 <4A7BECD9.20303@apache.org>
	 <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com>
	 <4A814BCD.2060500@apache.org>
	 <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com>
	 <77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com>
	 <45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com>
	 <4A8312C5.9080307@yahoo-inc.com>
	 <45f85f70908121227o679f4887l9ec1c053270af40a@mail.gmail.com>
	 <4A832601.1030001@yahoo-inc.com>
Date: Thu, 13 Aug 2009 13:55:27 +0300
Message-ID: <77938bc20908130355s27217f24x84446110b16c63ee@mail.gmail.com>
Subject: Re: HADOOP-4539 question
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0023545bda2803597c047103c6ae
X-Virus-Checked: Checked by ClamAV on apache.org

--0023545bda2803597c047103c6ae
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

>
> This is exactly the goal (long term). To evolve BN into StandbyNode,
> which will be able to take over when main NN dies without restarting
> anything else.
> And the only remaining step is to implement fail-over mechanism.
>
>

Just to clarify, for the near future, the only HA option is Cloudera  DRDB
approach.

Correct?

--0023545bda2803597c047103c6ae--

From common-user-return-16740-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 14:01:48 2009
Return-Path: <common-user-return-16740-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 45916 invoked from network); 13 Aug 2009 14:01:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 14:01:46 -0000
Received: (qmail 38398 invoked by uid 500); 13 Aug 2009 14:01:50 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 38331 invoked by uid 500); 13 Aug 2009 14:01:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 38321 invoked by uid 99); 13 Aug 2009 14:01:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 14:01:50 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [192.6.10.60] (HELO tobor.hpl.hp.com) (192.6.10.60)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 14:01:37 +0000
Received: from localhost (localhost [127.0.0.1])
	by tobor.hpl.hp.com (Postfix) with ESMTP id 832ACB7D1A
	for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 15:01:15 +0100 (BST)
X-Virus-Scanned: amavisd-new at hplb.hpl.hp.com
Received: from tobor.hpl.hp.com ([127.0.0.1])
	by localhost (tobor.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id h01v7dvZPrM4 for <common-user@hadoop.apache.org>;
	Thu, 13 Aug 2009 15:01:08 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by tobor.hpl.hp.com (Postfix) with ESMTPS id C5728B7D1D
	for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 15:00:51 +0100 (BST)
MailScanner-NULL-Check: 1250776839.65138@yiBsZoJuQpFOvZCrMiqwQQ
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7DE0c3O026752
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 15:00:39 +0100 (BST)
Message-ID: <4A841C86.3090605@apache.org>
Date: Thu, 13 Aug 2009 15:00:38 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: HADOOP-4539 question
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com> 	<4A7BECD9.20303@apache.org> <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com> 	<4A814BCD.2060500@apache.org> <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com> 	<77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com> 	<45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com> 	<4A8312C5.9080307@yahoo-inc.com> <45f85f70908121227o679f4887l9ec1c053270af40a@mail.gmail.com> <4A832601.1030001@yahoo-inc.com>
In-Reply-To: <4A832601.1030001@yahoo-inc.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7DE0c3O026752
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

Konstantin Shvachko wrote:
> And the only remaining step is to implement fail-over mechanism.

:)

Colleagues of mine work on HA stuff; I try and steer clear of it as it 
gets complex fast.  Test case: what happens when a network failure 
splits the datacentre in two, you now have two clusters each with half 
the data and possibly a primary/2ary master in each one. Then leave the 
partition up for a while, do inconsistent operations on each then have 
the network come back up.  Then work out how to merge the state

Looking at the facebook/google "multi-master" solution, I think they 
don't worry about consistency, just let the masters drift apart.

see also Johan's recent talk on HDFS: http://www.slideshare.net/steve_l/hdfs

From common-user-return-16741-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 16:15:02 2009
Return-Path: <common-user-return-16741-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7525 invoked from network); 13 Aug 2009 16:15:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 16:15:02 -0000
Received: (qmail 22016 invoked by uid 500); 13 Aug 2009 16:15:07 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21919 invoked by uid 500); 13 Aug 2009 16:15:07 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21909 invoked by uid 500); 13 Aug 2009 16:15:07 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 21906 invoked by uid 99); 13 Aug 2009 16:15:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 16:15:06 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 16:14:55 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1Mbcwk-0008NE-Fw
	for core-user@hadoop.apache.org; Thu, 13 Aug 2009 09:14:34 -0700
Message-ID: <24955366.post@talk.nabble.com>
Date: Thu, 13 Aug 2009 09:14:34 -0700 (PDT)
From: georgep <p0941p@gmail.com>
To: core-user@hadoop.apache.org
Subject: RE: Reducer hangs at 16%
In-Reply-To: <16C94259266DA34EA21390B762BECD1419AA4336@hcsmbx003.corp.satyam.ad>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: p0941p@gmail.com
References: <16C94259266DA34EA21390B762BECD14199DABB9@hcsmbx003.corp.satyam.ad> <C5C87893.CE63%jothipn@yahoo-inc.com> <16C94259266DA34EA21390B762BECD14199DACE1@hcsmbx003.corp.satyam.ad> <C5C885CE.CE7E%jothipn@yahoo-inc.com> <16C94259266DA34EA21390B762BECD14199DAE4B@hcsmbx003.corp.satyam.ad> <49A29CFC.5090601@yahoo-inc.com> <16C94259266DA34EA21390B762BECD14199DAE8B@hcsmbx003.corp.satyam.ad> <e4eb02ce0902230835h35c94663gd8df99343a380035@mail.gmail.com> <16C94259266DA34EA21390B762BECD1419AA4336@hcsmbx003.corp.satyam.ad>
X-Virus-Checked: Checked by ClamAV on apache.org


My reduce stops at 16%, just like your situation. I use ubuntu boxes for
hadoop, the default firewall seems to have no rule.  Do I have to open ports
for hadoop?  For example, 54310 and 54311 for hdfs and job tracker?  

Even after I change the iptables rule like "sudo iptables -A INPUT -p tcp
--dport 54310 -j ACCEPT" , the reduce problem persist.   What else can I do?  

Thanks.
George


Jagadesh_Doddi wrote:
> 
> I have opened the ports 50010, 50030, 50060, 50070, 50075 and 50090
> It works fine now. Thanks Matie.
> 
> Thanks
> Jagadesh Doddi
> 
> 
> -----Original Message-----
> From: Matei Zaharia [mailto:matei@cloudera.com]
> Sent: Monday, February 23, 2009 10:06 PM
> To: core-user@hadoop.apache.org
> Subject: Re: Reducer hangs at 16%
> 
> The fact that it works with one slave node doesn't mean much, because when
> the slave is alone, it's copying map outputs from itself and thus not
> going
> through the firewall. It sounds like the slaves can't open a connection to
> each other, which could well mean a firewall problem. Can you look at the
> output of the reduce task (by clicking it in the "running tasks" column in
> the web UI and going on to see the last 8k of output)? I imagine it will
> have fetched data from one slave and will be failing to connect to the
> other
> one.
> 
> On Mon, Feb 23, 2009 at 5:03 AM, Jagadesh_Doddi
> <Jagadesh_Doddi>wrote:
> 
>> It works as longs as I use any one of the slave nodes.
>> The moment I add both the slave nodes to conf/slaves, It fails.
>> So there is no issue with firewall or /etc/hosts entries.
>>
>> Thanks and Regards
>>
>> Jagadesh Doddi
>>
>>
>>
>> -----Original Message-----
>> From: Amar Kamat [mailto:amarrk@yahoo-inc.com]
>> Sent: Monday, February 23, 2009 6:26 PM
>> To: core-user@hadoop.apache.org
>> Subject: Re: Reducer hangs at 16%
>>
>> Looks like the reducer is able to fetch map output files from the local
>> box but fails to fetch it from the remote box. Can you check if there is
>> no firewall issue or /etc/hosts entries are correct?
>> Amar
>> Jagadesh_Doddi wrote:
>> > Hi
>> >
>> > I have changed the configuration to run Name node and job tracker on
>> the
>> same system.
>> > The job is started with bin/start-all.sh on NN
>> > With a single slave node, the job completes in 12 seconds, and the
>> console output is shown below:
>> >
>> > [root@Fedora1 hadoop-0.18.3]# bin/hadoop jar samples/wordcount.jar
>> org.myorg.WordCount input output1
>> > 09/02/23 17:19:30 WARN mapred.JobClient: Use GenericOptionsParser for
>> parsing the arguments. Applications should implement Tool for the same.
>> > 09/02/23 17:19:30 INFO mapred.FileInputFormat: Total input paths to
>> process : 1
>> > 09/02/23 17:19:30 INFO mapred.FileInputFormat: Total input paths to
>> process : 1
>> > 09/02/23 17:19:30 INFO mapred.JobClient: Running job:
>> job_200902231717_0001
>> > 09/02/23 17:19:31 INFO mapred.JobClient:  map 0% reduce 0%
>> > 09/02/23 17:19:37 INFO mapred.JobClient:  map 100% reduce 0%
>> > 09/02/23 17:19:42 INFO mapred.JobClient: Job complete:
>> job_200902231717_0001
>> > 09/02/23 17:19:42 INFO mapred.JobClient: Counters: 16
>> > 09/02/23 17:19:42 INFO mapred.JobClient:   Job Counters
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Data-local map tasks=2
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Launched reduce tasks=1
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Launched map tasks=2
>> > 09/02/23 17:19:42 INFO mapred.JobClient:   Map-Reduce Framework
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Map output records=25
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Reduce input records=23
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Map output bytes=238
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Map input records=5
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Combine output records=46
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Map input bytes=138
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Combine input records=48
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Reduce input groups=23
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Reduce output records=23
>> > 09/02/23 17:19:42 INFO mapred.JobClient:   File Systems
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     HDFS bytes written=175
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Local bytes written=648
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     HDFS bytes read=208
>> > 09/02/23 17:19:42 INFO mapred.JobClient:     Local bytes read=281
>> >
>> > With two slave nodes, the job completes in 13 minutes, and the console
>> output is shown below:
>> >
>> > [root@Fedora1 hadoop-0.18.3]# bin/hadoop jar samples/wordcount.jar
>> org.myorg.WordCount input output2
>> > 09/02/23 17:25:38 WARN mapred.JobClient: Use GenericOptionsParser for
>> parsing the arguments. Applications should implement Tool for the same.
>> > 09/02/23 17:25:38 INFO mapred.FileInputFormat: Total input paths to
>> process : 1
>> > 09/02/23 17:25:38 INFO mapred.FileInputFormat: Total input paths to
>> process : 1
>> > 09/02/23 17:25:39 INFO mapred.JobClient: Running job:
>> job_200902231722_0001
>> > 09/02/23 17:25:40 INFO mapred.JobClient:  map 0% reduce 0%
>> > 09/02/23 17:25:42 INFO mapred.JobClient:  map 50% reduce 0%
>> > 09/02/23 17:25:43 INFO mapred.JobClient:  map 100% reduce 0%
>> > 09/02/23 17:25:58 INFO mapred.JobClient:  map 100% reduce 16%
>> > 09/02/23 17:38:31 INFO mapred.JobClient: Task Id :
>> attempt_200902231722_0001_m_000000_0, Status : FAILED
>> > Too many fetch-failures
>> > 09/02/23 17:38:31 WARN mapred.JobClient: Error reading task outputNo
>> route to host
>> > 09/02/23 17:38:31 WARN mapred.JobClient: Error reading task outputNo
>> route to host
>> > 09/02/23 17:38:43 INFO mapred.JobClient: Job complete:
>> job_200902231722_0001
>> > 09/02/23 17:38:43 INFO mapred.JobClient: Counters: 16
>> > 09/02/23 17:38:43 INFO mapred.JobClient:   Job Counters
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Data-local map tasks=3
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Launched reduce tasks=1
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Launched map tasks=3
>> > 09/02/23 17:38:43 INFO mapred.JobClient:   Map-Reduce Framework
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Map output records=25
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Reduce input records=23
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Map output bytes=238
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Map input records=5
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Combine output records=46
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Map input bytes=138
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Combine input records=48
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Reduce input groups=23
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Reduce output records=23
>> > 09/02/23 17:38:43 INFO mapred.JobClient:   File Systems
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     HDFS bytes written=175
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Local bytes written=648
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     HDFS bytes read=208
>> > 09/02/23 17:38:43 INFO mapred.JobClient:     Local bytes read=281
>> >
>> > Thanks
>> >
>> > Jagadesh
>> >
>> >
>> >
>> > -----Original Message-----
>> > From: Jothi Padmanabhan [mailto:jothipn@yahoo-inc.com]
>> > Sent: Monday, February 23, 2009 4:57 PM
>> > To: core-user@hadoop.apache.org
>> > Subject: Re: Reducer hangs at 16%
>> >
>> > OK. I am guessing that your problem arises from having two entries for
>> > master. The master should be the node where the JT is run (for
>> > start-mapred.sh) and NN is run (for start-dfs.sh). This might need a
>> bit
>> > more effort to set up. To start with, you might want to try out having
>> both
>> > the JT and NN in the same machine (the node designated as master) and
>> then
>> > try start-all.sh. You need to configure you hadoop-site.xml correctly
>> as
>> > well.
>> >
>> > Jothi
>> >
>> >
>> >
>> >
>> > On 2/23/09 4:36 PM, "Jagadesh_Doddi" <Jagadesh_Doddi@satyam.com> wrote:
>> >
>> >
>> >> Hi
>> >>
>> >> I have setup as per the documentation in hadoop site.
>> >> On namenode, I am running bin/start-dfs.sh and on job tracker, I am
>> running
>> >> bin\start-mapred.sh
>> >>
>> >> Thanks and Regards
>> >>
>> >> Jagadesh Doddi
>> >>
>> >>
>> >>
>> >> -----Original Message-----
>> >> From: Jothi Padmanabhan [mailto:jothipn@yahoo-inc.com]
>> >> Sent: Monday, February 23, 2009 4:00 PM
>> >> To: core-user@hadoop.apache.org
>> >> Subject: Re: Reducer hangs at 16%
>> >>
>> >> Hi,
>> >>
>> >> This looks like a set up issue. See
>> >>
>> http://hadoop.apache.org/core/docs/current/cluster_setup.html#Configuration+
>> >> Files
>> >> On how to set this up correctly.
>> >>
>> >> As an aside, how are you bringing up the hadoop daemons (JobTracker,
>> >> Namenode, TT and Datanodes)?  Are you manually bringing them up or are
>> you
>> >> using bin/start-all.sh?
>> >>
>> >> Jothi
>> >>
>> >>
>> >> On 2/23/09 3:14 PM, "Jagadesh_Doddi" <Jagadesh_Doddi@satyam.com>
>> wrote:
>> >>
>> >>
>> >>> I have setup a distributed environment on Fedora OS to run Hadoop.
>> >>> System Fedora1 is the name node, Fedora2 is Job tracker, Fedora3 and
>> Fedora4
>> >>> are task trackers.
>> >>> Conf/masters contains the entries Fedora1, Fedors2, and conf/slaves
>> contains
>> >>> the entries Fedora3, Fedora4.
>> >>> When I run the sample wordcount example with single task tracker
>> (either
>> >>> Fedora3 or Fedora4), it works fine and the job completes in a few
>> seconds.
>> >>> However, when I add the other task tracker in conf/slaves, the
>> reducer
>> stop
>> >>> at
>> >>> 16% and the job completes after 13 minutes.
>> >>> The same problem exists in versions 16.4, 17.2.1 and 18.3. The output
>> on the
>> >>> namenode console is shown below:
>> >>>
>> >>> [root@Fedora1 hadoop-0.17.2.1Cluster]# bin/hadoop jar
>> samples/wordcount.jar
>> >>> org.myorg.WordCount input output
>> >>> 09/02/19 17:43:18 INFO mapred.FileInputFormat: Total input paths to
>> process :
>> >>> 1
>> >>> 09/02/19 17:43:19 INFO mapred.JobClient: Running job:
>> job_200902191741_0001
>> >>> 09/02/19 17:43:20 INFO mapred.JobClient:  map 0% reduce 0%
>> >>> 09/02/19 17:43:26 INFO mapred.JobClient:  map 50% reduce 0%
>> >>> 09/02/19 17:43:27 INFO mapred.JobClient:  map 100% reduce 0%
>> >>> 09/02/19 17:43:35 INFO mapred.JobClient:  map 100% reduce 16%
>> >>> 09/02/19 17:56:15 INFO mapred.JobClient: Task Id :
>> >>> task_200902191741_0001_m_000001_0, Status : FAILED
>> >>> Too many fetch-failures
>> >>> 09/02/19 17:56:15 WARN mapred.JobClient: Error reading task outputNo
>> route to
>> >>> host
>> >>> 09/02/19 17:56:18 WARN mapred.JobClient: Error reading task outputNo
>> route to
>> >>> host
>> >>> 09/02/19 17:56:25 INFO mapred.JobClient:  map 100% reduce 81%
>> >>> 09/02/19 17:56:26 INFO mapred.JobClient:  map 100% reduce 100%
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient: Job complete:
>> job_200902191741_0001
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient: Counters: 16
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:   Job Counters
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Launched map tasks=3
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Launched reduce tasks=1
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Data-local map tasks=3
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:   Map-Reduce Framework
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Map input records=5
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Map output records=25
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Map input bytes=138
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Map output bytes=238
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Combine input records=25
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Combine output
>> records=23
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Reduce input groups=23
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Reduce input records=23
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Reduce output records=23
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:   File Systems
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Local bytes read=522
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     Local bytes written=1177
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     HDFS bytes read=208
>> >>> 09/02/19 17:56:27 INFO mapred.JobClient:     HDFS bytes written=175
>> >>>
>> >>> Appreciate any help on this.
>> >>>
>> >>> Thanks
>> >>>
>> >>> Jagadesh
>> >>>
>> >>> DISCLAIMER:
>> >>> This email (including any attachments) is intended for the sole use
>> of
>> the
>> >>> intended recipient/s and may contain material that is CONFIDENTIAL
>> AND
>> >>> PRIVATE
>> >>> COMPANY INFORMATION. Any review or reliance by others or copying or
>> >>> distribution or forwarding of any or all of the contents in this
>> message is
>> >>> STRICTLY PROHIBITED. If you are not the intended recipient, please
>> contact
>> >>> the
>> >>> sender by email and delete all copies; your cooperation in this
>> regard
>> is
>> >>> appreciated.
>> >>>
>> >>
>> >> DISCLAIMER:
>> >> This email (including any attachments) is intended for the sole use of
>> the
>> >> intended recipient/s and may contain material that is CONFIDENTIAL AND
>> PRIVATE
>> >> COMPANY INFORMATION. Any review or reliance by others or copying or
>> >> distribution or forwarding of any or all of the contents in this
>> message
>> is
>> >> STRICTLY PROHIBITED. If you are not the intended recipient, please
>> contact the
>> >> sender by email and delete all copies; your cooperation in this regard
>> is
>> >> appreciated.
>> >>
>> >
>> >
>> >
>> > DISCLAIMER:
>> > This email (including any attachments) is intended for the sole use of
>> the intended recipient/s and may contain material that is CONFIDENTIAL
>> AND
>> PRIVATE COMPANY INFORMATION. Any review or reliance by others or copying
>> or
>> distribution or forwarding of any or all of the contents in this message
>> is
>> STRICTLY PROHIBITED. If you are not the intended recipient, please
>> contact
>> the sender by email and delete all copies; your cooperation in this
>> regard
>> is appreciated.
>> >
>>
>>
>>
>> DISCLAIMER:
>> This email (including any attachments) is intended for the sole use of
>> the
>> intended recipient/s and may contain material that is CONFIDENTIAL AND
>> PRIVATE COMPANY INFORMATION. Any review or reliance by others or copying
>> or
>> distribution or forwarding of any or all of the contents in this message
>> is
>> STRICTLY PROHIBITED. If you are not the intended recipient, please
>> contact
>> the sender by email and delete all copies; your cooperation in this
>> regard
>> is appreciated.
>>
> 
> DISCLAIMER:
> This email (including any attachments) is intended for the sole use of the
> intended recipient/s and may contain material that is CONFIDENTIAL AND
> PRIVATE COMPANY INFORMATION. Any review or reliance by others or copying
> or distribution or forwarding of any or all of the contents in this
> message is STRICTLY PROHIBITED. If you are not the intended recipient,
> please contact the sender by email and delete all copies; your cooperation
> in this regard is appreciated.
> 
> 

-- 
View this message in context: http://www.nabble.com/Reducer-hangs-at-16--tp22158282p24955366.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-16742-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 17:09:53 2009
Return-Path: <common-user-return-16742-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 26817 invoked from network); 13 Aug 2009 17:09:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 17:09:52 -0000
Received: (qmail 10907 invoked by uid 500); 13 Aug 2009 17:09:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10821 invoked by uid 500); 13 Aug 2009 17:09:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10811 invoked by uid 99); 13 Aug 2009 17:09:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:09:57 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [98.136.44.189] (HELO n64.bullet.mail.sp1.yahoo.com) (98.136.44.189)
    by apache.org (qpsmtpd/0.29) with SMTP; Thu, 13 Aug 2009 17:09:46 +0000
Received: from [69.147.84.145] by n64.bullet.mail.sp1.yahoo.com with NNFMP; 13 Aug 2009 17:09:25 -0000
Received: from [67.195.9.82] by t8.bullet.mail.sp1.yahoo.com with NNFMP; 13 Aug 2009 17:09:25 -0000
Received: from [67.195.9.100] by t2.bullet.mail.gq1.yahoo.com with NNFMP; 13 Aug 2009 17:09:24 -0000
Received: from [127.0.0.1] by omp104.mail.gq1.yahoo.com with NNFMP; 13 Aug 2009 17:09:24 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 984439.22440.bm@omp104.mail.gq1.yahoo.com
Received: (qmail 11474 invoked by uid 60001); 13 Aug 2009 17:09:24 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1250183364; bh=JfNcYwAf8cSsH89rSU451p0ZdMQIsnusJMFuJO7Pkjc=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=VqfVo608xBmjhoYZMkoQJQsY15O8NPGp/4rzeBsiNW8cGR3NjP9Ebdyf3NwwVYuNbhK2IkVX+nC1GAsbuH/WvAVpodtqytdEvXxHYdGdZ3CBIqE6hBU6SwUdtooYJUBWywPfS23IbdRZOE872a5Rr3JiUMkTAI5Y7l8kEVzeuHg=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=4tIx3u4XfY0CZdeH6vfA58+drmuPH+xJ5jUVjZTIFT1Gr5hwdx6tGmgg3IdT21a4EHUAoJ3OCYGrqBU4GuYX/T6puZsv1XcXQhgD19XawNYn3H0j1LTB4MQMJ24/mqH32zJSQI+7aEVa9sn2WEQ6D/Lvmc7+K8+qnNjwSzQkId8=;
Message-ID: <834694.10557.qm@web110111.mail.gq1.yahoo.com>
X-YMail-OSG: hPdMua8VM1l03iSsRRcoODbQTY.DSk2pqEkrdnetWXQ_Nx5Sff_fW5Fn2w5wdOv4D5XGQ_uqz58Yb584mxLDDttYm3qjS.yOXSQJQwNQiuZpg4QBYYPbMUCjB_LTDBdzYkDaDT.WSWeKbx6Lhz0eovT5qicLFcerqo0ul02z1Im_LWeF2anPcGl36b65LfkRxBeKHC_1aEoPUuV.b.e_YyS2hQj3YpASqNT.EGbBm5ikj3nORHOCo_772raEaKu7bjBSTSD48_yUOuAq9LjG2KN2JQpYWPSnNukaXdbT0jV6Bgl0Sx_v8a53JzcRk4EQRuw-
Received: from [216.243.71.77] by web110111.mail.gq1.yahoo.com via HTTP; Thu, 13 Aug 2009 10:09:24 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com>  <c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com>  <3b1311780908121936h5895a966r264a2bbd76a2c82e@mail.gmail.com> <e01b80590908122114i71903a73r163dff1d148dfa75@mail.gmail.com>
Date: Thu, 13 Aug 2009 10:09:24 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: How to re-read the config files
To: common-user@hadoop.apache.org
In-Reply-To: <e01b80590908122114i71903a73r163dff1d148dfa75@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-909100822-1250183364=:10557"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-909100822-1250183364=:10557
Content-Type: text/plain; charset=us-ascii

Hi,

I was wondering if there is way to let Hadoop re-read the config file (hadoop-site.xml) after  making some changes in it.

I don't want to restart the whole cluster for that.

I am using Hadoop 0.19.2

Thanks!
Arvind



      
--0-909100822-1250183364=:10557--


From common-user-return-16743-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 17:38:08 2009
Return-Path: <common-user-return-16743-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 38754 invoked from network); 13 Aug 2009 17:38:08 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 17:38:08 -0000
Received: (qmail 60967 invoked by uid 500); 13 Aug 2009 17:38:12 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 60875 invoked by uid 500); 13 Aug 2009 17:38:12 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 60865 invoked by uid 99); 13 Aug 2009 17:38:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:38:12 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:38:00 +0000
Received: from [10.72.185.127] (gentlepaint-lx.corp.yahoo.com [10.72.185.127])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7DHbK0Z044347
	for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 10:37:20 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=gyEUckoCN4VxcRfmUiaHXqlzd0WLhAZxS8vwQufRHqqRgkOAO49g96Oolz//ImWb
Message-ID: <4A844F50.8010407@yahoo-inc.com>
Date: Thu, 13 Aug 2009 10:37:20 -0700
From: Konstantin Shvachko <shv@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: HADOOP-4539 question
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com> 	<4A7BECD9.20303@apache.org> <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com> 	<4A814BCD.2060500@apache.org> <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com> 	<77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com> 	<45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com> 	<4A8312C5.9080307@yahoo-inc.com> <45f85f70908121227o679f4887l9ec1c053270af40a@mail.gmail.com> <4A832601.1030001@yahoo-inc.com> <4A841C86.3090605@apache.org>
In-Reply-To: <4A841C86.3090605@apache.org>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Steve,

There are other groups claimed they work on HA solution.
We had discussions about it not so long ago in this list.
Is it possible that your colleagues present their design?
As you point out the issue gets fairly complex fast,
particularly because of the split-brain problem you describe.

There are several jiras dedicated to the problem already.
You can post your design there or create a new one.

 > Looking at the facebook/google "multi-master" solution, I think they
 > don't worry about consistency, just let the masters drift apart.

Not sure I follow this.
What facebook/google "multi-master" solution?
Why would they not worry about consistency?
Consistency of what?

Thanks,
--Konstantin

Steve Loughran wrote:
> Konstantin Shvachko wrote:
>> And the only remaining step is to implement fail-over mechanism.
> 
> :)
> 
> Colleagues of mine work on HA stuff; I try and steer clear of it as it 
> gets complex fast.  Test case: what happens when a network failure 
> splits the datacentre in two, you now have two clusters each with half 
> the data and possibly a primary/2ary master in each one. Then leave the 
> partition up for a while, do inconsistent operations on each then have 
> the network come back up.  Then work out how to merge the state
> 
> Looking at the facebook/google "multi-master" solution, I think they 
> don't worry about consistency, just let the masters drift apart.
> 
> see also Johan's recent talk on HDFS: 
> http://www.slideshare.net/steve_l/hdfs
> 

From common-user-return-16744-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 17:41:57 2009
Return-Path: <common-user-return-16744-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 40590 invoked from network); 13 Aug 2009 17:41:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 17:41:56 -0000
Received: (qmail 67672 invoked by uid 500); 13 Aug 2009 17:42:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 67579 invoked by uid 500); 13 Aug 2009 17:42:01 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 67569 invoked by uid 99); 13 Aug 2009 17:42:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:42:01 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.211.172] (HELO mail-yw0-f172.google.com) (209.85.211.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:41:50 +0000
Received: by ywh2 with SMTP id 2so1289325ywh.2
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 10:41:28 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.91.204.23 with SMTP id g23mr701910agq.19.1250185284100; Thu, 
	13 Aug 2009 10:41:24 -0700 (PDT)
In-Reply-To: <4A844F50.8010407@yahoo-inc.com>
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com> 
	<4A814BCD.2060500@apache.org> <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com> 
	<77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com> 
	<45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com> 
	<4A8312C5.9080307@yahoo-inc.com> <45f85f70908121227o679f4887l9ec1c053270af40a@mail.gmail.com> 
	<4A832601.1030001@yahoo-inc.com> <4A841C86.3090605@apache.org> 
	<4A844F50.8010407@yahoo-inc.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Thu, 13 Aug 2009 10:41:03 -0700
Message-ID: <45f85f70908131041o70228d29sb72c17310145a3f7@mail.gmail.com>
Subject: Re: HADOOP-4539 question
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636af00e7c329f0047109713f
X-Virus-Checked: Checked by ClamAV on apache.org

--001636af00e7c329f0047109713f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 13, 2009 at 10:37 AM, Konstantin Shvachko <shv@yahoo-inc.com>wrote:

> Steve,
>
> There are other groups claimed they work on HA solution.
> We had discussions about it not so long ago in this list.
> Is it possible that your colleagues present their design?
> As you point out the issue gets fairly complex fast,
> particularly because of the split-brain problem you describe.
>

IMHO the split-brain problem is why failover has to either be triggered
manually, or has to be done by an external system like Linux-HA where you
can get multiple media connecting the two masters. In the past I've done
this for firewalls and DB servers using a null modem serial connection plus
a crossover plus pings over the LAN - with 3 separate heartbeats it's very
tough to get a split brain. If you absolutely must avoid it, you can also
trigger a "STONITH" policy: http://linux-ha.org/STONITH


>
> There are several jiras dedicated to the problem already.
> You can post your design there or create a new one.
>
> > Looking at the facebook/google "multi-master" solution, I think they
> > don't worry about consistency, just let the masters drift apart.
>
> Not sure I follow this.
> What facebook/google "multi-master" solution?
> Why would they not worry about consistency?
> Consistency of what?
>
> Thanks,
> --Konstantin
>
>
> Steve Loughran wrote:
>
>> Konstantin Shvachko wrote:
>>
>>> And the only remaining step is to implement fail-over mechanism.
>>>
>>
>> :)
>>
>> Colleagues of mine work on HA stuff; I try and steer clear of it as it
>> gets complex fast.  Test case: what happens when a network failure splits
>> the datacentre in two, you now have two clusters each with half the data and
>> possibly a primary/2ary master in each one. Then leave the partition up for
>> a while, do inconsistent operations on each then have the network come back
>> up.  Then work out how to merge the state
>>
>> Looking at the facebook/google "multi-master" solution, I think they don't
>> worry about consistency, just let the masters drift apart.
>>
>> see also Johan's recent talk on HDFS:
>> http://www.slideshare.net/steve_l/hdfs
>>
>>

--001636af00e7c329f0047109713f--

From common-user-return-16745-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 17:45:09 2009
Return-Path: <common-user-return-16745-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 42404 invoked from network); 13 Aug 2009 17:45:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 17:45:09 -0000
Received: (qmail 75958 invoked by uid 500); 13 Aug 2009 17:45:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 75861 invoked by uid 500); 13 Aug 2009 17:45:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 75848 invoked by uid 500); 13 Aug 2009 17:45:13 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 75843 invoked by uid 99); 13 Aug 2009 17:45:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:45:13 +0000
X-ASF-Spam-Status: No, hits=1.4 required=10.0
	tests=ASF_LIST_OPS,HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.210.185 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:45:04 +0000
Received: by yxe15 with SMTP id 15so1259700yxe.5
        for <multiple recipients>; Thu, 13 Aug 2009 10:44:41 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.101.161.3 with SMTP id n3mr1147451ano.24.1250185481430; Thu, 
	13 Aug 2009 10:44:41 -0700 (PDT)
Date: Thu, 13 Aug 2009 10:44:41 -0700
Message-ID: <77f4f8890908131044u38eed342o40fadf0050fe56b4@mail.gmail.com>
Subject: Intermediary Data on Fair Scheduler
From: Mithila Nagendra <mnagendr@asu.edu>
To: core-user@hadoop.apache.org, core-user-subscribe@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636ed6a868626de0471097d45
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed6a868626de0471097d45
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello All

When the fair scheduler switches between two jobs, what does it do with the
intermediary data? Does it dump the data/job states onto the disk (DFS)? Or
does it do a context switch (i.e. everything is in memory)? I was looking at
the scheduler for an application I'm working on, any pointers will be
appreciated!

Thanks!
Mithila Nagendra
Arizona State University

--001636ed6a868626de0471097d45--

From common-user-return-16746-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 17:47:06 2009
Return-Path: <common-user-return-16746-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 43261 invoked from network); 13 Aug 2009 17:47:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 17:47:06 -0000
Received: (qmail 81169 invoked by uid 500); 13 Aug 2009 17:47:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 81081 invoked by uid 500); 13 Aug 2009 17:47:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 81071 invoked by uid 99); 13 Aug 2009 17:47:10 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:47:10 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:46:58 +0000
Received: from [10.72.185.127] (gentlepaint-lx.corp.yahoo.com [10.72.185.127])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7DHjg02047220
	for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 10:45:42 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=iCam/3c36kqffqIsQ0Rp8uGKIbrtS+RJLUinJDl76TXujEqgPOB6S96EQTPa32EE
Message-ID: <4A845146.8030806@yahoo-inc.com>
Date: Thu, 13 Aug 2009 10:45:42 -0700
From: Konstantin Shvachko <shv@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: HADOOP-4539 question
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com>	 <4A7BECD9.20303@apache.org>	 <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com>	 <4A814BCD.2060500@apache.org>	 <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com>	 <77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com>	 <45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com>	 <4A8312C5.9080307@yahoo-inc.com>	 <45f85f70908121227o679f4887l9ec1c053270af40a@mail.gmail.com>	 <4A832601.1030001@yahoo-inc.com> <77938bc20908130355s27217f24x84446110b16c63ee@mail.gmail.com>
In-Reply-To: <77938bc20908130355s27217f24x84446110b16c63ee@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

There is no "native" HA solution for HDFS at the moment.
"External" HA solutions, like Coudera's may exist.
Cannot speak for everybody, but I know at least one different approach.

--Konstantin

Stas Oskin wrote:
> Hi.
> 
>> This is exactly the goal (long term). To evolve BN into StandbyNode,
>> which will be able to take over when main NN dies without restarting
>> anything else.
>> And the only remaining step is to implement fail-over mechanism.
>>
>>
> 
> Just to clarify, for the near future, the only HA option is Cloudera  DRDB
> approach.
> 
> Correct?
> 

From common-user-return-16747-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 17:53:42 2009
Return-Path: <common-user-return-16747-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 46656 invoked from network); 13 Aug 2009 17:53:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 17:53:42 -0000
Received: (qmail 96779 invoked by uid 500); 13 Aug 2009 17:53:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 96710 invoked by uid 500); 13 Aug 2009 17:53:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 96700 invoked by uid 99); 13 Aug 2009 17:53:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:53:47 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.211.172] (HELO mail-yw0-f172.google.com) (209.85.211.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 17:53:39 +0000
Received: by ywh2 with SMTP id 2so1300353ywh.2
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 10:53:17 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.117.13 with SMTP id p13mr648069agc.109.1250185997312; Thu, 
	13 Aug 2009 10:53:17 -0700 (PDT)
In-Reply-To: <77f4f8890908131044u38eed342o40fadf0050fe56b4@mail.gmail.com>
References: <77f4f8890908131044u38eed342o40fadf0050fe56b4@mail.gmail.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Thu, 13 Aug 2009 10:52:57 -0700
Message-ID: <45f85f70908131052v6d6d547dtb291eacb8b42efa1@mail.gmail.com>
Subject: Re: Intermediary Data on Fair Scheduler
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016362836cc45e2a80471099c2b
X-Virus-Checked: Checked by ClamAV on apache.org

--0016362836cc45e2a80471099c2b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Mithila,

I assume you're referring to fair scheduler preemption. In the preemption
scenario, tasks are completely killed, not paused. It's not like a
preemptive scheduler in your OS where things are "context switched". This is
why the preemption is not enabled by default and has tuning parameters that
only trigger preemption in certain situations.

Hope that helps,
-Todd

On Thu, Aug 13, 2009 at 10:44 AM, Mithila Nagendra <mnagendr@asu.edu> wrote:

> Hello All
>
> When the fair scheduler switches between two jobs, what does it do with the
> intermediary data? Does it dump the data/job states onto the disk (DFS)? Or
> does it do a context switch (i.e. everything is in memory)? I was looking
> at
> the scheduler for an application I'm working on, any pointers will be
> appreciated!
>
> Thanks!
> Mithila Nagendra
> Arizona State University
>

--0016362836cc45e2a80471099c2b--

From common-user-return-16748-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 18:33:14 2009
Return-Path: <common-user-return-16748-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75251 invoked from network); 13 Aug 2009 18:33:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 18:33:14 -0000
Received: (qmail 64337 invoked by uid 500); 13 Aug 2009 18:33:18 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 64256 invoked by uid 500); 13 Aug 2009 18:33:18 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 64246 invoked by uid 99); 13 Aug 2009 18:33:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 18:33:18 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.211.172 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.211.172] (HELO mail-yw0-f172.google.com) (209.85.211.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 18:33:09 +0000
Received: by ywh2 with SMTP id 2so1337309ywh.2
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 11:32:48 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.100.11.14 with SMTP id 14mr1195269ank.81.1250188368498; Thu, 
	13 Aug 2009 11:32:48 -0700 (PDT)
In-Reply-To: <45f85f70908131052v6d6d547dtb291eacb8b42efa1@mail.gmail.com>
References: <77f4f8890908131044u38eed342o40fadf0050fe56b4@mail.gmail.com>
	 <45f85f70908131052v6d6d547dtb291eacb8b42efa1@mail.gmail.com>
Date: Thu, 13 Aug 2009 11:32:48 -0700
Message-ID: <77f4f8890908131132w77d93e25i494ccf55ff996224@mail.gmail.com>
Subject: Re: Intermediary Data on Fair Scheduler
From: Mithila Nagendra <mnagendr@asu.edu>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e642dd649b51b504710a29c7
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e642dd649b51b504710a29c7
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Todd

So does this mean that when two jobs are assigned to a pool, where one job
has 1 map task and 1 reduce task, whereas the other has 5 map and 5 reduce
tasks, how will the switch between these jobs take place?

Lets say the scheduler starts with the bigger job, runs 1 map task, when it
switches to the shorter job what does it do with the intermediate data? for
instance in Hadoop on demand if we run a search query where would the search
keywords be stored? I assume if the bigger job is in middle of a map task
the smaller job will wait for the task to end before the the map task for
the shorter job is launched.

Thanks!
Mithila

On Thu, Aug 13, 2009 at 10:52 AM, Todd Lipcon <todd@cloudera.com> wrote:

> Hi Mithila,
>
> I assume you're referring to fair scheduler preemption. In the preemption
> scenario, tasks are completely killed, not paused. It's not like a
> preemptive scheduler in your OS where things are "context switched". This
> is
> why the preemption is not enabled by default and has tuning parameters that
> only trigger preemption in certain situations.
>
> Hope that helps,
> -Todd
>
> On Thu, Aug 13, 2009 at 10:44 AM, Mithila Nagendra <mnagendr@asu.edu>
> wrote:
>
> > Hello All
> >
> > When the fair scheduler switches between two jobs, what does it do with
> the
> > intermediary data? Does it dump the data/job states onto the disk (DFS)?
> Or
> > does it do a context switch (i.e. everything is in memory)? I was looking
> > at
> > the scheduler for an application I'm working on, any pointers will be
> > appreciated!
> >
> > Thanks!
> > Mithila Nagendra
> > Arizona State University
> >
>

--0016e642dd649b51b504710a29c7--

From common-user-return-16749-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 18:42:21 2009
Return-Path: <common-user-return-16749-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 77771 invoked from network); 13 Aug 2009 18:42:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 18:42:21 -0000
Received: (qmail 91692 invoked by uid 500); 13 Aug 2009 18:42:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91612 invoked by uid 500); 13 Aug 2009 18:42:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91597 invoked by uid 99); 13 Aug 2009 18:42:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 18:42:25 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.211.172] (HELO mail-yw0-f172.google.com) (209.85.211.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 18:42:17 +0000
Received: by ywh2 with SMTP id 2so1346100ywh.2
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 11:41:55 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.32.9 with SMTP id f9mr664923agf.103.1250188915584; Thu, 13 
	Aug 2009 11:41:55 -0700 (PDT)
In-Reply-To: <77f4f8890908131132w77d93e25i494ccf55ff996224@mail.gmail.com>
References: <77f4f8890908131044u38eed342o40fadf0050fe56b4@mail.gmail.com> 
	<45f85f70908131052v6d6d547dtb291eacb8b42efa1@mail.gmail.com> 
	<77f4f8890908131132w77d93e25i494ccf55ff996224@mail.gmail.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Thu, 13 Aug 2009 11:40:02 -0700
Message-ID: <45f85f70908131140m77237583x394ff41c1b80f496@mail.gmail.com>
Subject: Re: Intermediary Data on Fair Scheduler
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636163df93730d104710a4a11
X-Virus-Checked: Checked by ClamAV on apache.org

--001636163df93730d104710a4a11
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 13, 2009 at 11:32 AM, Mithila Nagendra <mnagendr@asu.edu> wrote:

> Hi Todd
>
> So does this mean that when two jobs are assigned to a pool, where one job
> has 1 map task and 1 reduce task, whereas the other has 5 map and 5 reduce
> tasks, how will the switch between these jobs take place?


The switching happens on the task level - after one of the map tasks from
the big job has finished, the small job will get its map task executed
before the rest of the other job's.


>
>
> Lets say the scheduler starts with the bigger job, runs 1 map task, when it
> switches to the shorter job what does it do with the intermediate data? for
> instance in Hadoop on demand if we run a search query where would the
> search
> keywords be stored? I assume if the bigger job is in middle of a map task
> the smaller job will wait for the task to end before the the map task for
> the shorter job is launched.
>

Intermediate data from the big job will be on the local disk like it always
is - this isn't anything special about the fair scheduler. Map outputs
remain in mapred.local.dir until the job is complete.

-Todd


On Thu, Aug 13, 2009 at 10:52 AM, Todd Lipcon <todd@cloudera.com> wrote:

> Hi Mithila,
>
> I assume you're referring to fair scheduler preemption. In the preemption
> scenario, tasks are completely killed, not paused. It's not like a
> preemptive scheduler in your OS where things are "context switched". This
> is
> why the preemption is not enabled by default and has tuning parameters
that
> only trigger preemption in certain situations.
>
> Hope that helps,
> -Todd
>
> On Thu, Aug 13, 2009 at 10:44 AM, Mithila Nagendra <mnagendr@asu.edu>
> wrote:
>
> > Hello All
> >
> > When the fair scheduler switches between two jobs, what does it do with
> the
> > intermediary data? Does it dump the data/job states onto the disk (DFS)?
> Or
> > does it do a context switch (i.e. everything is in memory)? I was
looking
> > at
> > the scheduler for an application I'm working on, any pointers will be
> > appreciated!
> >
> > Thanks!
> > Mithila Nagendra
> > Arizona State University
> >
>

--001636163df93730d104710a4a11--

From common-user-return-16750-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 18:50:41 2009
Return-Path: <common-user-return-16750-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80082 invoked from network); 13 Aug 2009 18:50:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 18:50:41 -0000
Received: (qmail 14732 invoked by uid 500); 13 Aug 2009 18:50:45 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 14695 invoked by uid 500); 13 Aug 2009 18:50:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 14685 invoked by uid 99); 13 Aug 2009 18:50:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 18:50:45 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 209.85.211.172 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.211.172] (HELO mail-yw0-f172.google.com) (209.85.211.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 18:50:37 +0000
Received: by ywh2 with SMTP id 2so1353686ywh.2
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 11:50:14 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.100.34.16 with SMTP id h16mr1195282anh.48.1250189413786; Thu, 
	13 Aug 2009 11:50:13 -0700 (PDT)
In-Reply-To: <45f85f70908131140m77237583x394ff41c1b80f496@mail.gmail.com>
References: <77f4f8890908131044u38eed342o40fadf0050fe56b4@mail.gmail.com>
	 <45f85f70908131052v6d6d547dtb291eacb8b42efa1@mail.gmail.com>
	 <77f4f8890908131132w77d93e25i494ccf55ff996224@mail.gmail.com>
	 <45f85f70908131140m77237583x394ff41c1b80f496@mail.gmail.com>
Date: Thu, 13 Aug 2009 11:50:13 -0700
Message-ID: <77f4f8890908131150g3f768024ka68517c0ee59ac71@mail.gmail.com>
Subject: Re: Intermediary Data on Fair Scheduler
From: Mithila Nagendra <mnagendr@asu.edu>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64653f2e925cc04710a67ae
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64653f2e925cc04710a67ae
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

This helps a lot! Thank you Todd.

Best Regards
Mithila

On Thu, Aug 13, 2009 at 11:40 AM, Todd Lipcon <todd@cloudera.com> wrote:

> On Thu, Aug 13, 2009 at 11:32 AM, Mithila Nagendra <mnagendr@asu.edu>
> wrote:
>
> > Hi Todd
> >
> > So does this mean that when two jobs are assigned to a pool, where one
> job
> > has 1 map task and 1 reduce task, whereas the other has 5 map and 5
> reduce
> > tasks, how will the switch between these jobs take place?
>
>
> The switching happens on the task level - after one of the map tasks from
> the big job has finished, the small job will get its map task executed
> before the rest of the other job's.
>
>
> >
> >
> > Lets say the scheduler starts with the bigger job, runs 1 map task, when
> it
> > switches to the shorter job what does it do with the intermediate data?
> for
> > instance in Hadoop on demand if we run a search query where would the
> > search
> > keywords be stored? I assume if the bigger job is in middle of a map task
> > the smaller job will wait for the task to end before the the map task for
> > the shorter job is launched.
> >
>
> Intermediate data from the big job will be on the local disk like it always
> is - this isn't anything special about the fair scheduler. Map outputs
> remain in mapred.local.dir until the job is complete.
>
> -Todd
>
>
> On Thu, Aug 13, 2009 at 10:52 AM, Todd Lipcon <todd@cloudera.com> wrote:
>
> > Hi Mithila,
> >
> > I assume you're referring to fair scheduler preemption. In the preemption
> > scenario, tasks are completely killed, not paused. It's not like a
> > preemptive scheduler in your OS where things are "context switched". This
> > is
> > why the preemption is not enabled by default and has tuning parameters
> that
> > only trigger preemption in certain situations.
> >
> > Hope that helps,
> > -Todd
> >
> > On Thu, Aug 13, 2009 at 10:44 AM, Mithila Nagendra <mnagendr@asu.edu>
> > wrote:
> >
> > > Hello All
> > >
> > > When the fair scheduler switches between two jobs, what does it do with
> > the
> > > intermediary data? Does it dump the data/job states onto the disk
> (DFS)?
> > Or
> > > does it do a context switch (i.e. everything is in memory)? I was
> looking
> > > at
> > > the scheduler for an application I'm working on, any pointers will be
> > > appreciated!
> > >
> > > Thanks!
> > > Mithila Nagendra
> > > Arizona State University
> > >
> >
>

--0016e64653f2e925cc04710a67ae--

From common-user-return-16751-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 19:49:01 2009
Return-Path: <common-user-return-16751-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 95547 invoked from network); 13 Aug 2009 19:49:01 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 19:49:01 -0000
Received: (qmail 94246 invoked by uid 500); 13 Aug 2009 19:49:05 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 94172 invoked by uid 500); 13 Aug 2009 19:49:05 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 94162 invoked by uid 99); 13 Aug 2009 19:49:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 19:49:05 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [208.97.132.202] (HELO spunkymail-a13.g.dreamhost.com) (208.97.132.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 19:48:55 +0000
Received: from enigma (75-92-224-96.sea.clearwire-dns.net [75.92.224.96])
	(using TLSv1 with cipher DHE-RSA-AES128-SHA (128/128 bits))
	(No client certificate requested)
	by spunkymail-a13.g.dreamhost.com (Postfix) with ESMTP id 9C2FA129B2A
	for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 12:48:06 -0700 (PDT)
From: Phil Hagelberg <phil@hagelb.org>
To: common-user@hadoop.apache.org
Subject: Failure distcping to S3
Date: Thu, 13 Aug 2009 12:48:05 -0700
Message-ID: <87praz7ax6.fsf@hagelb.org>
User-Agent: Gnus/5.13 (Gnus v5.13) Emacs/23.1.50 (gnu/linux)
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary="=-=-="
X-Virus-Checked: Checked by ClamAV on apache.org

--=-=-=


I'm trying to perform a distcp from HDFS to S3. I start it with something like:

  $ hadoop distcp /data s3n://my-bucket/packed/

The output shows a lot of 404 warnings. However, it never shows any
errors that presumably would be causing these 404s to begin with. I'm
assuming lots of upload attempts to S3 are failing, but for some reason
Hadoop is only logging the attempts to read these files it expects to
exist and not showing the log output for the original failures. I'm not
seeing errors in the logs of the individual nodes either.

In the end my job fails, but it gives precious little explanation as to
why. I've attached the output of distcp.

I've also tried increasing the retry max to 10 and the timeout to 2
minutes via jets3t.properties, but this doesn't seem to have an effect.

Any ideas?

thanks,
Phil Hagelberg
http://technomancy.us


--=-=-=--

From common-user-return-16752-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 20:07:45 2009
Return-Path: <common-user-return-16752-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 99071 invoked from network); 13 Aug 2009 20:07:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 20:07:45 -0000
Received: (qmail 17060 invoked by uid 500); 13 Aug 2009 20:07:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 16970 invoked by uid 500); 13 Aug 2009 20:07:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 54737 invoked by uid 99); 12 Aug 2009 03:32:38 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.198.237 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=6+K0klJ/cA2rTPs78eGfAv0sg2nRMwxyUkh+T/ZPvXk=;
        b=Dtx00SgdBPel9KflvCtolmSaFYJx2oso9sLpdcXPzTFcZVPb4yJ2KrpLfdMLRcZWxS
         C5H6QCXfisyw1UbJ2E6ueKOnc5wvnzaRcIHtjMNlRc75OWQeoEnPEasoLJtHVYXQkkjw
         hKR6lHw3B7Wx6zIiGle57QKpFn6XWMnVjf+No=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=Vg18C6hJypc67eDqlahrSXtC4d/+xS6GVuyQdmBWEShihldDpSdopCfiR68b8ApnyT
         HGapnMpfCK3Ei5upAOJSi/CsjktBJ9R0TEP3n3EpOZsfUlogcgzxkl5idfFFFxlK5+T/
         o0+HRqUdGlXJKKhwgN4REuzcGri6tWWfCoKto=
MIME-Version: 1.0
Date: Wed, 12 Aug 2009 11:32:08 +0800
Message-ID: <3b1311780908112032g5413e0ay8cfc8e29eabb0b8b@mail.gmail.com>
Subject: What will we encounter if we add a lot of nodes into the current 
	cluster?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd2c0eacf23920470e976a9
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd2c0eacf23920470e976a9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Dear all
    I'm sorry to disturb you.
    Our cluster has 200 nodes now. In order to improve its ability, we hope
to add 60 nodes into the current cluster. However, we all don't know what
will happen if we add so many nodes at the same time. Could you give me some
tips and notes? During the process, which part shall we pay much attention
on?
    Thank you!

    P.S. Our environment is hadoop-0.19.1, jdk1.6.0_06, linux redhat
enterprise 4.0

--000e0cd2c0eacf23920470e976a9--

From common-user-return-16753-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 20:08:08 2009
Return-Path: <common-user-return-16753-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 99294 invoked from network); 13 Aug 2009 20:08:08 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 20:08:08 -0000
Received: (qmail 22105 invoked by uid 500); 13 Aug 2009 20:08:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 22054 invoked by uid 500); 13 Aug 2009 20:08:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 54824 invoked by uid 99); 12 Aug 2009 03:32:43 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.198.237 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=FA3hxpvDDoasl+2jrnZH6+maCTEUrNu9CgR7U6ow6Tg=;
        b=qoC81EIDqwEE+z8zkgC0ahAmFuVdCSn7kDDw4gPaSY7q5KA/JJs/M1/YP6EUbTOamQ
         8QZubOaKBjFtVfLWKEddo61jo7rqjj0bP3DTeXjwHEJrWtbteRpA7RUWLwDtWtRUmuBc
         qeQjFIWY1CPs3VVzpzY1bucvzGWtJ5Z7ovPsA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=SFiDLlRRhKmJolY1pk/X4jxpdqkl3XPVcVCQfNVFKp6Z+6p/2jifh3LmczEWYh3V5y
         eWhJvczE+kjF9Tt+IpomRGe7mBnfr0a8tecZIFaIoTLn1k5Paoz12mUMIHIBZCzdz0bT
         BLIkN4h2/DnFxiMsOj5ZCuFonKp0g7HToJX4Q=
MIME-Version: 1.0
Date: Wed, 12 Aug 2009 11:32:10 +0800
Message-ID: <3b1311780908112032l5c1ab3c1mf27c7d6cdd7090e6@mail.gmail.com>
Subject: What will we encounter if we add a lot of nodes into the current 
	cluster?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd2950cd6953c0470e9768a
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd2950cd6953c0470e9768a
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Dear all
    I'm sorry to disturb you.
    Our cluster has 200 nodes now. In order to improve its ability, we hope
to add 60 nodes into the current cluster. However, we all don't know what
will happen if we add so many nodes at the same time. Could you give me some
tips and notes? During the process, which part shall we pay much attention
on?
    Thank you!

    P.S. Our environment is hadoop-0.19.1, jdk1.6.0_06, linux redhat
enterprise 4.0

--000e0cd2950cd6953c0470e9768a--

From common-user-return-16754-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 21:06:38 2009
Return-Path: <common-user-return-16754-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 15645 invoked from network); 13 Aug 2009 21:06:37 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 21:06:37 -0000
Received: (qmail 7893 invoked by uid 500); 13 Aug 2009 21:06:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 7822 invoked by uid 500); 13 Aug 2009 21:06:41 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 7812 invoked by uid 99); 13 Aug 2009 21:06:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 21:06:41 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 21:06:29 +0000
Received: from [172.21.149.52] (wlanvpn-mc2e-247-52.corp.yahoo.com [172.21.149.52])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7DL4h5m072332
	for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 14:04:43 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=BJO0uqXP2RmnzLS5I7ZKXYDYYCZL4fnVFN9FRq9JCsZG+i0C/5gjpj50yNDAkKA7
Message-ID: <4A847FEB.2080801@yahoo-inc.com>
Date: Thu, 13 Aug 2009 14:04:43 -0700
From: Jakob Homan <jhoman@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.12 (Macintosh/20080213)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: How to re-read the config files
References: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com>  <c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com>  <3b1311780908121936h5895a966r264a2bbd76a2c82e@mail.gmail.com> <e01b80590908122114i71903a73r163dff1d148dfa75@mail.gmail.com> <834694.10557.qm@web110111.mail.gq1.yahoo.com>
In-Reply-To: <834694.10557.qm@web110111.mail.gq1.yahoo.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Arvind-
    You'll probably want to look at the Configuration.reload() method, 
as demonstrated:

public class TestReloadConfig {
   public static void main(String[] args) throws IOException {
     Configuration conf = new Configuration();
     FileSystem fs = FileSystem.get(conf); // pull in dfs settings

     System.out.println("Replication = " + conf.get("dfs.replication"));
     System.out.println("Update file and press <enter>");
     new Scanner(System.in).nextLine();

     conf.reloadConfiguration();
     System.out.println("Now replication = " + conf.get("dfs.replication"));
   }
}

Note from the Javadoc: Values that are added via set methods will 
overlay values read from the resources.

Hope this helps.  Write back if you have more questions.

Thanks,
Jakob Homan
Hadoop at Yahoo!


Arvind Sharma wrote:
> Hi,
> 
> I was wondering if there is way to let Hadoop re-read the config file (hadoop-site.xml) after  making some changes in it.
> 
> I don't want to restart the whole cluster for that.
> 
> I am using Hadoop 0.19.2
> 
> Thanks!
> Arvind
> 
> 
> 
>       


From common-user-return-16755-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 22:09:53 2009
Return-Path: <common-user-return-16755-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 46921 invoked from network); 13 Aug 2009 22:09:53 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 22:09:53 -0000
Received: (qmail 90856 invoked by uid 500); 13 Aug 2009 22:09:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 90762 invoked by uid 500); 13 Aug 2009 22:09:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 90752 invoked by uid 99); 13 Aug 2009 22:09:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 22:09:57 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [98.136.44.43] (HELO n59.bullet.mail.sp1.yahoo.com) (98.136.44.43)
    by apache.org (qpsmtpd/0.29) with SMTP; Thu, 13 Aug 2009 22:09:44 +0000
Received: from [69.147.84.144] by n59.bullet.mail.sp1.yahoo.com with NNFMP; 13 Aug 2009 22:08:09 -0000
Received: from [67.195.9.81] by t6.bullet.mail.sp1.yahoo.com with NNFMP; 13 Aug 2009 22:08:09 -0000
Received: from [67.195.9.97] by t1.bullet.mail.gq1.yahoo.com with NNFMP; 13 Aug 2009 22:08:09 -0000
Received: from [127.0.0.1] by omp101.mail.gq1.yahoo.com with NNFMP; 13 Aug 2009 22:08:09 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 766687.52735.bm@omp101.mail.gq1.yahoo.com
Received: (qmail 4508 invoked by uid 60001); 13 Aug 2009 22:08:09 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1250201289; bh=LpjskW2Rd3KrC+iCuKhU8L3eSN5q/0HKz3I4O8BVaKM=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=LBrVZJCEdgVrKmyxbRTThuPD435qkuzhrvKpcg+G4kSf0vaRRrYGQQkMPLtptZaw6C5faYp9Dna96iRmCmIvHFqVW62sMDJ5iIT1l+ZBQmY7M/Wmga+5GYVBOq4ulxCWAY3I4sxhG7yue51u6MqNDvFzPizwsT6uj8nFO9NMZJM=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=lL0ab2WzLgvL7bmuBAO7qdrLS0vK4NK6DwhvAsiiorm48/mz/4bVA6znUJKf56izKQ6u8vyXCCxtxUNzHZ00BbYNAUItHWCLE8BnMdDvEfgb1QadK9EU3xbQaSbC6yBcRlYCdiU6xkKvsgdrvFTp9O91QfyMNgOlA98Es1duMQw=;
Message-ID: <632693.3537.qm@web110107.mail.gq1.yahoo.com>
X-YMail-OSG: pfor0Q4VM1lOroanTcHtgcf3UhH0nGDkJ_Qk3nkyNLAC4gYHeL5tRP90rLXwOVMVuz_cmqsy8JBEnoTIGkgxOjDJuXpA6sH6.h18j3z5_g1rpTDHZY2v9oD__DQ11oSU9ho0t35RBoIcIFfMDYZXPEGRQ2HshB38a5uZudVQIHBGL74GxoCWekl7XmIl3rBIO6IrrhoYBREDU78ulNB71QXE3clu2YcjOAC7nbGO.PMejKwcwaDDnhey6GhP2JZ7NcbMySA3oqOqh.u0QYXOFAadjJ2BU4eHOehTMCJMmXE2Pn4ThULF_fAoT2OWiKvHFZgRLzbT8n0UbrkDZZoYJ9Y_heFIvkOihOju_ExGHigHjg--
Received: from [216.243.71.77] by web110107.mail.gq1.yahoo.com via HTTP; Thu, 13 Aug 2009 15:08:09 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com>  <c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com>  <3b1311780908121936h5895a966r264a2bbd76a2c82e@mail.gmail.com> <e01b80590908122114i71903a73r163dff1d148dfa75@mail.gmail.com> <834694.10557.qm@web110111.mail.gq1.yahoo.com> <4A847FEB.2080801@yahoo-inc.com>
Date: Thu, 13 Aug 2009 15:08:09 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: Re: How to re-read the config files
To: common-user@hadoop.apache.org
In-Reply-To: <4A847FEB.2080801@yahoo-inc.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-96647977-1250201289=:3537"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-96647977-1250201289=:3537
Content-Type: text/plain; charset=us-ascii

Sorry,I should have mentioned that - this I want to do without the code change.

Something like - I have the cluster up and running and suddenly I realize that forgot to add some properties in the hadoop-site.xml file.  Now I can add these new properties - but how do these take into effect ? Without re-starting the cluster (which is in production and customer wouldn't like that either :-) )

Thanks!
Arvind




________________________________
From: Jakob Homan <jhoman@yahoo-inc.com>
To: common-user@hadoop.apache.org
Sent: Thursday, August 13, 2009 2:04:43 PM
Subject: Re: How to re-read the config files

Hey Arvind-
   You'll probably want to look at the Configuration.reload() method, as demonstrated:

public class TestReloadConfig {
  public static void main(String[] args) throws IOException {
    Configuration conf = new Configuration();
    FileSystem fs = FileSystem.get(conf); // pull in dfs settings

    System.out.println("Replication = " + conf.get("dfs.replication"));
    System.out.println("Update file and press <enter>");
    new Scanner(System.in).nextLine();

    conf.reloadConfiguration();
    System.out.println("Now replication = " + conf.get("dfs.replication"));
  }
}

Note from the Javadoc: Values that are added via set methods will overlay values read from the resources.

Hope this helps.  Write back if you have more questions.

Thanks,
Jakob Homan
Hadoop at Yahoo!


Arvind Sharma wrote:
> Hi,
> 
> I was wondering if there is way to let Hadoop re-read the config file (hadoop-site.xml) after  making some changes in it.
> 
> I don't want to restart the whole cluster for that.
> 
> I am using Hadoop 0.19.2
> 
> Thanks!
> Arvind
> 
> 
> 
>      


      
--0-96647977-1250201289=:3537--


From common-user-return-16756-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 22:22:07 2009
Return-Path: <common-user-return-16756-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 52929 invoked from network); 13 Aug 2009 22:22:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 22:22:07 -0000
Received: (qmail 2634 invoked by uid 500); 13 Aug 2009 22:22:12 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 2560 invoked by uid 500); 13 Aug 2009 22:22:12 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 2550 invoked by uid 99); 13 Aug 2009 22:22:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 22:22:12 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ted.dunning@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 22:22:04 +0000
Received: by gxk27 with SMTP id 27so1368255gxk.12
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 15:21:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=y0sGfDycZdTZckinJrfBAbSGrJUENRG8gLAE+4KPvjQ=;
        b=ThtRp7NgknZEYpETGe+e61rYDuJDjDL744ofgK+20pz7bXR8F6a5VdLnpMSI8sbaWk
         iSHmaPMtk2gCezjL7J5mjQM0EBBJ/809rvGs4P470TvZkMhcx8S2UImB1p6SbSVtz/U8
         2zFTSknL3grbEbWxZ7bHPzZqTRJ4AO7j7K94o=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=KL5ogZTG5gBlo9pgzLsaHVSkr64KwK8zpXX/ZXxAzSUoCKPEAuFwLcOPS115KSjJBu
         wr5nlfetwJ4npn/w6qcm5fu043tOwLO8m69U/FCD0QXW2om2clioyg/ERIj+WAlVYI9g
         PfpCblnSXpVqE+ICuKem3UBNJD/K0T18GkZMo=
MIME-Version: 1.0
Received: by 10.150.113.8 with SMTP id l8mr1863378ybc.288.1250202103066; Thu, 
	13 Aug 2009 15:21:43 -0700 (PDT)
In-Reply-To: <632693.3537.qm@web110107.mail.gq1.yahoo.com>
References: <3b1311780908112300g397efe71vcfd0242e88cd434f@mail.gmail.com> 
	<c7d45fc70908112327t44765af0hf391a4e08e2c3d2a@mail.gmail.com> 
	<3b1311780908121936h5895a966r264a2bbd76a2c82e@mail.gmail.com> 
	<e01b80590908122114i71903a73r163dff1d148dfa75@mail.gmail.com> 
	<834694.10557.qm@web110111.mail.gq1.yahoo.com> <4A847FEB.2080801@yahoo-inc.com> 
	<632693.3537.qm@web110107.mail.gq1.yahoo.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Thu, 13 Aug 2009 15:21:23 -0700
Message-ID: <c7d45fc70908131521g59ef9f98r95186a40b6c4a082@mail.gmail.com>
Subject: Re: How to re-read the config files
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd3980440325504710d5c82
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd3980440325504710d5c82
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

You can do a rolling restart of the nodes.  The customer won't notice and
running programs will still complete in good order.  If you have rack
awareness configured, you can restart as many datanodes in a single rack as
you like since that won't compromise replication.  Restarting task trackers
should be similarly painless since any tasks on that node will just be
re-run.

A few jobs may notice small delays in completion due to re-running tasks,
but the effect should be minimal, especially if you have speculative
execution running.

To change configuration on the namenode or jobtracker, you will need to
schedule a few seconds of cluster downtime to restart those processes.  That
should not be a problem since Hadoop should not generally be used in a
product situation requiring high availability.

On Thu, Aug 13, 2009 at 3:08 PM, Arvind Sharma <arvind321@yahoo.com> wrote:

> Sorry,I should have mentioned that - this I want to do without the code
> change.
>
> Something like - I have the cluster up and running and suddenly I realize
> that forgot to add some properties in the hadoop-site.xml file.  Now I can
> add these new properties - but how do these take into effect ? Without
> re-starting the cluster (which is in production and customer wouldn't like
> that either :-) )
>



-- 
Ted Dunning, CTO
DeepDyve

--000e0cd3980440325504710d5c82--

From common-user-return-16757-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 13 22:47:35 2009
Return-Path: <common-user-return-16757-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61734 invoked from network); 13 Aug 2009 22:47:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 13 Aug 2009 22:47:35 -0000
Received: (qmail 18985 invoked by uid 500); 13 Aug 2009 22:47:39 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 18906 invoked by uid 500); 13 Aug 2009 22:47:39 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 18896 invoked by uid 500); 13 Aug 2009 22:47:39 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 18893 invoked by uid 99); 13 Aug 2009 22:47:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 22:47:39 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of p0941p@gmail.com designates 209.85.211.172 as permitted sender)
Received: from [209.85.211.172] (HELO mail-yw0-f172.google.com) (209.85.211.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 13 Aug 2009 22:47:31 +0000
Received: by ywh2 with SMTP id 2so1562356ywh.2
        for <core-user@hadoop.apache.org>; Thu, 13 Aug 2009 15:47:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=zARrSEKfxQM9RKy+SxacU6iIA4DpGg8idWFWCxvCwd0=;
        b=LOjgL0gRiBBklu1t06LP2K2pxtqbfilhDihRDgX5CmkOhB5e0Bz0Mi63bQsRA8quJz
         m+wzhc1aBXaQPk4fmAkoimob8m3+F9BOHx5WnsmBzvNlBmJjtomgc8O9xJPL2ua3krc0
         2Nd4PPtRmETy5wboKvTpLwI/ip5RLLbdpkoZ0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=oPyupWvwePsbg5gjWD0bgoxoxg0Pmv2O84mksuldQO+nembj7IFPNwOjG1p85Nhuj+
         m4BlsILdEsQmBEr5oBEeseMrTZlNXzmVaPwVB9HtBysWhTx38mrKKlLtdy1y8NZq6tBu
         yfCtO8O65lJiDh/8dPiA01dtpNFYkmACRlmi4=
MIME-Version: 1.0
Received: by 10.150.80.16 with SMTP id d16mr1882846ybb.0.1250203624451; Thu, 
	13 Aug 2009 15:47:04 -0700 (PDT)
Date: Thu, 13 Aug 2009 15:47:04 -0700
Message-ID: <9c39bdeb0908131547o20b2cd58k37c2fc77abd719b5@mail.gmail.com>
Subject: About hanging at 16% for reducer
From: George Pang <p0941p@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd3acf0eeafde04710db628
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd3acf0eeafde04710db628
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Dear all,

A similar thread about reducer hanging at 16% suggested to open ports
50010,50020, ...and so on to solve the problem.  I disable my firewall
"Firstarter" and add rules on the mentioned ports at iptables.   It doesn't
work, still hangs at 16%.  The error message is the same.

After a long time it will finish the job, but there is a hang at the reduce
stage.

Obviously something wrong with the communication between my two nodes.
Because when one is absent everything goes fine.

Please help with any suggestion.
George

Console message:

09/08/13 13:55:41 INFO mapred.FileInputFormat: Total input paths to process
: 1
09/08/13 13:55:41 INFO mapred.FileInputFormat: Total input paths to process
: 1
09/08/13 13:55:42 INFO mapred.JobClient: Running job: job_200908131354_0001
09/08/13 13:55:43 INFO mapred.JobClient:  map 0% reduce 0%
09/08/13 13:55:47 INFO mapred.JobClient:  map 100% reduce 0%
*09/08/13 13:56:01 INFO mapred.JobClient:  map 100% reduce 16%*
*09/08/13 14:08:51 INFO mapred.JobClient: Task Id :
attempt_200908131354_0001_m_000001_0, Status : FAILED
Too many fetch-failures
09/08/13 14:08:51 WARN mapred.JobClient: Error reading task
outputwpang2-laptop
09/08/13 14:08:51 WARN mapred.JobClient: Error reading task
outputwpang2-laptop*
09/08/13 14:09:04 INFO mapred.JobClient: Job complete: job_200908131354_0001
09/08/13 14:09:04 INFO mapred.JobClient: Counters: 16
09/08/13 14:09:04 INFO mapred.JobClient:   File Systems
09/08/13 14:09:04 INFO mapred.JobClient:     HDFS bytes read=489388
09/08/13 14:09:04 INFO mapred.JobClient:     HDFS bytes written=160672
09/08/13 14:09:04 INFO mapred.JobClient:     Local bytes read=220865
09/08/13 14:09:04 INFO mapred.JobClient:     Local bytes written=491194
09/08/13 14:09:04 INFO mapred.JobClient:   Job Counters
09/08/13 14:09:04 INFO mapred.JobClient:     Launched reduce tasks=1
09/08/13 14:09:04 INFO mapred.JobClient:     Launched map tasks=3
09/08/13 14:09:04 INFO mapred.JobClient:     Data-local map tasks=3
09/08/13 14:09:04 INFO mapred.JobClient:   Map-Reduce Framework
09/08/13 14:09:04 INFO mapred.JobClient:     Reduce input groups=14855
09/08/13 14:09:04 INFO mapred.JobClient:     Combine output records=33283
09/08/13 14:09:04 INFO mapred.JobClient:     Map input records=9484
09/08/13 14:09:04 INFO mapred.JobClient:     Reduce output records=14855
09/08/13 14:09:04 INFO mapred.JobClient:     Map output bytes=793632
09/08/13 14:09:04 INFO mapred.JobClient:     Map input bytes=487253
09/08/13 14:09:04 INFO mapred.JobClient:     Combine input records=98456
09/08/13 14:09:04 INFO mapred.JobClient:     Map output records=80028
09/08/13 14:09:04 INFO mapred.JobClient:     Reduce input records=14855

--000e0cd3acf0eeafde04710db628--

From common-user-return-16758-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 02:03:05 2009
Return-Path: <common-user-return-16758-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 19100 invoked from network); 14 Aug 2009 02:03:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 02:03:05 -0000
Received: (qmail 46908 invoked by uid 500); 14 Aug 2009 02:03:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 46780 invoked by uid 500); 14 Aug 2009 02:03:09 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 46752 invoked by uid 99); 14 Aug 2009 02:03:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 02:03:09 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 02:02:58 +0000
Received: by gxk27 with SMTP id 27so1512253gxk.12
        for <multiple recipients>; Thu, 13 Aug 2009 19:02:37 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.113.11 with SMTP id l11mr831717agc.61.1250215357155; Thu, 
	13 Aug 2009 19:02:37 -0700 (PDT)
From: Christophe Bisciglia <christophe@cloudera.com>
Date: Thu, 13 Aug 2009 19:02:16 -0700
Message-ID: <69035570908131902o32deaa8cv147f753a7e741f55@mail.gmail.com>
Subject: Announcement: Cloudera Hadoop Training in San Francisco (August 
	26-28)
To: common-user@hadoop.apache.org, hive-user@hadoop.apache.org, 
	pig-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016361e86c041896e04711072a8
X-Virus-Checked: Checked by ClamAV on apache.org

--0016361e86c041896e04711072a8
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hadoop Fans, please pardon the short notice, but we wanted to let you know
that we are offering a 3 day training program at the end of the month in San
Francisco. There is a $300 discount for those who register before 11PM PDT
on August 20th.
Day 1: Hadoop Basics + Ecosystem and Deployment (data center, EC2, etc)
Day 2: Hive, Pig, and Data Processing Pipelines
Day 3: Advanced APIs + MapReduce Debugging and Optimization

You can see the full agenda here: http://www.eventbrite.com/event/408826812

We are using a smaller space than usual, and as such, can only accommodate
20 people. If you do want to come, please take advantage of the early bird
discount by registering soon :-)

<http://www.eventbrite.com/event/408826812>Cheers,
Christophe

-- 
get hadoop: cloudera.com/hadoop
online training: cloudera.com/hadoop-training
blog: cloudera.com/blog
twitter: twitter.com/cloudera

--0016361e86c041896e04711072a8--

From common-user-return-16759-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 03:16:38 2009
Return-Path: <common-user-return-16759-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 37080 invoked from network); 14 Aug 2009 03:16:38 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 03:16:38 -0000
Received: (qmail 79196 invoked by uid 500); 14 Aug 2009 03:16:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 79115 invoked by uid 500); 14 Aug 2009 03:16:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 79105 invoked by uid 99); 14 Aug 2009 03:16:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 03:16:40 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rvernica@gmail.com designates 209.85.198.225 as permitted sender)
Received: from [209.85.198.225] (HELO rv-out-0506.google.com) (209.85.198.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 03:16:32 +0000
Received: by rv-out-0506.google.com with SMTP id k40so337014rvb.29
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 20:16:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=wEziQwzkkp0hiwkvB0LEz96gdoKxT5JYTJu3F+wijFw=;
        b=E184en9SLnTRF00FaonbXMO+X9fHcLjBWN3XTFCNXE3os6GncziFCaOtMo/KqmTKKW
         CVDYa4/YmsgnpZLD7eyNckp4KYYWW50xd3BmkHqbPlid3w5ouwjiA4xpR4tII69LRM+1
         XYEmEJ5NiPpjUYblog8cbV80jQLoxq6pAXwyI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=au2vCz3dhEHe9by6baRA6m1/7aI5FHIX6Mw4PjvFj9+8vioZDs2+ImoeesSqCo0gq5
         UJnpfnEBOKfprhR7E2/5ZS4pXHgELCGtUkQuOLd53wU/mqAqoFzZAxBkpdPehF2GvgLi
         ryFWpgZlIAUGuNqKDAqN06EAyxfJeRoxiGZT4=
MIME-Version: 1.0
Received: by 10.141.34.20 with SMTP id m20mr817287rvj.120.1250219772686; Thu, 
	13 Aug 2009 20:16:12 -0700 (PDT)
In-Reply-To: <8FD8EC9D-4BD3-4027-AA59-00B6BD928A57@apache.org>
References: <b8208a3b0907220822g74ff57c2j802bd0c574b21eb@mail.gmail.com>
	 <8FD8EC9D-4BD3-4027-AA59-00B6BD928A57@apache.org>
Date: Thu, 13 Aug 2009 20:16:12 -0700
Message-ID: <b8208a3b0908132016i29496096p114b347b52815cfe@mail.gmail.com>
Subject: Re: generate task timeline figures like "Hadoop Sorts a Petabyte..." 
	blog
From: Rares Vernica <rvernica@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

On Wed, Jul 22, 2009 at 9:25 AM, Owen O'Malley<omalley@apache.org> wrote:
>
> On Jul 22, 2009, at 8:22 AM, Rares Vernica wrote:
>
>> Hello,
>>
>> I wonder how did the Yahoo! developers generate the Task Timeline
>> figures in their "Hadoop Sorts a Petabyte..." blog post:
>
> The script is at:
>
> http://people.apache.org/~omalley/tera-2009/job_history_summary.py

Thank you! It is very useful!

In the script, does "waste" mean tasks started redundantly and then killed?

Cheers,
Rares

From common-user-return-16760-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 03:28:25 2009
Return-Path: <common-user-return-16760-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 38363 invoked from network); 14 Aug 2009 03:28:25 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 03:28:25 -0000
Received: (qmail 91338 invoked by uid 500); 14 Aug 2009 03:28:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91256 invoked by uid 500); 14 Aug 2009 03:28:30 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91245 invoked by uid 99); 14 Aug 2009 03:28:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 03:28:29 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 03:28:18 +0000
Received: by vws40 with SMTP id 40so1073456vws.2
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 20:27:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=cmha2X7Yb54socFzHIJsCj8tifoxSYtMVSHFw2oPIP0=;
        b=xGKl/8fFOzVc9/L/ew1eT+p7TlJS3mrGAsIUrxd3ZyKKvWGjHac4QPgUCk5d0hXytU
         RtOQc/xDqvedb2ZWF0QCN48Ip0UVMWd8NizpvuX4ZcaxVmsht3CoXV5fE1SqMnjVRejd
         3+AvEHGW2NmW1izdtV+8PqCe5PnBM7ZfhKdiM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=fit/2oAlPMDg6Al7sTXCNuAZ/oTysHgiy+EAxZzOlc5kqMtPwGKq0JFi66J5u2/Id1
         6yeU4YBaRGRRtA2MP97byiiWvQ6GMyzOGrzguV5//o+zlwUg0b+p4AgP+kN+kn8G/nYm
         1xG7s6p/ZvroxZxtjAaAsfam5kmEe49uraKUA=
MIME-Version: 1.0
Received: by 10.220.90.19 with SMTP id g19mr1726957vcm.103.1250220476887; Thu, 
	13 Aug 2009 20:27:56 -0700 (PDT)
In-Reply-To: <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu>
	 <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com>
	 <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>
Date: Thu, 13 Aug 2009 20:27:56 -0700
Message-ID: <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
Subject: Re: What OS?
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f7d60a6a74de047111a30e
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f7d60a6a74de047111a30e
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Anyone have any performance numbers for Solaris or ZFS based datanodes.

The directory and inode cache sizes are a limiting factor for linux for
large and busy datanodes.

On Wed, Aug 12, 2009 at 7:45 AM, tim robertson <timrobertson100@gmail.com>wrote:

> Thanks guys.  I'll chat with sys admin and see what he thinks.
> We knew fedora would require a 6 month rebuild
>
>
> On Wed, Aug 12, 2009 at 4:36 PM, Edward Capriolo<edlinuxguru@gmail.com>
> wrote:
> > On Wed, Aug 12, 2009 at 8:03 AM, Brian Bockelman<bbockelm@cse.unl.edu>
> wrote:
> >> Hey Tim,
> >>
> >> One consideration is "how long is this OS version going to be receiving
> >> updates?" or "Do I do the operations team any favor by having them
> upgrade
> >> every 6 months?"
> >>
> >> Personally, I'd avoid Fedora for a production cluster because the lack
> of
> >> long-lived releases means that you'll be spending extra effort on
> upgrading
> >> the OS.
> >>
> >> Brian
> >>
> >> On Aug 12, 2009, at 6:05 AM, tim robertson wrote:
> >>
> >>> Hi all,
> >>>
> >>> Is fedora a decent choice of OS for a new hadoop cluster?  All our
> >>> other stuff is fedora, but is there was a strong case to move to
> >>> something else?
> >>>
> >>> Cheers
> >>>
> >>> Tim
> >>
> >>
> >
> > CentOS and Scientific Linux are Red Hat Enterprise Linux clones. I
> > advice people to go with them. Most of this is based on the fact that
> > CentOS is very compatible with RHEL. This is important because
> > packaged, but not open source software, is typically targeted at RHEL.
> > You can read about someone trying to install WebSphere on say Fedora
> > Core and see the hard aches. As mentioned above support life is an
> > issue. RHEL/CENT 5 will be supported until 2014.
> >
> > http://www.redhat.com/security/updates/errata/
> >
> > The Fedora line typically has support life of a few months. So your
> > package support dries up fast and then you have to get good with
> > RPM-build fast :)
> >
>



-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--001485f7d60a6a74de047111a30e--

From common-user-return-16761-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 03:59:20 2009
Return-Path: <common-user-return-16761-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 43264 invoked from network); 14 Aug 2009 03:59:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 03:59:19 -0000
Received: (qmail 13430 invoked by uid 500); 14 Aug 2009 03:59:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 13342 invoked by uid 500); 14 Aug 2009 03:59:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 13332 invoked by uid 99); 14 Aug 2009 03:59:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 03:59:23 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bogdan.maryniuk@gmail.com designates 209.85.220.224 as permitted sender)
Received: from [209.85.220.224] (HELO mail-fx0-f224.google.com) (209.85.220.224)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 03:59:14 +0000
Received: by fxm24 with SMTP id 24so1266031fxm.36
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 20:58:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=LR2LnmCdRE0mw1W84chLCAYLLrKO2VUVaHRy7MnLktY=;
        b=AYP8hj0AcCgoSDGsBqL498eV6QmhBZc2IXxyZ0rDdl4FiUvIptWlE2OGaaV3BkZSaR
         BQGDWKf+ASsp//Hnb/006zwmAcKRekZOlhiO0bIK0XRjtUDT+EtsegPBhIMx4qeipV1w
         Me6gbbmLJbMAVJcmGnmiKWu6dKZvLlrDkUMJc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=dBRkJk5xWa2XOvPTkdr/CVZlD4HQGW0KqkuWmiXJbVIBLlGQS5tJHQZmgArJPcoXl+
         CiYgqxseAJk0N0iRzi9DBfbxqjjMqOFswCUYQyiGysU71E2YCAgpWKfMdRq/Y0z9LvUj
         DGrg3NBrdiFIKFtezT16swrUidyGWrdEiX/+o=
MIME-Version: 1.0
Received: by 10.223.115.80 with SMTP id h16mr471587faq.52.1250222333217; Thu, 
	13 Aug 2009 20:58:53 -0700 (PDT)
In-Reply-To: <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu>
	 <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com>
	 <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>
	 <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
Date: Fri, 14 Aug 2009 12:58:53 +0900
Message-ID: <fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>
Subject: Re: What OS?
From: "Bogdan M. Maryniuk" <bogdan.maryniuk@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Fri, Aug 14, 2009 at 12:27 PM, Jason Venner<jason.hadoop@gmail.com> wrot=
e:
> Anyone have any performance numbers for Solaris or ZFS based datanodes.
>
> The directory and inode cache sizes are a limiting factor for linux for
> large and busy datanodes.

Uhmm... I do run it on zoned OpenSolaris, but I don't have a real
numbers, since you have to measure it yourself on the same hardware.

Actually, Phoronix.com (Warning: Biased Linux fanboys!) has a general
performance tests and they usually claim that Linux is mostly as twice
as faster at everything. However, I never saw such slow ZFS as they
show on their benchmarks as well as other factors are sometimes
ridiculously slow (some of them are true).

That's is really interesting to measure it on a two identical clusters
and see how well it works all together (I/O, memory, Networking etc).
But that's needed to kill lots of time for that, to make such
measurements properly, otherwise you will go definitely wrong
conclusions. However, building two identical clusters just for test =E2=80=
=94
lilbit boring. :-) And I seriously won't go Linux anyway due to a big
number of other reasons, even if someone proves OpenSolaris bit
slower.

At least what I can tell you right away: ZFS is a killer all aspects
to any FS Linux has at the moment (including bloody alpha BTRFS that
suffers due to weak for higher loads software RAID layer that is in a
Linux kernel) and Java runs faster on Solaris. Also make sure you
tuned TCP/IP stack, which is by default too conservative.

If you could try to measure it =E2=80=94 we would really appreciate that!

--=20
Kind regards, BM

Things, that are stupid at the beginning, rarely ends up wisely.

From common-user-return-16762-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 04:40:22 2009
Return-Path: <common-user-return-16762-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 52825 invoked from network); 14 Aug 2009 04:40:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 04:40:21 -0000
Received: (qmail 48277 invoked by uid 500); 14 Aug 2009 04:40:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 48176 invoked by uid 500); 14 Aug 2009 04:40:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 48165 invoked by uid 99); 14 Aug 2009 04:40:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 04:40:26 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of always.arvind@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 04:40:16 +0000
Received: by bwz19 with SMTP id 19so1301922bwz.37
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 21:39:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=gcfYBZRbPwVxeJCsdpg0jVqxD2f7cHYLuhLA40ff44E=;
        b=EYS2YbOgWUyree6BcUtpDTxGLAgBNsNWPeEFtialx48dRjeUOW3uSKxJNoynN7sczv
         CKZGvPuA9rGjWGmulo/Nkj6d/8mVKZv6KN9LqnA9yIGfLA4kHn7NwqRxZNdZmY6ezd+y
         iCTlnR1dMYJ8qjhkK9nlKdXs6nJa/CnToMtZg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=wcN9sfuEJZVOcfDDLk/PhjjKGvXoC32/6FEGe+Bp60ZUSRFOMmZUcKuwzs9KQ/oprI
         sn22O9WJsqccQ9xjmGeMsy/U6JiS4EtitoC9gU4Ql6UEv9MH2+9riOGluu3hZDbVdHH3
         MbSgB74spDoniASi/K4qowBo3B75r6MvwEYF0=
MIME-Version: 1.0
Received: by 10.239.157.147 with SMTP id q19mr120587hbc.61.1250224795235; Thu, 
	13 Aug 2009 21:39:55 -0700 (PDT)
Date: Fri, 14 Aug 2009 00:39:55 -0400
Message-ID: <1b0d5eca0908132139u31be44e1o4705b08f447d9f3b@mail.gmail.com>
Subject: Error in starting Pseudo-Distributed mode hadoop-0.19.2
From: arvind subramanian <always.arvind@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016364c7719cf354a047112a429
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364c7719cf354a047112a429
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

I am new to Hadoop, and am trying to get Hadoop started in
Pseudo-distributed mode  on   ubuntu jaunty.

In the archives I noticed that someone had a similar issue with
hadoop-0.20.0,   but the logs are different.

As in the quickstart  guide  (
http://hadoop.apache.org/common/docs/current/quickstart.html) , I
configured the xml files, and set up   passphraseless ssh


The output of  bin/hadoop namenode -format   is as follows :


09/08/13 23:52:49 INFO namenode.NameNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = arvind-laptop/127.0.1.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 0.19.2
STARTUP_MSG:   build =
https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.19 -r
789657; compiled by 'root' on Tue Jun 30 12:40:50 EDT 2009
************************************************************/
Re-format filesystem in /tmp/hadoop-arvind/dfs/name ? (Y or N) Y
09/08/13 23:52:52 INFO namenode.FSNamesystem:
fsOwner=arvind,arvind,adm,dialout,cdrom,plugdev,lpadmin,admin,sambashare
09/08/13 23:52:52 INFO namenode.FSNamesystem: supergroup=supergroup
09/08/13 23:52:52 INFO namenode.FSNamesystem: isPermissionEnabled=true
09/08/13 23:52:52 INFO common.Storage: Image file of size 96 saved in 0
seconds.
09/08/13 23:52:52 INFO common.Storage: Storage directory
/tmp/hadoop-arvind/dfs/name has been successfully formatted.
09/08/13 23:52:52 INFO namenode.NameNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at arvind-laptop/127.0.1.1
************************************************************/

The task-tracker log had the following error :

2009-08-13 23:11:55,884 ERROR org.apache.hadoop.mapred.TaskTracker: Can not
start task tracker because java.lang.RuntimeException: Not a host:port pair:
local
    at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:134)
    at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:121)
    at org.apache.hadoop.mapred.JobTracker.getAddress(JobTracker.java:1318)
    at org.apache.hadoop.mapred.TaskTracker.<init>(TaskTracker.java:884)
    at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:2798)



After this point,  I could not acess  these in my browser  :

   - NameNode - http://localhost:50070/
   - JobTracker - http://localhost:50030/

If anyone could give an hint  on what could be the issue, it would be
great!

On another note, the quick start guide pointed to Cloudera's  distribution
of  Hadoop, and they have  debian package for ubuntu.
Is the development plan of Apache and Cloudera same? Do both ship the same
source release?


Cheers,
Arvind

--0016364c7719cf354a047112a429--

From common-user-return-16763-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 05:22:04 2009
Return-Path: <common-user-return-16763-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61752 invoked from network); 14 Aug 2009 05:22:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 05:22:04 -0000
Received: (qmail 72969 invoked by uid 500); 14 Aug 2009 05:22:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 72898 invoked by uid 500); 14 Aug 2009 05:22:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 72888 invoked by uid 99); 14 Aug 2009 05:22:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 05:22:08 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 05:22:00 +0000
Received: by gxk27 with SMTP id 27so1615483gxk.12
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 22:21:39 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.91.95.5 with SMTP id x5mr956226agl.28.1250227299125; Thu, 13 
	Aug 2009 22:21:39 -0700 (PDT)
In-Reply-To: <fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com> 
	<F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu> <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com> 
	<32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com> 
	<314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com> 
	<fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Thu, 13 Aug 2009 22:21:19 -0700
Message-ID: <45f85f70908132221v449ec8b3s93a9baf530952383@mail.gmail.com>
Subject: Re: What OS?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64605040d8b710471133a0a
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64605040d8b710471133a0a
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 13, 2009 at 8:58 PM, Bogdan M. Maryniuk <
bogdan.maryniuk@gmail.com> wrote:

>  Also make sure you
> tuned TCP/IP stack, which is by default too conservative.
>

Any pointers on this? Would be interesting to see before/after tuning
benchmarks as well. Assuming this is a runtime tunable through something
like sysctl, it shouldn't be too hard to run a sort before and after.

-Todd

--0016e64605040d8b710471133a0a--

From common-user-return-16764-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 05:25:55 2009
Return-Path: <common-user-return-16764-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63347 invoked from network); 14 Aug 2009 05:25:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 05:25:55 -0000
Received: (qmail 75536 invoked by uid 500); 14 Aug 2009 05:25:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 75455 invoked by uid 500); 14 Aug 2009 05:25:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 75445 invoked by uid 99); 14 Aug 2009 05:25:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 05:25:59 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bogdan.maryniuk@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 05:25:49 +0000
Received: by bwz19 with SMTP id 19so1319702bwz.37
        for <common-user@hadoop.apache.org>; Thu, 13 Aug 2009 22:25:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=B2bfXXF1dMYgkW/a45Mrp8Ux6u9LvrlX/3Whody0/Is=;
        b=bgyNo4k/0fhrPdQ2s4jbNYEg2KegwtJqwKTkhGhKzzracED1djjkpkDkVOEbYlj0Kj
         YNFXtNw8tbVeZgEj9LveLesVBhiIX3cWprB9Bhap74zG80ccp/v23/MwonlYUV6imn6z
         mzCirvs7Qyfk/zfTJvFJaWruPcH+GAfJkDT24=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=B+9u3D7AwNyEtynO4Ke7iwWVtRkIiJIjIuN/dvn6E6Kssp5zlTZYikrKiE2K4M9nDB
         9GhX4yfWgR1YsyNdCl11ZLtejEVAd1Z6sX8dqHsXJa3O9WXyzMDpC5+lPmhaK6sCIaBx
         msgAtlbkA0wpXklJWXTT3OGvqh8YMbR0jYfYY=
MIME-Version: 1.0
Received: by 10.223.108.140 with SMTP id f12mr443325fap.69.1250227527043; Thu, 
	13 Aug 2009 22:25:27 -0700 (PDT)
In-Reply-To: <45f85f70908132221v449ec8b3s93a9baf530952383@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu>
	 <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com>
	 <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>
	 <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
	 <fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>
	 <45f85f70908132221v449ec8b3s93a9baf530952383@mail.gmail.com>
Date: Fri, 14 Aug 2009 14:25:27 +0900
Message-ID: <fa561940908132225v784b6b42oa152d99c3a2b0590@mail.gmail.com>
Subject: Re: What OS?
From: "Bogdan M. Maryniuk" <bogdan.maryniuk@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Fri, Aug 14, 2009 at 2:21 PM, Todd Lipcon<todd@cloudera.com> wrote:
>> =C2=A0Also make sure you
>> tuned TCP/IP stack, which is by default too conservative.
>>
>
> Any pointers on this?

You might start here: http://www.sean.de/Solaris/soltune.html

--=20
Kind regards, BM

Things, that are stupid at the beginning, rarely ends up wisely.

From common-user-return-16765-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 05:47:56 2009
Return-Path: <common-user-return-16765-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 72014 invoked from network); 14 Aug 2009 05:47:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 05:47:56 -0000
Received: (qmail 83090 invoked by uid 500); 14 Aug 2009 05:48:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82989 invoked by uid 500); 14 Aug 2009 05:48:01 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82974 invoked by uid 99); 14 Aug 2009 05:48:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 05:48:01 +0000
X-ASF-Spam-Status: No, hits=2.1 required=10.0
	tests=RCVD_BAD_ID,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of alexanderdai@163.com designates 220.181.12.182 as permitted sender)
Received: from [220.181.12.182] (HELO m12-182.163.com) (220.181.12.182)
    by apache.org (qpsmtpd/0.29) with SMTP; Fri, 14 Aug 2009 05:47:51 +0000
Received: from static-1.space.163.org (unknown [220.181.9.236])
	by mfast2 (Coremail) with SMTP id tsCowLAbGAhw+oRKPlBIAA==.22941S2;
	Fri, 14 Aug 2009 13:47:28 +0800 (CST)
Date: Fri, 14 Aug 2009 13:47:27 +0800
From: "alexanderdai"<alexanderdai@163.com>
To: common-user@hadoop.apache.org
Message-ID: <1699123922.135.1250228849099.JavaMail.dfs@static-1.space.163.org>
Subject: problems of example
MIME-Version: 1.0
Content-Type: text/plain;
	charset="UTF-8"
Content-Transfer-Encoding: quoted-printable
X-Priority: 3
X-Coremail-Antispam: 1Uf129KBjDUn29KB7ZKAUJUUUUUYxn0WfASr-VFAUDa7-sFnT
	9fnUUIcSsGvfJ3UbIYCTnIWIevJa73UjIFyTuYvj4RJUUUUUUUU
X-Virus-Checked: Checked by ClamAV on apache.org

hi=20
   there are some exceptions when i tested the examples.jar for example=20
java.lang.ClassNotFoundException: org.apache.hadoop.examples.AggregateWordC=
ount$WordCountPlugInClass
,but i ensure that the class WordCountPlugInClass exists. So i wonder this =
problem and my hadoop'version is hadoop0.20.0.

------------------
alexanderdai
2009-8-14

=00=00=00


From common-user-return-16766-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 07:01:12 2009
Return-Path: <common-user-return-16766-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7831 invoked from network); 14 Aug 2009 07:01:12 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 07:01:12 -0000
Received: (qmail 33833 invoked by uid 500); 14 Aug 2009 07:01:16 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 33741 invoked by uid 500); 14 Aug 2009 07:01:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 43842 invoked by uid 99); 14 Aug 2009 04:28:57 -0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of always.arvind@gmail.com designates 209.85.218.219 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=Um72rRXm6JlUZYv52Dp+5e0Oq6QcLwzeD7Y33/88XpI=;
        b=k0O37jtaSd9C71UUStDB+CkHvJqRLIWeBuic3R7zo0QJx9PbHUjmKey1smApUT4YIB
         TTRlq/xM26a2i3OEubVcfVP5PlCoCvv6UQ7l3TMhFJtlB76FqoQB6YURn4+XlLbXeBt0
         k6081yINJQaZZxVD6sgHfvWpvfWl8Q/nDW4VE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=Z9SJFWGT+TrTS4y9y7rrYrsWcD2fkcqu37IsbptWOacbVtmvsEyVX7+uRt61uFrBuS
         zWL00sgdaYKYqE6u0yJrbx6wEZR6bwjBCLo0swL+UwCQzzHKRN+Q8FLlKXe18SgqlFv/
         1ydmQow+peuN43flaLq4vcnCtsAk5dW7kjARI=
MIME-Version: 1.0
Date: Fri, 14 Aug 2009 00:28:27 -0400
Message-ID: <1b0d5eca0908132128h4a6600a5k9818997cf8663376@mail.gmail.com>
Subject: Error in starting Pseudo-Distributed mode hadoop-0.19.2
From: arvind subramanian <always.arvind@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f7d6e4cc2cf00471127b90
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f7d6e4cc2cf00471127b90
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

I am new to Hadoop, and am trying to get Hadoop started in
Pseudo-distributed mode  on   ubuntu jaunty.

In the archives I noticed that someone had a similar issue with
hadoop-0.20.0,   but the logs are different.

As in the quickstart  guide  (
http://hadoop.apache.org/common/docs/current/quickstart.html) , I
configured the xml files, and set up   passphraseless ssh


The output of  bin/hadoop namenode -format   is as follows :


09/08/13 23:52:49 INFO namenode.NameNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = arvind-laptop/127.0.1.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 0.19.2
STARTUP_MSG:   build =
https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.19 -r
789657; compiled by 'root' on Tue Jun 30 12:40:50 EDT 2009
************************************************************/
Re-format filesystem in /tmp/hadoop-arvind/dfs/name ? (Y or N) Y
09/08/13 23:52:52 INFO namenode.FSNamesystem:
fsOwner=arvind,arvind,adm,dialout,cdrom,plugdev,lpadmin,admin,sambashare
09/08/13 23:52:52 INFO namenode.FSNamesystem: supergroup=supergroup
09/08/13 23:52:52 INFO namenode.FSNamesystem: isPermissionEnabled=true
09/08/13 23:52:52 INFO common.Storage: Image file of size 96 saved in 0
seconds.
09/08/13 23:52:52 INFO common.Storage: Storage directory
/tmp/hadoop-arvind/dfs/name has been successfully formatted.
09/08/13 23:52:52 INFO namenode.NameNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at arvind-laptop/127.0.1.1
************************************************************/

The task-tracker log had the following error :

2009-08-13 23:11:55,884 ERROR org.apache.hadoop.mapred.TaskTracker: Can not
start task tracker because java.lang.RuntimeException: Not a host:port pair:
local
    at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:134)
    at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:121)
    at org.apache.hadoop.mapred.JobTracker.getAddress(JobTracker.java:1318)
    at org.apache.hadoop.mapred.TaskTracker.<init>(TaskTracker.java:884)
    at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:2798)



After this point,  I could not acess  these in my browser  :

   - NameNode - http://localhost:50070/
   - JobTracker - http://localhost:50030/

If anyone could give an hint  on what could be the issue, it would be
great!

On another note, the quick start guide pointed to Cloudera's  distribution
of  Hadoop, and they have  debian package for ubuntu.
Is the development plan of Apache and Cloudera same? Do both ship the same
source release?


Cheers,
Arvind

--001485f7d6e4cc2cf00471127b90--

From common-user-return-16767-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 08:08:11 2009
Return-Path: <common-user-return-16767-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 32570 invoked from network); 14 Aug 2009 08:08:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 08:08:11 -0000
Received: (qmail 16747 invoked by uid 500); 14 Aug 2009 08:08:15 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 16685 invoked by uid 500); 14 Aug 2009 08:08:15 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 16675 invoked by uid 99); 14 Aug 2009 08:08:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 08:08:15 +0000
X-ASF-Spam-Status: No, hits=-1.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vercego@us.ibm.com designates 32.97.182.142 as permitted sender)
Received: from [32.97.182.142] (HELO e2.ny.us.ibm.com) (32.97.182.142)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 08:08:04 +0000
Received: from d01relay04.pok.ibm.com (d01relay04.pok.ibm.com [9.56.227.236])
	by e2.ny.us.ibm.com (8.14.3/8.13.1) with ESMTP id n7E81p4n007659
	for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 04:01:51 -0400
Received: from d01av02.pok.ibm.com (d01av02.pok.ibm.com [9.56.224.216])
	by d01relay04.pok.ibm.com (8.13.8/8.13.8/NCO v10.0) with ESMTP id n7E87hTl175606
	for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 04:07:43 -0400
Received: from d01av02.pok.ibm.com (loopback [127.0.0.1])
	by d01av02.pok.ibm.com (8.12.11.20060308/8.13.3) with ESMTP id n7E84qL8001140
	for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 04:04:52 -0400
Received: from d01ml604.pok.ibm.com (d01ml604.pok.ibm.com [9.56.227.90])
	by d01av02.pok.ibm.com (8.12.11.20060308/8.12.11) with ESMTP id n7E84qbb001126
	for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 04:04:52 -0400
Subject: Vuk Ercegovac is out of the office.
Auto-Submitted: auto-generated
From: Vuk Ercegovac <vercego@us.ibm.com>
To: common-user@hadoop.apache.org
Message-ID: <OF7B05A5D5.BE2A4B20-ON85257612.002CA699-85257612.002CA699@us.ibm.com>
Date: Fri, 14 Aug 2009 04:07:42 -0400
X-MIMETrack: Serialize by Router on D01ML604/01/M/IBM(Release 8.5|December 05, 2008) at
 08/14/2009 04:07:42
MIME-Version: 1.0
Content-type: multipart/alternative; 
	Boundary="0__=0ABBFC81DFBF20098f9e8a93df938690918c0ABBFC81DFBF2009"
Content-Disposition: inline
X-Virus-Checked: Checked by ClamAV on apache.org

--0__=0ABBFC81DFBF20098f9e8a93df938690918c0ABBFC81DFBF2009
Content-type: text/plain; charset=US-ASCII


I will be out of the office starting  08/14/2009 and will not return until
09/02/2009.

I will be in europe and plan to check email.
--0__=0ABBFC81DFBF20098f9e8a93df938690918c0ABBFC81DFBF2009--


From common-user-return-16768-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 08:13:43 2009
Return-Path: <common-user-return-16768-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 33744 invoked from network); 14 Aug 2009 08:13:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 08:13:43 -0000
Received: (qmail 25904 invoked by uid 500); 14 Aug 2009 08:13:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25826 invoked by uid 500); 14 Aug 2009 08:13:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25816 invoked by uid 99); 14 Aug 2009 08:13:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 08:13:47 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bogdan.maryniuk@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 08:13:37 +0000
Received: by bwz19 with SMTP id 19so1389246bwz.37
        for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 01:13:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=lGFa0d/e4aVwF5SRfJVLavPPxv2hd3GBYI+48THIeO8=;
        b=rnYKh0NGPrWRVccD2TBSxJ2V/5bgYcftF0zuFpUZP8EIzXjeRcwcaEOC9L0fkjzRRa
         OYajyykz6lBh8DVCOxrL8GC6SE9w+reaHmJLq2gx8cf2ZDKdYO6v2RofFml0ZhOrilfQ
         xZUgErwTS0f3ySMCy4hWgCMTIHSRzeNI8W/Ws=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=fshYHb6xPXJFhZPMzYYKec5y9169eyAij8A0OH6s3+rz3t/SWGaH/9fAOtDAVLrVFS
         e6MYv9PQtDLmMURnFoeNPEueXvDsUXGWbvwcm1N+O7sMu8LdnqyTtGqf+Vh6UQr6wSRa
         wmh9GsvEXSw4B7revU1vvlHwXsv6p+PtpQ1tI=
MIME-Version: 1.0
Received: by 10.223.126.1 with SMTP id a1mr64233fas.8.1250237597329; Fri, 14 
	Aug 2009 01:13:17 -0700 (PDT)
In-Reply-To: <OF7B05A5D5.BE2A4B20-ON85257612.002CA699-85257612.002CA699@us.ibm.com>
References: <OF7B05A5D5.BE2A4B20-ON85257612.002CA699-85257612.002CA699@us.ibm.com>
Date: Fri, 14 Aug 2009 17:13:17 +0900
Message-ID: <fa561940908140113g59e1289ey6ba3d9fff66ad9ce@mail.gmail.com>
Subject: Re: Vuk Ercegovac is out of the office.
From: "Bogdan M. Maryniuk" <bogdan.maryniuk@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Fri, Aug 14, 2009 at 5:07 PM, Vuk Ercegovac<vercego@us.ibm.com> wrote:
> I will be out of the office starting =C2=A008/14/2009 and will not return=
 until
> 09/02/2009.
>
> I will be in europe and plan to check email.

Awesome! IBM rules.
Now silly autoreply is gonna spam here on each message. :-(

--=20
Kind regards, BM

Things, that are stupid at the beginning, rarely ends up wisely.

From common-user-return-16769-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 12:50:24 2009
Return-Path: <common-user-return-16769-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 42156 invoked from network); 14 Aug 2009 12:50:24 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 12:50:24 -0000
Received: (qmail 5333 invoked by uid 500); 14 Aug 2009 12:50:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 5244 invoked by uid 500); 14 Aug 2009 12:50:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 5198 invoked by uid 99); 14 Aug 2009 12:50:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 12:50:27 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ramaswamy_a@persistent.co.in designates 202.54.11.87 as permitted sender)
Received: from [202.54.11.87] (HELO bmapps.persistent.co.in) (202.54.11.87)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 12:50:20 +0000
Received: from bmapps.persistent.co.in (unknown [127.0.0.1])
	by bmapps.persistent.co.in (Symantec Mail Security) with ESMTP id E775F464090
	for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 18:19:53 +0530 (IST)
X-AuditID: 0a4e0006-a31f5bb000003b87-c3-4a855d71ac55
Received: from puneexchange.persistent.co.in (unknown [10.78.0.1])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by bmapps.persistent.co.in (Symantec Mail Security) with ESMTP id 98A45420004
	for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 18:19:53 +0530 (IST)
Received: from [10.77.45.95] (10.77.45.95) by puneexchange.persistent.co.in
 (10.77.224.53) with Microsoft SMTP Server (TLS) id 8.1.358.0; Fri, 14 Aug
 2009 18:19:53 +0530
Subject: Failing to executing the the
	/home/ramaswamy_a/hadoop/src/examples/pipes/impl/wordcount-simple.cc in
	Hadoop
From: Ramaswamy B.A <ramaswamy_a@persistent.co.in>
Reply-To: ramaswamy_a@persistent.co.in
To: <common-user@hadoop.apache.org>
Content-Type: multipart/alternative; boundary="=-X69ClRMWKrwpnYOYMhQr"
Organization: Persistent System
Date: Fri, 14 Aug 2009 18:21:12 +0530
Message-ID: <1250254272.2757.16.camel@ps2523fc9.persistent.co.in>
MIME-Version: 1.0
X-Mailer: Evolution 2.22.1 (2.22.1-2.fc9) 
X-Brightmail-Tracker: AAAAAA==
X-Virus-Checked: Checked by ClamAV on apache.org

--=-X69ClRMWKrwpnYOYMhQr
Content-Type: text/plain; charset="UTF-8"
content-transfer-encoding: 8bit

Hi All,

I am trying to execute a wordcount-smaple.cc program which is exist in
hadoop package. Built went fine with ant, but execution  failed,  throws
the following errors.

[ramaswamy_a@ps259 hadoop]$./bin/hadoop pipes
-program /home/ramaswamy_a/Rama/Hadoop/hadoop/hadoop-0.18.3/build/c
++-examples/Linux-i386-32/bin/pipes-sort  -input input  -output output
09/08/14 18:07:00 INFO jvm.JvmMetrics: Initializing JVM Metrics with
processName=JobTracker, sessionId=
09/08/14 18:07:00 WARN mapred.JobClient: Use GenericOptionsParser for
parsing the arguments. Applications should implement Tool for the same.
09/08/14 18:07:00 WARN mapred.JobClient: No job jar file set.  User
classes may not be found. See JobConf(Class) or JobConf#setJar(String).
09/08/14 18:07:00 INFO mapred.FileInputFormat: Total input paths to
process : 2
09/08/14 18:07:00 INFO mapred.FileInputFormat: Total input paths to
process : 2
09/08/14 18:07:01 INFO mapred.FileInputFormat: Total input paths to
process : 2
09/08/14 18:07:01 INFO mapred.FileInputFormat: Total input paths to
process : 2
09/08/14 18:07:01 INFO mapred.JobClient: Running job: job_local_0001
09/08/14 18:07:01 INFO mapred.MapTask: numReduceTasks: 1
09/08/14 18:07:01 INFO mapred.MapTask: io.sort.mb = 100
09/08/14 18:07:01 INFO mapred.MapTask: data buffer = 79691776/99614720
09/08/14 18:07:01 INFO mapred.MapTask: record buffer = 262144/327680
09/08/14 18:07:02 WARN mapred.LocalJobRunner: job_local_0001
java.lang.NullPointerException
	at
org.apache.hadoop.mapred.pipes.Application.<init>(Application.java:80)
	at
org.apache.hadoop.mapred.pipes.PipesMapRunner.run(PipesMapRunner.java:57)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:227)
	at org.apache.hadoop.mapred.LocalJobRunner
$Job.run(LocalJobRunner.java:157)
Exception in thread "main" java.io.IOException: Job failed!
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1113)
	at
org.apache.hadoop.mapred.pipes.Submitter.submitJob(Submitter.java:261)
	at org.apache.hadoop.mapred.pipes.Submitter.main(Submitter.java:417)
[ramaswamy_a@ps25 hadoop]$ 

It seems the the JobConf  is not set. 

Please let me know how to set the jobconf what should be the values for
this.


My Observations:
The
program /home/ramaswamy_a/hadoop/src/examples/pipes/impl/wordcount-simple.cc  is including the file /home/ramaswamy_a/hadoop/c++/Linux-i386-32/include/hadoop/Pipes.hh.

Pipes.hh contains JobConf which is an abstract class.
Is it needed  to write to our own JobConf  by inheriting the
Pipes.hh:JobConf class?


Please suggest me 

Thanks and Regards
Ramaswamy . B.A 



DISCLAIMER
==========
This e-mail may contain privileged and confidential information which is the property of Persistent Systems Ltd. It is intended only for the use of the individual or entity to which it is addressed. If you are not the intended recipient, you are not authorized to read, retain, copy, print, distribute or use this message. If you have received this communication in error, please notify the sender and delete all copies of this message. Persistent Systems Ltd. does not accept any liability for virus infected mails.

--=-X69ClRMWKrwpnYOYMhQr--

From common-user-return-16770-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 13:28:14 2009
Return-Path: <common-user-return-16770-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 59365 invoked from network); 14 Aug 2009 13:28:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 13:28:14 -0000
Received: (qmail 70636 invoked by uid 500); 14 Aug 2009 13:28:18 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 70549 invoked by uid 500); 14 Aug 2009 13:28:18 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 70539 invoked by uid 99); 14 Aug 2009 13:28:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 13:28:18 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 13:28:05 +0000
Received: from [192.168.0.102] (user-0cdvqhn.cable.mindspring.com [24.223.234.55])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7EDRe18003699
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 08:27:42 -0500
Message-Id: <8B85B396-F7EF-4D44-8468-D334748DFD80@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
Content-Type: multipart/signed; boundary=Apple-Mail-6--781163766; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: What OS?
Date: Fri, 14 Aug 2009 08:27:39 -0500
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com> <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu> <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com> <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com> <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-6--781163766
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit


On Aug 13, 2009, at 10:27 PM, Jason Venner wrote:

> Anyone have any performance numbers for Solaris or ZFS based  
> datanodes.
>
> The directory and inode cache sizes are a limiting factor for linux  
> for
> large and busy datanodes.

I haven't run into this at all, and we have quite large and busy  
datanodes.

However, I would recommend making sure you pick an OS you are  
comfortable administrating.  It doesn't do you any good to run Solaris  
due to speed (whatever the performance may be, better or worse) if it  
takes you twice as long to get basic admin tasks done.

I haven't benchmarked our Solaris nodes vs Linux nodes.  However,  
anecdotally, HDFS on Solaris/ZFS consumes significantly more CPU than  
HDFS on Linux/ext3.

Brian

>
> On Wed, Aug 12, 2009 at 7:45 AM, tim robertson <timrobertson100@gmail.com 
> >wrote:
>
>> Thanks guys.  I'll chat with sys admin and see what he thinks.
>> We knew fedora would require a 6 month rebuild
>>
>>
>> On Wed, Aug 12, 2009 at 4:36 PM, Edward Capriolo<edlinuxguru@gmail.com 
>> >
>> wrote:
>>> On Wed, Aug 12, 2009 at 8:03 AM, Brian Bockelman<bbockelm@cse.unl.edu 
>>> >
>> wrote:
>>>> Hey Tim,
>>>>
>>>> One consideration is "how long is this OS version going to be  
>>>> receiving
>>>> updates?" or "Do I do the operations team any favor by having them
>> upgrade
>>>> every 6 months?"
>>>>
>>>> Personally, I'd avoid Fedora for a production cluster because the  
>>>> lack
>> of
>>>> long-lived releases means that you'll be spending extra effort on
>> upgrading
>>>> the OS.
>>>>
>>>> Brian
>>>>
>>>> On Aug 12, 2009, at 6:05 AM, tim robertson wrote:
>>>>
>>>>> Hi all,
>>>>>
>>>>> Is fedora a decent choice of OS for a new hadoop cluster?  All our
>>>>> other stuff is fedora, but is there was a strong case to move to
>>>>> something else?
>>>>>
>>>>> Cheers
>>>>>
>>>>> Tim
>>>>
>>>>
>>>
>>> CentOS and Scientific Linux are Red Hat Enterprise Linux clones. I
>>> advice people to go with them. Most of this is based on the fact  
>>> that
>>> CentOS is very compatible with RHEL. This is important because
>>> packaged, but not open source software, is typically targeted at  
>>> RHEL.
>>> You can read about someone trying to install WebSphere on say Fedora
>>> Core and see the hard aches. As mentioned above support life is an
>>> issue. RHEL/CENT 5 will be supported until 2014.
>>>
>>> http://www.redhat.com/security/updates/errata/
>>>
>>> The Fedora line typically has support life of a few months. So your
>>> package support dries up fast and then you have to get good with
>>> RPM-build fast :)
>>>
>>
>
>
>
> -- 
> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> http://www.amazon.com/dp/1430219424?tag=jewlerymall
> www.prohadoopbook.com a community for Hadoop Professionals


--Apple-Mail-6--781163766
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-6--781163766--

From common-user-return-16771-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 14:08:54 2009
Return-Path: <common-user-return-16771-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80072 invoked from network); 14 Aug 2009 14:08:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 14:08:54 -0000
Received: (qmail 31425 invoked by uid 500); 14 Aug 2009 14:08:58 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 31333 invoked by uid 500); 14 Aug 2009 14:08:58 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 31323 invoked by uid 99); 14 Aug 2009 14:08:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 14:08:58 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of clarkemjj@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 14:08:49 +0000
Received: by bwz19 with SMTP id 19so1557276bwz.37
        for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 07:08:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=OAkdYFecbUU2cMMVKMIZ1N+etZvnEKsomFqnIHiB4p8=;
        b=abha5jT1i49fAzsn3GRR6iK1KTN5dkvSQAax8sHvZEXgKBqE705rFaapan4qC9f5vz
         VgjaPar03Fg1MssF7fNzwAufgizd1RptQMcLcmbr2+dYSVBIjtUMsJgFowJ7iLXHjKDc
         IJy98OJIktH3SzVyWa9YxaFZcLcaJ0Nr8h6j0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=fTpHJpikp8/TrypA/KoyU74jamIG1e/xdgzFgKjDi9GNzfE6h5BSWMtgZyQbBPrTor
         RkcB+cBcfOGTrdx/u+2Aa1UVW47Y8o+EAim7PeHZGjrw08LfAfyQgP68l53gn/R8bFYh
         +XZdBGGvc5MsrXVcwkY/XEoeUjkSRVEWWm8Yk=
MIME-Version: 1.0
Received: by 10.223.112.6 with SMTP id u6mr511622fap.63.1250258908477; Fri, 14 
	Aug 2009 07:08:28 -0700 (PDT)
In-Reply-To: <4A8149C2.3090102@apache.org>
References: <4238036a0908070910n16e5a24auc72a187aeea4ef66@mail.gmail.com>
	 <73d592f60908071903j5dc036b6qb1e06d2d8c42d8de@mail.gmail.com>
	 <4238036a0908100327x281de118ge3132817fc744ce8@mail.gmail.com>
	 <4A8149C2.3090102@apache.org>
Date: Fri, 14 Aug 2009 15:08:28 +0100
Message-ID: <4238036a0908140708k63df323je71d061d6627194c@mail.gmail.com>
Subject: Re: changing logging
From: John Clarke <clarkemjj@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6d36e8f1df7c004711a96ca
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6d36e8f1df7c004711a96ca
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I discoved that my changes to the log4j file DID take effect when I ran the
app in Hadoop. I was expecting the Eclipse plugin to use the Hadoop log4j
file even when the program was run as a standalone Java application but it
was not!  I added a log4j properties file to the classpath and my logging is
now working for both instances.

Thanks for all the help :)



2009/8/11 Steve Loughran <stevel@apache.org>

> John Clarke wrote:
>
>> Thanks for the reply. I considered that but I have a lot of threads in my
>> application and it's v handy to have log4j output the thread name with the
>> log message.
>>
>> It's like the log4j.properties file in the conf/ directory is not being
>> used
>> as any changes I make seem to have no effect!
>>
>
> Make sure there isn't a log4j. properties file in any JAR you are using; it
> will get picked up first.
> You can use Ant's <whichresource> task to find this out for you; give it
> the classpath you are using and it will set a property to the first instance
> of the resource that the classloader finds
>
>

--0016e6d36e8f1df7c004711a96ca--

From common-user-return-16772-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 14:11:36 2009
Return-Path: <common-user-return-16772-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80781 invoked from network); 14 Aug 2009 14:11:36 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 14:11:36 -0000
Received: (qmail 37183 invoked by uid 500); 14 Aug 2009 14:11:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 37121 invoked by uid 500); 14 Aug 2009 14:11:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 37111 invoked by uid 99); 14 Aug 2009 14:11:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 14:11:40 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of clarkemjj@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 14:11:32 +0000
Received: by fxm17 with SMTP id 17so1586665fxm.13
        for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 07:11:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=dA7+HdLTRZh/0jkTqFjAYQqm+tG24FLNg5G44wbEs1M=;
        b=G83B08nu61Xi4PcTVG0Y26nJs2KD14NjmhmvH5SPeEeBOr9KFh+y8gsmgw7IkpKQ6L
         EPpk5B3Cgk2Oj8ehJocZb764SLW8hryXlNs4Xgr7xZ81gUvdupoPclFmaKypVIUM6qpi
         LPn+mgD2XcIbsK4MFcL2MWVMnFroEfgbmGCSs=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=CzydZLuKqG/HZDrLA6Hdjhap6LCXaMlAPZlG3O0meGERV8Wy6WSLDtqdkAvYLtk+T/
         ZzFpON3PyHjelq1sFnbghftIA12ssSdwzXj3S7sUQwfcy9R8fRRM5j5EUj18sPKAMhii
         4jylVHVybZR83Qb02xxkvtMQTMwAyO10cYi9g=
MIME-Version: 1.0
Received: by 10.223.114.207 with SMTP id f15mr561783faq.90.1250259070976; Fri, 
	14 Aug 2009 07:11:10 -0700 (PDT)
Date: Fri, 14 Aug 2009 15:11:10 +0100
Message-ID: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>
Subject: Two output files?
From: John Clarke <clarkemjj@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e68dbd97cd852904711a9fc6
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e68dbd97cd852904711a9fc6
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

I want to output two text files from my MapReduce job but I am having
trouble understanding how to use the MultipleTextOutputFormat class to do
so.

I want to write to the two files depending on the key of each key/value
pair.

In the Reducer how do I tell it to write the different files? Normally I
just do an output.collect(key, val);.

Any help would be most appreciated.

Thanks,
John

--0016e68dbd97cd852904711a9fc6--

From common-user-return-16773-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 15:54:30 2009
Return-Path: <common-user-return-16773-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 21133 invoked from network); 14 Aug 2009 15:54:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 15:54:30 -0000
Received: (qmail 37952 invoked by uid 500); 14 Aug 2009 15:54:34 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 37879 invoked by uid 500); 14 Aug 2009 15:54:34 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 37869 invoked by uid 500); 14 Aug 2009 15:54:34 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 37866 invoked by uid 99); 14 Aug 2009 15:54:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 15:54:34 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 15:54:24 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1Mbz6R-0000Ek-65
	for core-user@hadoop.apache.org; Fri, 14 Aug 2009 08:54:03 -0700
Message-ID: <24974027.post@talk.nabble.com>
Date: Fri, 14 Aug 2009 08:54:03 -0700 (PDT)
From: Thibaut_ <tbritz@blue.lu>
To: core-user@hadoop.apache.org
Subject: Running procedure after last row has been processed in reducer
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: tbritz@blue.lu
X-Virus-Checked: Checked by ClamAV on apache.org


Hi,

As my reducer class is processing data in threads, I need to run a teardown
procedure when the last element was reached (to wait until the threads have
finished writing to the output collector).

The close function provided by the interface doesn't work, as when called,
all output files are allready closed and collecting data will fail. (Already
too late in code)

For Map jobs, there is a runner class which i can set
(conf.setMapRunnerClass()) which I can modifiy then to execute the teardown.
However there is no such setter for the Reducer.

Is there a possibility to check when the reduce function is called that this
is indeed the last time the reduce function is called? (I run hadoop in non
streaming mode).

Thanks,
Thibaut



-- 
View this message in context: http://www.nabble.com/Running-procedure-after-last-row-has-been-processed-in-reducer-tp24974027p24974027.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-16774-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 20:24:42 2009
Return-Path: <common-user-return-16774-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 36328 invoked from network); 14 Aug 2009 20:24:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 20:24:42 -0000
Received: (qmail 1334 invoked by uid 500); 14 Aug 2009 20:24:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 1238 invoked by uid 500); 14 Aug 2009 20:24:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 1228 invoked by uid 99); 14 Aug 2009 20:24:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 20:24:46 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.210.185 is neither permitted nor denied by domain of kjirapinyo@biz360.com)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 20:24:38 +0000
Received: by yxe15 with SMTP id 15so2380373yxe.5
        for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 13:24:16 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.90.45.19 with SMTP id s19mr1259574ags.100.1250281456652; Fri, 
	14 Aug 2009 13:24:16 -0700 (PDT)
In-Reply-To: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>
From: Kris Jirapinyo <kris.jirapinyo@biz360.com>
Date: Fri, 14 Aug 2009 13:23:52 -0700
Message-ID: <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>
Subject: Re: Two output files?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016362847fc17d9d704711fd686
X-Virus-Checked: Checked by ClamAV on apache.org

--0016362847fc17d9d704711fd686
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi John,
     If you have the Hadoop O'Reilly book, look at pg 206 for an example.
But basically, you just create a subclass of MultipleTextOutputFormat and
then inside it you override generateFileNameForKeyValue (for example) to
have the reducer emit the desired filenames.  For each key in the reducer,
it will write the text values to that file.  Make sure in the JobConf you
set OutputFormat to your class that extends MultipleTextOutputFormat.

-- Kris.

On Fri, Aug 14, 2009 at 7:11 AM, John Clarke <clarkemjj@gmail.com> wrote:

> Hi,
>
> I want to output two text files from my MapReduce job but I am having
> trouble understanding how to use the MultipleTextOutputFormat class to do
> so.
>
> I want to write to the two files depending on the key of each key/value
> pair.
>
> In the Reducer how do I tell it to write the different files? Normally I
> just do an output.collect(key, val);.
>
> Any help would be most appreciated.
>
> Thanks,
> John
>

--0016362847fc17d9d704711fd686--

From common-user-return-16775-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 20:27:19 2009
Return-Path: <common-user-return-16775-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 37094 invoked from network); 14 Aug 2009 20:27:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 20:27:19 -0000
Received: (qmail 5640 invoked by uid 500); 14 Aug 2009 20:27:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 5536 invoked by uid 500); 14 Aug 2009 20:27:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 5526 invoked by uid 99); 14 Aug 2009 20:27:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 20:27:23 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [64.78.17.19] (HELO EXHUB018-4.exch018.msoutlookonline.net) (64.78.17.19)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 20:27:13 +0000
Received: from EXVMBX018-1.exch018.msoutlookonline.net ([64.78.17.47]) by
 EXHUB018-4.exch018.msoutlookonline.net ([64.78.17.19]) with mapi; Fri, 14 Aug
 2009 13:26:53 -0700
From: Scott Carey <scott@richrelevance.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Fri, 14 Aug 2009 13:26:51 -0700
Subject: Re: What OS?
Thread-Topic: What OS?
Thread-Index: Acoc4xpBNW9To4cnRSOW1b9Rfy2/jwAOnPon
Message-ID: <C6AB169B.EDB4%scott@richrelevance.com>
In-Reply-To: <8B85B396-F7EF-4D44-8468-D334748DFD80@cse.unl.edu>
Accept-Language: en-US
Content-Language: en
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org



On 8/14/09 6:27 AM, "Brian Bockelman" <bbockelm@cse.unl.edu> wrote:

>=20
> On Aug 13, 2009, at 10:27 PM, Jason Venner wrote:
>=20
>> Anyone have any performance numbers for Solaris or ZFS based
>> datanodes.
>>=20
>> The directory and inode cache sizes are a limiting factor for linux
>> for
>> large and busy datanodes.
>=20
> I haven't run into this at all, and we have quite large and busy
> datanodes.
>=20
> However, I would recommend making sure you pick an OS you are
> comfortable administrating.  It doesn't do you any good to run Solaris
> due to speed (whatever the performance may be, better or worse) if it
> takes you twice as long to get basic admin tasks done.
>=20
> I haven't benchmarked our Solaris nodes vs Linux nodes.  However,
> anecdotally, HDFS on Solaris/ZFS consumes significantly more CPU than
> HDFS on Linux/ext3.
>=20
> Brian

I wonder if the extra CPU has anything to do with the ZFS checksums.
Perhaps it is lower with ZFS checksums off?  Since HDFS is already doing
checksums on the data that should be safe.

On the other hand, with ZFS you can get transparent, very fast compression
for free.

ext3 tends to get very fragmented very fast if there are concurrent writes.
XFS avoids that but only if you set the allocsize mount parameter large
enough.  In theory, ZFS should avoid fragmentation fairly well for
write-once data like HDFS but I have no experience with that in practice.


>=20
>>=20
>> On Wed, Aug 12, 2009 at 7:45 AM, tim robertson <timrobertson100@gmail.co=
m
>>> wrote:
>>=20
>>> Thanks guys.  I'll chat with sys admin and see what he thinks.
>>> We knew fedora would require a 6 month rebuild
>>>=20
>>>=20
>>> On Wed, Aug 12, 2009 at 4:36 PM, Edward Capriolo<edlinuxguru@gmail.com
>>>>=20
>>> wrote:
>>>> On Wed, Aug 12, 2009 at 8:03 AM, Brian Bockelman<bbockelm@cse.unl.edu
>>>>>=20
>>> wrote:
>>>>> Hey Tim,
>>>>>=20
>>>>> One consideration is "how long is this OS version going to be
>>>>> receiving
>>>>> updates?" or "Do I do the operations team any favor by having them
>>> upgrade
>>>>> every 6 months?"
>>>>>=20
>>>>> Personally, I'd avoid Fedora for a production cluster because the
>>>>> lack
>>> of
>>>>> long-lived releases means that you'll be spending extra effort on
>>> upgrading
>>>>> the OS.
>>>>>=20
>>>>> Brian
>>>>>=20
>>>>> On Aug 12, 2009, at 6:05 AM, tim robertson wrote:
>>>>>=20
>>>>>> Hi all,
>>>>>>=20
>>>>>> Is fedora a decent choice of OS for a new hadoop cluster?  All our
>>>>>> other stuff is fedora, but is there was a strong case to move to
>>>>>> something else?
>>>>>>=20
>>>>>> Cheers
>>>>>>=20
>>>>>> Tim
>>>>>=20
>>>>>=20
>>>>=20
>>>> CentOS and Scientific Linux are Red Hat Enterprise Linux clones. I
>>>> advice people to go with them. Most of this is based on the fact
>>>> that
>>>> CentOS is very compatible with RHEL. This is important because
>>>> packaged, but not open source software, is typically targeted at
>>>> RHEL.
>>>> You can read about someone trying to install WebSphere on say Fedora
>>>> Core and see the hard aches. As mentioned above support life is an
>>>> issue. RHEL/CENT 5 will be supported until 2014.
>>>>=20
>>>> http://www.redhat.com/security/updates/errata/
>>>>=20
>>>> The Fedora line typically has support life of a few months. So your
>>>> package support dries up fast and then you have to get good with
>>>> RPM-build fast :)
>>>>=20
>>>=20
>>=20
>>=20
>>=20
>> --=20
>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>> http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
>> www.prohadoopbook.com a community for Hadoop Professionals
>=20


From common-user-return-16776-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 14 20:56:11 2009
Return-Path: <common-user-return-16776-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 47003 invoked from network); 14 Aug 2009 20:56:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 14 Aug 2009 20:56:11 -0000
Received: (qmail 41773 invoked by uid 500); 14 Aug 2009 20:56:15 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 41677 invoked by uid 500); 14 Aug 2009 20:56:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 41666 invoked by uid 99); 14 Aug 2009 20:56:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 20:56:14 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tomwheel@gmail.com designates 209.85.221.188 as permitted sender)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 14 Aug 2009 20:56:05 +0000
Received: by qyk26 with SMTP id 26so1424411qyk.5
        for <common-user@hadoop.apache.org>; Fri, 14 Aug 2009 13:55:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=EVBxs/RgIn4lDKR0ag91i/FskLjqgtonYolArT9EAUw=;
        b=jpMuNCOfmqGqaUsUKQ1KoEVn0xV5TEfYQptsZjLtYyQChVYUiuWMTUkGXLO4VsOI4a
         0QfM8q5UA/KZrcecDphCbR7BpdW3mN36jYtbh21q943xVIV9zpNgjG7EHhbzumBX16gm
         VvvnR4LN4EyZCy/KH2kBZhh6gl59Lx2m/v8ig=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=k/nbzL1bn7pAq93SlwZnox7TbU0THl1Z9XyKOXe2xlQMS4KFXFwTeqM37iVbbsDSnj
         rSg6zazYviXw7FfUAsBiS5KlAAOBbyaqdZ1t1FQ32lwwkEUv6JLOrt9ynnf7r0xHekXx
         1mexN+PYn0sJB70fKYNDnftV3ubHy8P8Umx2w=
MIME-Version: 1.0
Received: by 10.229.119.131 with SMTP id z3mr1446578qcq.37.1250283342679; Fri, 
	14 Aug 2009 13:55:42 -0700 (PDT)
In-Reply-To: <fa561940908132225v784b6b42oa152d99c3a2b0590@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu>
	 <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com>
	 <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>
	 <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
	 <fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>
	 <45f85f70908132221v449ec8b3s93a9baf530952383@mail.gmail.com>
	 <fa561940908132225v784b6b42oa152d99c3a2b0590@mail.gmail.com>
Date: Fri, 14 Aug 2009 15:55:41 -0500
Message-ID: <4a6f63fa0908141355o4c20eb6n926b348262e5aec8@mail.gmail.com>
Subject: Re: What OS?
From: Tom Wheeler <tomwheel@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

On Fri, Aug 14, 2009 at 12:25 AM, Bogdan M.
Maryniuk<bogdan.maryniuk@gmail.com> wrote:
>> Any pointers on this?
>
> You might start here: http://www.sean.de/Solaris/soltune.html

Check these out too:

   http://www.solarisinternals.com/wiki/index.php/Networks

   http://docs.sun.com/app/docs/doc/819-3681/abeir?a=view

I'd also add that you can tune a Linux system for maximum performance
at a single task too, though recent kernels have a pretty good
autotuning capability that makes this unnecessary in most cases.

I'd agree with some of the others' advice that you should probably
pick an OS for ease of administration, availability of updates,
overall cost and so on.   Either Solaris or Linux would be a good
choice.

I'd expect performance between either OS on the same hardware to be
pretty similar, but it's always hard to speculate on performance. The
best option would be for you to do a proof of concept with a couple of
machines so you can gauge what performance would be like based on the
actual jobs you'll be running.

-- 
Tom Wheeler
http://www.tomwheeler.com/

From common-user-return-16777-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 06:05:17 2009
Return-Path: <common-user-return-16777-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70366 invoked from network); 16 Aug 2009 06:05:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 06:05:17 -0000
Received: (qmail 52972 invoked by uid 500); 16 Aug 2009 06:05:17 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52873 invoked by uid 500); 16 Aug 2009 06:05:17 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52849 invoked by uid 99); 16 Aug 2009 06:05:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 06:05:17 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 06:05:08 +0000
Received: by vws40 with SMTP id 40so1962145vws.2
        for <multiple recipients>; Sat, 15 Aug 2009 23:04:47 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:from:date
         :message-id:subject:to:content-type:content-transfer-encoding;
        bh=HBKPXEtiqQXdgKf+U3jT35u/rmR/0HDV7Sg6Vk57Pd4=;
        b=wgLDUG7qRWhCHk9YyQehzseAkbMWQ8tmICvkbrl7d7VCv4Jwa/bcAFNVz9dlE9cwXW
         TCZKwnrx7mm7AoYXLFWrDH6YgC7OO4cFFmmgeLG3oh1Rnd8oeQiq28/K/MT5GYS1W1+e
         n0skEQEbZU3sYa8m57MASUmeLkd7UaJ/oj8P8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:from:date:message-id:subject:to:content-type
         :content-transfer-encoding;
        b=b6otyQqsUFVErGBx09K+Ui1Vg6RC7Rua/fKQdOZxCvPp4Xc6DshBu0UNnB+TLO69x9
         qzjw+WVn+boocVx+vDHTf+LcFqIy9vPj8t9Ycs6bc8A7FsjBZTU9lj7FtTHzQaqvXofc
         NIOJVL2o+bTOzqMbAmerSsPDJ8Ih34fLziLm8=
MIME-Version: 1.0
Received: by 10.220.42.73 with SMTP id r9mr3496338vce.106.1250402687144; Sat, 
	15 Aug 2009 23:04:47 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 16 Aug 2009 02:04:27 -0400
Message-ID: <1e7471d50908152304q251c05daga5563047f058d12b@mail.gmail.com>
Subject: 404 Error on Web UI
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,
I reformmated by hdfs system and ran Hadoop. The jobtrackers,
namenodes are all running, i can go to namenode:50070 and get an
opening webpage(via lynx)but when i click to go to
http://jobtracker:50030/jobtracker.jsp it get 404 Error for
RequestURI=/jobtracker.jsp


This was an open problem (0.15.3 -
http://mail-archives.apache.org/mod_mbox/hadoop-core-user/200802.mbox/%3C47B5A57D.3010802@attributor.com%3E)

Has it been solved? What is the solution?

Thanks and Regards
Saptarshi

From common-user-return-16778-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 06:05:17 2009
Return-Path: <common-user-return-16778-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70376 invoked from network); 16 Aug 2009 06:05:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 06:05:17 -0000
Received: (qmail 53007 invoked by uid 500); 16 Aug 2009 06:05:17 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52875 invoked by uid 500); 16 Aug 2009 06:05:17 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52858 invoked by uid 500); 16 Aug 2009 06:05:17 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 52849 invoked by uid 99); 16 Aug 2009 06:05:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 06:05:17 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 06:05:08 +0000
Received: by vws40 with SMTP id 40so1962145vws.2
        for <multiple recipients>; Sat, 15 Aug 2009 23:04:47 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:from:date
         :message-id:subject:to:content-type:content-transfer-encoding;
        bh=HBKPXEtiqQXdgKf+U3jT35u/rmR/0HDV7Sg6Vk57Pd4=;
        b=wgLDUG7qRWhCHk9YyQehzseAkbMWQ8tmICvkbrl7d7VCv4Jwa/bcAFNVz9dlE9cwXW
         TCZKwnrx7mm7AoYXLFWrDH6YgC7OO4cFFmmgeLG3oh1Rnd8oeQiq28/K/MT5GYS1W1+e
         n0skEQEbZU3sYa8m57MASUmeLkd7UaJ/oj8P8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:from:date:message-id:subject:to:content-type
         :content-transfer-encoding;
        b=b6otyQqsUFVErGBx09K+Ui1Vg6RC7Rua/fKQdOZxCvPp4Xc6DshBu0UNnB+TLO69x9
         qzjw+WVn+boocVx+vDHTf+LcFqIy9vPj8t9Ycs6bc8A7FsjBZTU9lj7FtTHzQaqvXofc
         NIOJVL2o+bTOzqMbAmerSsPDJ8Ih34fLziLm8=
MIME-Version: 1.0
Received: by 10.220.42.73 with SMTP id r9mr3496338vce.106.1250402687144; Sat, 
	15 Aug 2009 23:04:47 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 16 Aug 2009 02:04:27 -0400
Message-ID: <1e7471d50908152304q251c05daga5563047f058d12b@mail.gmail.com>
Subject: 404 Error on Web UI
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,
I reformmated by hdfs system and ran Hadoop. The jobtrackers,
namenodes are all running, i can go to namenode:50070 and get an
opening webpage(via lynx)but when i click to go to
http://jobtracker:50030/jobtracker.jsp it get 404 Error for
RequestURI=/jobtracker.jsp


This was an open problem (0.15.3 -
http://mail-archives.apache.org/mod_mbox/hadoop-core-user/200802.mbox/%3C47B5A57D.3010802@attributor.com%3E)

Has it been solved? What is the solution?

Thanks and Regards
Saptarshi

From common-user-return-16779-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 06:20:30 2009
Return-Path: <common-user-return-16779-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80981 invoked from network); 16 Aug 2009 06:20:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 06:20:29 -0000
Received: (qmail 59368 invoked by uid 500); 16 Aug 2009 06:20:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 59267 invoked by uid 500); 16 Aug 2009 06:20:30 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 59247 invoked by uid 99); 16 Aug 2009 06:20:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 06:20:30 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 06:20:20 +0000
Received: by vws40 with SMTP id 40so1964206vws.2
        for <multiple recipients>; Sat, 15 Aug 2009 23:20:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:from:date
         :message-id:subject:to:content-type:content-transfer-encoding;
        bh=WV8UXoi3plqDCqB4TV7GGj7iHryzAUXKnv41jqLUeQY=;
        b=Ix+pb53Ita+MOKOh67ifxBc77B5r1PGozqn1fwWRkfN+xdf2v7wmZ56h6ZL6Irtpmx
         CgAv7Vcr5ikeu/CkUsAXt6CoDi5uJXfFXTZqcLBqUnsl1Dku5lmoWg7PcwX5KMbTLpVy
         xLKIN4jtL7cqBExMbWFGYJ91JPjUWyJLAR20U=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:from:date:message-id:subject:to:content-type
         :content-transfer-encoding;
        b=Yx6LQvLznvy+PK7DyD7i5ozUPTOKCXtMLjO8xnCQIdW8XWAnU9cDrpc0IqnbcUdqFE
         WVfagzQ2gYNZVszDHvjv6gmB1Zs7uNxsrQ5VEDEqXHeCzHqZJDRxSmlqHjGgaShd9miI
         8s55Sdq6bXqdZUCmFlxmftVjwwHndLVoEpEP0=
MIME-Version: 1.0
Received: by 10.220.14.4 with SMTP id e4mr3537237vca.101.1250403600135; Sat, 
	15 Aug 2009 23:20:00 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 16 Aug 2009 02:19:40 -0400
Message-ID: <1e7471d50908152319u32a082d0j9233df780e4a6ae5@mail.gmail.com>
Subject: Jobtracker still finding old task nodes
To: core-user@hadoop.apache.org, common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,
After formatting the HDFS and removing several entries from the slaves
file, when I start up
$HADOOP/bin/start-all.sh (hadoop 0.20)
I get this in jobtracker.log
All the machines save acrux have been removed the from the slaves file.
Both acrux and the jobtracker have the same conf files.

Why does it discover the old machines? Does it automatically discover
new machines?

Thanks and Regards
Saptarshi

WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
record of 'previous' heartbeat for 'tracker_deneb.'; reinitializing
the tasktracker
WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
record of 'previous' heartbeat for
'tracker_adhara.stat.purdue.edu:localhost.localdomain/127.0.0.1:37715';
reinitializing the tasktracker
WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
record of 'previous' heartbeat for 'tracker_castor'; reinitializing
the
tasktracker
2009-08-16 02:15:03,146 INFO org.apache.hadoop.net.NetworkTopology:
Adding a new node: /default-rack/deneb.
2009-08-16 02:15:03,161 INFO org.apache.hadoop.net.NetworkTopology:
Adding a new node: /default-rack/adhara
2009-08-16 02:15:03,165 INFO org.apache.hadoop.net.NetworkTopology:
Adding a new node: /default-rack/castor
2009-08-16 02:15:03,193 INFO org.apache.hadoop.net.NetworkTopology:
Adding a new node: /default-rack/acrux.
2009-08-16 02:15:15,158 ERROR org.apache.hadoop.mapred.PoolManager:
Failed to reload allocations file - will use existing allocation

From common-user-return-16780-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 06:20:30 2009
Return-Path: <common-user-return-16780-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81004 invoked from network); 16 Aug 2009 06:20:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 06:20:29 -0000
Received: (qmail 59419 invoked by uid 500); 16 Aug 2009 06:20:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 59271 invoked by uid 500); 16 Aug 2009 06:20:30 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 59252 invoked by uid 500); 16 Aug 2009 06:20:30 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 59247 invoked by uid 99); 16 Aug 2009 06:20:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 06:20:30 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 06:20:20 +0000
Received: by vws40 with SMTP id 40so1964206vws.2
        for <multiple recipients>; Sat, 15 Aug 2009 23:20:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:from:date
         :message-id:subject:to:content-type:content-transfer-encoding;
        bh=WV8UXoi3plqDCqB4TV7GGj7iHryzAUXKnv41jqLUeQY=;
        b=Ix+pb53Ita+MOKOh67ifxBc77B5r1PGozqn1fwWRkfN+xdf2v7wmZ56h6ZL6Irtpmx
         CgAv7Vcr5ikeu/CkUsAXt6CoDi5uJXfFXTZqcLBqUnsl1Dku5lmoWg7PcwX5KMbTLpVy
         xLKIN4jtL7cqBExMbWFGYJ91JPjUWyJLAR20U=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:from:date:message-id:subject:to:content-type
         :content-transfer-encoding;
        b=Yx6LQvLznvy+PK7DyD7i5ozUPTOKCXtMLjO8xnCQIdW8XWAnU9cDrpc0IqnbcUdqFE
         WVfagzQ2gYNZVszDHvjv6gmB1Zs7uNxsrQ5VEDEqXHeCzHqZJDRxSmlqHjGgaShd9miI
         8s55Sdq6bXqdZUCmFlxmftVjwwHndLVoEpEP0=
MIME-Version: 1.0
Received: by 10.220.14.4 with SMTP id e4mr3537237vca.101.1250403600135; Sat, 
	15 Aug 2009 23:20:00 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 16 Aug 2009 02:19:40 -0400
Message-ID: <1e7471d50908152319u32a082d0j9233df780e4a6ae5@mail.gmail.com>
Subject: Jobtracker still finding old task nodes
To: core-user@hadoop.apache.org, common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,
After formatting the HDFS and removing several entries from the slaves
file, when I start up
$HADOOP/bin/start-all.sh (hadoop 0.20)
I get this in jobtracker.log
All the machines save acrux have been removed the from the slaves file.
Both acrux and the jobtracker have the same conf files.

Why does it discover the old machines? Does it automatically discover
new machines?

Thanks and Regards
Saptarshi

WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
record of 'previous' heartbeat for 'tracker_deneb.'; reinitializing
the tasktracker
WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
record of 'previous' heartbeat for
'tracker_adhara.stat.purdue.edu:localhost.localdomain/127.0.0.1:37715';
reinitializing the tasktracker
WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
record of 'previous' heartbeat for 'tracker_castor'; reinitializing
the
tasktracker
2009-08-16 02:15:03,146 INFO org.apache.hadoop.net.NetworkTopology:
Adding a new node: /default-rack/deneb.
2009-08-16 02:15:03,161 INFO org.apache.hadoop.net.NetworkTopology:
Adding a new node: /default-rack/adhara
2009-08-16 02:15:03,165 INFO org.apache.hadoop.net.NetworkTopology:
Adding a new node: /default-rack/castor
2009-08-16 02:15:03,193 INFO org.apache.hadoop.net.NetworkTopology:
Adding a new node: /default-rack/acrux.
2009-08-16 02:15:15,158 ERROR org.apache.hadoop.mapred.PoolManager:
Failed to reload allocations file - will use existing allocation

From common-user-return-16781-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 11:50:51 2009
Return-Path: <common-user-return-16781-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 78268 invoked from network); 16 Aug 2009 11:50:51 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 11:50:51 -0000
Received: (qmail 716 invoked by uid 500); 16 Aug 2009 11:50:55 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 625 invoked by uid 500); 16 Aug 2009 11:50:55 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 615 invoked by uid 99); 16 Aug 2009 11:50:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 11:50:55 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bogdan.maryniuk@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 11:50:46 +0000
Received: by fxm17 with SMTP id 17so2335233fxm.13
        for <common-user@hadoop.apache.org>; Sun, 16 Aug 2009 04:50:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=YXjrHhE4nf+sj0MqDbvOfe7NTocK+/W4+vsyYmKOFLY=;
        b=X7oEy8FDVYBjVxkQj3QSJPHZxcZfkNc4x9AVz0/samZ52nmd9/7b/cQ8PhUj9K+wp6
         3FgFt3ja0lsm/Yq7/AJWbNvQqyhfty5v7Q/XYr/NlhwOHgwOgq8TJG+VWBm6RH2iX8VM
         QRz2mZGarxAX0uv8fwpVygbjA+i30H+71INxA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=r2D64Exsynob84/v1Y0lNJHqgDferPQCssGvmQNjkC9uktHU+lVExI1zzVtGA93RmD
         Wvg3rMA6le7eBVyEI5ubluHrqZxC/QvjtJh4OKdHJLwAExixB3wCxZPkeTJWCsihgF05
         n65LOW0GcZy9zxMe/N+0EaEMhUhabO0LEdBKo=
MIME-Version: 1.0
Received: by 10.223.121.193 with SMTP id i1mr749063far.27.1250423425920; Sun, 
	16 Aug 2009 04:50:25 -0700 (PDT)
In-Reply-To: <4a6f63fa0908141355o4c20eb6n926b348262e5aec8@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu>
	 <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com>
	 <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>
	 <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
	 <fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>
	 <45f85f70908132221v449ec8b3s93a9baf530952383@mail.gmail.com>
	 <fa561940908132225v784b6b42oa152d99c3a2b0590@mail.gmail.com>
	 <4a6f63fa0908141355o4c20eb6n926b348262e5aec8@mail.gmail.com>
Date: Sun, 16 Aug 2009 20:50:25 +0900
Message-ID: <fa561940908160450g4fb04ed7m26e83025e8e0081c@mail.gmail.com>
Subject: Re: What OS?
From: "Bogdan M. Maryniuk" <bogdan.maryniuk@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Sat, Aug 15, 2009 at 5:55 AM, Tom Wheeler<tomwheel@gmail.com> wrote:
> I'd expect performance between either OS on the same hardware to be
> pretty similar, but it's always hard to speculate on performance. The
> best option would be for you to do a proof of concept with a couple of
> machines so you can gauge what performance would be like based on the
> actual jobs you'll be running.

That's what I basically said before. :-)

My few cents in this conversation: personally I go Solaris instead of
Linux for other reasons. It is ZFS, self-healing, zones, better TCP/IP
stack, better Sun Java, its overall stability etc. Performance is not
primary point actually =E2=80=94 I bet more on stability and manageability,
which I find much more sophisticated on OpenSolaris, rather than on
Linux (although OpenSolaris has lots of quite ugly things too)...
Although, recent changes in OpenSolaris (e.g. new memory management)
only proves more and more that my decision to drop Linux was damn
right. :-)

--=20
Kind regards, BM

Things, that are stupid at the beginning, rarely ends up wisely.

From common-user-return-16782-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 15:48:35 2009
Return-Path: <common-user-return-16782-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 53032 invoked from network); 16 Aug 2009 15:48:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 15:48:35 -0000
Received: (qmail 11240 invoked by uid 500); 16 Aug 2009 15:48:39 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 11154 invoked by uid 500); 16 Aug 2009 15:48:39 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 11144 invoked by uid 99); 16 Aug 2009 15:48:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 15:48:39 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of edlinuxguru@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 15:48:31 +0000
Received: by fxm17 with SMTP id 17so2397161fxm.13
        for <common-user@hadoop.apache.org>; Sun, 16 Aug 2009 08:48:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=sEe50MdD4VHDc8MuZyVdyEV5YJ0b6o9WIY/hsdBcBF8=;
        b=Rell7q7Y8DZuefUOO+JHbeKfb+tdnP4l8vT8KvahMWvFtViGN+4fhUv5tZv22WNJJi
         8eH722OSoPEIZJVo8JcKOrmZ6Ik2wrp8Se3xOaVkpwcLArMQaRPibNMEJUBOzoDE3FIY
         8dVnJbSiWZE+5EKccp54o+a1t3LdEmzhZWFfI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=abvlmpwvQJtyYuinsx/ZRQ30WkSHtvXyRRRp4iD4SC6033Acix/d+YCZCaqlGYl9BU
         ZUb8ivUf8pdJ5nqCYWRhRI7uFWDmljNBw6VW7WJIZgvGSLgtjHXCRS53+wuqqQvr6w32
         DwkQY5I+Y5HxGXucCWB28HFdzYzT7/4eMr8Fo=
MIME-Version: 1.0
Received: by 10.239.138.18 with SMTP id n18mr202421hbn.40.1250437688503; Sun, 
	16 Aug 2009 08:48:08 -0700 (PDT)
In-Reply-To: <fa561940908160450g4fb04ed7m26e83025e8e0081c@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <F64B91DA-5559-466B-9D48-B7DB83533B25@cse.unl.edu>
	 <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com>
	 <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>
	 <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
	 <fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>
	 <45f85f70908132221v449ec8b3s93a9baf530952383@mail.gmail.com>
	 <fa561940908132225v784b6b42oa152d99c3a2b0590@mail.gmail.com>
	 <4a6f63fa0908141355o4c20eb6n926b348262e5aec8@mail.gmail.com>
	 <fa561940908160450g4fb04ed7m26e83025e8e0081c@mail.gmail.com>
Date: Sun, 16 Aug 2009 11:48:08 -0400
Message-ID: <cbbf4b570908160848o7c0b9875g641a627e97a680d5@mail.gmail.com>
Subject: Re: What OS?
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Sun, Aug 16, 2009 at 7:50 AM, Bogdan M.
Maryniuk<bogdan.maryniuk@gmail.com> wrote:
> On Sat, Aug 15, 2009 at 5:55 AM, Tom Wheeler<tomwheel@gmail.com> wrote:
>> I'd expect performance between either OS on the same hardware to be
>> pretty similar, but it's always hard to speculate on performance. The
>> best option would be for you to do a proof of concept with a couple of
>> machines so you can gauge what performance would be like based on the
>> actual jobs you'll be running.
>
> That's what I basically said before. :-)
>
> My few cents in this conversation: personally I go Solaris instead of
> Linux for other reasons. It is ZFS, self-healing, zones, better TCP/IP
> stack, better Sun Java, its overall stability etc. Performance is not
> primary point actually =97 I bet more on stability and manageability,
> which I find much more sophisticated on OpenSolaris, rather than on
> Linux (although OpenSolaris has lots of quite ugly things too)...
> Although, recent changes in OpenSolaris (e.g. new memory management)
> only proves more and more that my decision to drop Linux was damn
> right. :-)
>
> --
> Kind regards, BM
>
> Things, that are stupid at the beginning, rarely ends up wisely.
>

More two cents coming from me. Often picking the target platform of
the project is a safe bet. For example, say you desire to use the
fuse-dfs front end. Often times if you chose the same platform as the
majority of the community you can either find a binary package, or be
relatively confident that the install will go easy.

Now a quick retort to this that thinking is "Hadoop is open source it
should build on every platform". That thinking is true with a wrinkle
or two. Suppose you want to start using the fuse front end for the DFS
and your OS is say FreeBSD. You are entering uncharted waters, you
might hit some some minor incompatibility like something between make
and GMake, and you might have to start patching scripts, patching
code, or opening a Jira and asking for help it could be anywhere from
a quick fix to a tricky fix. Whereas someone who installed a more
tested platform had might have got it running out of the box and moved
onto bigger and better things like actually using fuse-dfs.

A quick example with this our cluster is Cent5. Someone hit me with a
requirement to be able to kick off jobs from a node running FreeBSD.
When i try to kick up a job using the compression libraries it failed,
most likely because I did had to use a ported/jvm that is not exactly
identical to the sun JVM or maybe something in the native libraries.
My quick fix was to turn off compression. I am probably the ONLY
person on the internet trying to do this. It could take hours/days of
research for me to figure out what is going on here. (I do have better
things to do)

So even though you can probably run a cluster with FreeBSD or Windows
ME you are definitely making more work for yourself and you are on an
island if you have an issue.

From common-user-return-16783-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 15:58:27 2009
Return-Path: <common-user-return-16783-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 55127 invoked from network); 16 Aug 2009 15:58:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 15:58:26 -0000
Received: (qmail 17540 invoked by uid 500); 16 Aug 2009 15:58:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 17413 invoked by uid 500); 16 Aug 2009 15:58:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 17395 invoked by uid 99); 16 Aug 2009 15:58:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 15:58:28 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 15:58:20 +0000
Received: by vws40 with SMTP id 40so2064744vws.2
        for <multiple recipients>; Sun, 16 Aug 2009 08:57:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:content-type;
        bh=pqu1XIgwXJxlLqv8PReXfis6+dsxmpYEqIYq7bdg+oU=;
        b=FlATGniJA+CyXchElyKwVEFeK/gT+hBF4tByU+GDI6lVIy3GetXdE4f82trltgOZs0
         Pgsj+5hIjIsNnR71SG0CofmOFiBCHxu+MoCIAYfrIk7izs1AEYW0p3St2e64xU3RyzwM
         mSHHRfsHmVwKBSa7lqk3ZuS7aRjpSLQhiHmIg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:content-type;
        b=XYKr+JikmhB1ipYX+Top/QlNvPG5osgJhA0vhWyApva2q6Sp9SR9AjhwwTapAsrabv
         8VeFoFbHglSyhFdyUvjZAeHw3Y1y27BJ8ikRepR8lvtYNIZoJGHOfoAa1yQrNpZ7+0Bb
         MjVADJz9FJNrzWdRl59TmWLQlHHNLx92pPs+0=
MIME-Version: 1.0
Received: by 10.220.90.3 with SMTP id g3mr3788614vcm.51.1250438279080; Sun, 16 
	Aug 2009 08:57:59 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
In-Reply-To: <1e7471d50908152304q251c05daga5563047f058d12b@mail.gmail.com>
References: <1e7471d50908152304q251c05daga5563047f058d12b@mail.gmail.com>
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 16 Aug 2009 11:57:39 -0400
Message-ID: <1e7471d50908160857t3bdeefb7lc207903606a2a0f4@mail.gmail.com>
Subject: Re: 404 Error on Web UI
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e645fa8a702bfb04714459f9
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e645fa8a702bfb04714459f9
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Well it works now, but after numerous starts/restarts and reinstallation(oh,
and removing the classpath in bashrc, it appears HBASE once had this issue)

Regards
Saptarshi

On Sun, Aug 16, 2009 at 2:04 AM, Saptarshi Guha <saptarshi.guha@gmail.com>wrote:

> Hello,
> I reformmated by hdfs system and ran Hadoop. The jobtrackers,
> namenodes are all running, i can go to namenode:50070 and get an
> opening webpage(via lynx)but when i click to go to
> http://jobtracker:50030/jobtracker.jsp it get 404 Error for
> RequestURI=/jobtracker.jsp
>
>
> This was an open problem (0.15.3 -
>
> http://mail-archives.apache.org/mod_mbox/hadoop-core-user/200802.mbox/%3C47B5A57D.3010802@attributor.com%3E
> )
>
> Has it been solved? What is the solution?
>
> Thanks and Regards
> Saptarshi
>

--0016e645fa8a702bfb04714459f9--

From common-user-return-16784-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 15:58:27 2009
Return-Path: <common-user-return-16784-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 55141 invoked from network); 16 Aug 2009 15:58:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 15:58:26 -0000
Received: (qmail 17580 invoked by uid 500); 16 Aug 2009 15:58:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 17420 invoked by uid 500); 16 Aug 2009 15:58:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 17401 invoked by uid 500); 16 Aug 2009 15:58:28 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 17395 invoked by uid 99); 16 Aug 2009 15:58:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 15:58:28 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 15:58:20 +0000
Received: by vws40 with SMTP id 40so2064744vws.2
        for <multiple recipients>; Sun, 16 Aug 2009 08:57:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:content-type;
        bh=pqu1XIgwXJxlLqv8PReXfis6+dsxmpYEqIYq7bdg+oU=;
        b=FlATGniJA+CyXchElyKwVEFeK/gT+hBF4tByU+GDI6lVIy3GetXdE4f82trltgOZs0
         Pgsj+5hIjIsNnR71SG0CofmOFiBCHxu+MoCIAYfrIk7izs1AEYW0p3St2e64xU3RyzwM
         mSHHRfsHmVwKBSa7lqk3ZuS7aRjpSLQhiHmIg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:content-type;
        b=XYKr+JikmhB1ipYX+Top/QlNvPG5osgJhA0vhWyApva2q6Sp9SR9AjhwwTapAsrabv
         8VeFoFbHglSyhFdyUvjZAeHw3Y1y27BJ8ikRepR8lvtYNIZoJGHOfoAa1yQrNpZ7+0Bb
         MjVADJz9FJNrzWdRl59TmWLQlHHNLx92pPs+0=
MIME-Version: 1.0
Received: by 10.220.90.3 with SMTP id g3mr3788614vcm.51.1250438279080; Sun, 16 
	Aug 2009 08:57:59 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
In-Reply-To: <1e7471d50908152304q251c05daga5563047f058d12b@mail.gmail.com>
References: <1e7471d50908152304q251c05daga5563047f058d12b@mail.gmail.com>
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 16 Aug 2009 11:57:39 -0400
Message-ID: <1e7471d50908160857t3bdeefb7lc207903606a2a0f4@mail.gmail.com>
Subject: Re: 404 Error on Web UI
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e645fa8a702bfb04714459f9
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e645fa8a702bfb04714459f9
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Well it works now, but after numerous starts/restarts and reinstallation(oh,
and removing the classpath in bashrc, it appears HBASE once had this issue)

Regards
Saptarshi

On Sun, Aug 16, 2009 at 2:04 AM, Saptarshi Guha <saptarshi.guha@gmail.com>wrote:

> Hello,
> I reformmated by hdfs system and ran Hadoop. The jobtrackers,
> namenodes are all running, i can go to namenode:50070 and get an
> opening webpage(via lynx)but when i click to go to
> http://jobtracker:50030/jobtracker.jsp it get 404 Error for
> RequestURI=/jobtracker.jsp
>
>
> This was an open problem (0.15.3 -
>
> http://mail-archives.apache.org/mod_mbox/hadoop-core-user/200802.mbox/%3C47B5A57D.3010802@attributor.com%3E
> )
>
> Has it been solved? What is the solution?
>
> Thanks and Regards
> Saptarshi
>

--0016e645fa8a702bfb04714459f9--

From common-user-return-16786-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 16:10:52 2009
Return-Path: <common-user-return-16786-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 57897 invoked from network); 16 Aug 2009 16:10:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 16:10:52 -0000
Received: (qmail 27008 invoked by uid 500); 16 Aug 2009 16:10:54 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26873 invoked by uid 500); 16 Aug 2009 16:10:54 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 26853 invoked by uid 500); 16 Aug 2009 16:10:54 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 26847 invoked by uid 99); 16 Aug 2009 16:10:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 16:10:54 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 16:10:44 +0000
Received: by vws40 with SMTP id 40so2067774vws.2
        for <multiple recipients>; Sun, 16 Aug 2009 09:10:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:content-type;
        bh=lny++PXjmdfmFf3H9KpBpPySPVf7XSC8ZEkMRiqtBSM=;
        b=Z4qnj9/4WNtrl/0k6Fu+ElIDG2F4NO1WdaPF9Toeo+tDxqkSFqDZ9uPkRZxLViChb3
         jFQ47+odlpk/h0y6yfWj2UYHmi/I2k+8uTRzlYK4WX8oDR/DluvKVPLQWkTgeIfogktn
         NSbUMM7kr63M4HTrPTUmyUrbBGV1cqWS77U+Q=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:content-type;
        b=iKm00ZLuo9KkmXR/jYVojZqPVukNqdaqwFus+1eFJ+ynaqpmWjbmeYkTDR+oW903+K
         Fv1szzjsneY58ZtU/2ZQnO0LHg2ESWd++fmSshAobe9ClTf1ufzIM5s8flyr3auqcYJv
         0ZxLSoHFmW4mqqSCD80/nsB+HJrWu8Z/y/jsQ=
MIME-Version: 1.0
Received: by 10.220.96.81 with SMTP id g17mr3826308vcn.52.1250439023065; Sun, 
	16 Aug 2009 09:10:23 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
In-Reply-To: <1e7471d50908152319u32a082d0j9233df780e4a6ae5@mail.gmail.com>
References: <1e7471d50908152319u32a082d0j9233df780e4a6ae5@mail.gmail.com>
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 16 Aug 2009 12:10:03 -0400
Message-ID: <1e7471d50908160910p67f904f7ud9565193ca2d93af@mail.gmail.com>
Subject: Re: Jobtracker still finding old task nodes
To: core-user@hadoop.apache.org, common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6469c46c879fa04714485eb
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6469c46c879fa04714485eb
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

My mistake, i had assumed the trackers were not running on those machines.
But they were ...

On Sun, Aug 16, 2009 at 2:19 AM, Saptarshi Guha <saptarshi.guha@gmail.com>wrote:

> Hello,
> After formatting the HDFS and removing several entries from the slaves
> file, when I start up
> $HADOOP/bin/start-all.sh (hadoop 0.20)
> I get this in jobtracker.log
> All the machines save acrux have been removed the from the slaves file.
> Both acrux and the jobtracker have the same conf files.
>
> Why does it discover the old machines? Does it automatically discover
> new machines?
>
> Thanks and Regards
> Saptarshi
>
> WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
> record of 'previous' heartbeat for 'tracker_deneb.'; reinitializing
> the tasktracker
> WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
> record of 'previous' heartbeat for
> 'tracker_adhara.stat.purdue.edu:localhost.localdomain/127.0.0.1:37715';
> reinitializing the tasktracker
> WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
> record of 'previous' heartbeat for 'tracker_castor'; reinitializing
> the
> tasktracker
> 2009-08-16 02:15:03,146 INFO org.apache.hadoop.net.NetworkTopology:
> Adding a new node: /default-rack/deneb.
> 2009-08-16 02:15:03,161 INFO org.apache.hadoop.net.NetworkTopology:
> Adding a new node: /default-rack/adhara
> 2009-08-16 02:15:03,165 INFO org.apache.hadoop.net.NetworkTopology:
> Adding a new node: /default-rack/castor
> 2009-08-16 02:15:03,193 INFO org.apache.hadoop.net.NetworkTopology:
> Adding a new node: /default-rack/acrux.
> 2009-08-16 02:15:15,158 ERROR org.apache.hadoop.mapred.PoolManager:
> Failed to reload allocations file - will use existing allocation
>

--0016e6469c46c879fa04714485eb--

From common-user-return-16785-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 16:10:52 2009
Return-Path: <common-user-return-16785-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 57888 invoked from network); 16 Aug 2009 16:10:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 16:10:52 -0000
Received: (qmail 26930 invoked by uid 500); 16 Aug 2009 16:10:54 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26867 invoked by uid 500); 16 Aug 2009 16:10:54 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 26847 invoked by uid 99); 16 Aug 2009 16:10:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 16:10:54 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saptarshi.guha@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 16:10:44 +0000
Received: by vws40 with SMTP id 40so2067774vws.2
        for <multiple recipients>; Sun, 16 Aug 2009 09:10:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:content-type;
        bh=lny++PXjmdfmFf3H9KpBpPySPVf7XSC8ZEkMRiqtBSM=;
        b=Z4qnj9/4WNtrl/0k6Fu+ElIDG2F4NO1WdaPF9Toeo+tDxqkSFqDZ9uPkRZxLViChb3
         jFQ47+odlpk/h0y6yfWj2UYHmi/I2k+8uTRzlYK4WX8oDR/DluvKVPLQWkTgeIfogktn
         NSbUMM7kr63M4HTrPTUmyUrbBGV1cqWS77U+Q=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:content-type;
        b=iKm00ZLuo9KkmXR/jYVojZqPVukNqdaqwFus+1eFJ+ynaqpmWjbmeYkTDR+oW903+K
         Fv1szzjsneY58ZtU/2ZQnO0LHg2ESWd++fmSshAobe9ClTf1ufzIM5s8flyr3auqcYJv
         0ZxLSoHFmW4mqqSCD80/nsB+HJrWu8Z/y/jsQ=
MIME-Version: 1.0
Received: by 10.220.96.81 with SMTP id g17mr3826308vcn.52.1250439023065; Sun, 
	16 Aug 2009 09:10:23 -0700 (PDT)
Reply-To: saptarshi.guha@gmail.com
In-Reply-To: <1e7471d50908152319u32a082d0j9233df780e4a6ae5@mail.gmail.com>
References: <1e7471d50908152319u32a082d0j9233df780e4a6ae5@mail.gmail.com>
From: Saptarshi Guha <saptarshi.guha@gmail.com>
Date: Sun, 16 Aug 2009 12:10:03 -0400
Message-ID: <1e7471d50908160910p67f904f7ud9565193ca2d93af@mail.gmail.com>
Subject: Re: Jobtracker still finding old task nodes
To: core-user@hadoop.apache.org, common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6469c46c879fa04714485eb
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6469c46c879fa04714485eb
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

My mistake, i had assumed the trackers were not running on those machines.
But they were ...

On Sun, Aug 16, 2009 at 2:19 AM, Saptarshi Guha <saptarshi.guha@gmail.com>wrote:

> Hello,
> After formatting the HDFS and removing several entries from the slaves
> file, when I start up
> $HADOOP/bin/start-all.sh (hadoop 0.20)
> I get this in jobtracker.log
> All the machines save acrux have been removed the from the slaves file.
> Both acrux and the jobtracker have the same conf files.
>
> Why does it discover the old machines? Does it automatically discover
> new machines?
>
> Thanks and Regards
> Saptarshi
>
> WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
> record of 'previous' heartbeat for 'tracker_deneb.'; reinitializing
> the tasktracker
> WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
> record of 'previous' heartbeat for
> 'tracker_adhara.stat.purdue.edu:localhost.localdomain/127.0.0.1:37715';
> reinitializing the tasktracker
> WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find
> record of 'previous' heartbeat for 'tracker_castor'; reinitializing
> the
> tasktracker
> 2009-08-16 02:15:03,146 INFO org.apache.hadoop.net.NetworkTopology:
> Adding a new node: /default-rack/deneb.
> 2009-08-16 02:15:03,161 INFO org.apache.hadoop.net.NetworkTopology:
> Adding a new node: /default-rack/adhara
> 2009-08-16 02:15:03,165 INFO org.apache.hadoop.net.NetworkTopology:
> Adding a new node: /default-rack/castor
> 2009-08-16 02:15:03,193 INFO org.apache.hadoop.net.NetworkTopology:
> Adding a new node: /default-rack/acrux.
> 2009-08-16 02:15:15,158 ERROR org.apache.hadoop.mapred.PoolManager:
> Failed to reload allocations file - will use existing allocation
>

--0016e6469c46c879fa04714485eb--

From common-user-return-16787-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 16 16:47:30 2009
Return-Path: <common-user-return-16787-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61926 invoked from network); 16 Aug 2009 16:47:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 16 Aug 2009 16:47:30 -0000
Received: (qmail 48881 invoked by uid 500); 16 Aug 2009 16:47:34 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 48798 invoked by uid 500); 16 Aug 2009 16:47:34 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 48788 invoked by uid 99); 16 Aug 2009 16:47:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 16:47:34 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bogdan.maryniuk@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 16 Aug 2009 16:47:24 +0000
Received: by fxm17 with SMTP id 17so2413398fxm.13
        for <common-user@hadoop.apache.org>; Sun, 16 Aug 2009 09:47:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=e3vhpTBjVDR9oQhoZNHrd9qdgVH9XiUaWA0gEHWRPws=;
        b=IRQvHvF9MelvhZRxxmm7V1sZRgDDqH/do41HY6kBibvu21EByR3Zdlh24WKosDRgfX
         jt435QMS3COwPvMolAKqOeUwSWFRHbPNApdVFAYGIwyrIcgwx2K1+gnbCEsgXDt05zsD
         qQzt12uD5HChXU7bSvY5ge7DnwQTA875w0va8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=gJhjE39RjQz4L/92VycM0rynv8ZvWSn2DjuBi4v/K6+rkDY4x6vxr/LU+JZoilt7Bo
         ReRME2wA5zk8yzaIJMUDFvjAhlntKHoLrCjj925BNB7TEyxfUQR08jEUJLtJPptoU/94
         XqHXBJUE6Vorf6rnJpJ8zmHJyspf9YVKwX6nM=
MIME-Version: 1.0
Received: by 10.223.121.208 with SMTP id i16mr746200far.32.1250441224630; Sun, 
	16 Aug 2009 09:47:04 -0700 (PDT)
In-Reply-To: <cbbf4b570908160848o7c0b9875g641a627e97a680d5@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <cbbf4b570908120736w46698a49ka209bd85430480ff@mail.gmail.com>
	 <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>
	 <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
	 <fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>
	 <45f85f70908132221v449ec8b3s93a9baf530952383@mail.gmail.com>
	 <fa561940908132225v784b6b42oa152d99c3a2b0590@mail.gmail.com>
	 <4a6f63fa0908141355o4c20eb6n926b348262e5aec8@mail.gmail.com>
	 <fa561940908160450g4fb04ed7m26e83025e8e0081c@mail.gmail.com>
	 <cbbf4b570908160848o7c0b9875g641a627e97a680d5@mail.gmail.com>
Date: Mon, 17 Aug 2009 01:47:04 +0900
Message-ID: <fa561940908160947w6c0a72d5w241c9e52732f98d6@mail.gmail.com>
Subject: Re: What OS?
From: "Bogdan M. Maryniuk" <bogdan.maryniuk@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

On Mon, Aug 17, 2009 at 12:48 AM, Edward Capriolo<edlinuxguru@gmail.com> wrote:
> My quick fix was to turn off compression. I am probably the ONLY
> person on the internet trying to do this.

Well, yes... Because why do the hell you need that FreeBSD thing with
outdated and nearly unusable ZFS (although they claim they fixed
anyhow v13 recently on dev 8.0 and it does not crashes that miserably
as before) and bad Java, if there is OpenSolaris? Same to GlassFish:
branch for FreeBSD never touched two years, AFAIK...

IMO, FreeBSD thing is only good for a routers due to TCP/IP stack
(although recent changes in OpenSolaris and a Crossbow project says
also really a lot), but for what else?..

P.S. FUSE: it is userland. Thus DFS + FUSE = FUBAR. :-)

-- 
Kind regards, BM

Things, that are stupid at the beginning, rarely ends up wisely.

From common-user-return-16788-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 00:01:41 2009
Return-Path: <common-user-return-16788-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 31913 invoked from network); 17 Aug 2009 00:01:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 00:01:40 -0000
Received: (qmail 78959 invoked by uid 500); 17 Aug 2009 00:01:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 78895 invoked by uid 500); 17 Aug 2009 00:01:44 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 78885 invoked by uid 99); 17 Aug 2009 00:01:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 00:01:44 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of edlinuxguru@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 00:01:36 +0000
Received: by fxm17 with SMTP id 17so2533877fxm.13
        for <common-user@hadoop.apache.org>; Sun, 16 Aug 2009 17:01:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=uU6GwUJTlBYB4VBKQUZgTnpe6N94B6qS22PfhyZL3mc=;
        b=aE0ZkzkWq9JBwF1VV6F8mhTzrz/LzL2e9Wv/xcXlFdRWCV5IgPfYtQKOhpstYdw6Lo
         4xszCtX6mBqi3POYnPNn3LmDhvv4l+UkKhqnEoEmNaYdlXqGyTwFXAkXA6VUyC25j6Qa
         qVpWxdSMwUWAU36CRK32aqV1xxlKX2f6TdT2s=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=SB5A7+NhbMt5sSO+U2+O/6g2d5lScKjvbAD4DNk3d1iIlJLnuVlhXHKtqXnvk7mlyF
         ZZbUyk+YBxoeVsQU5ndqH9aMA5QnNaAyH6uRHcz3E4N/uO0ZXF+tLLjn+QY9wQ4pE0p7
         Ts3ByyRyOTQud9mIqhU1oFnOjrjSJFGSDuIk4=
MIME-Version: 1.0
Received: by 10.239.184.148 with SMTP id y20mr252682hbg.61.1250467275460; Sun, 
	16 Aug 2009 17:01:15 -0700 (PDT)
In-Reply-To: <fa561940908160947w6c0a72d5w241c9e52732f98d6@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>
	 <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
	 <fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>
	 <45f85f70908132221v449ec8b3s93a9baf530952383@mail.gmail.com>
	 <fa561940908132225v784b6b42oa152d99c3a2b0590@mail.gmail.com>
	 <4a6f63fa0908141355o4c20eb6n926b348262e5aec8@mail.gmail.com>
	 <fa561940908160450g4fb04ed7m26e83025e8e0081c@mail.gmail.com>
	 <cbbf4b570908160848o7c0b9875g641a627e97a680d5@mail.gmail.com>
	 <fa561940908160947w6c0a72d5w241c9e52732f98d6@mail.gmail.com>
Date: Sun, 16 Aug 2009 20:01:15 -0400
Message-ID: <cbbf4b570908161701x412c19bcq57e770470438f09b@mail.gmail.com>
Subject: Re: What OS?
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

while I completely agree with you about freebsd, that is not the point
I was driving at. Linux is the main target platform.you chose another
platform you have more work for yourself.if you have a problem like
the one I had, probably no one else has the same environment as you so
replicating your issue could be difficult.


On 8/16/09, Bogdan M. Maryniuk <bogdan.maryniuk@gmail.com> wrote:
> On Mon, Aug 17, 2009 at 12:48 AM, Edward Capriolo<edlinuxguru@gmail.com>
> wrote:
>> My quick fix was to turn off compression. I am probably the ONLY
>> person on the internet trying to do this.
>
> Well, yes... Because why do the hell you need that FreeBSD thing with
> outdated and nearly unusable ZFS (although they claim they fixed
> anyhow v13 recently on dev 8.0 and it does not crashes that miserably
> as before) and bad Java, if there is OpenSolaris? Same to GlassFish:
> branch for FreeBSD never touched two years, AFAIK...
>
> IMO, FreeBSD thing is only good for a routers due to TCP/IP stack
> (although recent changes in OpenSolaris and a Crossbow project says
> also really a lot), but for what else?..
>
> P.S. FUSE: it is userland. Thus DFS + FUSE = FUBAR. :-)
>
> --
> Kind regards, BM
>
> Things, that are stupid at the beginning, rarely ends up wisely.
>

From common-user-return-16789-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 01:21:05 2009
Return-Path: <common-user-return-16789-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 58416 invoked from network); 17 Aug 2009 01:21:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 01:21:05 -0000
Received: (qmail 19113 invoked by uid 500); 17 Aug 2009 01:21:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 19009 invoked by uid 500); 17 Aug 2009 01:21:09 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 18999 invoked by uid 99); 17 Aug 2009 01:21:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 01:21:09 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bogdan.maryniuk@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 01:21:01 +0000
Received: by fxm17 with SMTP id 17so2550591fxm.13
        for <common-user@hadoop.apache.org>; Sun, 16 Aug 2009 18:20:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=MkYtVitGlDLIfrGdwXznozwneYo86RTt6v3TKG143Ls=;
        b=e3intSaagDibSnWyzj/b3Ed73SvrfKNlN0LqCk+FAAwNuHdTGOUBNFw/4L950N6z+y
         29OMwBA/9eLX+M9OFm7QjI7SAfuKjgehkXH2YdTXUPaE/lqZZ/zjtE4gp5RxFnM0HnAM
         WlQ1q8hg0yAVjzOnnN8Rv9jN74Xorh7kk22RI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=j1IyD41GgsllAXrDnextiiiCwmd7m2crNJVZcIeRPUf5kBuKsYhXvx6KQlmkBdOWtq
         Da933o8d0kVDup3PfU/+R2DoJZl8UriiKWfELcuwH+DYsQVDkoGvrLnPt1vWafl47wNn
         MuUOTT6TcrFZ1uTyuFGoFyfn62UorZP7xAWLg=
MIME-Version: 1.0
Received: by 10.223.144.210 with SMTP id a18mr783371fav.35.1250472039703; Sun, 
	16 Aug 2009 18:20:39 -0700 (PDT)
In-Reply-To: <cbbf4b570908161701x412c19bcq57e770470438f09b@mail.gmail.com>
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>
	 <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>
	 <fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>
	 <45f85f70908132221v449ec8b3s93a9baf530952383@mail.gmail.com>
	 <fa561940908132225v784b6b42oa152d99c3a2b0590@mail.gmail.com>
	 <4a6f63fa0908141355o4c20eb6n926b348262e5aec8@mail.gmail.com>
	 <fa561940908160450g4fb04ed7m26e83025e8e0081c@mail.gmail.com>
	 <cbbf4b570908160848o7c0b9875g641a627e97a680d5@mail.gmail.com>
	 <fa561940908160947w6c0a72d5w241c9e52732f98d6@mail.gmail.com>
	 <cbbf4b570908161701x412c19bcq57e770470438f09b@mail.gmail.com>
Date: Mon, 17 Aug 2009 10:20:39 +0900
Message-ID: <fa561940908161820w7cd407a0t599d44e0a198bf54@mail.gmail.com>
Subject: Re: What OS?
From: "Bogdan M. Maryniuk" <bogdan.maryniuk@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

On Mon, Aug 17, 2009 at 9:01 AM, Edward Capriolo<edlinuxguru@gmail.com> wrote:
> Linux is the main target platform.you chose another
> platform you have more work for yourself.

Well, in some cases yes, as long as you have JNI... :-( That's why Sun
discourage people to use it and wants things done in a plain Java.
However, it is not always possible (e.g. FUSE).

> if you have a problem like
> the one I had, probably no one else has the same environment as you so
> replicating your issue could be difficult.

Agreed here. However, I don't know what is bigger evil: to ditch some
questionable features (FUSE, for example) or trembling that %$#@ ext3
just died again?

-- 
Kind regards, BM

Things, that are stupid at the beginning, rarely ends up wisely.

From common-user-return-16790-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 06:36:27 2009
Return-Path: <common-user-return-16790-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75586 invoked from network); 17 Aug 2009 06:36:27 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 06:36:27 -0000
Received: (qmail 65519 invoked by uid 500); 17 Aug 2009 06:36:31 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 65427 invoked by uid 500); 17 Aug 2009 06:36:31 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 65417 invoked by uid 99); 17 Aug 2009 06:36:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 06:36:31 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 06:36:23 +0000
Received: by ywh36 with SMTP id 36so4195391ywh.31
        for <common-user@hadoop.apache.org>; Sun, 16 Aug 2009 23:36:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=g1M2ZRHvueFtdfWymbK4nhBk/KRNR1hCpNBQPlnBBJY=;
        b=G3VOdYLawDrQYnjcUZmuoAlx1AnbuOg3CHCjbR/yQm8ptrNUy/8ns+OY+UXmaOOFDC
         36VDCiFc3pZXgFW6JgDsEblRYya6szI8q9jAu1xio0OWVOVpt0WkX3GEM6M90xiZFNB8
         C85+UlsAGgCvNlQdMRBo9oA1xLqnWmfa1x2fo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=GD5UftT3Sp72jqNZwY9d2UcY+OEqVcIX2ENJ07Ir0HpT4Yw7M9y9MAqqeUYz2RBhie
         wlqP2KBwd+tHBxJJOOw2M+c3RiXqZdzaXvlFCBMmlccAcFmt/R0bGiS+dNEt5DljIq9W
         AhQoJOqfyPi1/vBda4lPXDb47Gytlux7ssaL0=
MIME-Version: 1.0
Received: by 10.100.252.9 with SMTP id z9mr2971740anh.34.1250490962253; Sun, 
	16 Aug 2009 23:36:02 -0700 (PDT)
Date: Mon, 17 Aug 2009 14:36:02 +0800
Message-ID: <3b1311780908162336q7bcd8da6na1999982ed83aa7e@mail.gmail.com>
Subject: Why the jobs are suspended when I add new nodes?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016369fa35e9999fe0471509d1b
X-Virus-Checked: Checked by ClamAV on apache.org

--0016369fa35e9999fe0471509d1b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi, all
    When I add another 50 nodes into the current cluster(200 nodes) at the
same time, the jobs run very smoothly at first. However, after a while, all
the jobs are suspended and never continue.
    I have no idea but to remove the new nodes. And the jobs run smoothly
again. Now I have to add nodes one by one. I won't add second node until the
jobs run smoothly after adding first node.
    Have you ever encountered the same situation? Could you give me some
tips and notes?
    Thank you!
    Inifok

--0016369fa35e9999fe0471509d1b--

From common-user-return-16791-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 06:53:15 2009
Return-Path: <common-user-return-16791-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81552 invoked from network); 17 Aug 2009 06:53:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 06:53:14 -0000
Received: (qmail 80306 invoked by uid 500); 17 Aug 2009 06:53:19 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80209 invoked by uid 500); 17 Aug 2009 06:53:18 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 80199 invoked by uid 500); 17 Aug 2009 06:53:18 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 80196 invoked by uid 99); 17 Aug 2009 06:53:18 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 06:53:18 +0000
X-ASF-Spam-Status: No, hits=1.1 required=10.0
	tests=FORGED_HOTMAIL_RCVD2,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 06:53:10 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1Mcw5J-00016R-FH
	for core-user@hadoop.apache.org; Sun, 16 Aug 2009 23:52:49 -0700
Message-ID: <25001925.post@talk.nabble.com>
Date: Sun, 16 Aug 2009 23:52:49 -0700 (PDT)
From: hotangs <hotangs1221@hotmail.com>
To: core-user@hadoop.apache.org
Subject: Chukwa agent and collector error
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: hotangs1221@hotmail.com
X-Virus-Checked: Checked by ClamAV on apache.org


May i post question, this forum?

My cluster consisted hadoop-0.18.3, chukwa-0.1.2 and java-6-sun-1.6.0.14.

I don't know this chukwa start error message.

CMD : chukwa/bin/start-all.sh

All agent occur this message.

 /home/pccs/hadoop/chukwa/bin/../bin/agent.sh: 24: function: not found
PCCS03: Shutting down agent.../home/pccs/hadoop/chukwa/bin/../bin/agent.sh:
27: Syntax error: Bad fd number

and collector occur this message.

PCCSMASTER: /home/pccs/hadoop/chukwa/bin/../bin/jettyCollector.sh: 24:
function: not found
PCCSMASTER: Shutting down
Collector.../home/pccs/hadoop/chukwa/bin/../bin/jettyCollector.sh: 26:
Syntax error: Bad fd number


I need your help. thanks.
-- 
View this message in context: http://www.nabble.com/Chukwa-agent-and-collector-error-tp25001925p25001925.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-16792-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 08:00:50 2009
Return-Path: <common-user-return-16792-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 9353 invoked from network); 17 Aug 2009 08:00:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 08:00:50 -0000
Received: (qmail 39323 invoked by uid 500); 17 Aug 2009 08:00:54 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 39238 invoked by uid 500); 17 Aug 2009 08:00:54 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 39228 invoked by uid 99); 17 Aug 2009 08:00:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 08:00:54 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 08:00:45 +0000
Received: by gxk27 with SMTP id 27so3594306gxk.12
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 01:00:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=JS7Wp2eReBI+rh9muotNbulozz6WLBlBgTrpvhiw3qg=;
        b=iE7PFMeNbMbWuo8A1pTASPr7U38eUKxYO40rDx7ur4TRyCWD49Z5Fh4CbnsY1Bz4o+
         NffV3Dd76nNukcQtjKGtMPpkpds7G8+VkI1ihMOUD0GFWgZz9FnwI4OHgKa1xjdAjQBD
         TG7xlBwr6B56VDTYQzFEL0InHx/RTyw3P/oaQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=otYNTHjTMZl+ISXmhiXU77B1e745ZWY8vA6mg6vC5hJHea2MkjNC2tNOpYU4Vh023W
         KaZSefMUD8wMgg6a6mHYKLoZv2F6B0BOR+buFMP4DbuFnD8jPXIRNLyN2sDNIrKme9Xt
         z7TSlWHtYb+lGFgMtWi82oCnJV4wxlR+JU7DE=
MIME-Version: 1.0
Received: by 10.150.238.18 with SMTP id l18mr5037181ybh.14.1250496024085; Mon, 
	17 Aug 2009 01:00:24 -0700 (PDT)
In-Reply-To: <3b1311780908162336q7bcd8da6na1999982ed83aa7e@mail.gmail.com>
References: <3b1311780908162336q7bcd8da6na1999982ed83aa7e@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Mon, 17 Aug 2009 01:00:04 -0700
Message-ID: <c7d45fc70908170100t2124f221hddff79872c6809ce@mail.gmail.com>
Subject: Re: Why the jobs are suspended when I add new nodes?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd3585a4f063c047151cb2c
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd3585a4f063c047151cb2c
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Have you looked at the logs?

On Sun, Aug 16, 2009 at 11:36 PM, yang song <hadoop.inifok@gmail.com> wrote:

> Hi, all
>    When I add another 50 nodes into the current cluster(200 nodes) at the
> same time, the jobs run very smoothly at first. However, after a while, all
> the jobs are suspended and never continue.
>
>

--000e0cd3585a4f063c047151cb2c--

From common-user-return-16793-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 08:30:20 2009
Return-Path: <common-user-return-16793-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 22429 invoked from network); 17 Aug 2009 08:30:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 08:30:19 -0000
Received: (qmail 85365 invoked by uid 500); 17 Aug 2009 08:30:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 85261 invoked by uid 500); 17 Aug 2009 08:30:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 85250 invoked by uid 99); 17 Aug 2009 08:30:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 08:30:24 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of clarkemjj@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 08:30:15 +0000
Received: by bwz19 with SMTP id 19so3003542bwz.37
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 01:29:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=uK4bFv70ikTeqWrxUb07cd+zDwTyw/jKkB9jE8fr6Zo=;
        b=lYXyZ955eYqCdC23smJDZ4x87YytuOH7lEKSVeK30Ex9v73pZDBksIiCoVlgEU2S2V
         A1SMavDne+6jptGNvC4dAVvSf++qHaZwU32VgPcbdLB1BOZ2Wx3/YxcBvyljQ2EqwFZJ
         vQ+iSD1QRrYLBWG30wsVxsNwRMS4uQ4iQv/Fw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=Fww93f5Um7LS7qV2jzMWS2TtjVgmNqvJPyCoBOIuRAy1qhUKxyyTrsiDr/xshcO5sn
         1iF/e2IFbDKPeITElDWtVSNA7QRLzIn9iUInl2LLH4ynIgqMLPd7bFko9UqYveyELC7f
         OQg5AcpnVssZ5x4/6uJdMc5xPOjnfs3cNm0O0=
MIME-Version: 1.0
Received: by 10.223.144.201 with SMTP id a9mr831623fav.17.1250497793302; Mon, 
	17 Aug 2009 01:29:53 -0700 (PDT)
In-Reply-To: <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>
	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>
Date: Mon, 17 Aug 2009 09:29:53 +0100
Message-ID: <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>
Subject: Re: Two output files?
From: John Clarke <clarkemjj@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0023545bd814c3212b047152345f
X-Virus-Checked: Checked by ClamAV on apache.org

--0023545bd814c3212b047152345f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Fantastic, I will try that :) A little push in the right driection helps
hugely! I don't have that book yet but I'm planning on getting it.

cheers
John,



2009/8/14 Kris Jirapinyo <kris.jirapinyo@biz360.com>

> Hi John,
>     If you have the Hadoop O'Reilly book, look at pg 206 for an example.
> But basically, you just create a subclass of MultipleTextOutputFormat and
> then inside it you override generateFileNameForKeyValue (for example) to
> have the reducer emit the desired filenames.  For each key in the reducer,
> it will write the text values to that file.  Make sure in the JobConf you
> set OutputFormat to your class that extends MultipleTextOutputFormat.
>
> -- Kris.
>
> On Fri, Aug 14, 2009 at 7:11 AM, John Clarke <clarkemjj@gmail.com> wrote:
>
> > Hi,
> >
> > I want to output two text files from my MapReduce job but I am having
> > trouble understanding how to use the MultipleTextOutputFormat class to do
> > so.
> >
> > I want to write to the two files depending on the key of each key/value
> > pair.
> >
> > In the Reducer how do I tell it to write the different files? Normally I
> > just do an output.collect(key, val);.
> >
> > Any help would be most appreciated.
> >
> > Thanks,
> > John
> >
>

--0023545bd814c3212b047152345f--

From common-user-return-16794-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 09:59:07 2009
Return-Path: <common-user-return-16794-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 82489 invoked from network); 17 Aug 2009 09:59:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 09:59:06 -0000
Received: (qmail 15317 invoked by uid 500); 17 Aug 2009 09:59:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 15231 invoked by uid 500); 17 Aug 2009 09:59:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 15221 invoked by uid 99); 17 Aug 2009 09:59:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 09:59:10 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [192.6.10.2] (HELO colossus.hpl.hp.com) (192.6.10.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 09:58:58 +0000
Received: from localhost (localhost [127.0.0.1])
	by colossus.hpl.hp.com (Postfix) with ESMTP id ACF3F1BA339
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:58:36 +0100 (BST)
X-Virus-Scanned: Debian amavisd-new at hpl.hp.com
Received: from colossus.hpl.hp.com ([127.0.0.1])
	by localhost (colossus.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id Y50qOiKnY78i for <common-user@hadoop.apache.org>;
	Mon, 17 Aug 2009 10:58:35 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by colossus.hpl.hp.com (Postfix) with ESMTPS id 9DAF31BA316
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:58:35 +0100 (BST)
MailScanner-NULL-Check: 1251107903.54964@R9bgM1rRjCUYohtutd/+FQ
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7H9wMak002660
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:58:22 +0100 (BST)
Message-ID: <4A8929BE.4000009@apache.org>
Date: Mon, 17 Aug 2009 10:58:22 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: HADOOP-4539 question
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com> 	<4A7BECD9.20303@apache.org> <77938bc20908071329h33574722ua9c9ac56871a7fe8@mail.gmail.com> 	<4A814BCD.2060500@apache.org> <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com> 	<77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com> 	<45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com> 	<4A8312C5.9080307@yahoo-inc.com> <45f85f70908121227o679f4887l9ec1c053270af40a@mail.gmail.com> <4A832601.1030001@yahoo-inc.com> <4A841C86.3090605@apache.org> <4A844F50.8010407@yahoo-inc.com>
In-Reply-To: <4A844F50.8010407@yahoo-inc.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7H9wMak002660
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

Konstantin Shvachko wrote:
> Steve,
> 
> There are other groups claimed they work on HA solution.
> We had discussions about it not so long ago in this list.
> Is it possible that your colleagues present their design?
> As you point out the issue gets fairly complex fast,
> particularly because of the split-brain problem you describe.

Konstantin, if we had an HA HDFS, you'd know about it, not least because 
I'd be trying to get it checked in.

I was just describing the general datacentre partitioning problem that 
crops up in all HA databases.

> 
> There are several jiras dedicated to the problem already.
> You can post your design there or create a new one.
> 
>  > Looking at the facebook/google "multi-master" solution, I think they
>  > don't worry about consistency, just let the masters drift apart.
> 
> Not sure I follow this.
> What facebook/google "multi-master" solution?

Johan mentions it : http://www.slideshare.net/steve_l/hdfs


> Why would they not worry about consistency?
> Consistency of what?#

imagine you have >1 NN, each with a view of the world as reported by the 
DNs, the map of where blocks live. If you dont do failover, but maintain 
separate directory structures in each NN, then you can have the two NN's 
indices diverge, without worrying about reconciling them later.

-steve

From common-user-return-16795-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 10:07:13 2009
Return-Path: <common-user-return-16795-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 87427 invoked from network); 17 Aug 2009 10:07:13 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 10:07:13 -0000
Received: (qmail 26604 invoked by uid 500); 17 Aug 2009 10:07:17 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26523 invoked by uid 500); 17 Aug 2009 10:07:17 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 26513 invoked by uid 99); 17 Aug 2009 10:07:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 10:07:17 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [192.6.10.60] (HELO tobor.hpl.hp.com) (192.6.10.60)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 10:07:07 +0000
Received: from localhost (localhost [127.0.0.1])
	by tobor.hpl.hp.com (Postfix) with ESMTP id AEFD4B7CCF
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 11:06:45 +0100 (BST)
X-Virus-Scanned: amavisd-new at hplb.hpl.hp.com
Received: from tobor.hpl.hp.com ([127.0.0.1])
	by localhost (tobor.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id 29UT1KYrrkc1 for <common-user@hadoop.apache.org>;
	Mon, 17 Aug 2009 11:06:39 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by tobor.hpl.hp.com (Postfix) with ESMTPS id F08C7B7CCB
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 11:06:38 +0100 (BST)
MailScanner-NULL-Check: 1251108386.82186@PjFc9EIwjOTsd620qs0j/A
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7HA6PRg003059
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 11:06:26 +0100 (BST)
Message-ID: <4A892BA1.9080409@apache.org>
Date: Mon, 17 Aug 2009 11:06:25 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: What OS?
References: <32120a6a0908120405u21486944x8545894c925e8f64@mail.gmail.com>	 <32120a6a0908120745l2c5be688j95f32d35b589f98c@mail.gmail.com>	 <314098690908132027x61ce179dwa3f2f9244c2f7960@mail.gmail.com>	 <fa561940908132058t342ec027qd8234fac0fb384f3@mail.gmail.com>	 <45f85f70908132221v449ec8b3s93a9baf530952383@mail.gmail.com>	 <fa561940908132225v784b6b42oa152d99c3a2b0590@mail.gmail.com>	 <4a6f63fa0908141355o4c20eb6n926b348262e5aec8@mail.gmail.com>	 <fa561940908160450g4fb04ed7m26e83025e8e0081c@mail.gmail.com>	 <cbbf4b570908160848o7c0b9875g641a627e97a680d5@mail.gmail.com>	 <fa561940908160947w6c0a72d5w241c9e52732f98d6@mail.gmail.com> <cbbf4b570908161701x412c19bcq57e770470438f09b@mail.gmail.com>
In-Reply-To: <cbbf4b570908161701x412c19bcq57e770470438f09b@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7HA6PRg003059
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

Edward Capriolo wrote:
> while I completely agree with you about freebsd, that is not the point
> I was driving at. Linux is the main target platform.you chose another
> platform you have more work for yourself.if you have a problem like
> the one I had, probably no one else has the same environment as you so
> replicating your issue could be difficult.


I agree, but would note that even on linux you can encounter fun, such as
* JRockit vs Sun JVM problems
* DNS quirks due to where your cluster lives
* timezone isses (not seen this in hadoop, but I have in Axis 1, where 
something didnt work when local TZ== GMT)
* OS locale issues (common in turkish locales, as "I".toLower()!="i") there)
..etc. Your cluster is different from everyone elses

Yet by encountering those problems, and tracking down and fixing them 
yourself, and getting those patches back in, life will be easier for the 
people who follow you.

Therefore I say: go out and explore, but expect that the further you 
deviate from the "approved" solution: single locked down Linux cluster 
with well-managed DNS, rDNS, NTP, running Sun java6, the more obscure 
the problems that surface will be, and the more the codebase will 
benefit from your experiences, provided you push your patches back,


-steve

From common-user-return-16796-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 13:16:21 2009
Return-Path: <common-user-return-16796-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 99239 invoked from network); 17 Aug 2009 13:16:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 13:16:21 -0000
Received: (qmail 4698 invoked by uid 500); 17 Aug 2009 13:16:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 4616 invoked by uid 500); 17 Aug 2009 13:16:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 4606 invoked by uid 99); 17 Aug 2009 13:16:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 13:16:21 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of edlinuxguru@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 13:16:12 +0000
Received: by fxm17 with SMTP id 17so2810900fxm.13
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 06:15:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=fCrlkk5JgwIMZXbyLXDmlioqAcztXWdScoDAoBdsZsE=;
        b=kqFxRSb+ilN9iTMRuFpWnYMT2HnaCmA3Y4ua2bdoumSPOMBf65rrZhcZUBF+6kKy9B
         /o/YA2qlbC6YGfQ/Iip5eMN4XFArp7vj8KseG8O3JAb5USbTJ6iKeDNq/BD62auxiMbz
         GR5xeAD1d//Bsa+9XOVXChj7Z1vHusGdn6Bf4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=VCQe/4FPQUFQGFaOIxiBckZ5RWLjUMGwGrj6VRwg/gTFfOmL2LIsc9gd7i++/odq/Z
         wZhcUCTxlDz2kUu2XkUnTd+A1yY/adBDfn22XB856dY4elsnifGmXjzY81eUC1Ire+Fe
         Dcupmx9DQzPqasNNdDraOMDNNOmThxmWCjyxE=
MIME-Version: 1.0
Received: by 10.239.145.136 with SMTP id s8mr293545hba.46.1250514951867; Mon, 
	17 Aug 2009 06:15:51 -0700 (PDT)
In-Reply-To: <4A845146.8030806@yahoo-inc.com>
References: <77938bc20908061046g4a802304y759eec04e0a111bb@mail.gmail.com>
	 <4A814BCD.2060500@apache.org>
	 <45f85f70908111042h61d0fd10ga3ee1cb882977964@mail.gmail.com>
	 <77938bc20908120342q63fc6d65t52525e367af37018@mail.gmail.com>
	 <45f85f70908120821w71912e4at349320603b00c757@mail.gmail.com>
	 <4A8312C5.9080307@yahoo-inc.com>
	 <45f85f70908121227o679f4887l9ec1c053270af40a@mail.gmail.com>
	 <4A832601.1030001@yahoo-inc.com>
	 <77938bc20908130355s27217f24x84446110b16c63ee@mail.gmail.com>
	 <4A845146.8030806@yahoo-inc.com>
Date: Mon, 17 Aug 2009 09:15:51 -0400
Message-ID: <cbbf4b570908170615u602c6ca9hf48cbe3a01607e48@mail.gmail.com>
Subject: Re: HADOOP-4539 question
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

There are some native ha like solutions that feature clustering
electing a dc and messaging. Check out shoal. I tinkered with build a
linux ha like kit over shoal.

On 8/13/09, Konstantin Shvachko <shv@yahoo-inc.com> wrote:
> There is no "native" HA solution for HDFS at the moment.
> "External" HA solutions, like Coudera's may exist.
> Cannot speak for everybody, but I know at least one different approach.
>
> --Konstantin
>
> Stas Oskin wrote:
>> Hi.
>>
>>> This is exactly the goal (long term). To evolve BN into StandbyNode,
>>> which will be able to take over when main NN dies without restarting
>>> anything else.
>>> And the only remaining step is to implement fail-over mechanism.
>>>
>>>
>>
>> Just to clarify, for the near future, the only HA option is Cloudera  DRDB
>> approach.
>>
>> Correct?
>>
>

From common-user-return-16797-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 13:56:40 2009
Return-Path: <common-user-return-16797-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 25192 invoked from network); 17 Aug 2009 13:56:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 13:56:40 -0000
Received: (qmail 73147 invoked by uid 500); 17 Aug 2009 13:56:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 73092 invoked by uid 500); 17 Aug 2009 13:56:44 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 73082 invoked by uid 99); 17 Aug 2009 13:56:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 13:56:44 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 13:56:36 +0000
Received: by yxe15 with SMTP id 15so3965015yxe.5
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 06:56:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=3oOpTzP0raOboe3gNUDKbSswPYbqCRlqwj51xLGQMMQ=;
        b=jZxLbJPke0OyTjRsoW+LRUILwvaXEWC7diUZ5TpvLazSl9E/pQAoDoCq970CLY5KCx
         fco0qnRmFA9WmhhGi21REnRPjnmwgNS2qrO3MXqetPrj01V9ENyDRn/Hjm5FvUUNeesn
         M1/+o+x5mDoDgxOYf3AYUuMizbhleQ7gJZyIM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=JESKpmTotgphIzoqEBizY7LI3tEh+1xs1h/85pZXEMDnZG1/wAH7XEVNz6IAfOOWKE
         GfF5t8YlDrNDOhbBEibfLNZzr5v6DtGf3c6Gw3MMKT1yzmcIc0FNbSN3lddBW2JPcHoy
         dyz+hHl1cIykcMzLoGlBUOnX+Ccmxu+eY5l8c=
MIME-Version: 1.0
Received: by 10.100.246.14 with SMTP id t14mr3383953anh.176.1250517374805; 
	Mon, 17 Aug 2009 06:56:14 -0700 (PDT)
In-Reply-To: <c7d45fc70908170100t2124f221hddff79872c6809ce@mail.gmail.com>
References: <3b1311780908162336q7bcd8da6na1999982ed83aa7e@mail.gmail.com>
	 <c7d45fc70908170100t2124f221hddff79872c6809ce@mail.gmail.com>
Date: Mon, 17 Aug 2009 21:56:14 +0800
Message-ID: <3b1311780908170656k34a84c92ye057f49eb1aeaff3@mail.gmail.com>
Subject: Re: Why the jobs are suspended when I add new nodes?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e68dec47e928b0047156c30a
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e68dec47e928b0047156c30a
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

The situation is I can't find any unusual thing from the logs.
Maybe there is a lot of data to transfer since so many new nodes and the
jobs are waiting for it

2009/8/17 Ted Dunning <ted.dunning@gmail.com>

> Have you looked at the logs?
>
> On Sun, Aug 16, 2009 at 11:36 PM, yang song <hadoop.inifok@gmail.com>
> wrote:
>
> > Hi, all
> >    When I add another 50 nodes into the current cluster(200 nodes) at the
> > same time, the jobs run very smoothly at first. However, after a while,
> all
> > the jobs are suspended and never continue.
> >
> >
>

--0016e68dec47e928b0047156c30a--

From common-user-return-16798-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 14:10:55 2009
Return-Path: <common-user-return-16798-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 33851 invoked from network); 17 Aug 2009 14:10:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 14:10:55 -0000
Received: (qmail 1842 invoked by uid 500); 17 Aug 2009 14:10:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 1763 invoked by uid 500); 17 Aug 2009 14:10:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 1753 invoked by uid 99); 17 Aug 2009 14:10:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 14:10:59 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mathias.demare@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 14:10:49 +0000
Received: by fxm17 with SMTP id 17so2848175fxm.13
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 07:10:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:from:date:message-id:subject:to:cc:content-type;
        bh=FASDqU6X50TF/yKsdxjKL8zqEGAf55GTSDaS8C+GltU=;
        b=e+HrkWR4BQa+J9R/lgshT+bry1ErJ5lM+gbxJgVMYifBfjAYcGhItuGbB2ypgtwzgC
         6O/SRmSnktXqUR7/R5RhrdxFnTsS0Q/1Oe6awRY+Z2+gQviKIJ6NwplGaeHbxf0ijDL/
         64pRVd/ORNvV1WNVyLeNIpojF9tgDcA7i5SqU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        b=IcyOouRdLrw6nogwCnJrx7C68nvWoadrrxev+6Yyun1YFOEU8ObXlPrtZ/Z7wtP+zf
         fz3V6+pKDljhuhUW3UPHezq5Uc2i2aIp9NSN3EgM/4anQ7dtf/OOCA2KTPjkwn7vA1Mo
         g5wn4U2qXyfq5MwRs9L+OBo3u+7a/tkwi7yoU=
MIME-Version: 1.0
Received: by 10.204.151.83 with SMTP id b19mr2701799bkw.102.1250518229117; 
	Mon, 17 Aug 2009 07:10:29 -0700 (PDT)
Reply-To: mathias.demare@gmail.com
In-Reply-To: <375c60f40908120039n2f2eb88ekbefc62b1335410ed@mail.gmail.com>
References: <375c60f40908090218i364a5596hbbd3c42a626882f7@mail.gmail.com> 
	<C6A58EE1.150E2%knoguchi@yahoo-inc.com> <375c60f40908120039n2f2eb88ekbefc62b1335410ed@mail.gmail.com>
From: =?UTF-8?Q?Mathias_De_Mar=C3=A9?= <mathias.demare@gmail.com>
Date: Mon, 17 Aug 2009 16:10:09 +0200
Message-ID: <375c60f40908170710r6f0cd1d7o75039f6591d0ef8c@mail.gmail.com>
Subject: Re: Some tasks fail to report status between the end of the map and 
	the beginning of the merge
To: Koji Noguchi <knoguchi@yahoo-inc.com>
Cc: common-user@hadoop.apache.org, Amogh Vasekar <amogh@yahoo-inc.com>
Content-Type: multipart/alternative; boundary=0015175cad8cd4ecea047156f681
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175cad8cd4ecea047156f681
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

2009/8/12 Mathias De Mar=C3=A9 <mathias.demare@gmail.com>

> Thank you, that's very useful.
> In addition, I changed the way the tasks work, so they store their data i=
n
> HBase now (since it's more suited for handling small files).
> I'm not 100% sure yet if the problems have been resolved (still doing
> extensive testing), but I think I might have gotten rid of them (and I'll
> add the 'skipping records' option in case I do get a failure).
>


Hi,

I can get everything to 'run' successfully now, but there are still some
tasks that crash.

I was thinking perhaps my Writable class is the issue, so I'll just post it
here. Does anyone notice anything that could cause a hang? In particular th=
e
readFields and write methods could perhaps be the reason (but I just don't
see it).

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;
import org.apache.hadoop.io.ArrayWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.io.WritableComparable;

/**
 * Contains information on a URL, which other URLs link to it and if it has
been crawled previously.
 * @author mathias
 */
public class URLInfo implements Writable, WritableComparable {
    String url;
    Text[] linkedfrom;
    int urlStatus;
    int seconds;

    public URLInfo() {
        url =3D "";
        linkedfrom =3D new Text[0];
        urlStatus =3D Constants.URL_NEW;
        seconds =3D 1;
    }

    /**
     *
     * @param url
     * @param linkedfrom Must only contains domain names, nothing appended
     * @param urlStatus
     */
    public URLInfo(String url, Text[] linkedfrom, int urlStatus, int
seconds) {
        this.url =3D url;
        this.linkedfrom =3D linkedfrom;
        this.urlStatus =3D urlStatus;
        this.seconds =3D seconds;
    }

    public void write(DataOutput out) throws IOException {
        new Text(url).write(out);
        new ArrayWritable(Text.class, linkedfrom).write(out);
        new IntWritable(urlStatus).write(out);
        new IntWritable(seconds).write(out);
    }

    public void readFields(DataInput in) throws IOException {
        url =3D Text.readString(in);
        ArrayWritable aw =3D new ArrayWritable(Text.class);
        aw.readFields(in);
        Writable[] linkedfromWritable =3D aw.get();
        linkedfrom =3D new Text[linkedfromWritable.length];
        for(int i=3D0; i<linkedfromWritable.length; i++) {
            linkedfrom[i] =3D (Text) linkedfromWritable[i];
        }
        IntWritable iw =3D new IntWritable();
        iw.readFields(in);
        urlStatus =3D iw.get();
        IntWritable iw2 =3D new IntWritable();
        iw2.readFields(in);
        seconds =3D iw2.get();
    }

    public int compareTo(Object o) {
        return url.compareToIgnoreCase(((URLInfo) o).url);
    }

    public void setURLStatus(int urlStatus) {
        this.urlStatus =3D urlStatus;
    }

    public int getURLStatus() {
        return urlStatus;
    }

    public void setLinkedFrom(Text[] linkedfrom) {
        this.linkedfrom =3D linkedfrom;
    }

    public Text[] getLinkedFrom() {
        return linkedfrom;
    }

    public String getURL() {
        return new String(url);
    }

    public int getSeconds() {
        return seconds;
    }

    public void setSeconds(int seconds) {
        this.seconds =3D seconds;
    }

    @Override
    public String toString() {
        return new String(url);
    }

    @Override
    public boolean equals(Object obj) {
        if(!(obj instanceof URLInfo)) {
            return false;
        }
        URLInfo urlObject =3D (URLInfo) obj;
        return this.getURL().equals(urlObject.getURL());
    }

}

--0015175cad8cd4ecea047156f681--

From common-user-return-16799-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 14:37:53 2009
Return-Path: <common-user-return-16799-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 47845 invoked from network); 17 Aug 2009 14:37:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 14:37:52 -0000
Received: (qmail 49675 invoked by uid 500); 17 Aug 2009 14:37:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 49609 invoked by uid 500); 17 Aug 2009 14:37:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 49599 invoked by uid 500); 17 Aug 2009 14:37:56 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 49596 invoked by uid 99); 17 Aug 2009 14:37:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 14:37:56 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of stas.oskin@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 14:37:47 +0000
Received: by bwz19 with SMTP id 19so3187933bwz.37
        for <core-user@hadoop.apache.org>; Mon, 17 Aug 2009 07:37:26 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=SAoMh4ndvpaxdAlN7WlXt/041s/gVLiCC6uTxXcNrJc=;
        b=ePMmS06RFhUAYP2kXQC5ltn7hL/uvHTztE6YHLE7bF3REqzMf6viPytUiCTLRsyr6u
         o4WG/WPFKALvIA5TabFowWIL2zb8t5zz0IeDhOnQXged4+zGkZkPCYwer/CdleKWJLoL
         OKn9VSTtnXbUS2IgrjUyFFvqjfOKJryYQt8iY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=D2YwIGfqrT7GjJKT68d4c22xrst8t/p/svM/Tfg07sVcRbNFFhnxk3cl/a3sSHKnq2
         38R15ZicxiL6uiVkGYUzNpQUih2CGbWjkF0otjSuUWzNwnTXWCiy+X2s0ZkgUgIJB/dl
         Zk+9zZPHdQfNZrb+AN859e60cbvOgvrpSnq2U=
MIME-Version: 1.0
Received: by 10.223.144.210 with SMTP id a18mr888419fav.35.1250519846597; Mon, 
	17 Aug 2009 07:37:26 -0700 (PDT)
Date: Mon, 17 Aug 2009 17:37:26 +0300
Message-ID: <77938bc20908170737k2dc01e96rdeead467af8adbb3@mail.gmail.com>
Subject: Non-root user blocks root on DFS?
From: Stas Oskin <stas.oskin@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0023545bd0983db54f0471575702
X-Virus-Checked: Checked by ClamAV on apache.org

--0023545bd0983db54f0471575702
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

I have a directory created by the root user with the 777 permissions.

When an application running under non-root user (called dev1) createded
sub-directories in this directory, it made some directories with 777, and
some with 755. This causes the app launched under root user not being able
to erase files from these directories, and throwing the following
exceptions:

org.apache.hadoop.fs.permission.AccessControlException:
org.apache.hadoop.fs.permission.AccessControlException: Permission denied:
user=root, access=WRITE, inode="snapshots":dev1:supergroup:rwxr-xr-x
 at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
 at
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
 at
org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:90)
at
org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:52)
 at org.apache.hadoop.dfs.DFSClient.delete(DFSClient.java:530)
at
org.apache.hadoop.dfs.DistributedFileSystem.delete(DistributedFileSystem.java:210)
 at org.util.FileUtils.deleteFile(FileUtils.java:365)
Caused by: org.apache.hadoop.ipc.RemoteException:
org.apache.hadoop.fs.permission.AccessControlException: Permission denied:
user=root, access=WRITE, inode="snapshots":dev1:supergroup:rwxr-xr-x at
org.apache.hadoop.dfs.PermissionChecker.check(PermissionChecker.java:175)
at org.apache.hadoop.dfs.PermissionChecker.check(PermissionChecker.java:156)
 at
org.apache.hadoop.dfs.PermissionChecker.checkPermission(PermissionChecker.java:107)
at
org.apache.hadoop.dfs.FSNamesystem.checkPermission(FSNamesystem.java:4238)
 at
org.apache.hadoop.dfs.FSNamesystem.deleteInternal(FSNamesystem.java:1527)
at org.apache.hadoop.dfs.FSNamesystem.delete(FSNamesystem.java:1497)
 at org.apache.hadoop.dfs.NameNode.delete(NameNode.java:425)
at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
 at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
 at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:481)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:890)

at org.apache.hadoop.ipc.Client.call(Client.java:716)
at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
 at org.apache.hadoop.dfs.$Proxy17.delete(Unknown Source)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
 at java.lang.reflect.Method.invoke(Method.java:597)
at
org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
 at
org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
at org.apache.hadoop.dfs.$Proxy17.delete(Unknown Source)
 at org.apache.hadoop.dfs.DFSClient.delete(DFSClient.java:528)
... 5 more



This brings the following questions:

1) Is the root user considered same level as non-root user in DFS?
2) Any idea why the dev1 created some directories with 777, and some with
755, even that their root directory was 777?

There is no any particular code in the application, which may set the
directory permissions.

Thanks for any idea.

--0023545bd0983db54f0471575702--

From common-user-return-16800-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 15:13:20 2009
Return-Path: <common-user-return-16800-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 60945 invoked from network); 17 Aug 2009 15:13:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 15:13:19 -0000
Received: (qmail 25816 invoked by uid 500); 17 Aug 2009 15:13:19 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25731 invoked by uid 500); 17 Aug 2009 15:13:19 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25679 invoked by uid 99); 17 Aug 2009 15:13:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 15:13:19 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 15:13:10 +0000
Received: from pcp088944pcs.unl.edu (pcp088944pcs.unl.edu [129.93.158.59])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7HFCjiT001800
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT);
	Mon, 17 Aug 2009 10:12:48 -0500
Cc: core-user@hadoop.apache.org
Message-Id: <2EB4C722-D3D6-4A4B-B825-91BCB186C3E6@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <77938bc20908170737k2dc01e96rdeead467af8adbb3@mail.gmail.com>
Content-Type: multipart/signed; boundary=Apple-Mail-42--515657638; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: Non-root user blocks root on DFS?
Date: Mon, 17 Aug 2009 10:12:45 -0500
References: <77938bc20908170737k2dc01e96rdeead467af8adbb3@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-42--515657638
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Hey Stas,

IIRC, the user with "special privileges" in Hadoop is the superuser.   
By default, the superuser is the user who runs the Hadoop Namenode.

So, if the user "hadoop" runs the Hadoop Namenode, then "hadoop" is  
the superuser who has the permissions normally given to root in Unix.   
I don't remember if there is a way to set the superuser manually.

Am I correct in guessing that the namenode is running as non-root?

Brian

On Aug 17, 2009, at 9:37 AM, Stas Oskin wrote:

> Hi.
>
> I have a directory created by the root user with the 777 permissions.
>
> When an application running under non-root user (called dev1)  
> createded
> sub-directories in this directory, it made some directories with  
> 777, and
> some with 755. This causes the app launched under root user not  
> being able
> to erase files from these directories, and throwing the following
> exceptions:
>
> org.apache.hadoop.fs.permission.AccessControlException:
> org.apache.hadoop.fs.permission.AccessControlException: Permission  
> denied:
> user=root, access=WRITE, inode="snapshots":dev1:supergroup:rwxr-xr-x
> at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native  
> Method)
> at
> sun 
> .reflect 
> .NativeConstructorAccessorImpl 
> .newInstance(NativeConstructorAccessorImpl.java:39)
> at
> sun 
> .reflect 
> .DelegatingConstructorAccessorImpl 
> .newInstance(DelegatingConstructorAccessorImpl.java:27)
> at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
> at
> org 
> .apache 
> .hadoop 
> .ipc.RemoteException.instantiateException(RemoteException.java:90)
> at
> org 
> .apache 
> .hadoop 
> .ipc.RemoteException.unwrapRemoteException(RemoteException.java:52)
> at org.apache.hadoop.dfs.DFSClient.delete(DFSClient.java:530)
> at
> org 
> .apache 
> .hadoop.dfs.DistributedFileSystem.delete(DistributedFileSystem.java: 
> 210)
> at org.util.FileUtils.deleteFile(FileUtils.java:365)
> Caused by: org.apache.hadoop.ipc.RemoteException:
> org.apache.hadoop.fs.permission.AccessControlException: Permission  
> denied:
> user=root, access=WRITE, inode="snapshots":dev1:supergroup:rwxr-xr-x  
> at
> org.apache.hadoop.dfs.PermissionChecker.check(PermissionChecker.java: 
> 175)
> at  
> org.apache.hadoop.dfs.PermissionChecker.check(PermissionChecker.java: 
> 156)
> at
> org 
> .apache 
> .hadoop.dfs.PermissionChecker.checkPermission(PermissionChecker.java: 
> 107)
> at
> org.apache.hadoop.dfs.FSNamesystem.checkPermission(FSNamesystem.java: 
> 4238)
> at
> org.apache.hadoop.dfs.FSNamesystem.deleteInternal(FSNamesystem.java: 
> 1527)
> at org.apache.hadoop.dfs.FSNamesystem.delete(FSNamesystem.java:1497)
> at org.apache.hadoop.dfs.NameNode.delete(NameNode.java:425)
> at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
> at
> sun 
> .reflect 
> .DelegatingMethodAccessorImpl 
> .invoke(DelegatingMethodAccessorImpl.java:25)
> at java.lang.reflect.Method.invoke(Method.java:597)
> at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:481)
> at org.apache.hadoop.ipc.Server$Handler.run(Server.java:890)
>
> at org.apache.hadoop.ipc.Client.call(Client.java:716)
> at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
> at org.apache.hadoop.dfs.$Proxy17.delete(Unknown Source)
> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> at
> sun 
> .reflect 
> .NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> at
> sun 
> .reflect 
> .DelegatingMethodAccessorImpl 
> .invoke(DelegatingMethodAccessorImpl.java:25)
> at java.lang.reflect.Method.invoke(Method.java:597)
> at
> org 
> .apache 
> .hadoop 
> .io 
> .retry 
> .RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
> at
> org 
> .apache 
> .hadoop 
> .io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java: 
> 59)
> at org.apache.hadoop.dfs.$Proxy17.delete(Unknown Source)
> at org.apache.hadoop.dfs.DFSClient.delete(DFSClient.java:528)
> ... 5 more
>
>
>
> This brings the following questions:
>
> 1) Is the root user considered same level as non-root user in DFS?
> 2) Any idea why the dev1 created some directories with 777, and some  
> with
> 755, even that their root directory was 777?
>
> There is no any particular code in the application, which may set the
> directory permissions.
>
> Thanks for any idea.


--Apple-Mail-42--515657638
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64

MIAGCSqGSIb3DQEHAqCAMIACAQExCzAJBgUrDgMCGgUAMIAGCSqGSIb3DQEHAQAAoIIICjCCA/gw
ggLgoAMCAQICASkwDQYJKoZIhvcNAQEFBQAwdTETMBEGCgmSJomT8ixkARkWA25ldDESMBAGCgmS
JomT8ixkARkWAkVTMQ4wDAYDVQQKEwVFU25ldDEgMB4GA1UECxMXQ2VydGlmaWNhdGUgQXV0aG9y
aXRpZXMxGDAWBgNVBAMTD0VTbmV0IFJvb3QgQ0EgMTAeFw0wMjEyMDUwODAwMDBaFw0xMzAxMjUw
ODAwMDBaMGkxEzARBgoJkiaJk/IsZAEZFgNvcmcxGDAWBgoJkiaJk/IsZAEZFghET0VHcmlkczEg
MB4GA1UECxMXQ2VydGlmaWNhdGUgQXV0aG9yaXRpZXMxFjAUBgNVBAMTDURPRUdyaWRzIENBIDEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC09dYjYaPbCD5mtbiQb7Ka3y1qAm0ZcqKC
FciWcfe8Kwcuy9tjHuIsLf9ZItdkDW4xy8sua9nJlx3KlwjtumTMtOtg35KZCknUd8KM4VGTSFdL
VG9AbNayef76caVCGM1+jyF0Lq03kauGOPTcNfZe1TZa3e1c9rc8ljV5OSWa/mfsCACyS5zFIWu0
yIDNyJdf+n0hwaPN53wllpJ30taD+JBjQ7h2k4xRWzeaznLOb9OztZVRA/1sVze+iczFh2xwa4Vd
Gy0eIIPw1pfvYwxO36rm0S109qvbsNlaroPRbxerPKakQLpKe034Xcx7gBPqUk/FxoRRWin5EWN3
rz9LAgMBAAGjgZ4wgZswDgYDVR0PAQH/BAQDAgGGMBEGCWCGSAGG+EIBAQQEAwIAhzAdBgNVHQ4E
FgQUyhkdEo5upDhdQtQxDgjb2Y0XDV0wHwYDVR0jBBgwFoAUvF1NSC/4NZRZq1yJSz7RsjoUAeow
DwYDVR0TAQH/BAUwAwEB/zAlBgNVHREEHjAcgRpET0VHcmlkcy1DQS0xQGRvZWdyaWRzLm9yZzAN
BgkqhkiG9w0BAQUFAAOCAQEAZNVrIDLqe39CEOiJt7Q7EpBPhAihMvDTSf/42u0SMbUmChww4mLm
ph5DBghZUVF8Yn59kRZMn1QLOtO1HzLqvAvPITacZVPlJgG2IXzlR636YghZFAycbIUEOJDBHR4v
tQO1KDxgZwvAbtmKIoxvhUCq2xsfFt9kCBBn+JYtQ6O5LsBJq3PmuubeMcc7mbQAfJZ7h/3Qghgk
FIhmE1+LBXPJbkuP8vgfg6h2BKoAf5TFfZECgGZKimfN110tBvfedGZwYYd3/GsJc83B0JN1gny0
gqNVPm392UchXGeBRrHnm2gkhIkr48Oq6EmNGV9/a6XfbplQW/JWbtPVPWkaizCCBAowggLyoAMC
AQICAwCB+zANBgkqhkiG9w0BAQUFADBpMRMwEQYKCZImiZPyLGQBGRYDb3JnMRgwFgYKCZImiZPy
LGQBGRYIRE9FR3JpZHMxIDAeBgNVBAsTF0NlcnRpZmljYXRlIEF1dGhvcml0aWVzMRYwFAYDVQQD
Ew1ET0VHcmlkcyBDQSAxMB4XDTA5MDYwMjE5NDExM1oXDTEwMDYwMjE5NDExM1owYTETMBEGCgmS
JomT8ixkARkWA29yZzEYMBYGCgmSJomT8ixkARkWCGRvZWdyaWRzMQ8wDQYDVQQLEwZQZW9wbGUx
HzAdBgNVBAMTFkJyaWFuIEJvY2tlbG1hbiA1MDQzMDcwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAw
ggEKAoIBAQDPWEl7hBiuFRVBSY4SwvG0HpkCZi74a0BeD0tNARgxoQVJ7jhJjR3G4y8ino0/5axt
2EEfIWUE+DVpV37IWOQl8q/wdvicnhbfjByxBbq4sfWPLepU7+Kd8k1FKHRHermARn9VxEkFLrLB
Gp7O5EX4mFHDaQy+Vv0thtA+m4qKoM+DA/8cOkJA5Rn6ZS/v/vtBzJh9HimVnhBx4+rw2cvKN+7r
lKsm7qTn9TCZmrQ97CvBEXSkHS11m8vYF6ZwcTgSCJM0M9nnX5JilupQO1vDICXSUZeWX2xpsqeL
x1PFGWgDaYXxFGtTRt2Qc9EPwf9Dr72xGPbKN8u5HylpOMDnAgMBAAGjgcIwgb8wEQYJYIZIAYb4
QgEBBAQDAgWgMA4GA1UdDwEB/wQEAwIF4DAfBgNVHSMEGDAWgBTKGR0Sjm6kOF1C1DEOCNvZjRcN
XTAYBgNVHSAEETAPMA0GCyqGSIb3TAMHAQMAMD4GA1UdHwQ3MDUwM6AxoC+GLWh0dHA6Ly9jcmwu
ZG9lZ3JpZHMub3JnLzFjM2YyY2E4LzFjM2YyY2E4LmNybDAfBgNVHREEGDAWgRRiYm9ja2VsbUBj
c2UudW5sLmVkdTANBgkqhkiG9w0BAQUFAAOCAQEAp6KjcWnfnH/MGlUkUWstE9gtPeymHp+2r4zI
w8JXigncJh/8qpSZqBcVhD24WFowI95otblrKYNZKW9f2G/hWwDSxZFqHhCDxFO12vDthrzOc3EH
CwypJPvIlZPt/E/x93XruzPxJwPz84DKKuPoJAMeNlADbd+92YtRr2y+VuMpgZaebMAoeCdWH8Cq
Y8xheNMajf8uiImBbatDuCu7qRvhwgxsMNLHEt4h853K1Zc181RlFGXG1+uL/Q/8VeKiASiCu+7L
1zpfLg7OCr6rJHb5S7wU+CeAvzSqmyy0fd2mwPeiX7huK+Cw4UjaB3yGKItzWT+KQJnV//wcSrzZ
dTGCAv0wggL5AgEBMHAwaTETMBEGCgmSJomT8ixkARkWA29yZzEYMBYGCgmSJomT8ixkARkWCERP
RUdyaWRzMSAwHgYDVQQLExdDZXJ0aWZpY2F0ZSBBdXRob3JpdGllczEWMBQGA1UEAxMNRE9FR3Jp
ZHMgQ0EgMQIDAIH7MAkGBSsOAwIaBQCgggFiMBgGCSqGSIb3DQEJAzELBgkqhkiG9w0BBwEwHAYJ
KoZIhvcNAQkFMQ8XDTA5MDgxNzE1MTI0NVowIwYJKoZIhvcNAQkEMRYEFJC4/QMqgLm9DTPfJ9pH
uGAt2ZyzMH8GCSsGAQQBgjcQBDFyMHAwaTETMBEGCgmSJomT8ixkARkWA29yZzEYMBYGCgmSJomT
8ixkARkWCERPRUdyaWRzMSAwHgYDVQQLExdDZXJ0aWZpY2F0ZSBBdXRob3JpdGllczEWMBQGA1UE
AxMNRE9FR3JpZHMgQ0EgMQIDAIH7MIGBBgsqhkiG9w0BCRACCzFyoHAwaTETMBEGCgmSJomT8ixk
ARkWA29yZzEYMBYGCgmSJomT8ixkARkWCERPRUdyaWRzMSAwHgYDVQQLExdDZXJ0aWZpY2F0ZSBB
dXRob3JpdGllczEWMBQGA1UEAxMNRE9FR3JpZHMgQ0EgMQIDAIH7MA0GCSqGSIb3DQEBAQUABIIB
AMw4fjSA6NU5lvK+Ffkp3UnRez8RFxkbE/czjhsxqdcrmedapHMuABIDqJtDNiBn1sT4GEGWkSAk
tNK6vkI3mjDaA0LpfQImvygZhlSldJIq0ygqw2ffgMQ357V4+hk8Fs8p/iexk5PdOVdHgcg4nW9D
cOxr+1PQ+qgE85LJROSygOrVOXJFtLoTSMD/Xyl+96G9oMOto9bVWu2aVwyZRaatrJYB3bwXyl0o
6s5bqSKzK4Z7CM7WuFWAGJJmSEu8BMpC/k18JuwLbOO7+CLJP7FXY9pemIdS5DOBtzCb6FYPdAIc
5MesB86XW7EFRDzODgnOON23LXRafhQ8PPIWl9EAAAAAAAA=

--Apple-Mail-42--515657638--

From common-user-return-16801-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 15:13:20 2009
Return-Path: <common-user-return-16801-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 60962 invoked from network); 17 Aug 2009 15:13:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 15:13:19 -0000
Received: (qmail 25830 invoked by uid 500); 17 Aug 2009 15:13:19 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25743 invoked by uid 500); 17 Aug 2009 15:13:19 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25696 invoked by uid 500); 17 Aug 2009 15:13:19 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 25679 invoked by uid 99); 17 Aug 2009 15:13:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 15:13:19 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 15:13:10 +0000
Received: from pcp088944pcs.unl.edu (pcp088944pcs.unl.edu [129.93.158.59])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7HFCjiT001800
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT);
	Mon, 17 Aug 2009 10:12:48 -0500
Cc: core-user@hadoop.apache.org
Message-Id: <2EB4C722-D3D6-4A4B-B825-91BCB186C3E6@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <77938bc20908170737k2dc01e96rdeead467af8adbb3@mail.gmail.com>
Content-Type: multipart/signed; boundary=Apple-Mail-42--515657638; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: Non-root user blocks root on DFS?
Date: Mon, 17 Aug 2009 10:12:45 -0500
References: <77938bc20908170737k2dc01e96rdeead467af8adbb3@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-42--515657638
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Hey Stas,

IIRC, the user with "special privileges" in Hadoop is the superuser.   
By default, the superuser is the user who runs the Hadoop Namenode.

So, if the user "hadoop" runs the Hadoop Namenode, then "hadoop" is  
the superuser who has the permissions normally given to root in Unix.   
I don't remember if there is a way to set the superuser manually.

Am I correct in guessing that the namenode is running as non-root?

Brian

On Aug 17, 2009, at 9:37 AM, Stas Oskin wrote:

> Hi.
>
> I have a directory created by the root user with the 777 permissions.
>
> When an application running under non-root user (called dev1)  
> createded
> sub-directories in this directory, it made some directories with  
> 777, and
> some with 755. This causes the app launched under root user not  
> being able
> to erase files from these directories, and throwing the following
> exceptions:
>
> org.apache.hadoop.fs.permission.AccessControlException:
> org.apache.hadoop.fs.permission.AccessControlException: Permission  
> denied:
> user=root, access=WRITE, inode="snapshots":dev1:supergroup:rwxr-xr-x
> at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native  
> Method)
> at
> sun 
> .reflect 
> .NativeConstructorAccessorImpl 
> .newInstance(NativeConstructorAccessorImpl.java:39)
> at
> sun 
> .reflect 
> .DelegatingConstructorAccessorImpl 
> .newInstance(DelegatingConstructorAccessorImpl.java:27)
> at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
> at
> org 
> .apache 
> .hadoop 
> .ipc.RemoteException.instantiateException(RemoteException.java:90)
> at
> org 
> .apache 
> .hadoop 
> .ipc.RemoteException.unwrapRemoteException(RemoteException.java:52)
> at org.apache.hadoop.dfs.DFSClient.delete(DFSClient.java:530)
> at
> org 
> .apache 
> .hadoop.dfs.DistributedFileSystem.delete(DistributedFileSystem.java: 
> 210)
> at org.util.FileUtils.deleteFile(FileUtils.java:365)
> Caused by: org.apache.hadoop.ipc.RemoteException:
> org.apache.hadoop.fs.permission.AccessControlException: Permission  
> denied:
> user=root, access=WRITE, inode="snapshots":dev1:supergroup:rwxr-xr-x  
> at
> org.apache.hadoop.dfs.PermissionChecker.check(PermissionChecker.java: 
> 175)
> at  
> org.apache.hadoop.dfs.PermissionChecker.check(PermissionChecker.java: 
> 156)
> at
> org 
> .apache 
> .hadoop.dfs.PermissionChecker.checkPermission(PermissionChecker.java: 
> 107)
> at
> org.apache.hadoop.dfs.FSNamesystem.checkPermission(FSNamesystem.java: 
> 4238)
> at
> org.apache.hadoop.dfs.FSNamesystem.deleteInternal(FSNamesystem.java: 
> 1527)
> at org.apache.hadoop.dfs.FSNamesystem.delete(FSNamesystem.java:1497)
> at org.apache.hadoop.dfs.NameNode.delete(NameNode.java:425)
> at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
> at
> sun 
> .reflect 
> .DelegatingMethodAccessorImpl 
> .invoke(DelegatingMethodAccessorImpl.java:25)
> at java.lang.reflect.Method.invoke(Method.java:597)
> at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:481)
> at org.apache.hadoop.ipc.Server$Handler.run(Server.java:890)
>
> at org.apache.hadoop.ipc.Client.call(Client.java:716)
> at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
> at org.apache.hadoop.dfs.$Proxy17.delete(Unknown Source)
> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> at
> sun 
> .reflect 
> .NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> at
> sun 
> .reflect 
> .DelegatingMethodAccessorImpl 
> .invoke(DelegatingMethodAccessorImpl.java:25)
> at java.lang.reflect.Method.invoke(Method.java:597)
> at
> org 
> .apache 
> .hadoop 
> .io 
> .retry 
> .RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
> at
> org 
> .apache 
> .hadoop 
> .io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java: 
> 59)
> at org.apache.hadoop.dfs.$Proxy17.delete(Unknown Source)
> at org.apache.hadoop.dfs.DFSClient.delete(DFSClient.java:528)
> ... 5 more
>
>
>
> This brings the following questions:
>
> 1) Is the root user considered same level as non-root user in DFS?
> 2) Any idea why the dev1 created some directories with 777, and some  
> with
> 755, even that their root directory was 777?
>
> There is no any particular code in the application, which may set the
> directory permissions.
>
> Thanks for any idea.


--Apple-Mail-42--515657638
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-42--515657638--

From common-user-return-16802-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 15:22:46 2009
Return-Path: <common-user-return-16802-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63748 invoked from network); 17 Aug 2009 15:22:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 15:22:46 -0000
Received: (qmail 47223 invoked by uid 500); 17 Aug 2009 15:22:50 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 47161 invoked by uid 500); 17 Aug 2009 15:22:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 47151 invoked by uid 500); 17 Aug 2009 15:22:50 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 47147 invoked by uid 99); 17 Aug 2009 15:22:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 15:22:49 +0000
X-ASF-Spam-Status: No, hits=1.4 required=10.0
	tests=FORGED_YAHOO_RCVD,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 15:22:40 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1Md42N-0002hy-PY
	for core-user@hadoop.apache.org; Mon, 17 Aug 2009 08:22:19 -0700
Message-ID: <25008761.post@talk.nabble.com>
Date: Mon, 17 Aug 2009 08:22:19 -0700 (PDT)
From: tigertail <tyczjs@yahoo.com>
To: core-user@hadoop.apache.org
Subject: Percentage calculation?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: tyczjs@yahoo.com
X-Virus-Checked: Checked by ClamAV on apache.org


Hi Hadoop/MapReduce experts,

My question might be naive, But I am really stuck here and I am looking
forward to get helps/advises from you.

I have an input file like
key1, 2
key2, 1
key1, 1
key3, 1

It is easy to write a M/R code to calculate the count for each key and
output sth like
key1, 3
key2, 1
key3, 1

But, how I can calculate the percentage of each key over all keys, with the
above input, I would expect to get the output as
key1, 0.60
key2, 0.20
key3, 0.20

One naive method is to calculate the total count (5 with the above input)
which is saved in a file. Then the file is read in before M/R starts. But it
is obviously ugly and slow. 

I also tried to set a static enum Counters { INPUT_WORDS }
In mapper I do context.getCounter(Counters.INPUT_WORDS).increment(1);
In reducer I do context.getCounter(Counters.INPUT_WORDS).getCounter();
But it does not work.

Is there more elegant way?
-- 
View this message in context: http://www.nabble.com/Percentage-calculation--tp25008761p25008761.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-16803-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 16:09:39 2009
Return-Path: <common-user-return-16803-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 79380 invoked from network); 17 Aug 2009 16:09:33 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 16:09:33 -0000
Received: (qmail 27016 invoked by uid 500); 17 Aug 2009 16:08:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26246 invoked by uid 500); 17 Aug 2009 16:08:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25344 invoked by uid 99); 17 Aug 2009 16:03:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 16:03:23 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jingkei.ly@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 16:03:12 +0000
Received: by ewy26 with SMTP id 26so3104711ewy.29
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 09:02:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:sender:received:in-reply-to
         :references:from:date:x-google-sender-auth:message-id:subject:to
         :content-type;
        bh=oXHZyUdHcoqd5Oz3MrLecTWrvrt2cQ1RFVyylshSu8g=;
        b=G1DyAFYAyc1gKSuC3pT9+LIWa0xBwEssTKv9Im8x9P96DT4pvyqOF1Npn2opRVdVXw
         613w2t3FUtOr885al9V86mrk7gyo1L0bDNvDxgMIRndtekGuPLJEyJKF3B4KnQTmFr9w
         MabVV+YD+bQ169d3JS+QlTdVlzKxtHgAi8MqA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:sender:in-reply-to:references:from:date
         :x-google-sender-auth:message-id:subject:to:content-type;
        b=X6PGWQC+0eICTzCumAYPTiCA31lEEdvvzpfPoSNfOeTHq82A0AjqRknh8u1Lzwgu+Q
         JfhkfoEP/053OcrLzRjsxAALyA+dvYz0zboOjC5pJTyoWcQdw/lZpzSc1xvo8H+OzCB4
         eQOFrkpPuKGmkaNaMe+bDBv1gAi5naStIRMZo=
MIME-Version: 1.0
Sender: jingkei.ly@gmail.com
Received: by 10.210.119.16 with SMTP id r16mr7181981ebc.49.1250524971526; Mon, 
	17 Aug 2009 09:02:51 -0700 (PDT)
In-Reply-To: <25008761.post@talk.nabble.com>
References: <25008761.post@talk.nabble.com>
From: Jingkei Ly <jly.list@googlemail.com>
Date: Mon, 17 Aug 2009 17:02:30 +0100
X-Google-Sender-Auth: ec31ae500945292f
Message-ID: <c238cbb50908170902t3e337982r70af53daf810960e@mail.gmail.com>
Subject: Re: Percentage calculation?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00151748de6cb648ee047158886e
X-Virus-Checked: Checked by ClamAV on apache.org

--00151748de6cb648ee047158886e
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

does using *
context.getCounter(Counters.INPUT_WORDS).getCounter().getValue();* make a
difference?

2009/8/17 tigertail <tyczjs@yahoo.com>

>
> Hi Hadoop/MapReduce experts,
>
> My question might be naive, But I am really stuck here and I am looking
> forward to get helps/advises from you.
>
> I have an input file like
> key1, 2
> key2, 1
> key1, 1
> key3, 1
>
> It is easy to write a M/R code to calculate the count for each key and
> output sth like
> key1, 3
> key2, 1
> key3, 1
>
> But, how I can calculate the percentage of each key over all keys, with the
> above input, I would expect to get the output as
> key1, 0.60
> key2, 0.20
> key3, 0.20
>
> One naive method is to calculate the total count (5 with the above input)
> which is saved in a file. Then the file is read in before M/R starts. But
> it
> is obviously ugly and slow.
>
> I also tried to set a static enum Counters { INPUT_WORDS }
> In mapper I do context.getCounter(Counters.INPUT_WORDS).increment(1);
> In reducer I do context.getCounter(Counters.INPUT_WORDS).getCounter();
> But it does not work.
>
> Is there more elegant way?
> --
> View this message in context:
> http://www.nabble.com/Percentage-calculation--tp25008761p25008761.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>
>

--00151748de6cb648ee047158886e--

From common-user-return-16804-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 16:14:31 2009
Return-Path: <common-user-return-16804-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 82255 invoked from network); 17 Aug 2009 16:14:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 16:14:30 -0000
Received: (qmail 72052 invoked by uid 500); 17 Aug 2009 16:14:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 71960 invoked by uid 500); 17 Aug 2009 16:14:34 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 71950 invoked by uid 99); 17 Aug 2009 16:14:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 16:14:34 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of thkunkel@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 16:14:25 +0000
Received: by ywh36 with SMTP id 36so4566837ywh.31
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 09:14:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=ISHRpgU13ja/+TMJUKm65C/zaKD/mUI1/MUUsyt2EMQ=;
        b=cGg7LvyttsUgg8E7JeKmpue5K/wKrxJNQ55Tq+ou2J5WymexKmaflGT2zROBQuQCM0
         acUhVJXZ1g2WdfVmpElTYXpuz15S9QY6utJdImsYYyEYwvl765aY44KEA/fWxxKgSpg1
         XtQo8jsIiYisPNuMDMidcy9dhUt4qFmlvYcoE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=UHlvsmGZwJqzDWF0bvy/hZjfzZ84wKKCe7R+sZc3RBHVoKY2n6PqgYUnPippS1Q0NT
         vrHRibPAysdVRWHXmqqlQmmIvMGFwlHurWlvFu66qLTHg6UObG2oXJNBjFc678zrUZD8
         8Y9xTXScryfNkCjX/r5fHkJlRCHHgwpbS4cxo=
MIME-Version: 1.0
Received: by 10.90.198.4 with SMTP id v4mr2890717agf.79.1250525644063; Mon, 17 
	Aug 2009 09:14:04 -0700 (PDT)
Date: Mon, 17 Aug 2009 11:14:04 -0500
Message-ID: <8134a2730908170914h29daf4d7j72f576d7769abe4e@mail.gmail.com>
Subject: Upgrade to 0.20.0
From: Turner Kunkel <thkunkel@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636283d9ecc04c1047158b0f6
X-Virus-Checked: Checked by ClamAV on apache.org

--001636283d9ecc04c1047158b0f6
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello all,
I had 0.18.0 working and recently downloaded 0.20.0 and copied over the
information from .18 where I figured it should go.
However, the HDFS isn't working.  I have JAVA_HOME in hadoop-env.sh set
correctly and I think I have core-site, hdfs-site, and mapred-site correct.
All the SSH connections are fine and I have the masters and slaves files
set.
Is there anything I'm missing?

Thanks.
-- 

-Turner Kunkel

--001636283d9ecc04c1047158b0f6--

From common-user-return-16805-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:00:45 2009
Return-Path: <common-user-return-16805-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 95452 invoked from network); 17 Aug 2009 17:00:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:00:45 -0000
Received: (qmail 41759 invoked by uid 500); 17 Aug 2009 17:00:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 41711 invoked by uid 500); 17 Aug 2009 17:00:48 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 41701 invoked by uid 99); 17 Aug 2009 17:00:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:00:48 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of verma.vibhooti@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:00:38 +0000
Received: by ewy26 with SMTP id 26so3145049ewy.29
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:00:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=DDW1K2TxYiG++QypwsS5z3ZIIpyNW5oq+r9GVktdPRo=;
        b=ni/TQbqKn4YlCDcPZxjFSN9g9sh2D17TEUx3RZmTut45PR6S0TrmVqpfyt6fFk4yR7
         20spnXgjoTdt9gAaNL6XFUOShC4ofNZTV/Eqx/XF3DBBSQKi4/ovXWA58zElDItMCXxn
         DVRDS3eQXuctDZvjbkoZ1cZOIuoO44/r3u6t4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=npDXsiJfxsqX2xxSus8uOBJJE1POhQyJgoNOwvUzi9cq4nszj8pNY3IIC/FwpMGOc3
         iDRlhX+aTuIXYgn4Fz6614uhrvU06P2b7+zczIIP61fVfFfe11NF21sYMWUqiV1Q8nnr
         nQjAIQan6k3Vmooua5uYQabW2c76Mb+bH0AtU=
MIME-Version: 1.0
Received: by 10.216.48.1 with SMTP id u1mr1024889web.189.1250528418066; Mon, 
	17 Aug 2009 10:00:18 -0700 (PDT)
In-Reply-To: <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>
	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>
	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>
Date: Mon, 17 Aug 2009 22:30:18 +0530
Message-ID: <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>
Subject: Re: Two output files?
From: Vibhooti Verma <verma.vibhooti@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016364d212123f0b504715956cc
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364d212123f0b504715956cc
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi John,


Here is the example, where you can change the filename specified in the conf.

protected String generateFileNameForKeyValue(Object key, Object value,
String name) {
		
		return  name.concat(key.toString() + "_" + name);

		return keyBasedName;
	}



--
vibhooti



On Mon, Aug 17, 2009 at 1:59 PM, John Clarke <clarkemjj@gmail.com> wrote:

> Fantastic, I will try that :) A little push in the right driection helps
> hugely! I don't have that book yet but I'm planning on getting it.
>
> cheers
> John,
>
>
>
> 2009/8/14 Kris Jirapinyo <kris.jirapinyo@biz360.com>
>
> > Hi John,
> >     If you have the Hadoop O'Reilly book, look at pg 206 for an example.
> > But basically, you just create a subclass of MultipleTextOutputFormat and
> > then inside it you override generateFileNameForKeyValue (for example) to
> > have the reducer emit the desired filenames.  For each key in the
> reducer,
> > it will write the text values to that file.  Make sure in the JobConf you
> > set OutputFormat to your class that extends MultipleTextOutputFormat.
> >
> > -- Kris.
> >
> > On Fri, Aug 14, 2009 at 7:11 AM, John Clarke <clarkemjj@gmail.com>
> wrote:
> >
> > > Hi,
> > >
> > > I want to output two text files from my MapReduce job but I am having
> > > trouble understanding how to use the MultipleTextOutputFormat class to
> do
> > > so.
> > >
> > > I want to write to the two files depending on the key of each key/value
> > > pair.
> > >
> > > In the Reducer how do I tell it to write the different files? Normally
> I
> > > just do an output.collect(key, val);.
> > >
> > > Any help would be most appreciated.
> > >
> > > Thanks,
> > > John
> > >
> >
>



-- 
cheers,
Vibhooti

--0016364d212123f0b504715956cc--

From common-user-return-16806-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:23:15 2009
Return-Path: <common-user-return-16806-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 5941 invoked from network); 17 Aug 2009 17:23:15 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:23:15 -0000
Received: (qmail 72372 invoked by uid 500); 17 Aug 2009 17:23:19 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 72289 invoked by uid 500); 17 Aug 2009 17:23:19 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 72279 invoked by uid 99); 17 Aug 2009 17:23:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:23:19 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of cubicdesign@gmail.com designates 74.125.78.25 as permitted sender)
Received: from [74.125.78.25] (HELO ey-out-2122.google.com) (74.125.78.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:23:08 +0000
Received: by ey-out-2122.google.com with SMTP id 22so659849eye.35
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:22:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:date:from
         :user-agent:mime-version:to:subject:references:in-reply-to
         :content-type;
        bh=jD/pcv2Vn7lXZEnEjR8OPVw1TIAGfc3i6DyoQ/0EQoI=;
        b=w4sDQ3ph6tqkQvtyZhsf2ZDnqFQVgKxgcA0WYI2Yx2JW8JlLI/IFvmWdE8e7+H+Y8L
         5xzbB1fp6cI9Ks7jeVELs062jKoQJOuj86n/N+NYcKmzhW/BIfUcxtUFDigyLJbiUWcv
         C94KRGG1kVxDSiQPPWp3jyJBe55C4AdUfM0YI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type;
        b=xLvT9RrXXizoaPOXbH/xkBFoZdPoZRE5m7m0naSfim5KcvCF4mL2UPeSTKGSg9wXAj
         V1pxvRRfpeDkyD9eXp59daL0oeTz7SXx4GzwR78jWym6q8gWSyiodfSOgTCIuhSn4Pf7
         UT/eDiAeCykZ/9MhlaPhWRGrOnnzCMmNdWH4w=
Received: by 10.210.78.16 with SMTP id a16mr3558097ebb.1.1250529768678;
        Mon, 17 Aug 2009 10:22:48 -0700 (PDT)
Received: from ?192.168.220.104? (host-091-096-208-041.ewe-ip-backbone.de [91.96.208.41])
        by mx.google.com with ESMTPS id 10sm1041711eyz.41.2009.08.17.10.22.47
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Mon, 17 Aug 2009 10:22:48 -0700 (PDT)
Message-ID: <4A8991E5.8000102@Gmail.com>
Date: Mon, 17 Aug 2009 19:22:45 +0200
From: CubicDesign <cubicdesign@gmail.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Ubuntu/Hadoop incompatibilities?
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com> <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>
In-Reply-To: <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>
Content-Type: multipart/alternative;
 boundary="------------010104030109000008060006"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------010104030109000008060006
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Hi.

I have seen two articles (tutorials) on the Internet saying that Hadoop 
is incompatible with Ubuntu.
Now I also have problems making Hadoop work and I start to believe those 
two articles.

Anybody can confirm that has successfully installed Hadoop on Ubuntu?

Thanks

--------------010104030109000008060006--

From common-user-return-16807-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:26:55 2009
Return-Path: <common-user-return-16807-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 8945 invoked from network); 17 Aug 2009 17:26:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:26:55 -0000
Received: (qmail 78414 invoked by uid 500); 17 Aug 2009 17:26:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 78348 invoked by uid 500); 17 Aug 2009 17:26:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 78338 invoked by uid 99); 17 Aug 2009 17:26:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:26:59 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [171.67.219.88] (HELO smtp-roam.stanford.edu) (171.67.219.88)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:26:48 +0000
Received: from smtp-roam.stanford.edu (localhost.localdomain [127.0.0.1])
	by localhost (Postfix) with SMTP id 5CEDE37DBE
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:26:27 -0700 (PDT)
Received: from tablet (DN800cde0f.Stanford.EDU [128.12.222.15])
	(using TLSv1 with cipher RC4-MD5 (128/128 bits))
	(No client certificate requested)
	(Authenticated sender: umka)
	by smtp-roam.stanford.edu (Postfix) with ESMTPSA id DDD3937DBC
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:26:26 -0700 (PDT)
From: "Dmitry Pushkarev" <umka@stanford.edu>
To: <common-user@hadoop.apache.org>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com> <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com> <4A8991E5.8000102@Gmail.com>
In-Reply-To: <4A8991E5.8000102@Gmail.com>
Subject: RE: Ubuntu/Hadoop incompatibilities?
Date: Mon, 17 Aug 2009 10:26:19 -0700
Message-ID: <000301ca1f5f$d5adece0$8109c6a0$@edu>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: 7bit
X-Mailer: Microsoft Office Outlook 12.0
Thread-Index: AcofX2uJft/VJpuRTzW+A5z6iYojGwAAEejw
Content-Language: en-us
X-Virus-Checked: Checked by ClamAV on apache.org

We have a cluster of over 40 machines all running ubuntu. As long as you can
run java hadoop should run just fine. 

-----Original Message-----
From: CubicDesign [mailto:cubicdesign@gmail.com] 
Sent: Monday, August 17, 2009 10:23 AM
To: common-user@hadoop.apache.org
Subject: Ubuntu/Hadoop incompatibilities?

Hi.

I have seen two articles (tutorials) on the Internet saying that Hadoop 
is incompatible with Ubuntu.
Now I also have problems making Hadoop work and I start to believe those 
two articles.

Anybody can confirm that has successfully installed Hadoop on Ubuntu?

Thanks


From common-user-return-16808-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:27:32 2009
Return-Path: <common-user-return-16808-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 9277 invoked from network); 17 Aug 2009 17:27:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:27:31 -0000
Received: (qmail 81064 invoked by uid 500); 17 Aug 2009 17:27:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80986 invoked by uid 500); 17 Aug 2009 17:27:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 80960 invoked by uid 99); 17 Aug 2009 17:27:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:27:30 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jdcryans@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:27:21 +0000
Received: by fxm17 with SMTP id 17so2981206fxm.13
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:27:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:sender:received:in-reply-to
         :references:date:x-google-sender-auth:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=gFOmAS8pxO9eqQ4JGvPA6Rgy5axpg8VapqCnKYvgvwM=;
        b=FP0lZw3PwXgK+hIus2XqpAErb9qNuQZ4Ow09Z19I70xzsMl7YbI3mKS31EaDz0rHkd
         pnkFAVlO0HqiPWxj80/OEqSvtNEzczgBNVBqoHC14KdduOHfMsSSgyYcFmTMmdTb4TSs
         63AYTnllvLYAt0agDilbccENzfDinadNotX5Y=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:sender:in-reply-to:references:date
         :x-google-sender-auth:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=o+ZLMhPsJAWdcf0md9srSEm+zV3TnhRW5//6i7+cxboZA/UWC9nZeQY9CJcfA2qin3
         Prn36UJqaUZTdjz6S5PR/JVthBFfq9OujqwfmTKynw+DGvMXFrr1DpSKXB/g0mNxCftA
         BSmW/t7yAXhsZy/YW8i4JpzjzZ69FzK27Ysy4=
MIME-Version: 1.0
Sender: jdcryans@gmail.com
Received: by 10.223.4.149 with SMTP id 21mr922654far.28.1250530021147; Mon, 17 
	Aug 2009 10:27:01 -0700 (PDT)
In-Reply-To: <4A8991E5.8000102@Gmail.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>
	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>
	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>
	 <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>
	 <4A8991E5.8000102@Gmail.com>
Date: Mon, 17 Aug 2009 13:27:01 -0400
X-Google-Sender-Auth: 876fc488ae93c67d
Message-ID: <31a243e70908171027n74d2f708n28aeb97894a6b532@mail.gmail.com>
Subject: Re: Ubuntu/Hadoop incompatibilities?
From: Jean-Daniel Cryans <jdcryans@apache.org>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

It is compatible and don't see how it could not be. All my clusters
are on ubuntu.

J-D

On Mon, Aug 17, 2009 at 1:22 PM, CubicDesign<cubicdesign@gmail.com> wrote:
> Hi.
>
> I have seen two articles (tutorials) on the Internet saying that Hadoop is
> incompatible with Ubuntu.
> Now I also have problems making Hadoop work and I start to believe those two
> articles.
>
> Anybody can confirm that has successfully installed Hadoop on Ubuntu?
>
> Thanks
>

From common-user-return-16809-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:28:56 2009
Return-Path: <common-user-return-16809-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 10198 invoked from network); 17 Aug 2009 17:28:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:28:56 -0000
Received: (qmail 85534 invoked by uid 500); 17 Aug 2009 17:29:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 85445 invoked by uid 500); 17 Aug 2009 17:28:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 85435 invoked by uid 99); 17 Aug 2009 17:28:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:28:59 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:28:48 +0000
Received: from [10.73.145.24] (travelsoon-lm.corp.yahoo.com [10.73.145.24])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7HHSMWl075115
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:28:22 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=bYQIy7nwvxZwh8wRw/3Xnv93sgCbGhzBAeDq1NjgMx3/pvmJrO5t5XkrAXopC+yl
Message-ID: <4A899335.1040306@yahoo-inc.com>
Date: Mon, 17 Aug 2009 10:28:21 -0700
From: Jakob Homan <jhoman@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.12 (Macintosh/20080213)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Upgrade to 0.20.0
References: <8134a2730908170914h29daf4d7j72f576d7769abe4e@mail.gmail.com>
In-Reply-To: <8134a2730908170914h29daf4d7j72f576d7769abe4e@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Some more detailed information or, hopefully, some logs would be helpful 
here.  Have you verified that the namenode and datanodes are being 
started correctly?
-Jakob


Turner Kunkel wrote:
> Hello all,
> I had 0.18.0 working and recently downloaded 0.20.0 and copied over the
> information from .18 where I figured it should go.
> However, the HDFS isn't working.  I have JAVA_HOME in hadoop-env.sh set
> correctly and I think I have core-site, hdfs-site, and mapred-site correct.
> All the SSH connections are fine and I have the masters and slaves files
> set.
> Is there anything I'm missing?
> 
> Thanks.


From common-user-return-16810-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:32:06 2009
Return-Path: <common-user-return-16810-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11809 invoked from network); 17 Aug 2009 17:32:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:32:05 -0000
Received: (qmail 88886 invoked by uid 500); 17 Aug 2009 17:32:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 88819 invoked by uid 500); 17 Aug 2009 17:32:09 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 88809 invoked by uid 99); 17 Aug 2009 17:32:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:32:09 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ryan.justin.smith@gmail.com designates 74.125.78.24 as permitted sender)
Received: from [74.125.78.24] (HELO ey-out-2122.google.com) (74.125.78.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:32:00 +0000
Received: by ey-out-2122.google.com with SMTP id 22so661120eye.35
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:31:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=GMbrlCDe3/MPBoVnBfs3cDQSQ1TH4BGmaAY/CMch/NU=;
        b=uaFX6rK6HHKY+8PvgQHsPiGfyuYXxBXRrXYxk4LB+4+reRcNKCv5KA9+gy0gF1xAPd
         saAd/VdXaxws6R9x2UM3z1p+EBl5lZY/XFGGjF5tqEZhsYhlddhigOgm5gIwdR9nd0mA
         Nqq9/z3uc+C7QOH27QPov6tGhwTOdgEHVW/IE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=KcPS00n1Vj9qv38yCuLAuaoYWbMcN92p+hMv9nDmErLfqZQ65vRUOb03gcy/ViXQ+X
         cyjKiUTYGifwI8BRg9OoRDDmOX1dxBOfLhOFTTqmxlv1DZlu3MOK0vS2YSSAb1a0FkYQ
         E1f5eYTZm1XNRaKIBZrSdpeGXiqnP8HuUZKnQ=
MIME-Version: 1.0
Received: by 10.216.29.82 with SMTP id h60mr1081223wea.162.1250530298969; Mon, 
	17 Aug 2009 10:31:38 -0700 (PDT)
In-Reply-To: <4A8991E5.8000102@Gmail.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>
	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>
	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>
	 <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>
	 <4A8991E5.8000102@Gmail.com>
Date: Mon, 17 Aug 2009 13:31:38 -0400
Message-ID: <ae4767d10908171031s6f80bb80ob179c8e3dbd63925@mail.gmail.com>
Subject: Re: Ubuntu/Hadoop incompatibilities?
From: Ryan Smith <ryan.justin.smith@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6dd8d01403da1047159c6cc
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6dd8d01403da1047159c6cc
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

When i set my first Hadoop cluster up, I followed this tutorial.  I also
used ubuntu, haven't had any problems wrt the OS.

http://www.michael-noll.com/wiki/Running_Hadoop_On_Ubuntu_Linux_(Multi-Node_Cluster)




On Mon, Aug 17, 2009 at 1:22 PM, CubicDesign <cubicdesign@gmail.com> wrote:

> Hi.
>
> I have seen two articles (tutorials) on the Internet saying that Hadoop is
> incompatible with Ubuntu.
> Now I also have problems making Hadoop work and I start to believe those
> two articles.
>
> Anybody can confirm that has successfully installed Hadoop on Ubuntu?
>
> Thanks
>

--0016e6dd8d01403da1047159c6cc--

From common-user-return-16811-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:34:51 2009
Return-Path: <common-user-return-16811-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 13575 invoked from network); 17 Aug 2009 17:34:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:34:50 -0000
Received: (qmail 95636 invoked by uid 500); 17 Aug 2009 17:34:54 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95564 invoked by uid 500); 17 Aug 2009 17:34:54 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95553 invoked by uid 99); 17 Aug 2009 17:34:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:34:54 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:34:42 +0000
Received: from [10.73.145.24] (travelsoon-lm.corp.yahoo.com [10.73.145.24])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7HHYH5w078297
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:34:18 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=XQKoVmchqmxs5h4uJBGMGasGAUm6iutH+s6KcPhmqKs8xffW63lENmY/jF72SSUF
Message-ID: <4A899499.4080902@yahoo-inc.com>
Date: Mon, 17 Aug 2009 10:34:17 -0700
From: Jakob Homan <jhoman@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.12 (Macintosh/20080213)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Ubuntu/Hadoop incompatibilities?
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com> <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com> <4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu>
In-Reply-To: <000301ca1f5f$d5adece0$8109c6a0$@edu>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Ubuntu will work fine.  The only to-do item is to make sure Sun's Java 
is installed and pointed-to, rather than th Open JDK that Ubuntu ships 
with by default.

Jakob Homan
Hadoop at Yahoo!

Dmitry Pushkarev wrote:
> We have a cluster of over 40 machines all running ubuntu. As long as you can
> run java hadoop should run just fine. 
> 
> -----Original Message-----
> From: CubicDesign [mailto:cubicdesign@gmail.com] 
> Sent: Monday, August 17, 2009 10:23 AM
> To: common-user@hadoop.apache.org
> Subject: Ubuntu/Hadoop incompatibilities?
> 
> Hi.
> 
> I have seen two articles (tutorials) on the Internet saying that Hadoop 
> is incompatible with Ubuntu.
> Now I also have problems making Hadoop work and I start to believe those 
> two articles.
> 
> Anybody can confirm that has successfully installed Hadoop on Ubuntu?
> 
> Thanks
> 


From common-user-return-16812-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:36:57 2009
Return-Path: <common-user-return-16812-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 14621 invoked from network); 17 Aug 2009 17:36:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:36:56 -0000
Received: (qmail 99666 invoked by uid 500); 17 Aug 2009 17:36:58 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 99554 invoked by uid 500); 17 Aug 2009 17:36:58 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 99531 invoked by uid 99); 17 Aug 2009 17:36:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:36:58 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:36:50 +0000
Received: by bwz19 with SMTP id 19so3297457bwz.37
        for <multiple recipients>; Mon, 17 Aug 2009 10:36:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=tLwn2oA3hM/2+ZHkWhKGBOulnsPmbfCBYZe6O2doZn8=;
        b=liNrU5FJUgwkSXweF4cOOsL1eqe+xq5aghNPQUG53iHwQ3n8RmTr2co+83ZlXkHJte
         mvkCXhfk0RFpusxqh2zaRAHTJ4YXm0pco/NFcBBvJMBTNyu1MYFjlm8x0vLoLXlm8ack
         DCxRZcTSqNP2KUQqPLr5xx9jYbY1MQXKH9K6k=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        b=FDIkQKsPjxnbh9it6OlFyKPRSx272VzpQDZYXBLLwjTjdy/rlVOHynzW916MBP5fem
         GNPYx5suTUpIUH6wzT/A7BnWdbTxtMD93jQfEtQiewibZ3RIXcVviX8f+slQWiIH1/1M
         G9t6JTqp/U5IIQ9sNMWxtmtZeX+5mhMrWnlmE=
MIME-Version: 1.0
Received: by 10.223.143.79 with SMTP id t15mr905447fau.2.1250530588217; Mon, 
	17 Aug 2009 10:36:28 -0700 (PDT)
In-Reply-To: <2EB4C722-D3D6-4A4B-B825-91BCB186C3E6@cse.unl.edu>
References: <77938bc20908170737k2dc01e96rdeead467af8adbb3@mail.gmail.com>
	 <2EB4C722-D3D6-4A4B-B825-91BCB186C3E6@cse.unl.edu>
Date: Mon, 17 Aug 2009 20:36:27 +0300
Message-ID: <77938bc20908171036w60eb3941ia63c89977ed3d2e1@mail.gmail.com>
Subject: Re: Non-root user blocks root on DFS?
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0023545bda287dd136047159d766
X-Virus-Checked: Checked by ClamAV on apache.org

--0023545bda287dd136047159d766
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Brian.

2009/8/17 Brian Bockelman <bbockelm@cse.unl.edu>

> Hey Stas,
>
> IIRC, the user with "special privileges" in Hadoop is the superuser.  By
> default, the superuser is the user who runs the Hadoop Namenode.
>

I think you right, because I need to su to hadoop in order to use the shell.


>
> So, if the user "hadoop" runs the Hadoop Namenode, then "hadoop" is the
> superuser who has the permissions normally given to root in Unix.  I don't
> remember if there is a way to set the superuser manually.
>

I see, it's clear now.


>
> Am I correct in guessing that the namenode is running as non-root?
>

You completely right.

So this explains why "root" unable to erase the files created by "dev1".


The question remain, how "dev1" created file permissions 755, while the
parent directory was with 777 permissions?

Also, is there a way to make non-superuser user a super-user?

Regards.

--0023545bda287dd136047159d766--

From common-user-return-16813-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:36:57 2009
Return-Path: <common-user-return-16813-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 14614 invoked from network); 17 Aug 2009 17:36:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:36:56 -0000
Received: (qmail 99696 invoked by uid 500); 17 Aug 2009 17:36:58 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 99557 invoked by uid 500); 17 Aug 2009 17:36:58 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 99538 invoked by uid 500); 17 Aug 2009 17:36:58 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 99531 invoked by uid 99); 17 Aug 2009 17:36:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:36:58 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:36:50 +0000
Received: by bwz19 with SMTP id 19so3297457bwz.37
        for <multiple recipients>; Mon, 17 Aug 2009 10:36:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=tLwn2oA3hM/2+ZHkWhKGBOulnsPmbfCBYZe6O2doZn8=;
        b=liNrU5FJUgwkSXweF4cOOsL1eqe+xq5aghNPQUG53iHwQ3n8RmTr2co+83ZlXkHJte
         mvkCXhfk0RFpusxqh2zaRAHTJ4YXm0pco/NFcBBvJMBTNyu1MYFjlm8x0vLoLXlm8ack
         DCxRZcTSqNP2KUQqPLr5xx9jYbY1MQXKH9K6k=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        b=FDIkQKsPjxnbh9it6OlFyKPRSx272VzpQDZYXBLLwjTjdy/rlVOHynzW916MBP5fem
         GNPYx5suTUpIUH6wzT/A7BnWdbTxtMD93jQfEtQiewibZ3RIXcVviX8f+slQWiIH1/1M
         G9t6JTqp/U5IIQ9sNMWxtmtZeX+5mhMrWnlmE=
MIME-Version: 1.0
Received: by 10.223.143.79 with SMTP id t15mr905447fau.2.1250530588217; Mon, 
	17 Aug 2009 10:36:28 -0700 (PDT)
In-Reply-To: <2EB4C722-D3D6-4A4B-B825-91BCB186C3E6@cse.unl.edu>
References: <77938bc20908170737k2dc01e96rdeead467af8adbb3@mail.gmail.com>
	 <2EB4C722-D3D6-4A4B-B825-91BCB186C3E6@cse.unl.edu>
Date: Mon, 17 Aug 2009 20:36:27 +0300
Message-ID: <77938bc20908171036w60eb3941ia63c89977ed3d2e1@mail.gmail.com>
Subject: Re: Non-root user blocks root on DFS?
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0023545bda287dd136047159d766
X-Virus-Checked: Checked by ClamAV on apache.org

--0023545bda287dd136047159d766
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Brian.

2009/8/17 Brian Bockelman <bbockelm@cse.unl.edu>

> Hey Stas,
>
> IIRC, the user with "special privileges" in Hadoop is the superuser.  By
> default, the superuser is the user who runs the Hadoop Namenode.
>

I think you right, because I need to su to hadoop in order to use the shell.


>
> So, if the user "hadoop" runs the Hadoop Namenode, then "hadoop" is the
> superuser who has the permissions normally given to root in Unix.  I don't
> remember if there is a way to set the superuser manually.
>

I see, it's clear now.


>
> Am I correct in guessing that the namenode is running as non-root?
>

You completely right.

So this explains why "root" unable to erase the files created by "dev1".


The question remain, how "dev1" created file permissions 755, while the
parent directory was with 777 permissions?

Also, is there a way to make non-superuser user a super-user?

Regards.

--0023545bda287dd136047159d766--

From common-user-return-16814-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:46:59 2009
Return-Path: <common-user-return-16814-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 20623 invoked from network); 17 Aug 2009 17:46:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:46:58 -0000
Received: (qmail 16332 invoked by uid 500); 17 Aug 2009 17:47:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 16254 invoked by uid 500); 17 Aug 2009 17:47:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 16244 invoked by uid 99); 17 Aug 2009 17:47:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:47:02 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:46:53 +0000
Received: by yxe15 with SMTP id 15so4183310yxe.5
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:46:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=QaZHregqca8U7NPjwxhis0CNBYmmJWZbr2G/6yn2QSE=;
        b=cMWtIp74bG/qDMOuPEMG/N6fPgMnHhYSUH288rTWTpsHzvu+s3VSUzUKYCFQYLbJ7j
         igTX5QUIT1EdX6mwodyUJy+DqlivjuzE/TIOdhlzpeox2Uca/G2IJY8xw7TI43QOHRne
         sHtszFOHOxgSv6NM5QTSCHOXIf4dGmE/OTBpE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=bKxfzBvtNIBowidErWGWEYKL8yJZwlVEYgPSF8UZC78kRIHI/wxELhXnmfksoVRlQy
         T7cxH8Dd/frsavRLSM8j1kvyKEWR3Z2ojuAECXd1Nd9KN0ri2U0dWUdxVc0b5Bqv+2in
         tC9cKANVs3352WDR88LS0gGbWqiQklfsniM3g=
MIME-Version: 1.0
Received: by 10.150.166.12 with SMTP id o12mr6076647ybe.79.1250531186060; Mon, 
	17 Aug 2009 10:46:26 -0700 (PDT)
In-Reply-To: <4A899499.4080902@yahoo-inc.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com> 
	<42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com> 
	<4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com> 
	<99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com> 
	<4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu> 
	<4A899499.4080902@yahoo-inc.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Mon, 17 Aug 2009 10:46:06 -0700
Message-ID: <c7d45fc70908171046g80cec01re1424b0157309b70@mail.gmail.com>
Subject: Re: Ubuntu/Hadoop incompatibilities?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd5a184202ee7047159fb15
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd5a184202ee7047159fb15
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

I use ubuntu both in-house and on EC2 for hadoop.

Zero problems once you have the real java.

On Mon, Aug 17, 2009 at 10:34 AM, Jakob Homan <jhoman@yahoo-inc.com> wrote:

> Ubuntu will work fine.  The only to-do item is to make sure Sun's Java is
> installed and pointed-to, rather than th Open JDK that Ubuntu ships with by
> default.
>
>

--000e0cd5a184202ee7047159fb15--

From common-user-return-16815-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 17:49:17 2009
Return-Path: <common-user-return-16815-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 21739 invoked from network); 17 Aug 2009 17:49:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 17:49:17 -0000
Received: (qmail 20927 invoked by uid 500); 17 Aug 2009 17:49:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20829 invoked by uid 500); 17 Aug 2009 17:49:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20819 invoked by uid 99); 17 Aug 2009 17:49:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:49:21 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of xcolwell@gmail.com designates 209.85.221.188 as permitted sender)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 17:49:11 +0000
Received: by qyk26 with SMTP id 26so2355665qyk.5
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 10:48:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:date:from
         :user-agent:mime-version:to:subject:references:in-reply-to
         :content-type:content-transfer-encoding;
        bh=qq7peS3tZOuCcCr9lWZH0E15ZGwTtPcP0YyULBvvPnQ=;
        b=fNBfS1S6Ofiz5vHIUhwHZlKR2v3UXcUYX3PuO5Loc/H6OGDBbP64YUB8HeFyUxBrc5
         IR3oyLZqt2v6laZYTSnbX6C2Ys702ImlLKNshlnfnRzZfrn+eN6kj+KZeofJVkO0q8Oz
         3VVbFaHwg5TIx2QGoH/7+JR6jBqjdk/QjT1iw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        b=vQegh8wXeBsbKIfvplHPJ+Y2y+pmH8fgdIfGaF65zs/uw8dGn+ylC4WggXPg87m9g4
         hm4uRpLmd6H5GgvO4fpacjDmf6smetuqlOxuaA500K2k4JoYfFupY1OufS/ZpiUlkDjj
         eK66kOv+8Z/G6s+MoIE2YLkOd/C3ucVveqjlM=
Received: by 10.224.22.204 with SMTP id o12mr4472130qab.150.1250531330788;
        Mon, 17 Aug 2009 10:48:50 -0700 (PDT)
Received: from ?10.1.20.106? (dsl254-070-240.nyc1.dsl.speakeasy.net [216.254.70.240])
        by mx.google.com with ESMTPS id 5sm8717268qwg.30.2009.08.17.10.48.49
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Mon, 17 Aug 2009 10:48:50 -0700 (PDT)
Message-ID: <4A899803.9090108@gmail.com>
Date: Mon, 17 Aug 2009 13:48:51 -0400
From: brien colwell <xcolwell@gmail.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Ubuntu/Hadoop incompatibilities?
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com> <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com> <4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu> <4A899499.4080902@yahoo-inc.com>
In-Reply-To: <4A899499.4080902@yahoo-inc.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Actually Ubuntu comes out of the box with an entry in the hosts file 
(/etc/hosts) that maps the computer name to the loopback address. (btw 
I'm not sure if this is specific to Ubuntu) The effect is that all name 
lookups from the machine for itself resolve to 127.0.0.1. We've seen 
Hadoop daemons on Ubuntu bind their sockets to the loopback address, 
which will  not accept requests from the outside. Symptoms here are that 
the cluster works on a single machine but will not distribute.

Just check your netstat tables for the addresses on which the Hadoop 
daemons are bound. They should be external addresses. The solution we 
use is to remove the entry in the hosts file.





Jakob Homan wrote:
> Ubuntu will work fine.  The only to-do item is to make sure Sun's Java 
> is installed and pointed-to, rather than th Open JDK that Ubuntu ships 
> with by default.
>
> Jakob Homan
> Hadoop at Yahoo!
>
> Dmitry Pushkarev wrote:
>> We have a cluster of over 40 machines all running ubuntu. As long as 
>> you can
>> run java hadoop should run just fine.
>> -----Original Message-----
>> From: CubicDesign [mailto:cubicdesign@gmail.com] Sent: Monday, August 
>> 17, 2009 10:23 AM
>> To: common-user@hadoop.apache.org
>> Subject: Ubuntu/Hadoop incompatibilities?
>>
>> Hi.
>>
>> I have seen two articles (tutorials) on the Internet saying that 
>> Hadoop is incompatible with Ubuntu.
>> Now I also have problems making Hadoop work and I start to believe 
>> those two articles.
>>
>> Anybody can confirm that has successfully installed Hadoop on Ubuntu?
>>
>> Thanks
>>
>


From common-user-return-16816-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 19:48:11 2009
Return-Path: <common-user-return-16816-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 79710 invoked from network); 17 Aug 2009 19:48:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 19:48:11 -0000
Received: (qmail 62468 invoked by uid 500); 17 Aug 2009 19:48:15 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 62365 invoked by uid 500); 17 Aug 2009 19:48:15 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 62355 invoked by uid 500); 17 Aug 2009 19:48:15 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 62352 invoked by uid 99); 17 Aug 2009 19:48:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 19:48:15 +0000
X-ASF-Spam-Status: No, hits=1.4 required=10.0
	tests=FORGED_YAHOO_RCVD,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 19:48:01 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1Md8BB-0004uq-3W
	for core-user@hadoop.apache.org; Mon, 17 Aug 2009 12:47:41 -0700
Message-ID: <25013023.post@talk.nabble.com>
Date: Mon, 17 Aug 2009 12:47:41 -0700 (PDT)
From: tigertail <tyczjs@yahoo.com>
To: core-user@hadoop.apache.org
Subject: Re: Percentage calculation?
In-Reply-To: <25008761.post@talk.nabble.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: tyczjs@yahoo.com
References: <25008761.post@talk.nabble.com>
X-Virus-Checked: Checked by ClamAV on apache.org


Can sb help please? I would expect there must be some easy way to do that.

Some corrections,
In reducer I do context.getCounter(Counters.INPUT_WORDS).getValue();
But it does not work. it always returns 0.


tigertail wrote:
> 
> Hi Hadoop/MapReduce experts,
> 
> My question might be naive, But I am really stuck here and I am looking
> forward to get helps/advises from you.
> 
> I have an input file like
> key1, 2
> key2, 1
> key1, 1
> key3, 1
> 
> It is easy to write a M/R code to calculate the count for each key and
> output sth like
> key1, 3
> key2, 1
> key3, 1
> 
> But, how I can calculate the percentage of each key over all keys, with
> the above input, I would expect to get the output as
> key1, 0.60
> key2, 0.20
> key3, 0.20
> 
> One naive method is to calculate the total count (5 with the above input)
> which is saved in a file. Then the file is read in before M/R starts. But
> it is obviously ugly and slow. 
> 
> I also tried to set a static enum Counters { INPUT_WORDS }
> In mapper I do context.getCounter(Counters.INPUT_WORDS).increment(1);
> In reducer I do context.getCounter(Counters.INPUT_WORDS).getValue();
> But it does not work. it always returns 0.
> 
> Is there more elegant way?
> 

-- 
View this message in context: http://www.nabble.com/Percentage-calculation--tp25008761p25013023.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-16817-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 20:34:20 2009
Return-Path: <common-user-return-16817-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 91022 invoked from network); 17 Aug 2009 20:34:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 20:34:20 -0000
Received: (qmail 89840 invoked by uid 500); 17 Aug 2009 20:34:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 89755 invoked by uid 500); 17 Aug 2009 20:34:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 89745 invoked by uid 99); 17 Aug 2009 20:34:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 20:34:24 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cubicdesign@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 20:34:13 +0000
Received: by ewy26 with SMTP id 26so3287927ewy.29
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 13:33:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:date:from
         :user-agent:mime-version:to:subject:references:in-reply-to
         :content-type;
        bh=+1WNm5v1cZJ2m2fEfaG0m93mxo9gtPBj6jpAuXJC3eU=;
        b=pygt036xF7n5HeKcrVTZfeRJThiTV7Q3zgB/Qwhk6etKoaUj7vwX40ZLE6lD59Bv4i
         VPc2xu0H073s1Sz2vl52KGzm7Z5Phw1tXNAbIF4n8QO06JB/8w+AEK/pbb6Es5fbkCeb
         yinHA6qES3CgLFDgIahyinLrsXowRaM13flKY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type;
        b=sDz1k3HVS4YjYLGvPvuvZCYnV0TENqSXmcBvx294YtFk0s1x2vm/iS25Yg+czqbQfo
         gYJZIlfxPWMIeu/qwyIA7eiA5wD8+I2A2/hOlP5oZSVVSq9uv4Ztq6jslsVzNt8OK3ue
         uZuppRbtKUX+pCtrIiJu4j2XzFYy+sTYAqv1k=
Received: by 10.210.53.1 with SMTP id b1mr3444581eba.56.1250541232418;
        Mon, 17 Aug 2009 13:33:52 -0700 (PDT)
Received: from ?192.168.220.104? (host-091-096-211-158.ewe-ip-backbone.de [91.96.211.158])
        by mx.google.com with ESMTPS id 28sm1213651eyg.52.2009.08.17.13.33.51
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Mon, 17 Aug 2009 13:33:51 -0700 (PDT)
Message-ID: <4A89BEAC.9070306@Gmail.com>
Date: Mon, 17 Aug 2009 22:33:48 +0200
From: CubicDesign <cubicdesign@gmail.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Ubuntu/Hadoop incompatibilities?
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com> <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com> <4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu> <4A899499.4080902@yahoo-inc.com> <4A899803.9090108@gmail.com>
In-Reply-To: <4A899803.9090108@gmail.com>
Content-Type: multipart/alternative;
 boundary="------------070400070008080308080701"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------070400070008080308080701
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Thank you all for your answers.

My problem with Hadoop on Ubuntu is that I cannot make the DataNode 
server to work properly (at least this is where I think the error is). I 
get an "File jobtracker.info could only be replicated to 0 nodes instead 
of 1" error message. All other servers are running fine. I am running 
Hadoop in a single (test) machine.


The results for jps and netstats are:


jps
4465 NameNode
4553 DataNode
5105 Jps
4717 JobTracker
4649 SecondaryNameNode
4807 TaskTracker


    
sudo netstat -plten | grep java
tcp        0      0 0.0.0.0:50722           0.0.0.0:*               
LISTEN      1000       13858       4553/java      
tcp        0      0 0.0.0.0:50020           0.0.0.0:*               
LISTEN      1000       15130       4553/java      
tcp        0      0 127.0.0.1:54310         0.0.0.0:*               
LISTEN      1000       13564       4465/java      
tcp        0      0 127.0.0.1:54311         0.0.0.0:*               
LISTEN      1000       14571       4717/java      
tcp        0      0 0.0.0.0:59080           0.0.0.0:*               
LISTEN      1000       14547       4717/java      
tcp        0      0 0.0.0.0:50090           0.0.0.0:*               
LISTEN      1000       14943       4649/java      
tcp        0      0 127.0.0.1:40555         0.0.0.0:*               
LISTEN      1000       15057       4807/java      
tcp        0      0 0.0.0.0:50060           0.0.0.0:*               
LISTEN      1000       15031       4807/java      
tcp        0      0 0.0.0.0:47661           0.0.0.0:*               
LISTEN      1000       14247       4649/java      
tcp        0      0 0.0.0.0:50030           0.0.0.0:*               
LISTEN      1000       14941       4717/java      
tcp        0      0 0.0.0.0:57839           0.0.0.0:*               
LISTEN      1000       13514       4465/java      
tcp        0      0 0.0.0.0:50070           0.0.0.0:*               
LISTEN      1000       14533       4465/java      
tcp        0      0 0.0.0.0:50010           0.0.0.0:*               
LISTEN      1000       14765       4553/java      
tcp        0      0 0.0.0.0:50075           0.0.0.0:*               
LISTEN      1000       14946       4553/java      
  


--------------070400070008080308080701--

From common-user-return-16818-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 20:56:09 2009
Return-Path: <common-user-return-16818-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 97563 invoked from network); 17 Aug 2009 20:56:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 20:56:09 -0000
Received: (qmail 11717 invoked by uid 500); 17 Aug 2009 20:56:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 11629 invoked by uid 500); 17 Aug 2009 20:56:12 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 11619 invoked by uid 99); 17 Aug 2009 20:56:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 20:56:12 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 20:56:03 +0000
Received: from [10.72.106.226] (heighthigh-lx.corp.yahoo.com [10.72.106.226])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7HKssNM099284
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 13:54:54 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=vabcVnKHaD+AeUqDI737Ddl06iwn4bwIC9cDsnWdJRYdjE9LV21MtkDcs58HTJgg
Message-ID: <4A89C39E.9030105@yahoo-inc.com>
Date: Mon, 17 Aug 2009 13:54:54 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Upgrade to 0.20.0
References: <8134a2730908170914h29daf4d7j72f576d7769abe4e@mail.gmail.com> <4A899335.1040306@yahoo-inc.com>
In-Reply-To: <4A899335.1040306@yahoo-inc.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


Checking NameNode log would help. Mostly likely reason would be that you 
didn't give '-upgrade' option to 'start-dfs.sh' script. HDFS forces you 
to run with this option when you go to newer versions.

Yes, it is not very kind to innocent users.. but it's been that way 
mainly to avoid accidental upgrade or data loss. As the number of users 
grows, I think some of these policies will change.

Raghu.

Jakob Homan wrote:
> Some more detailed information or, hopefully, some logs would be helpful 
> here.  Have you verified that the namenode and datanodes are being 
> started correctly?
> -Jakob
> 
> 
> Turner Kunkel wrote:
>> Hello all,
>> I had 0.18.0 working and recently downloaded 0.20.0 and copied over the
>> information from .18 where I figured it should go.
>> However, the HDFS isn't working.  I have JAVA_HOME in hadoop-env.sh set
>> correctly and I think I have core-site, hdfs-site, and mapred-site 
>> correct.
>> All the SSH connections are fine and I have the masters and slaves files
>> set.
>> Is there anything I'm missing?
>>
>> Thanks.
> 


From common-user-return-16819-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 20:58:06 2009
Return-Path: <common-user-return-16819-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 98281 invoked from network); 17 Aug 2009 20:58:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 20:58:06 -0000
Received: (qmail 17147 invoked by uid 500); 17 Aug 2009 20:58:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 17047 invoked by uid 500); 17 Aug 2009 20:58:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 17037 invoked by uid 99); 17 Aug 2009 20:58:10 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 20:58:10 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of dali.kilani@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 20:57:59 +0000
Received: by ewy26 with SMTP id 26so3302718ewy.29
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 13:57:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:date:message-id:subject:from:to:content-type;
        bh=cD/A9CHfPnmBnHe66+agBEB7EhrVEfmLg+9lc8nevSs=;
        b=J0u8SgsZiXMmwMDUYI6Wu2s+uS9rJFCFXKUDfm23vbOjjMPtDRny8AsUX3AFOjr7pK
         cwrqnV1ch++lFSiLia0G/Uhu0kh8Fnlr6X9SFVwgphmRBq2Vd01CshEUVw/nRogBy8fe
         i6McAy31YDmPJdnR93wklscUkkTbFdhug7Qnc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:date:message-id
         :subject:from:to:content-type;
        b=SOt1viaXitA6vCPPVzSq5kpCyWZeybsHLRhZTMjHB1Qywo0gqGLOoNrMxJDph2uyT4
         dA6NiaPaLbogKSm/kf0MwTLXpPp1T5lDY6kvDD1YAf/A1H3JMvcnR8rFd25U4cvdhjtX
         0wzcPowkA9hdBkRJ4IzLkjhwlgGwH0IUFNt2I=
MIME-Version: 1.0
Received: by 10.210.78.16 with SMTP id a16mr7555189ebb.66.1250542659333; Mon, 
	17 Aug 2009 13:57:39 -0700 (PDT)
Reply-To: mohamed.kilani@m4x.org
In-Reply-To: <4A89BEAC.9070306@Gmail.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>
	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>
	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>
	 <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>
	 <4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu>
	 <4A899499.4080902@yahoo-inc.com> <4A899803.9090108@gmail.com>
	 <4A89BEAC.9070306@Gmail.com>
Date: Mon, 17 Aug 2009 13:57:39 -0700
Message-ID: <77d4e5730908171357v526c146aybef60abe62019753@mail.gmail.com>
Subject: Re: Ubuntu/Hadoop incompatibilities?
From: Dali Kilani <dali.kilani@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd1eb70fc6eff04715ca63d
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd1eb70fc6eff04715ca63d
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Can you double check that your data node doesn't have the same /etc/hosts
issue mentioned above in the thread? (i.e. machine name resolves to
127.0.0.1)
Dali
On Mon, Aug 17, 2009 at 1:33 PM, CubicDesign <cubicdesign@gmail.com> wrote:

> Thank you all for your answers.
>
> My problem with Hadoop on Ubuntu is that I cannot make the DataNode server
> to work properly (at least this is where I think the error is). I get an
> "File jobtracker.info could only be replicated to 0 nodes instead of 1"
> error message. All other servers are running fine. I am running Hadoop in a
> single (test) machine.
>
>
> The results for jps and netstats are:
>
>
> jps
> 4465 NameNode
> 4553 DataNode
> 5105 Jps
> 4717 JobTracker
> 4649 SecondaryNameNode
> 4807 TaskTracker
>
>
>   sudo netstat -plten | grep java
> tcp        0      0 0.0.0.0:50722           0.0.0.0:*               LISTEN
>      1000       13858       4553/java      tcp        0      0
> 0.0.0.0:50020           0.0.0.0:*               LISTEN      1000
> 15130       4553/java      tcp        0      0 127.0.0.1:54310
> 0.0.0.0:*               LISTEN      1000       13564       4465/java
>  tcp        0      0 127.0.0.1:54311         0.0.0.0:*
> LISTEN      1000       14571       4717/java      tcp        0      0
> 0.0.0.0:59080           0.0.0.0:*               LISTEN      1000
> 14547       4717/java      tcp        0      0 0.0.0.0:50090
> 0.0.0.0:*               LISTEN      1000       14943       4649/java
>  tcp        0      0 127.0.0.1:40555         0.0.0.0:*
> LISTEN      1000       15057       4807/java      tcp        0      0
> 0.0.0.0:50060           0.0.0.0:*               LISTEN      1000
> 15031       4807/java      tcp        0      0 0.0.0.0:47661
> 0.0.0.0:*               LISTEN      1000       14247       4649/java
>  tcp        0      0 0.0.0.0:50030           0.0.0.0:*
> LISTEN      1000       14941       4717/java      tcp        0      0
> 0.0.0.0:57839           0.0.0.0:*               LISTEN      1000
> 13514       4465/java      tcp        0      0 0.0.0.0:50070
> 0.0.0.0:*               LISTEN      1000       14533       4465/java
>  tcp        0      0 0.0.0.0:50010           0.0.0.0:*
> LISTEN      1000       14765       4553/java      tcp        0      0
> 0.0.0.0:50075           0.0.0.0:*               LISTEN      1000
> 14946       4553/java
>



-- 
Dali Kilani
===========
Phone :  (650) 492-5921 (Google Voice)
E-Fax  :  (775) 552-2982

--000e0cd1eb70fc6eff04715ca63d--

From common-user-return-16820-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 20:59:06 2009
Return-Path: <common-user-return-16820-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 98552 invoked from network); 17 Aug 2009 20:59:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 20:59:06 -0000
Received: (qmail 20155 invoked by uid 500); 17 Aug 2009 20:59:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20053 invoked by uid 500); 17 Aug 2009 20:59:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20043 invoked by uid 99); 17 Aug 2009 20:59:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 20:59:10 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of dali.kilani@gmail.com designates 209.85.219.226 as permitted sender)
Received: from [209.85.219.226] (HELO mail-ew0-f226.google.com) (209.85.219.226)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 20:59:00 +0000
Received: by ewy26 with SMTP id 26so3303372ewy.29
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 13:58:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:date:message-id:subject:from:to:content-type;
        bh=FdiXL1XFlaoxsywTnMoKeeOM01EjSkHuM0S5XokZHSg=;
        b=SuF1/1FLnPBdpbkpfL8ZtxcU6vKw5d+TGkG3MuoFEF3QzyJ5VNE7gnGVbgXMab5Fo5
         DNdnXLB6QdOKp7j/ix4JDQnoC07rMT3uuexUG9HHppgP3sb1yYal+clREeDOvITGT75q
         u6+axd9Cp90KfS6Kc2C+hhMCuk35gE5FKSmaE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:date:message-id
         :subject:from:to:content-type;
        b=liiZ1vxuWM2A5DlJoU5Z+OwSIPP56krd/WLSnAOBIjVopUjt6BQ4eAp0wXFP3OdqQV
         mpPnDRk0RaV9r1pX8BFUZH51Eog4aNnVE4GugT5dK9jlmjVKNQoUXQoX1fFHYpAO8smW
         Qm4J2pHqVUZcx42IvcFRrkaAcIfvVyjdEPrJ8=
MIME-Version: 1.0
Received: by 10.210.133.17 with SMTP id g17mr4141722ebd.93.1250542719441; Mon, 
	17 Aug 2009 13:58:39 -0700 (PDT)
Reply-To: mohamed.kilani@m4x.org
In-Reply-To: <4A89BEAC.9070306@Gmail.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>
	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>
	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>
	 <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>
	 <4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu>
	 <4A899499.4080902@yahoo-inc.com> <4A899803.9090108@gmail.com>
	 <4A89BEAC.9070306@Gmail.com>
Date: Mon, 17 Aug 2009 13:58:39 -0700
Message-ID: <77d4e5730908171358y19c91811kbad90fbd97e6e775@mail.gmail.com>
Subject: Re: Ubuntu/Hadoop incompatibilities?
From: Dali Kilani <dali.kilani@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015174be14a919afe04715caa28
X-Virus-Checked: Checked by ClamAV on apache.org

--0015174be14a919afe04715caa28
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Can you double check that your data node doesn't have the same /etc/hosts
issue mentioned above in the thread? (i.e. machine name resolves to
127.0.0.1)
Dali
On Mon, Aug 17, 2009 at 1:33 PM, CubicDesign <cubicdesign@gmail.com> wrote:

> Thank you all for your answers.
>
> My problem with Hadoop on Ubuntu is that I cannot make the DataNode server
> to work properly (at least this is where I think the error is). I get an
> "File jobtracker.info could only be replicated to 0 nodes instead of 1"
> error message. All other servers are running fine. I am running Hadoop in a
> single (test) machine.
>
>
> The results for jps and netstats are:
>
>
> jps
> 4465 NameNode
> 4553 DataNode
> 5105 Jps
> 4717 JobTracker
> 4649 SecondaryNameNode
> 4807 TaskTracker
>
>
>   sudo netstat -plten | grep java
> tcp        0      0 0.0.0.0:50722           0.0.0.0:*               LISTEN
>      1000       13858       4553/java      tcp        0      0
> 0.0.0.0:50020           0.0.0.0:*               LISTEN      1000
> 15130       4553/java      tcp        0      0 127.0.0.1:54310
> 0.0.0.0:*               LISTEN      1000       13564       4465/java
>  tcp        0      0 127.0.0.1:54311         0.0.0.0:*
> LISTEN      1000       14571       4717/java      tcp        0      0
> 0.0.0.0:59080           0.0.0.0:*               LISTEN      1000
> 14547       4717/java      tcp        0      0 0.0.0.0:50090
> 0.0.0.0:*               LISTEN      1000       14943       4649/java
>  tcp        0      0 127.0.0.1:40555         0.0.0.0:*
> LISTEN      1000       15057       4807/java      tcp        0      0
> 0.0.0.0:50060           0.0.0.0:*               LISTEN      1000
> 15031       4807/java      tcp        0      0 0.0.0.0:47661
> 0.0.0.0:*               LISTEN      1000       14247       4649/java
>  tcp        0      0 0.0.0.0:50030           0.0.0.0:*
> LISTEN      1000       14941       4717/java      tcp        0      0
> 0.0.0.0:57839           0.0.0.0:*               LISTEN      1000
> 13514       4465/java      tcp        0      0 0.0.0.0:50070
> 0.0.0.0:*               LISTEN      1000       14533       4465/java
>  tcp        0      0 0.0.0.0:50010           0.0.0.0:*
> LISTEN      1000       14765       4553/java      tcp        0      0
> 0.0.0.0:50075           0.0.0.0:*               LISTEN      1000
> 14946       4553/java
>



-- 
Dali Kilani
===========
Phone :  (650) 492-5921 (Google Voice)
E-Fax  :  (775) 552-2982

--0015174be14a919afe04715caa28--

From common-user-return-16821-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 21:01:47 2009
Return-Path: <common-user-return-16821-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 99488 invoked from network); 17 Aug 2009 21:01:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 21:01:46 -0000
Received: (qmail 24671 invoked by uid 500); 17 Aug 2009 21:01:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 24580 invoked by uid 500); 17 Aug 2009 21:01:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 24570 invoked by uid 99); 17 Aug 2009 21:01:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 21:01:50 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [68.142.237.92] (HELO n7.bullet.re3.yahoo.com) (68.142.237.92)
    by apache.org (qpsmtpd/0.29) with SMTP; Mon, 17 Aug 2009 21:01:40 +0000
Received: from [68.142.237.88] by n7.bullet.re3.yahoo.com with NNFMP; 17 Aug 2009 21:01:18 -0000
Received: from [67.195.9.81] by t4.bullet.re3.yahoo.com with NNFMP; 17 Aug 2009 21:01:18 -0000
Received: from [67.195.9.97] by t1.bullet.mail.gq1.yahoo.com with NNFMP; 17 Aug 2009 21:01:18 -0000
Received: from [127.0.0.1] by omp101.mail.gq1.yahoo.com with NNFMP; 17 Aug 2009 21:01:18 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 548454.43633.bm@omp101.mail.gq1.yahoo.com
Received: (qmail 84234 invoked by uid 60001); 17 Aug 2009 21:01:18 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1250542878; bh=ZcqggfA15LGwSkXXHVHHv3n8nYHhOLdiXVnCNhu73vI=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=tADzVLb6HQsTGQ4C58LFHsKBy+KykGwOmF6pWzIQACKn6OwJfdMbUByenPU2xZyIvRmI/p++aDf+m4BsggOtnHzYCvy/fD4n83gK54Lgm4KDgeQcwD7M40H3oJmSRZS2qVI1qEJQ+cMj1cIPg9A8Y22jKo2bp2/rgMNjP0z7Tvc=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=Uhs+Tqd/D46sdlgMXiOKYCU5iufu88QiVr7v4Xm1DHkieTvg5K9hwrrSSLtDkwun0IJRdOHxt1/ODh/ulCSNWrdf4XvTSQFle6rA6a/fnPZ/REqgRKyx6s0YPca/DNwDVWbty+EyZelTJ41SFbgF1i+dPUx404hkgLRI8Za/jQ0=;
Message-ID: <428663.76474.qm@web110105.mail.gq1.yahoo.com>
X-YMail-OSG: tO2ZDQMVM1lqiEr9NKSDgEgm6kalvR6QZV58wEV1LXxW59.Rd5qAVPPgg1L1_V4kikFdq45IREylbGq27VQH31CPZKsYAWnryBTIDNLf394tuwEKPJVJaCN5fYP2Y9L2tjPrFru_Ahm9WKTWCTD1H9jqfGmunqVHLhwUQzuOCSMIrj1vLQgnw9kzyhEYel8h0Erw3yLXpcIbexQ.4jJCDV8EtJoP5lXjiwyze_OD6K6O3IHD4XDc4uouPpI1RgDsDlnrGSH6iop63GTEq2sHh8xAKq35U8wwMhV5Ox6CFb3j18GR4nupoJYCZKVjjjhFmE8-
Received: from [216.243.71.77] by web110105.mail.gq1.yahoo.com via HTTP; Mon, 17 Aug 2009 14:01:18 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>  <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>  <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>  <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>  <4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu>  <4A899499.4080902@yahoo-inc.com> <4A899803.9090108@gmail.com>  <4A89BEAC.9070306@Gmail.com> <77d4e5730908171358y19c91811kbad90fbd97e6e775@mail.gmail.com>
Date: Mon, 17 Aug 2009 14:01:18 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: Hadoop - flush() files
To: common-user@hadoop.apache.org
In-Reply-To: <77d4e5730908171358y19c91811kbad90fbd97e6e775@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-1007162562-1250542878=:76474"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-1007162562-1250542878=:76474
Content-Type: text/plain; charset=us-ascii

Hi,

I was wondering if anyone here have stared using (or has been using) the newer Hadoop versions (0-20.1 ??? ) - which provides API for flushing out any open files on the HDFS ?

Are there any known issues I should be aware of ?

Thanks!
Arvind



      
--0-1007162562-1250542878=:76474--


From common-user-return-16823-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 22:08:52 2009
Return-Path: <common-user-return-16823-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 20079 invoked from network); 17 Aug 2009 22:08:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 22:08:52 -0000
Received: (qmail 75738 invoked by uid 500); 17 Aug 2009 21:41:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 75676 invoked by uid 500); 17 Aug 2009 21:41:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 75666 invoked by uid 99); 17 Aug 2009 21:41:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 21:41:08 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jingkei.ly@gmail.com designates 74.125.78.25 as permitted sender)
Received: from [74.125.78.25] (HELO ey-out-2122.google.com) (74.125.78.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 21:41:00 +0000
Received: by ey-out-2122.google.com with SMTP id 22so695083eye.35
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 14:40:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:sender:received:in-reply-to
         :references:from:date:x-google-sender-auth:message-id:subject:to
         :content-type;
        bh=NWGLiAEvgKRv2VnMnP+TISaKLrKGjhDascIfo8X8vPw=;
        b=kbW6K9gHazPraNge/zGbp9d7YIg4Apn8Xg4h6JDFKuycQVJ5xTEeN8eRb8mGDZIsKO
         0oh2XcfezbFUnKdwrED8FF/F/q7PzcyMNNWJdO2pfqEEytCDHEn8o9JYy7tXtx05o0Tw
         esLmnQyFaouZBM8pRrTHsBZ2jTxrVmLLMMWQo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:sender:in-reply-to:references:from:date
         :x-google-sender-auth:message-id:subject:to:content-type;
        b=FwYs5GpMWK44ZwdUyiD2UCKyIHjAX2x9BgXtN1YqEawG1dXSlb+rDIgDvh2JdRsiAC
         UqFFqgcVuVwnPaIn2LJ0woI/J7diWyABWUlpoHI0K2ZtXZPIwgO4dyqiqCd6wZsaBmef
         yf2i2Q0MqMKoTwuOiIvPi5GvGpfNfM6uRDrxc=
MIME-Version: 1.0
Sender: jingkei.ly@gmail.com
Received: by 10.210.140.11 with SMTP id n11mr3814171ebd.88.1250545238360; Mon, 
	17 Aug 2009 14:40:38 -0700 (PDT)
In-Reply-To: <25013023.post@talk.nabble.com>
References: <25008761.post@talk.nabble.com> <25013023.post@talk.nabble.com>
From: Jingkei Ly <jly.list@googlemail.com>
Date: Mon, 17 Aug 2009 22:40:18 +0100
X-Google-Sender-Auth: 8e0169b3e6aee523
Message-ID: <c238cbb50908171440j61017f30sdda8dc960c1eed7@mail.gmail.com>
Subject: Re: Percentage calculation?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015174c3d84b543f104715d4014
X-Virus-Checked: Checked by ClamAV on apache.org

--0015174c3d84b543f104715d4014
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

If the counter method doesn't work, I've used a slightly hacky way to do
something like this in the past with the 0.19 API.

In the Mapper I kept an instance variable keeping the count, and in the
close() method I wrote out a file unique to each mapper task containing the
final value of the instance variable.

Then in the Reducers it would read in all the values and aggregate them
together to give you the total count across all mappers. It relies on the
fact that the Reducers don't start before all the Mappers have finished.

i.e. in pseudo-code

class Mapper {
    int inputWords = 0;

    map(key, value){
         inputWords += value;
    }

    close() {
         // write out inputWords to a file unique to this mapper task
    }
}

class Reducer {
    int totalInputWords = 0;

    reduce() {
        if (firstTime)  {
            for all inputWordFiles, f {
                 int mapperInputWord = f.readInt();
                 totalInputWords += mapperInputWord;
            }
        }
        // use totalInputWords to calculate percentage
    }

}

Hope that makes sense.

2009/8/17 tigertail <tyczjs@yahoo.com>

>
> Can sb help please? I would expect there must be some easy way to do that.
>
> Some corrections,
> In reducer I do context.getCounter(Counters.INPUT_WORDS).getValue();
> But it does not work. it always returns 0.
>
>
> tigertail wrote:
> >
> > Hi Hadoop/MapReduce experts,
> >
> > My question might be naive, But I am really stuck here and I am looking
> > forward to get helps/advises from you.
> >
> > I have an input file like
> > key1, 2
> > key2, 1
> > key1, 1
> > key3, 1
> >
> > It is easy to write a M/R code to calculate the count for each key and
> > output sth like
> > key1, 3
> > key2, 1
> > key3, 1
> >
> > But, how I can calculate the percentage of each key over all keys, with
> > the above input, I would expect to get the output as
> > key1, 0.60
> > key2, 0.20
> > key3, 0.20
> >
> > One naive method is to calculate the total count (5 with the above input)
> > which is saved in a file. Then the file is read in before M/R starts. But
> > it is obviously ugly and slow.
> >
> > I also tried to set a static enum Counters { INPUT_WORDS }
> > In mapper I do context.getCounter(Counters.INPUT_WORDS).increment(1);
> > In reducer I do context.getCounter(Counters.INPUT_WORDS).getValue();
> > But it does not work. it always returns 0.
> >
> > Is there more elegant way?
> >
>
> --
> View this message in context:
> http://www.nabble.com/Percentage-calculation--tp25008761p25013023.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>
>

--0015174c3d84b543f104715d4014--

From common-user-return-16822-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 22:23:35 2009
Return-Path: <common-user-return-16822-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 38544 invoked from network); 17 Aug 2009 22:23:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 22:23:34 -0000
Received: (qmail 48028 invoked by uid 500); 17 Aug 2009 21:21:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 47938 invoked by uid 500); 17 Aug 2009 21:21:52 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 47924 invoked by uid 99); 17 Aug 2009 21:21:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 21:21:52 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 21:21:42 +0000
Received: from thickbeside-lm.corp.yahoo.com (thickbeside-lm.corp.yahoo.com [10.72.109.129])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7HLL3wl054767;
	Mon, 17 Aug 2009 14:21:03 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:from:to:content-type:
	content-transfer-encoding:subject:mime-version:date:x-mailer;
	b=M8e57rL2JVwVEwPTXNC1W4Rhpg0MQHo2OScyKQlubWco0+Ab6pb+gBblY26nrsXJ
Message-Id: <F98D6F45-DEA7-4B70-8F1B-BFFA423C52C4@yahoo-inc.com>
From: Nigel Daley <ndaley@yahoo-inc.com>
To: general@hadoop.apache.org, common-user@hadoop.apache.org
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Subject: Impact of MS search deal on Y! Hadoop development
Mime-Version: 1.0 (Apple Message framework v935.3)
Date: Mon, 17 Aug 2009 14:21:03 -0700
X-Mailer: Apple Mail (2.935.3)
X-Virus-Checked: Checked by ClamAV on apache.org

Ok, this is old news now...but we continue to get questions.  For  
those that didn't see it, Eric Baldeschwieler wrote a blog a couple  
weeks ago on Yahoo!'s continued strong investment in Hadoop.

http://developer.yahoo.net/blogs/hadoop/2009/07/news_flash_hadoop_development.html

Nige

From common-user-return-16824-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 22:48:23 2009
Return-Path: <common-user-return-16824-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 52131 invoked from network); 17 Aug 2009 22:48:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 22:48:23 -0000
Received: (qmail 61813 invoked by uid 500); 17 Aug 2009 22:48:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 61704 invoked by uid 500); 17 Aug 2009 22:48:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 61694 invoked by uid 99); 17 Aug 2009 22:48:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 22:48:40 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cubicdesign@gmail.com designates 209.85.219.214 as permitted sender)
Received: from [209.85.219.214] (HELO mail-ew0-f214.google.com) (209.85.219.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 22:48:29 +0000
Received: by ewy10 with SMTP id 10so3377356ewy.37
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 15:48:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:date:from
         :user-agent:mime-version:to:subject:references:in-reply-to
         :content-type;
        bh=jBK35OxVx1z3H99IZgj2NpFqvWfTFbaUXBuwtyw5cJE=;
        b=x1FBj1JxXLegyC18jXulAOzsCLvPfhIe5i1ky1FGUWAk75F56t2WhSX/zGIByTsXhx
         6Nxh0t2Zak/+Hwyhh9+6Tm+WpQAhcs6pmy8K0UJpeHg58MLRQjqNKAt6hbjeTLjNXLs6
         F8T3Qq6CwEQBYpEQaJeOSoO99noDE1pEr4xz8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type;
        b=Erc1k+QpdbwiKYoqrEwQNAzLSX0pORrTXxQyZF4lecr8NLw6BmeZ6zX8Fyd3CGq5Sl
         erxE0NKr5uLX4PJV6j1Jj7nhjZ9wCB7YiCexVLSn9oMNB+YhPORcgjx3QZ9ya+Ikc/WF
         iuMGlqMp2YtcxRYllbCSzuJ/PSpsyKnJizm5Y=
Received: by 10.210.111.6 with SMTP id j6mr431262ebc.62.1250549288420;
        Mon, 17 Aug 2009 15:48:08 -0700 (PDT)
Received: from ?192.168.220.104? (host-091-096-211-158.ewe-ip-backbone.de [91.96.211.158])
        by mx.google.com with ESMTPS id 5sm842420eyf.48.2009.08.17.15.48.07
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Mon, 17 Aug 2009 15:48:07 -0700 (PDT)
Message-ID: <4A89DE24.4030004@Gmail.com>
Date: Tue, 18 Aug 2009 00:48:04 +0200
From: CubicDesign <cubicdesign@gmail.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Ubuntu/Hadoop incompatibilities?
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>	 <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>	 <4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu>	 <4A899499.4080902@yahoo-inc.com> <4A899803.9090108@gmail.com>	 <4A89BEAC.9070306@Gmail.com> <77d4e5730908171358y19c91811kbad90fbd97e6e775@mail.gmail.com>
In-Reply-To: <77d4e5730908171358y19c91811kbad90fbd97e6e775@mail.gmail.com>
Content-Type: multipart/alternative;
 boundary="------------030208090004000309010102"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------030208090004000309010102
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Solved.
It was a bug in Hadoop 020. There is a PATCH file available to fix this 
bug in v0.20. The bug was definitively fixed in v0.21.

Sorry, I cannot post the exact link (I don't have access to the link 
right now) but if anybody else has the same error, it should search the 
Apache web site. The patch file can be semi-automatically applied using 
the "patch" command.

:)

Dali Kilani wrote:
> Can you double check that your data node doesn't have the same /etc/hosts
> issue mentioned above in the thread? (i.e. machine name resolves to
> 127.0.0.1)
> Dali
> On Mon, Aug 17, 2009 at 1:33 PM, CubicDesign <cubicdesign@gmail.com> wrote:
>
>   
>> Thank you all for your answers.
>>
>> My problem with Hadoop on Ubuntu is that I cannot make the DataNode server
>> to work properly (at least this is where I think the error is). I get an
>> "File jobtracker.info could only be replicated to 0 nodes instead of 1"
>> error message. All other servers are running fine. I am running Hadoop in a
>> single (test) machine.
>>
>>
>> The results for jps and netstats are:
>>
>>
>> jps
>> 4465 NameNode
>> 4553 DataNode
>> 5105 Jps
>> 4717 JobTracker
>> 4649 SecondaryNameNode
>> 4807 TaskTracker
>>
>>
>>   sudo netstat -plten | grep java
>> tcp        0      0 0.0.0.0:50722           0.0.0.0:*               LISTEN
>>      1000       13858       4553/java      tcp        0      0
>> 0.0.0.0:50020           0.0.0.0:*               LISTEN      1000
>> 15130       4553/java      tcp        0      0 127.0.0.1:54310
>> 0.0.0.0:*               LISTEN      1000       13564       4465/java
>>  tcp        0      0 127.0.0.1:54311         0.0.0.0:*
>> LISTEN      1000       14571       4717/java      tcp        0      0
>> 0.0.0.0:59080           0.0.0.0:*               LISTEN      1000
>> 14547       4717/java      tcp        0      0 0.0.0.0:50090
>> 0.0.0.0:*               LISTEN      1000       14943       4649/java
>>  tcp        0      0 127.0.0.1:40555         0.0.0.0:*
>> LISTEN      1000       15057       4807/java      tcp        0      0
>> 0.0.0.0:50060           0.0.0.0:*               LISTEN      1000
>> 15031       4807/java      tcp        0      0 0.0.0.0:47661
>> 0.0.0.0:*               LISTEN      1000       14247       4649/java
>>  tcp        0      0 0.0.0.0:50030           0.0.0.0:*
>> LISTEN      1000       14941       4717/java      tcp        0      0
>> 0.0.0.0:57839           0.0.0.0:*               LISTEN      1000
>> 13514       4465/java      tcp        0      0 0.0.0.0:50070
>> 0.0.0.0:*               LISTEN      1000       14533       4465/java
>>  tcp        0      0 0.0.0.0:50010           0.0.0.0:*
>> LISTEN      1000       14765       4553/java      tcp        0      0
>> 0.0.0.0:50075           0.0.0.0:*               LISTEN      1000
>> 14946       4553/java
>>
>>     
>
>
>
>   

--------------030208090004000309010102--

From common-user-return-16825-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 17 22:52:13 2009
Return-Path: <common-user-return-16825-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 53270 invoked from network); 17 Aug 2009 22:52:13 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 17 Aug 2009 22:52:13 -0000
Received: (qmail 69545 invoked by uid 500); 17 Aug 2009 22:52:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 69468 invoked by uid 500); 17 Aug 2009 22:52:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 69458 invoked by uid 99); 17 Aug 2009 22:52:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 22:52:29 +0000
X-ASF-Spam-Status: No, hits=4.9 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_NEUTRAL,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 17 Aug 2009 22:52:20 +0000
Received: by gxk27 with SMTP id 27so4234751gxk.12
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 15:51:58 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.91.7.17 with SMTP id k17mr3169725agi.24.1250549518606; Mon, 17 
	Aug 2009 15:51:58 -0700 (PDT)
In-Reply-To: <4A89DE24.4030004@Gmail.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com> 
	<4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com> 
	<99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com> 
	<4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu> 
	<4A899499.4080902@yahoo-inc.com> <4A899803.9090108@gmail.com> 
	<4A89BEAC.9070306@Gmail.com> <77d4e5730908171358y19c91811kbad90fbd97e6e775@mail.gmail.com> 
	<4A89DE24.4030004@Gmail.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Mon, 17 Aug 2009 15:51:38 -0700
Message-ID: <45f85f70908171551ycd65748n7ba5d7899d721020@mail.gmail.com>
Subject: Re: Ubuntu/Hadoop incompatibilities?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636284b68d4a58204715e3f6f
X-Virus-Checked: Checked by ClamAV on apache.org

--001636284b68d4a58204715e3f6f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

When you get a chance, could you please send out the JIRA that had this
patch? Is it committed to branch-20? If not, it probably should be before
the 0.20.1 release.

-Todd

On Mon, Aug 17, 2009 at 3:48 PM, CubicDesign <cubicdesign@gmail.com> wrote:

> Solved.
> It was a bug in Hadoop 020. There is a PATCH file available to fix this bug
> in v0.20. The bug was definitively fixed in v0.21.
>
> Sorry, I cannot post the exact link (I don't have access to the link right
> now) but if anybody else has the same error, it should search the Apache web
> site. The patch file can be semi-automatically applied using the "patch"
> command.
>
> :)
>
>
> Dali Kilani wrote:
>
>> Can you double check that your data node doesn't have the same /etc/hosts
>> issue mentioned above in the thread? (i.e. machine name resolves to
>> 127.0.0.1)
>> Dali
>> On Mon, Aug 17, 2009 at 1:33 PM, CubicDesign <cubicdesign@gmail.com>
>> wrote:
>>
>>
>>
>>> Thank you all for your answers.
>>>
>>> My problem with Hadoop on Ubuntu is that I cannot make the DataNode
>>> server
>>> to work properly (at least this is where I think the error is). I get an
>>> "File jobtracker.info could only be replicated to 0 nodes instead of 1"
>>> error message. All other servers are running fine. I am running Hadoop in
>>> a
>>> single (test) machine.
>>>
>>>
>>> The results for jps and netstats are:
>>>
>>>
>>> jps
>>> 4465 NameNode
>>> 4553 DataNode
>>> 5105 Jps
>>> 4717 JobTracker
>>> 4649 SecondaryNameNode
>>> 4807 TaskTracker
>>>
>>>
>>>  sudo netstat -plten | grep java
>>> tcp        0      0 0.0.0.0:50722           0.0.0.0:*
>>> LISTEN
>>>     1000       13858       4553/java      tcp        0      0
>>> 0.0.0.0:50020           0.0.0.0:*               LISTEN      1000
>>> 15130       4553/java      tcp        0      0 127.0.0.1:54310
>>> 0.0.0.0:*               LISTEN      1000       13564       4465/java
>>>  tcp        0      0 127.0.0.1:54311         0.0.0.0:*
>>> LISTEN      1000       14571       4717/java      tcp        0      0
>>> 0.0.0.0:59080           0.0.0.0:*               LISTEN      1000
>>> 14547       4717/java      tcp        0      0 0.0.0.0:50090
>>> 0.0.0.0:*               LISTEN      1000       14943       4649/java
>>>  tcp        0      0 127.0.0.1:40555         0.0.0.0:*
>>> LISTEN      1000       15057       4807/java      tcp        0      0
>>> 0.0.0.0:50060           0.0.0.0:*               LISTEN      1000
>>> 15031       4807/java      tcp        0      0 0.0.0.0:47661
>>> 0.0.0.0:*               LISTEN      1000       14247       4649/java
>>>  tcp        0      0 0.0.0.0:50030           0.0.0.0:*
>>> LISTEN      1000       14941       4717/java      tcp        0      0
>>> 0.0.0.0:57839           0.0.0.0:*               LISTEN      1000
>>> 13514       4465/java      tcp        0      0 0.0.0.0:50070
>>> 0.0.0.0:*               LISTEN      1000       14533       4465/java
>>>  tcp        0      0 0.0.0.0:50010           0.0.0.0:*
>>> LISTEN      1000       14765       4553/java      tcp        0      0
>>> 0.0.0.0:50075           0.0.0.0:*               LISTEN      1000
>>> 14946       4553/java
>>>
>>>
>>>
>>
>>
>>
>>
>>
>

--001636284b68d4a58204715e3f6f--

From common-user-return-16826-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 00:18:09 2009
Return-Path: <common-user-return-16826-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80060 invoked from network); 18 Aug 2009 00:18:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 00:18:09 -0000
Received: (qmail 50060 invoked by uid 500); 18 Aug 2009 00:18:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 49982 invoked by uid 500); 18 Aug 2009 00:18:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 49972 invoked by uid 99); 18 Aug 2009 00:18:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 00:18:25 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vliaskov@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 00:18:14 +0000
Received: by vws40 with SMTP id 40so2739843vws.2
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 17:17:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=Y5HQ+EnFqbdVh5Pw7H2qSc8hCOm6dKqR6M86UI10WOo=;
        b=EvB9M6+gHWM2wYGsag7HOd24tZ0sHin30jH3mJMMitvvg/qUbuJ4lc5nm1dFoWf8Z0
         wM3HFC85/taqAY8H/v0g5KS+hgE1lK+zW19KN0eIE7A3w1CqMWjRSJFTSqm7Sqv0PnlS
         Vomlh+TTSXo0aeQFP1InlzK0uIQ+UWFNvXbuw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=SeZ2VUy3XLZgcuilMNVU0tcXD5vpqrILVdcpZ0aObrP5w8IwoIA99FZOu/TWhpB5jI
         q6c+hD7dC4HLVeiN1jV2C+iXnxMh3VJ6tTB1Mir+tWhC9ld6x93HEo/WesNHVhEnD0yh
         iKdUgZqzrmOvhMfEF5emrFRIMDxs+Y4JfP5FQ=
MIME-Version: 1.0
Received: by 10.220.58.208 with SMTP id i16mr5751783vch.20.1250554671664; Mon, 
	17 Aug 2009 17:17:51 -0700 (PDT)
Date: Mon, 17 Aug 2009 19:17:51 -0500
Message-ID: <bec373e0908171717r66a736efkbd384530718b4c86@mail.gmail.com>
Subject: utilizing all cores on single-node hadoop
From: Vasilis Liaskovitis <vliaskov@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

I am a beginner trying to setup a few simple hadoop tests on a single
node before moving on to a cluster. I am just using the simple
wordcount example for now. My question is what's the best way to
guarantee utilization of all cores on a single-node? So assuming a
single node with 16-cores what are the suggested values for:

mapred.map.tasks
mapred.reduce.tasks
mapred.tasktracker.map.tasks.maximum
mapred.tasktracker.map.tasks.maxium

I found an old similar thread
http://www.mail-archive.com/hadoop-user@lucene.apache.org/msg00152.html
and I have followed similar settings for my 16-core system (e.g.
map.tasks=reduce.tasks=90 and map.tasks.maximum=100), however I always
see only 3-4 cores utilized using top.

- The description for mapred.map.tasks says "Ignored when
mapred.job.tracker is "local" ", and in my case
mapred.job.tracker=hdfs://localhost:54311
is it possible that the map.tasks and reduce.tasks I am setting are
being ignored? How can I verify this? Is there a way to enforce my
values even on a localhost scenario like this?

- Are there other config options/values that I need to set besides the
4 I mentioned above?

- Also is it possible that for short tasks, I won't see full
utilization of all cores anyway? Something along those lines is
mentioned in an issue a year ago:
http://issues.apache.org/jira/browse/HADOOP-3136
"If the individual tasks are very short i.e. run for less than the
heartbeat interval the TaskTracker serially runs one task at a time"

I am using hadoop-0.19.2

thanks for any guidance,

- Vasilis

From common-user-return-16827-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 00:25:45 2009
Return-Path: <common-user-return-16827-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 87524 invoked from network); 18 Aug 2009 00:25:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 00:25:45 -0000
Received: (qmail 55124 invoked by uid 500); 18 Aug 2009 00:26:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 55043 invoked by uid 500); 18 Aug 2009 00:26:01 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 55033 invoked by uid 99); 18 Aug 2009 00:26:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 00:26:01 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [208.97.132.202] (HELO spunkymail-a4.g.dreamhost.com) (208.97.132.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 00:25:52 +0000
Received: from enigma (96-26-232-193.sea.clearwire-dns.net [96.26.232.193])
	(using TLSv1 with cipher DHE-RSA-AES128-SHA (128/128 bits))
	(No client certificate requested)
	by spunkymail-a4.g.dreamhost.com (Postfix) with ESMTP id D902D3BA10
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 17:25:30 -0700 (PDT)
From: Phil Hagelberg <phil@hagelb.org>
To: common-user@hadoop.apache.org
Subject: Re-using output directories
Date: Mon, 17 Aug 2009 17:25:28 -0700
Message-ID: <87fxbqhssn.fsf@hagelb.org>
User-Agent: Gnus/5.13 (Gnus v5.13) Emacs/23.1.50 (gnu/linux)
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
X-Virus-Checked: Checked by ClamAV on apache.org


I'm trying to write a Hadoop job that will add documents to an existing
lucene index. My initial idea was to set the index as the output
directory and create and IndexWriter based on
FileOutputFormat.getOutputPath(context), but this requires that the
output path not exist when the job begins. I also had the idea to use
the job's working directory instead, but it appears the job _must_ be
configured with an output path; it can't be left unset.

I'm thinking the answer would be to set it to a bogus tempfile and
delete that, but that seems awful hacky. There's got to be a better way
to handle this, right?

-Phil

From common-user-return-16828-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 02:25:48 2009
Return-Path: <common-user-return-16828-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 41009 invoked from network); 18 Aug 2009 02:25:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 02:25:48 -0000
Received: (qmail 55326 invoked by uid 500); 18 Aug 2009 02:26:05 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 55239 invoked by uid 500); 18 Aug 2009 02:26:05 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 55229 invoked by uid 99); 18 Aug 2009 02:26:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 02:26:05 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of eddymier@gmail.com designates 209.85.200.172 as permitted sender)
Received: from [209.85.200.172] (HELO wf-out-1314.google.com) (209.85.200.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 02:25:57 +0000
Received: by wf-out-1314.google.com with SMTP id 23so840182wfg.2
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 19:25:37 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=3ILCqsA2hoN9JVHPTCClsxPZCVMlft9/6FEXomTB2QE=;
        b=YpbkXxa8NEoVZceBVxQX3Nqy/Pdy++DaPH/FGrUIkc3uIoY//opjSNJptGzIqenqcF
         zI2EGnfhEBLtPxLhBY+CGQNaZz+zLcRd7jxqeFPALG56UT8gyzLkWMEAC9/UAq50To/S
         NvIZJqmI8VRfcNS5rNsQu2dTz65eEP7vHmY7w=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=ddM1jA69uP/MzFcqWp5bAygkxPE0vu1SeEzS3VH3V2QuW4D5GEocx7S0kgduXbPxLU
         CnfGTqh4crsU/FLXq7PF+b2m4xj0vgFVi4BNt5570G/jshcW2DK7o/12XxKECCnkNwW3
         RrdICpjuD2DavzltrefQODmaZaDSoNXXUlhqw=
MIME-Version: 1.0
Received: by 10.142.210.13 with SMTP id i13mr818245wfg.304.1250562337049; Mon, 
	17 Aug 2009 19:25:37 -0700 (PDT)
In-Reply-To: <d6d7c4410908051022j74ff9e67j37a09de6657b77ba@mail.gmail.com>
References: <b4e9dc6e0908050609pe4f9506ib79bdbfe927f14d5@mail.gmail.com>
	 <d6d7c4410908051022j74ff9e67j37a09de6657b77ba@mail.gmail.com>
Date: Tue, 18 Aug 2009 10:25:37 +0800
Message-ID: <b4e9dc6e0908171925n5e57e3f3vd5392e962dc466d1@mail.gmail.com>
Subject: Re: questions about HDFS file access synchronization
From: "Zhang Bingjun (Eddy)" <eddymier@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd32eaade8c090471613bc7
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd32eaade8c090471613bc7
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hi Aaron,

Thank you so much for your reply!

After taking your notes, I realize it may not be necessary to enforce file
lock synchronization on the file system level (HDFS here). In the
traditional abstraction of file systems, the file access synchronization is
the programmers' work to make sure their critical sections are correctly set
so that the concurrent programs do not write the same files at the same time
(one example of access synchronization).

File lock mechanism for access synchronization or data consistency becomes
necessary only when we move to database abstraction on top of file systems.

That's what I think about the traditional designs or abstractions of file
systems and databases. Please correct me if I am wrong.

Based on the above thoughts, we will use HDFS by taking the traditional file
system abstraction (without file lock). If we really need the file access
synchronization, we may go for HBase.

Thanks again for your reply! It is really inspiring. Please shot your
comments if I am wrong in any points. :)

Best regards,
Zhang Bingjun (Eddy)

E-mail: eddymier@gmail.com, bingjun@nus.edu.sg, bingjun@comp.nus.edu.sg
Tel No: +65-96188110 (M)


On Thu, Aug 6, 2009 at 1:22 AM, Aaron Kimball <aaron@cloudera.com> wrote:

> On Wed, Aug 5, 2009 at 6:09 AM, Zhang Bingjun (Eddy) <eddymier@gmail.com
> >wrote:
>
> > Hi All,
> >
> > I am quite new to Hadoop. May I ask a simple question about HDFS file
> > access
> > synchronization?
> >
> > For some very typical scenarios below, how does HDFS respond? Is there a
> > way
> > to synchronize file access in HDFS?
> >
> > A tries to read a file currently being written by B.
>
>
> There is no sync() call in HDFS. A will read whatever portion of B's data
> has already been committed to disk by the datanode. It is unspecified how
> much data this will contain. It may be variable depending on which replica
> of the file A is reading. After B close()'s the file, all the data will be
> available to A.
>
>
> >
> > A tries to write a file currently being written by B.
>
>
> This will fail. HDFS does not allow multiple writers to a file. The
> FileSystem.create() call used by A to open the file for write access will
> throw IOException.
>
>
> >
> > A tries to write a file currently being read by B.
>
>
> This will fail. HDFS does not allow file updates, so if the file already
> exists and B is reading it, the FileSystem.create() call used by A will
> fail
> with IOException.
>
>
> >
> >
> > We plan to put some shared data in HDFS so that multiple applications can
> > share the data between them. The ideal case is that the underlying
> > distributed file system (HDFS here) will provide file access
> > synchronization
> > so that applications know when they can or cannot operate on a certain
> > file.
> > Is this way of thinking correct? What is the typical design for this kind
> > of
> > application scenario?
>
>
> You'll have to think carefully. You can't update files. There is also no
> equivalent of flock(), so you can't use files as locks for exclusive access
> to some part of a work flow. If that's what you need, you may want to look
> at the ZooKeeper project and see if you can't integrate ZK into your
> system.
> ZK is specifically designed to handle locking, mutual exclusion, and other
> distributed synchronization problems.
>
>
>
> >
> >
> > I am quite confused. Definitely need to read more about HDFS and other
> > distributed file systems. But before that, I would appreciate very much
> the
> > input from experts in the mailing list.
>
>
> http://hadoop.apache.org/common/docs/r0.20.0/hdfs_user_guide.html and
> http://hadoop.apache.org/common/docs/r0.20.0/hdfs_design.html are good
> places to start.
>
>
> >
> >
> > Thanks a lot!
> >
> > Best regards,
> > Zhang Bingjun (Eddy)
> >
> > E-mail: eddymier@gmail.com, bingjun@nus.edu.sg, bingjun@comp.nus.edu.sg
> > Tel No: +65-96188110 (M)
> >
>
> Cheers,
> - Aaron
>

--000e0cd32eaade8c090471613bc7--

From common-user-return-16829-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 05:07:21 2009
Return-Path: <common-user-return-16829-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 95409 invoked from network); 18 Aug 2009 05:07:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 05:07:21 -0000
Received: (qmail 87295 invoked by uid 500); 18 Aug 2009 05:07:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87238 invoked by uid 500); 18 Aug 2009 05:07:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87228 invoked by uid 99); 18 Aug 2009 05:07:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 05:07:37 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.216.190 as permitted sender)
Received: from [209.85.216.190] (HELO mail-px0-f190.google.com) (209.85.216.190)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 05:07:28 +0000
Received: by pxi28 with SMTP id 28so1553702pxi.2
        for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 22:07:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=YzJOxGrRzl9rGYvB2LQhDwAjLMdSLgT3TdIc8cfkJ+g=;
        b=qnivP7piXXH+VNXEBlv3GYXDdGSPP3tCfiNHSl8mGY435tGeGp0G682l/1Q+6jM4L6
         R9sTFJHKO7Wj5j9doVtpEdMRTgOpYnJ6JqY0WNnX4B5HM2dHN/CtdcsrILXiUh1AUTow
         xvJd2IQ1zMRob6oAreSLYDBIiKJhqT+exo3f0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=RTkEESheIWBSENg7eIQcYiVL2E0L4haAKiR3v8vCdzqR2zYzGAnEGsTCK1cKHwcqc8
         I3auSar35gTXX1MgqvkP2XAyDMcBa0x4Z2b9KO019vEx6bnRdh/C2RFQH9jeRe5aojzr
         MUUIw596sfi49LHgIx1fBOyPYkLRN1/uyNKkU=
MIME-Version: 1.0
Received: by 10.143.21.35 with SMTP id y35mr827894wfi.210.1250572028084; Mon, 
	17 Aug 2009 22:07:08 -0700 (PDT)
In-Reply-To: <bec373e0908171717r66a736efkbd384530718b4c86@mail.gmail.com>
References: <bec373e0908171717r66a736efkbd384530718b4c86@mail.gmail.com>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Tue, 18 Aug 2009 10:36:48 +0530
Message-ID: <e01b80590908172206g1fc04218p7df876f5b7b08cab@mail.gmail.com>
Subject: Re: utilizing all cores on single-node hadoop
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00504502cb1e8000fd0471637d64
X-Virus-Checked: Checked by ClamAV on apache.org

--00504502cb1e8000fd0471637d64
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Vasilis,

Here's some info that I know:

mapred.map.tasks - this is a job-specific setting. This is just a hint to
InputFormat as to how many InputSplits (and hence MapTasks) you want for
your job. The default InputFormat classes usually keep each split size to
the HDFS block size (64MB default). So if your input data is less than 64
MB, it will just result in only 1 split and hence 1 MapTask only.

mapred.reduce.tasks - this is also a job-specific setting.

mapred.tasktracker.map.tasks.maximum
mapred.tasktracker.reduce.tasks.maximum

The above 2 are tasktracker-specific config options and determine how many
"simultaneous" MapTasks and ReduceTasks run on each TT. Ideally on a 8-core
box, you would want to set map.tasks.maximum to something like 6 and
reduce.tasks.maximum to 4 to utilize all the 8 cores to the maximum (there's
a little bit of over-subscription to account for tasks idling while doing
I/O).

In the web admin console, how many map-tasks and reduce-tasks are reported
to have been launched for your job?

Cheers,
Harish

On Tue, Aug 18, 2009 at 5:47 AM, Vasilis Liaskovitis <vliaskov@gmail.com>wrote:

> Hi,
>
> I am a beginner trying to setup a few simple hadoop tests on a single
> node before moving on to a cluster. I am just using the simple
> wordcount example for now. My question is what's the best way to
> guarantee utilization of all cores on a single-node? So assuming a
> single node with 16-cores what are the suggested values for:
>
> mapred.map.tasks
> mapred.reduce.tasks
>
mapred.tasktracker.map.tasks.maximum
> mapred.tasktracker.map.tasks.maxium
>

> I found an old similar thread
> http://www.mail-archive.com/hadoop-user@lucene.apache.org/msg00152.html
> and I have followed similar settings for my 16-core system (e.g.
> map.tasks=reduce.tasks=90 and map.tasks.maximum=100), however I always
> see only 3-4 cores utilized using top.
>
> - The description for mapred.map.tasks says "Ignored when
> mapred.job.tracker is "local" ", and in my case
> mapred.job.tracker=hdfs://localhost:54311
> is it possible that the map.tasks and reduce.tasks I am setting are
> being ignored? How can I verify this? Is there a way to enforce my
> values even on a localhost scenario like this?
>
> - Are there other config options/values that I need to set besides the
> 4 I mentioned above?
>
> - Also is it possible that for short tasks, I won't see full
> utilization of all cores anyway? Something along those lines is
> mentioned in an issue a year ago:
> http://issues.apache.org/jira/browse/HADOOP-3136
> "If the individual tasks are very short i.e. run for less than the
> heartbeat interval the TaskTracker serially runs one task at a time"
>
> I am using hadoop-0.19.2
>
> thanks for any guidance,
>
> - Vasilis
>



-- 
Harish Mallipeddi
http://blog.poundbang.in

--00504502cb1e8000fd0471637d64--

From common-user-return-16830-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 05:37:41 2009
Return-Path: <common-user-return-16830-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 12063 invoked from network); 18 Aug 2009 05:37:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 05:37:41 -0000
Received: (qmail 20322 invoked by uid 500); 18 Aug 2009 05:37:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20226 invoked by uid 500); 18 Aug 2009 05:37:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20215 invoked by uid 99); 18 Aug 2009 05:37:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 05:37:57 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.20] (HELO mrout1-b.corp.re1.yahoo.com) (69.147.107.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 05:37:44 +0000
Received: from EGL-EX07CAS01.ds.corp.yahoo.com (egl-ex07cas01.eglbp.corp.yahoo.com [203.83.248.208])
	by mrout1-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7I5agQ8090592
	for <common-user@hadoop.apache.org>; Mon, 17 Aug 2009 22:36:43 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=w8J5rLpbUzWSRlfuveTCzDwRrIasjO9InsuH49uPcawy+a5bb4m82usFKpuAxHBC
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.206]) by
 EGL-EX07CAS01.ds.corp.yahoo.com ([203.83.248.215]) with mapi; Tue, 18 Aug
 2009 11:06:42 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Tue, 18 Aug 2009 11:05:35 +0530
Subject: RE: utilizing all cores on single-node hadoop
Thread-Topic: utilizing all cores on single-node hadoop
Thread-Index: Acofwv8MSy8sdJcUTrOgY1WaQuwegQAAnLpA
Message-ID: <616DA47B2EF5B944B91846785B512FF4CFADEA6F56@EGL-EX07VS01.ds.corp.yahoo.com>
References: <bec373e0908171717r66a736efkbd384530718b4c86@mail.gmail.com>
 <e01b80590908172206g1fc04218p7df876f5b7b08cab@mail.gmail.com>
In-Reply-To: <e01b80590908172206g1fc04218p7df876f5b7b08cab@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

While setting mapred.tasktracker.map.tasks.maximum and mapred.tasktracker.r=
educe.tasks.maximum, please consider the memory usage your application migh=
t have since all tasks will be competing for the same and might reduce over=
all performance.

Thanks,
Amogh
-----Original Message-----
From: Harish Mallipeddi [mailto:harish.mallipeddi@gmail.com]=20
Sent: Tuesday, August 18, 2009 10:37 AM
To: common-user@hadoop.apache.org
Subject: Re: utilizing all cores on single-node hadoop

Hi Vasilis,

Here's some info that I know:

mapred.map.tasks - this is a job-specific setting. This is just a hint to
InputFormat as to how many InputSplits (and hence MapTasks) you want for
your job. The default InputFormat classes usually keep each split size to
the HDFS block size (64MB default). So if your input data is less than 64
MB, it will just result in only 1 split and hence 1 MapTask only.

mapred.reduce.tasks - this is also a job-specific setting.

mapred.tasktracker.map.tasks.maximum
mapred.tasktracker.reduce.tasks.maximum

The above 2 are tasktracker-specific config options and determine how many
"simultaneous" MapTasks and ReduceTasks run on each TT. Ideally on a 8-core
box, you would want to set map.tasks.maximum to something like 6 and
reduce.tasks.maximum to 4 to utilize all the 8 cores to the maximum (there'=
s
a little bit of over-subscription to account for tasks idling while doing
I/O).

In the web admin console, how many map-tasks and reduce-tasks are reported
to have been launched for your job?

Cheers,
Harish

On Tue, Aug 18, 2009 at 5:47 AM, Vasilis Liaskovitis <vliaskov@gmail.com>wr=
ote:

> Hi,
>
> I am a beginner trying to setup a few simple hadoop tests on a single
> node before moving on to a cluster. I am just using the simple
> wordcount example for now. My question is what's the best way to
> guarantee utilization of all cores on a single-node? So assuming a
> single node with 16-cores what are the suggested values for:
>
> mapred.map.tasks
> mapred.reduce.tasks
>
mapred.tasktracker.map.tasks.maximum
> mapred.tasktracker.map.tasks.maxium
>

> I found an old similar thread
> http://www.mail-archive.com/hadoop-user@lucene.apache.org/msg00152.html
> and I have followed similar settings for my 16-core system (e.g.
> map.tasks=3Dreduce.tasks=3D90 and map.tasks.maximum=3D100), however I alw=
ays
> see only 3-4 cores utilized using top.
>
> - The description for mapred.map.tasks says "Ignored when
> mapred.job.tracker is "local" ", and in my case
> mapred.job.tracker=3Dhdfs://localhost:54311
> is it possible that the map.tasks and reduce.tasks I am setting are
> being ignored? How can I verify this? Is there a way to enforce my
> values even on a localhost scenario like this?
>
> - Are there other config options/values that I need to set besides the
> 4 I mentioned above?
>
> - Also is it possible that for short tasks, I won't see full
> utilization of all cores anyway? Something along those lines is
> mentioned in an issue a year ago:
> http://issues.apache.org/jira/browse/HADOOP-3136
> "If the individual tasks are very short i.e. run for less than the
> heartbeat interval the TaskTracker serially runs one task at a time"
>
> I am using hadoop-0.19.2
>
> thanks for any guidance,
>
> - Vasilis
>



--=20
Harish Mallipeddi
http://blog.poundbang.in

From common-user-return-16831-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 07:58:19 2009
Return-Path: <common-user-return-16831-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 67714 invoked from network); 18 Aug 2009 07:58:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 07:58:19 -0000
Received: (qmail 95779 invoked by uid 500); 18 Aug 2009 07:58:36 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95707 invoked by uid 500); 18 Aug 2009 07:58:36 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95697 invoked by uid 500); 18 Aug 2009 07:58:36 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 95694 invoked by uid 99); 18 Aug 2009 07:58:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 07:58:36 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sugandha.n87@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 07:58:27 +0000
Received: by yxe15 with SMTP id 15so4734066yxe.5
        for <core-user@hadoop.apache.org>; Tue, 18 Aug 2009 00:58:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=Y+kKqVuQ7pm5944O+vP9OLmNppFuEpdbuOjAXYVgees=;
        b=BWjNcahh6Qzkdmh8WECSmqFeLLNDUg7/gG1GZp8oAUDW7bG2n0eI534XhRgQC4dcB/
         ukz+/7Sn5fkfiQmSZCsUxFxTebFR5NmaAMaqkXEPZaJpxujq3MAwBe7HOxoLoEASmOTd
         nZVs4um6Gfs5ABZ+06qavwZm71IYiYC9/jKG4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=Z0vYfUf3YKdBRkOuRhV4/Nk+UW9ElKGgSQ3rmvbpB6FXuRPZ0z3fmHbvL7A18N0mPc
         YwHwuO4t+1TfCPI6mTCLr8eG3Eaw4htD3UY1D1sm0ROz7oWZNYZIv6EOZ9rj/+R0N8nF
         zP2n2e5aM2W4KpjCu5pe28U3nh8RWXlicYCqs=
MIME-Version: 1.0
Received: by 10.231.30.204 with SMTP id v12mr1594299ibc.1.1250582285934; Tue, 
	18 Aug 2009 00:58:05 -0700 (PDT)
Date: Tue, 18 Aug 2009 13:28:05 +0530
Message-ID: <6f72e2db0908180058o1c0ad4c5rf80f77c5cff797ac@mail.gmail.com>
Subject: Re: Some issues!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000325575832ea62e1047165e099
X-Virus-Checked: Checked by ClamAV on apache.org

--000325575832ea62e1047165e099
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello!

    I am planning to implement a DFS of that would work on the same lines of
principle as of HDFS but, with some extra features. Like as, Encryption and
decryption of data that would be transferred between remote client and
Hadoop cluster.

   I want to encrypt data before or while placing it in HDFS and then while
retreival of the same, vice versa should happen,i.e; decryption....


Can you please suggest me how to approach for the entire episode?

Regards!
Sugandha

--000325575832ea62e1047165e099--

From common-user-return-16832-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 08:26:13 2009
Return-Path: <common-user-return-16832-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 74905 invoked from network); 18 Aug 2009 08:26:13 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 08:26:13 -0000
Received: (qmail 37576 invoked by uid 500); 18 Aug 2009 08:26:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 37496 invoked by uid 500); 18 Aug 2009 08:26:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 37486 invoked by uid 99); 18 Aug 2009 08:26:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 08:26:29 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of clarkemjj@gmail.com designates 209.85.218.219 as permitted sender)
Received: from [209.85.218.219] (HELO mail-bw0-f219.google.com) (209.85.218.219)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 08:26:21 +0000
Received: by bwz19 with SMTP id 19so3773064bwz.37
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 01:26:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=BB27PazEm5cxsZG/Z9Crh03liSDkfKyw0suCurD8ZBY=;
        b=EaFBia+TMhv8wZ20EawKL+UL4iY27416TbdePqB73wNuUG75TjyupQH6oG4okP+I+Y
         f3fP8tc5nU2I1nBmmkpvyQ0zhJHsFvcq+p9nmONwkus0zU/qIBckXAfWLWBc54FrNrg2
         9Skr1JmE1i7l0SL4VqwCakH67uqeaBhCjxE30=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=nyaxbXtxunUjlJNCkmSTussVA0UjJRLneqFvbBjy7iSsUPcvz+wzn/vvejlOL6YJau
         sdTZ4fNVVpehrDxs0s+xICkzEGtTw/v5JRMjo4NpMGDMbQbjJ5tLjG3UM7l4hI3S7du/
         hQjlTNHVLYteN8j8XPRSz64wUZZuJ598dXQ+Q=
MIME-Version: 1.0
Received: by 10.223.15.86 with SMTP id j22mr1040771faa.47.1250583959856; Tue, 
	18 Aug 2009 01:25:59 -0700 (PDT)
In-Reply-To: <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>
	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>
	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>
	 <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>
Date: Tue, 18 Aug 2009 09:25:59 +0100
Message-ID: <4238036a0908180125o1ceab489m90bb39e77753d720@mail.gmail.com>
Subject: Re: Two output files?
From: John Clarke <clarkemjj@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001517447f0cb066430471664468
X-Virus-Checked: Checked by ClamAV on apache.org

--001517447f0cb066430471664468
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Cheers, that is pretty much what I did except I chose my file name based on
the first few chars of the keys. I have included it below for others looking
for the solution:

==========================================
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.lib.MultipleTextOutputFormat;

public class MyMultipleTextOutputFormat extends
MultipleTextOutputFormat<Text, Text> {

    /**
     * Override so can specify custom file names bases on the key and/or
value
     */
    @Override
    protected String generateFileNameForKeyValue(Text key, Text value,
String name) {

        // here we can choose a name based on the key or value
        String fileName = "output1_" + name;

        if(key.toString().startsWith("sometext")
            fileName = "output2_" + name;

        return fileName;
    }
}

// END


// Define the above as the output format when setting up the JobConf
jobConf.setOutputFormat(MyMultipleTextOutputFormat.class);


// in the Reduce class simply output as before
output.collect(key, val);

==========================================


John.




2009/8/17 Vibhooti Verma <verma.vibhooti@gmail.com>

> Hi John,
>
>
> Here is the example, where you can change the filename specified in the
> conf.
>
> protected String generateFileNameForKeyValue(Object key, Object value,
> String name) {
>
>                return  name.concat(key.toString() + "_" + name);
>
>                return keyBasedName;
>        }
>
>
>
> --
> vibhooti
>
>
>
> On Mon, Aug 17, 2009 at 1:59 PM, John Clarke <clarkemjj@gmail.com> wrote:
>
> > Fantastic, I will try that :) A little push in the right driection helps
> > hugely! I don't have that book yet but I'm planning on getting it.
> >
> > cheers
> > John,
> >
> >
> >
> > 2009/8/14 Kris Jirapinyo <kris.jirapinyo@biz360.com>
> >
> > > Hi John,
> > >     If you have the Hadoop O'Reilly book, look at pg 206 for an
> example.
> > > But basically, you just create a subclass of MultipleTextOutputFormat
> and
> > > then inside it you override generateFileNameForKeyValue (for example)
> to
> > > have the reducer emit the desired filenames.  For each key in the
> > reducer,
> > > it will write the text values to that file.  Make sure in the JobConf
> you
> > > set OutputFormat to your class that extends MultipleTextOutputFormat.
> > >
> > > -- Kris.
> > >
> > > On Fri, Aug 14, 2009 at 7:11 AM, John Clarke <clarkemjj@gmail.com>
> > wrote:
> > >
> > > > Hi,
> > > >
> > > > I want to output two text files from my MapReduce job but I am having
> > > > trouble understanding how to use the MultipleTextOutputFormat class
> to
> > do
> > > > so.
> > > >
> > > > I want to write to the two files depending on the key of each
> key/value
> > > > pair.
> > > >
> > > > In the Reducer how do I tell it to write the different files?
> Normally
> > I
> > > > just do an output.collect(key, val);.
> > > >
> > > > Any help would be most appreciated.
> > > >
> > > > Thanks,
> > > > John
> > > >
> > >
> >
>
>
>
> --
> cheers,
> Vibhooti
>

--001517447f0cb066430471664468--

From common-user-return-16833-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 08:42:16 2009
Return-Path: <common-user-return-16833-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80057 invoked from network); 18 Aug 2009 08:42:16 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 08:42:16 -0000
Received: (qmail 68907 invoked by uid 500); 18 Aug 2009 08:42:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 68817 invoked by uid 500); 18 Aug 2009 08:42:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 68807 invoked by uid 99); 18 Aug 2009 08:42:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 08:42:32 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of enis.soz@gmail.com designates 72.14.220.152 as permitted sender)
Received: from [72.14.220.152] (HELO fg-out-1718.google.com) (72.14.220.152)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 08:42:22 +0000
Received: by fg-out-1718.google.com with SMTP id 13so801541fge.12
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 01:42:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:date:from
         :user-agent:mime-version:to:subject:references:in-reply-to
         :content-type:content-transfer-encoding;
        bh=9wOBuzyBuBtnZllM9TK3KbbchFLK60jDuT/iG5538lc=;
        b=Hjw5crjkvCVAL2JO7JeT9cpUoMHLCLc3AwtNeNQBYO8v7NLXnWrECLrEUHgBEtanPr
         t0OsYAxBFYnP4Tg2V4ODvby+pk9K1zE5CCtSA6BGnMxHUWrMGCO2Ln0pTUsgV2kKq7Yo
         wyLqM3Q0U25g3qwwtljT40TVvQpBy/V8KP6Zc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        b=AaNT9/fuKkwO/amnJuj5o5FJ65KlAqn+dJNu/U3ciTMvaNiSnM1/AhJxAzRVH/5zHS
         tN4qml1brqtXezuThm7uSIdc4Lz68R6U6JIz4wy5ctzh6EDz1P/QWV6mlHozJP5D3eRh
         FyzuD51Nt4lvAy7uws3WrA/GdkxfVhFT3rmpc=
Received: by 10.87.31.28 with SMTP id i28mr3040778fgj.30.1250584921579;
        Tue, 18 Aug 2009 01:42:01 -0700 (PDT)
Received: from ?192.168.2.15? ([85.105.135.220])
        by mx.google.com with ESMTPS id 4sm5682390fgg.14.2009.08.18.01.42.00
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Tue, 18 Aug 2009 01:42:00 -0700 (PDT)
Message-ID: <4A8A6949.4010504@gmail.com>
Date: Tue, 18 Aug 2009 11:41:45 +0300
From: Enis Soztutar <enis.soz@gmail.com>
User-Agent: Thunderbird 2.0.0.19 (X11/20090105)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Re-using output directories
References: <87fxbqhssn.fsf@hagelb.org>
In-Reply-To: <87fxbqhssn.fsf@hagelb.org>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Phil Hagelberg wrote:
> I'm trying to write a Hadoop job that will add documents to an existing
> lucene index. My initial idea was to set the index as the output
> directory and create and IndexWriter based on
> FileOutputFormat.getOutputPath(context), but this requires that the
> output path not exist when the job begins. I also had the idea to use
> the job's working directory instead, but it appears the job _must_ be
> configured with an output path; it can't be left unset.
>
> I'm thinking the answer would be to set it to a bogus tempfile and
> delete that, but that seems awful hacky. There's got to be a better way
> to handle this, right?
>
> -Phil
>   
You may write your own output format for this. Please check the index 
contrib module in hadoop/src/contrib and the Indexer class in Nutch.

From common-user-return-16834-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 08:56:56 2009
Return-Path: <common-user-return-16834-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 83790 invoked from network); 18 Aug 2009 08:56:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 08:56:56 -0000
Received: (qmail 87829 invoked by uid 500); 18 Aug 2009 08:57:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87751 invoked by uid 500); 18 Aug 2009 08:57:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87741 invoked by uid 500); 18 Aug 2009 08:57:13 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 87738 invoked by uid 99); 18 Aug 2009 08:57:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 08:57:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sugandha.n87@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 08:57:03 +0000
Received: by yxe15 with SMTP id 15so4757566yxe.5
        for <core-user@hadoop.apache.org>; Tue, 18 Aug 2009 01:56:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=ouP3Yrk1o+V53y+LJTW3NCGomxJ2oiv0+0th0Zlq7IU=;
        b=lJ4yeeMer3z6dxhPpcDmj0/643QUXhAy+AZvE6c8rkH4KPisJvTpHFSskj9NghvSNF
         D3J4Jgq0pTKcwH+FaaccfPdALPYS/ZXwtq+UXvB7CnnbxxA7MG3OXkFjZYzlE+kxjh5W
         JhzVeElVnwskDjWIFWpnmFH4wgaxvH18XXo9k=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=s19m2ekUdl8yqA+XgE/OrzxH7z+B3uoOPaH1biMmf4I5KVPxzC3DO9svFBpBHj+eW1
         GJVT/M0zSDlEs0jPdAjkpdKzOh7ozR4Tc/icEWHIkmVdcD6aO4uiD2zxbSmVquYqEtgO
         1AFTaTjjM/9zd4PnUllxDYS7mIM2VPBLXcXbw=
MIME-Version: 1.0
Received: by 10.231.19.205 with SMTP id c13mr2920109ibb.53.1250585801827; Tue, 
	18 Aug 2009 01:56:41 -0700 (PDT)
Date: Tue, 18 Aug 2009 14:26:41 +0530
Message-ID: <6f72e2db0908180156w574a23a9nf7d041b5977432fb@mail.gmail.com>
Subject: Datanode-Failure..!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221538fd1a7aa78f047166b2cb
X-Virus-Checked: Checked by ClamAV on apache.org

--00221538fd1a7aa78f047166b2cb
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello!  I am trying to invoke datanode named as repository1.  But, it's
giving me below errors. Also, I tried formatting namenode and cleaning up
the temporary directories. But, no help. And, I am not getting the relevant
error details or status in log file as well...
Do help me out on this..!


hadoop@repository1:~/Softwares/hadoop/hadoop-0.19.0$ bin/hadoop datanode
09/08/18 14:28:43 INFO datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = repository1/10.20.220.35
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.19.0
STARTUP_MSG:   build =
https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.19 -r 713890;
compiled by 'ndaley' on Fri Nov 14 03:12:29 UTC 2008
************************************************************/
09/08/18 14:28:43 WARN datanode.DataNode: Invalid directory in dfs.data.dir:
can not create directory: /home/hadoop/Softwares/hadoop-0.19.0/temp/dfs/data
09/08/18 14:28:43 ERROR datanode.DataNode: All directories in dfs.data.dir
are invalid.
09/08/18 14:28:43 INFO datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at repository1/10.20.220.35
************************************************************/


-- 
Regards!
Sugandha

--00221538fd1a7aa78f047166b2cb--

From common-user-return-16835-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 09:00:34 2009
Return-Path: <common-user-return-16835-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 85021 invoked from network); 18 Aug 2009 09:00:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 09:00:34 -0000
Received: (qmail 94721 invoked by uid 500); 18 Aug 2009 09:00:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 94641 invoked by uid 500); 18 Aug 2009 09:00:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 94630 invoked by uid 99); 18 Aug 2009 09:00:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 09:00:51 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of outbackdan@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 09:00:40 +0000
Received: by ywh36 with SMTP id 36so5252647ywh.31
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 02:00:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=W89qjOLfoL540VLNvWgRF1zmCeOHpdW3NDBFVEs50BA=;
        b=MLBePiWbbl0vwEyyZgTYvU6ss+4lsKhQFvtfIZXiewX1+dg0DieYd2MuMSz9t87VXP
         Fq7EhOMRotlFRzK+VOgnmiPIk3yD6ltzCGRXoAOpZXZX4dZdcYqUYB5I/6sLVf4K1zqF
         KW9QP7LdFlGmNADGhSm+sLkyIAXJlxWQqpr1M=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=OauOH23K97loDJy6L+ipQecNJQJoNWVnDQKGVPgaGQaCmeutmEL6cb+c5bIW8MMUTV
         MMsuPGp+eEfZf4rHJTzHwOmaCR11kbYFqkUKhgiZiAe7ZC2DJc1Z7TEsHC0xBeUvThW2
         1A6+nhIgoFiZ9UsEMXwRoge+R1VxT2rOyl19c=
MIME-Version: 1.0
Received: by 10.151.4.5 with SMTP id g5mr7628822ybi.159.1250586019720; Tue, 18 
	Aug 2009 02:00:19 -0700 (PDT)
Date: Tue, 18 Aug 2009 19:00:19 +1000
Message-ID: <c9f8312d0908180200r5dc1c2e6mffcf7b18088456ed@mail.gmail.com>
Subject: RuntimeException: Not a host:port pair: local error when running 
	bin/start-mapred.sh
From: Daniel someone <outbackdan@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd29a207778ce047166bf33
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd29a207778ce047166bf33
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi everybody,

I am after some help with the following error that I am getting when I try
to start the start-mapred.sh. To me looked like it was getting "local"
passed as the hostname:port pair but I have double checked my settings in
"core-site.xml" and they look correct to me, I have tried changing the
values of mapred.job.tracker to FQDN and IP but this had not changed the
behaviour.

I am running:
hadoop 0.20.0
Java 1.6.0._16

Any help appreciated
Regards
Dan

Error seen in logs:

2009-08-18 18:34:07,102 INFO org.apache.hadoop.mapred.JobTracker:
STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = xxxxxx/xxxxxx
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.0
STARTUP_MSG:   build =
https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r 763504;
compiled by 'ndale
y' on Thu Apr  9 05:18:40 UTC 2009
************************************************************/
2009-08-18 18:34:08,622 FATAL org.apache.hadoop.mapred.JobTracker:
java.lang.RuntimeException: Not a host:port pair: l
ocal
        at
org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:136)
        at
org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:123)
        at
org.apache.hadoop.mapred.JobTracker.getAddress(JobTracker.java:1756)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1521)
        at
org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:174)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:3528)

2009-08-18 18:34:08,627 INFO org.apache.hadoop.mapred.JobTracker:
SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at
tel-lab-dns.ddcl.didata.com.au/10.96.201.231
************************************************************/

--000e0cd29a207778ce047166bf33--

From common-user-return-16836-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 10:29:28 2009
Return-Path: <common-user-return-16836-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 35049 invoked from network); 18 Aug 2009 10:29:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 10:29:27 -0000
Received: (qmail 38259 invoked by uid 500); 18 Aug 2009 10:29:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 38158 invoked by uid 500); 18 Aug 2009 10:29:44 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 38148 invoked by uid 99); 18 Aug 2009 10:29:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 10:29:44 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rajeevjain319@gmail.com designates 209.85.200.173 as permitted sender)
Received: from [209.85.200.173] (HELO wf-out-1314.google.com) (209.85.200.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 10:29:36 +0000
Received: by wf-out-1314.google.com with SMTP id 23so919442wfg.2
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 03:29:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=64JDFchNYao/MftsVd7NVIt62ypkzeNZwMiOo9V/e+A=;
        b=AmItwehzQeqi15BSqKe1pUyLOlmEa/RbzPt1QXrqtQcNsDX/EtRhRHiI6FSj/dax9U
         HKEYaIcaR7KX+IfpJHbWVx/2k+QtRtEDW7xYyOoqUbKKm+rAAWjlOSthJ+Z0jJD5ru3O
         AGRi7jLnRSLDItipE8JVpA0N5ztfAoHj6yhQ0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=LD/QxwNWfQ3IUkIqlioeQs/15jjEOkkxbRmVfGEzyBPSUR+S8zsWdxF24Co6chxLnP
         DtZ84YQn0f7anvM02IfFUYjDlWOf2K5T6peH2Vt9QHW2EpqZzFZVm5mNx6LjA9eJ9Ivz
         5q+NB0GRdmZ78OXedCqeqOeGtmjGil/pVWF8E=
MIME-Version: 1.0
Received: by 10.142.5.39 with SMTP id 39mr986532wfe.81.1250591356313; Tue, 18 
	Aug 2009 03:29:16 -0700 (PDT)
Date: Tue, 18 Aug 2009 15:59:16 +0530
Message-ID: <8b9e350908180329q4e352f4cle960f8be90612c99@mail.gmail.com>
Subject: Standalone operation of Hadoop Pipes Program
From: Rajeev Jain <rajeevjain319@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00504502b1c18d6100047167fd6f
X-Virus-Checked: Checked by ClamAV on apache.org

--00504502b1c18d6100047167fd6f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

Is it possible to run Hadoop Pipes C++ programs in standalone mode?

I'm using the following configuration file without success, please advise.
I've tested the binary under DFS (Pseudo Mode) and the results are correct.
My standalone mode error is reproduced below.

FYI, I'm using Hadoop 0.20 w/ Java 1.6.0_16

Thanks,

RJ

Configuration (wcount.xml):

<?xml version="1.0"?>
<configuration>
    <property>
        <name>hadoop.pipes.executable</name>
        <value>/home/rj/work/p1/wcount-cc</value>
    </property>
    <property>
        <name>hadoop.pipes.java.recordreader</name>
        <value>true</value>
    </property>
    <property>
        <name>hadoop.pipes.java.recordwriter</name>
        <value>true</value>
    </property>
</configuration>


Command Line:

[rj@scoobydoo p1]$ hadoop pipes -conf conf/wcount.xml -input input -out
put output


Run Output:

09/08/18 20:15:00 INFO jvm.JvmMetrics: Initializing JVM Metrics with
processName
=JobTracker, sessionId=
09/08/18 20:15:00 WARN mapred.JobClient: No job jar file set.  User classes
may
not be found. See JobConf(Class) or JobConf#setJar(String).
09/08/18 20:15:00 INFO mapred.FileInputFormat: Total input paths to process
: 1
09/08/18 20:15:00 INFO mapred.JobClient: Running job: job_local_0001
09/08/18 20:15:00 INFO mapred.FileInputFormat: Total input paths to process
: 1
09/08/18 20:15:00 INFO mapred.MapTask: numReduceTasks: 1
09/08/18 20:15:00 INFO mapred.MapTask: io.sort.mb = 100
09/08/18 20:15:01 INFO mapred.MapTask: data buffer = 79691776/99614720
09/08/18 20:15:01 INFO mapred.MapTask: record buffer = 262144/327680
09/08/18 20:15:01 WARN mapred.LocalJobRunner: job_local_0001
java.lang.NullPointerException
        at
org.apache.hadoop.mapred.pipes.Application.<init>(Application.java:91
)
        at
org.apache.hadoop.mapred.pipes.PipesMapRunner.run(PipesMapRunner.java
:68)
        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:356)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
        at
org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:1
76)
09/08/18 20:15:01 INFO mapred.JobClient:  map 0% reduce 0%
09/08/18 20:15:01 INFO mapred.JobClient: Job complete: job_local_0001
09/08/18 20:15:01 INFO mapred.JobClient: Counters: 0
Exception in thread "main" java.io.IOException: Job failed!
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1255)
        at
org.apache.hadoop.mapred.pipes.Submitter.runJob(Submitter.java:244)
        at org.apache.hadoop.mapred.pipes.Submitter.run(Submitter.java:480)
        at org.apache.hadoop.mapred.pipes.Submitter.main(Submitter.java:494)

--00504502b1c18d6100047167fd6f--

From common-user-return-16837-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 11:04:26 2009
Return-Path: <common-user-return-16837-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 45264 invoked from network); 18 Aug 2009 11:04:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 11:04:26 -0000
Received: (qmail 75675 invoked by uid 500); 18 Aug 2009 11:04:43 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 75578 invoked by uid 500); 18 Aug 2009 11:04:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 75563 invoked by uid 99); 18 Aug 2009 11:04:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 11:04:42 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [192.6.10.2] (HELO colossus.hpl.hp.com) (192.6.10.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 11:04:32 +0000
Received: from localhost (localhost [127.0.0.1])
	by colossus.hpl.hp.com (Postfix) with ESMTP id BF4411BA30E
	for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 12:04:09 +0100 (BST)
X-Virus-Scanned: Debian amavisd-new at hpl.hp.com
Received: from colossus.hpl.hp.com ([127.0.0.1])
	by localhost (colossus.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id Zg6YoAoJtgKy for <common-user@hadoop.apache.org>;
	Tue, 18 Aug 2009 12:04:09 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by colossus.hpl.hp.com (Postfix) with ESMTPS id 0A24C1BA2E7
	for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 12:04:08 +0100 (BST)
MailScanner-NULL-Check: 1251198236.79016@NoKaQMGX1sv5jF9oo4mBDg
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7IB3s6v006465
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 12:03:54 +0100 (BST)
Message-ID: <4A8A8A9A.3010804@apache.org>
Date: Tue, 18 Aug 2009 12:03:54 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Ubuntu/Hadoop incompatibilities?
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>	 <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>	 <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com> <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com> <4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu> <4A899499.4080902@yahoo-inc.com> <4A899803.9090108@gmail.com>
In-Reply-To: <4A899803.9090108@gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7IB3s6v006465
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

brien colwell wrote:
> Actually Ubuntu comes out of the box with an entry in the hosts file 
> (/etc/hosts) that maps the computer name to the loopback address. (btw 
> I'm not sure if this is specific to Ubuntu) The effect is that all name 
> lookups from the machine for itself resolve to 127.0.0.1. We've seen 
> Hadoop daemons on Ubuntu bind their sockets to the loopback address, 
> which will  not accept requests from the outside. Symptoms here are that 
> the cluster works on a single machine but will not distribute.
> 
> Just check your netstat tables for the addresses on which the Hadoop 
> daemons are bound. They should be external addresses. The solution we 
> use is to remove the entry in the hosts file.
> 

yes, this really annoys me.
http://jira.smartfrog.org/jira/browse/SFOS-1191

And others.

https://bugs.launchpad.net/ubuntu/+source/netcfg/+bug/234543

caused by this
https://bugs.launchpad.net/ubuntu/+bug/94048

It was done to help people on desktops and laptops, but it stops your 
machine working well over the network.


From common-user-return-16838-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 11:11:08 2009
Return-Path: <common-user-return-16838-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 52191 invoked from network); 18 Aug 2009 11:11:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 11:11:07 -0000
Received: (qmail 86746 invoked by uid 500); 18 Aug 2009 11:11:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 86657 invoked by uid 500); 18 Aug 2009 11:11:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 86647 invoked by uid 500); 18 Aug 2009 11:11:24 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 86644 invoked by uid 99); 18 Aug 2009 11:11:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 11:11:24 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sugandha.n87@gmail.com designates 209.85.132.241 as permitted sender)
Received: from [209.85.132.241] (HELO an-out-0708.google.com) (209.85.132.241)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 11:11:15 +0000
Received: by an-out-0708.google.com with SMTP id c38so1639930ana.29
        for <core-user@hadoop.apache.org>; Tue, 18 Aug 2009 04:10:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=LWGKWEITvAGpFFQf5xvyG26Cr79mCvD2goXSXfEfRUQ=;
        b=F0O/v13kU2//Lhx/f2N5Y9EZfO9X3bQTY1cLWp0gF3cin6qqYIEMbbKy8wraY2aRjk
         D1pKCWpJeVCD5tw7PaibUM+rRagg+oveP3YjdT63TSsoYQpZlto6Q6F0h3CSvHAlNhc4
         hzVTnFYAE15YJ4D+qFlsOZfI9SAxMl2kAm3AE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=Nr8OR8Nt5OHNyLFFj2Eg0xSVQV6SaJcWgbMTrGuCAwHbEHpBVHpbrM3YCYvORZ+1qI
         H7HhwdPi/w5ZtMqMeYZguXNTiNSma2ktUjNGyDvccE2Wv6O/0y/lip3u+f3CKdYEVyXh
         tS5aq95/rdRgV6himm+gMmHF1/9+o1pXwgqpU=
MIME-Version: 1.0
Received: by 10.231.33.137 with SMTP id h9mr3076479ibd.15.1250593853096; Tue, 
	18 Aug 2009 04:10:53 -0700 (PDT)
Date: Tue, 18 Aug 2009 16:40:53 +0530
Message-ID: <6f72e2db0908180410m1675a27bv28bbe1c096208060@mail.gmail.com>
Subject: Rack Awareness!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000325575e5e5f4365047168920d
X-Virus-Checked: Checked by ClamAV on apache.org

--000325575e5e5f4365047168920d
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

 Hello!


 I have 6 nodes and I want to configure them in racks. Below are the details
of machines::





  *Name of the machine* *IP's* *Roles Played*




 namenode 10.20.220.30 namenode
 jobsec 10.20.220.31 jobtracker and secondaryNN
 repository1 10.20.220.35 DN and TT -1  repository2 10.20.220.78 DN and TT
-2  repository3 10.20.220.71 DN and TT -3  repository4 10.20.220.74 DN and
TT -4


Now, I want to configure first three Datanodes(35,78,71) in rack 1 of
jobtracker and the 4th DN(74) in rack2 of jobtracker(jobsec here). Thus,
here jobsec is in a way datacenter,right?
Below is the python script written. please let me know, whether it is
correct or not. Also, just by setting this file's value in specified tag in
hadoop-site.xml, the script will get invoked? The machines wd automaricaly
get configured as per the topology mentioned in script???

#!/usr/bin/env python

'''
This script used by hadoop to determine network/rack topology.  It
should be specified in hadoop-site.xml via topology.script.file.name
Property.

<property>
  name>topology.script.file.name</name>
 <value>/home/hadoop/topology.py</value>
</property>
'''

import sys
from string import join




DEFAULT_RACK = '/default/rack0';

RACK_MAP =
{
    '10.20.220.35' : '/jobsec/rack1',
    '10.20.220.78' : '/jobsec/rack1',
    '10.20.220.71' : '/jobsec/rack1',

    '10.20.220.74' : '/jobsec/rack2',
}

if len(sys.argv)==1:
     print DEFAULT_RACK
else:
     print join([RACK_MAP.get(i, DEFAULT_RACK) for i in sys.argv[1:]]," ")


-- 
Regards!
Sugandha

--000325575e5e5f4365047168920d--

From common-user-return-16839-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 11:15:16 2009
Return-Path: <common-user-return-16839-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 52914 invoked from network); 18 Aug 2009 11:15:16 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 11:15:16 -0000
Received: (qmail 90127 invoked by uid 500); 18 Aug 2009 11:15:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 90052 invoked by uid 500); 18 Aug 2009 11:15:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 90036 invoked by uid 500); 18 Aug 2009 11:15:32 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 90029 invoked by uid 99); 18 Aug 2009 11:15:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 11:15:32 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sugandha.n87@gmail.com designates 209.85.132.241 as permitted sender)
Received: from [209.85.132.241] (HELO an-out-0708.google.com) (209.85.132.241)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 11:15:23 +0000
Received: by an-out-0708.google.com with SMTP id c38so1640684ana.29
        for <core-user@hadoop.apache.org>; Tue, 18 Aug 2009 04:15:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=53f7iN6IywQKFFoPa9vgQqYlTAnrZ1+OvPyeOaTq2Pw=;
        b=wlprhoO3bnvKlr48hWV8aFhst5+sv4YFJOZ3SAavaIWa/ErCVq857QhTGjR6qmXUR6
         NTaeA2PT9vIrtHSblAn6jiFSWl7F/4iFjrCLo2rA2yYavVO2gsiYXJF8Vce+MBMw+uOH
         pKWHLmlW4WIXehKB+oWV4ZWiuqzxtiegB2b4I=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=MvxAUFCotSMp1LOoyihPsnDkv+PtLyk67ZCBWDtsM1fG45oNmXu70F7TnfxK5CQfOC
         8EU+EuHx+NG/i6Nwx6nNfWMzs7/sUySbAul2+I0WhB/FbnILstWen0+Mwzp9zGh4CEsN
         sFbbCb+rVR87fZkTfybNJB6BI4frItZdfpUuQ=
MIME-Version: 1.0
Received: by 10.231.38.140 with SMTP id b12mr2995858ibe.29.1250594099732; Tue, 
	18 Aug 2009 04:14:59 -0700 (PDT)
Date: Tue, 18 Aug 2009 16:44:59 +0530
Message-ID: <6f72e2db0908180414s15a5dfddqbea3c49d9bb1bfd@mail.gmail.com>
Subject: Hadoop version!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0003255746f212a13f047168a167
X-Virus-Checked: Checked by ClamAV on apache.org

--0003255746f212a13f047168a167
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello!
I am currently using 0.19.0 version of hadoop. If I need to upgrade to the
latest one, what am I supposed to do? It should be least pain taking, as i
Have already setup a 6 node cluster running many jobs currently..!

-- 
Regards!
Sugandha

--0003255746f212a13f047168a167--

From common-user-return-16840-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 12:16:11 2009
Return-Path: <common-user-return-16840-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70695 invoked from network); 18 Aug 2009 12:16:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 12:16:11 -0000
Received: (qmail 51093 invoked by uid 500); 18 Aug 2009 12:16:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 51016 invoked by uid 500); 18 Aug 2009 12:16:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 51006 invoked by uid 500); 18 Aug 2009 12:16:28 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 51003 invoked by uid 99); 18 Aug 2009 12:16:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 12:16:28 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wasimbari@msn.com designates 65.54.246.148 as permitted sender)
Received: from [65.54.246.148] (HELO bay0-omc2-s12.bay0.hotmail.com) (65.54.246.148)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 12:16:17 +0000
Received: from BAY102-W29 ([64.4.61.129]) by bay0-omc2-s12.bay0.hotmail.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Tue, 18 Aug 2009 05:15:57 -0700
Message-ID: <BAY102-W29B1ADDCE27DD6683002B6BCFF0@phx.gbl>
Content-Type: multipart/alternative;
	boundary="_77d28ce8-806c-494e-864d-98ff0caf411b_"
X-Originating-IP: [212.117.81.29]
From: Wasim Bari <wasimbari@msn.com>
To: <core-user@hadoop.apache.org>
Subject: Customized inputformat
Date: Tue, 18 Aug 2009 12:15:57 +0000
Importance: Normal
MIME-Version: 1.0
X-OriginalArrivalTime: 18 Aug 2009 12:15:57.0299 (UTC) FILETIME=[A40D1C30:01CA1FFD]
X-Virus-Checked: Checked by ClamAV on apache.org

--_77d28ce8-806c-494e-864d-98ff0caf411b_
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable


=20

=20

Hi=2C

   i am trying to write a cutomized inputformat but have some problems in g=
etting recored.=20

=20

My file format is :

=20

TextLinees [1 -n ]

EMPTY LINE

TextLinees [1 -n ]

EMPTY LINE

END OF FILE

=20

I have extended TextInputFormat and this is my NEXt function:

=20

public boolean next(LongWritable key=2C Text value) throws IOException {  =
=20

  =20

   Text txt =3D new Text ()=3B
   Long lo=3D0L=3B
   int b=3D0=3B
   StringBuffer str =3D new StringBuffer()=3B
  =20

    recordStartPos =3D pos=3B                           // Postion of Each =
record =2C in Constructor it is intilized with split.getstart()
   while ((b=3DlineReader.readLine(txt))>2){    // UNTIL i get an emoty lin=
e
     pos +=3D txt.getBytes().length=3B               //increment the positi=
on=20
    str.append(txt + "\n")=3B
   }=20
   if(pos > end)
    return false=3B=20
    try{=20
    StringTokenizer strTok =3D new StringTokenizer(str.substring(5=2C20))=
=3B    // geting some value from string
    lo =3D Long.valueOf(( strTok.nextToken()))=3B
    }catch (Exception w){}
    key.set(lo)=3B
    value.set(str.toString())=3B

}

=20

=20

So i belive it should send ONE record [multiple text lines before an EMPTY =
string] to the mapper but its missing some records.

=20

looking for you people help and guidance.=20

=20

Regards=2C

Wasim

=20

=20

=20

--_77d28ce8-806c-494e-864d-98ff0caf411b_--

From common-user-return-16841-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 14:35:28 2009
Return-Path: <common-user-return-16841-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 44051 invoked from network); 18 Aug 2009 14:35:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 14:35:28 -0000
Received: (qmail 2815 invoked by uid 500); 18 Aug 2009 14:35:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 2729 invoked by uid 500); 18 Aug 2009 14:35:44 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 2719 invoked by uid 500); 18 Aug 2009 14:35:44 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 2716 invoked by uid 99); 18 Aug 2009 14:35:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 14:35:44 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wasimbari@msn.com designates 65.54.246.157 as permitted sender)
Received: from [65.54.246.157] (HELO bay0-omc2-s21.bay0.hotmail.com) (65.54.246.157)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 14:35:34 +0000
Received: from BAY102-W21 ([64.4.61.121]) by bay0-omc2-s21.bay0.hotmail.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Tue, 18 Aug 2009 07:35:14 -0700
Message-ID: <BAY102-W2141C486C4C43CB06A4B2EBCFF0@phx.gbl>
Content-Type: multipart/mixed;
	boundary="_61028e06-76a2-4cc3-b861-52d80269bf67_"
X-Originating-IP: [212.117.81.29]
From: Wasim Bari <wasimbari@msn.com>
To: <core-user@hadoop.apache.org>
Subject: Customized InputFormat
Date: Tue, 18 Aug 2009 14:35:13 +0000
Importance: Normal
MIME-Version: 1.0
X-OriginalArrivalTime: 18 Aug 2009 14:35:14.0265 (UTC) FILETIME=[1930EC90:01CA2011]
X-Virus-Checked: Checked by ClamAV on apache.org

--_61028e06-76a2-4cc3-b861-52d80269bf67_
Content-Type: multipart/alternative;
	boundary="_4571ff09-84d4-4253-9b28-19c1f8d9fcff_"

--_4571ff09-84d4-4253-9b28-19c1f8d9fcff_
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable


=20

Hi=2C

   I tried anotherway to implement the InputFileFormat which returns <Key=
=2CMultipleLines> as record to mapper.

=20

I used this logic: Used a LineRecordReader to read file line by line and ke=
ep storing these lines in buffer.=20

when i encouters an empty string =2C Set the buffer to value and return the=
 result. Please see the attached code.=20

=20

=20

But i get Java Heap error. apparently its because of buffer writing=2C but =
data is not so big and i am unable to find the solution.=20

=20

Please have a look and guide me.=20

=20

regards=2C

=20

=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D

package initial=3B

import java.io.IOException=3B

import org.apache.hadoop.io.DataOutputBuffer=3B

import org.apache.hadoop.io.LongWritable=3B

import org.apache.hadoop.io.Text=3B

import org.apache.hadoop.mapred.FileSplit=3B

import org.apache.hadoop.mapred.InputSplit=3B

import org.apache.hadoop.mapred.JobConf=3B

import org.apache.hadoop.mapred.RecordReader=3B

import org.apache.hadoop.mapred.Reporter=3B

import org.apache.hadoop.mapred.TextInputFormat=3B

import org.apache.log4j.Logger=3B

@SuppressWarnings("deprecation")

public class PTextInputFormat1 extends TextInputFormat {

=20

public void configure(JobConf jobConf) {

super.configure(jobConf)=3B

}

public RecordReader<LongWritable=2C Text> getRecordReader(InputSplit inputS=
plit=2C JobConf jobConf=2C

Reporter reporter) throws IOException {

return new PTextRecordReader((FileSplit) inputSplit=2C jobConf)=3B

}

public static class PTextRecordReader implements RecordReader<LongWritable=
=2C Text> {

private static final Logger sLogger =3D Logger.getLogger(PTextRecordReader.=
class)=3B



private DataOutputBuffer buffer =3D new DataOutputBuffer()=3B

private JobConf job=3B

private FileSplit FSplit=3B

private long start=3B

private long end=3B

private int count=3B

org.apache.hadoop.mapred.LineRecordReader lineRecordReader=3B

public PTextRecordReader(FileSplit split=2C JobConf jobConf) throws IOExcep=
tion {



FSplit=3Dsplit=3B

start =3D split.getStart()=3B

job =3D jobConf=3B

lineRecordReader =3D new org.apache.hadoop.mapred.LineRecordReader(job=2CFS=
plit)=3B

end =3D start + split.getLength()=3B

}

public boolean next(LongWritable key=2C Text value) throws IOException {=20



if (lineRecordReader.next(key=2C value)){

while (value.toString().length()!=3D0){

buffer.write(value.getBytes())=3B

numberOfLines++=3B

}

key.set(count++)=3B

value.set(buffer.getData()=2C 0=2C buffer.getLength())=3B

buffer.reset()=3B

return true=3B

}

buffer.reset()=3B

return false=3B



}



public LongWritable createKey() {

return new LongWritable()=3B

}

public Text createValue() {

return new Text()=3B

}

public long getStart() {

return start=3B

}

public long getEnd() {

return end=3B

}

public long getPos() throws IOException {

return lineRecordReader.getPos()=3B

}



public float getProgress() throws IOException {

return lineRecordReader.getProgress()=3B

}

@Override

public void close() throws IOException {

lineRecordReader.close()=3B



}

}

}

--_4571ff09-84d4-4253-9b28-19c1f8d9fcff_
Content-Type: text/html; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

<html>
<head>
<style>
.hmmessage P
{
margin:0px=3B
padding:0px
}
body.hmmessage
{
font-size: 10pt=3B
font-family:Verdana
}
</style>
</head>
<body class=3D'hmmessage'>
&nbsp=3B<BR>
Hi=2C<BR>
&nbsp=3B&nbsp=3B I tried anotherway to implement the InputFileFormat&nbsp=
=3Bwhich returns &lt=3BKey=2CMultipleLines&gt=3B as record to mapper.<BR>
&nbsp=3B<BR>
I used&nbsp=3Bthis logic:&nbsp=3BUsed&nbsp=3Ba LineRecordReader to read fil=
e line by line and keep storing these lines in buffer. <BR>
when i encouters an empty string =2C Set the buffer to value and return the=
 result. Please see the attached code. <BR>
&nbsp=3B<BR>
&nbsp=3B<BR>
But i get Java Heap error. apparently its because of buffer writing=2C but =
data is not so big and i am unable to find the solution. <BR>
&nbsp=3B<BR>
Please have a look and guide me. <BR>
&nbsp=3B<BR>
regards=2C<BR>
&nbsp=3B<BR>
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<BR><SPAN lang=3DE=
N>
package initial=3B<BR>
import java.io.IOException=3B<BR>
import org.apache.hadoop.io.DataOutputBuffer=3B<BR>
import org.apache.hadoop.io.LongWritable=3B<BR>
import org.apache.hadoop.io.Text=3B<BR>
import org.apache.hadoop.mapred.FileSplit=3B<BR>
import org.apache.hadoop.mapred.InputSplit=3B<BR>
import org.apache.hadoop.mapred.JobConf=3B<BR>
import org.apache.hadoop.mapred.RecordReader=3B<BR>
import org.apache.hadoop.mapred.Reporter=3B<BR>
import org.apache.hadoop.mapred.TextInputFormat=3B<BR>
import org.apache.log4j.Logger=3B<BR>
@SuppressWarnings("deprecation")<BR>
public class PTextInputFormat1 extends TextInputFormat {<BR>
&nbsp=3B<BR>
public void configure(JobConf jobConf) {<BR>
super.configure(jobConf)=3B<BR>
}<BR>
public RecordReader&lt=3BLongWritable=2C Text&gt=3B getRecordReader(InputSp=
lit inputSplit=2C JobConf jobConf=2C<BR>
Reporter reporter) throws IOException {<BR>
return new PTextRecordReader((FileSplit) inputSplit=2C jobConf)=3B<BR>
}<BR>
public static class PTextRecordReader implements RecordReader&lt=3BLongWrit=
able=2C Text&gt=3B {<BR>
private static final Logger sLogger =3D Logger.getLogger(PTextRecordReader.=
class)=3B<BR>
<BR>
private DataOutputBuffer buffer =3D new DataOutputBuffer()=3B<BR>
private JobConf job=3B<BR>
private FileSplit FSplit=3B<BR>
private long start=3B<BR>
private long end=3B<BR>
private int count=3B<BR>
org.apache.hadoop.mapred.LineRecordReader lineRecordReader=3B<BR>
public PTextRecordReader(FileSplit split=2C JobConf jobConf) throws IOExcep=
tion {<BR>
<BR>
FSplit=3Dsplit=3B<BR>
start =3D split.getStart()=3B<BR>
job =3D jobConf=3B<BR>
lineRecordReader =3D new org.apache.hadoop.mapred.LineRecordReader(job=2CFS=
plit)=3B<BR>
end =3D start + split.getLength()=3B<BR>
}<BR>
public boolean next(LongWritable key=2C Text value) throws IOException { <B=
R>
<BR>
if (lineRecordReader.next(key=2C value)){<BR>
while (value.toString().length()!=3D0){<BR>
buffer.write(value.getBytes())=3B<BR>
numberOfLines++=3B<BR>
}<BR>
key.set(count++)=3B<BR>
value.set(buffer.getData()=2C 0=2C buffer.getLength())=3B<BR>
buffer.reset()=3B<BR>
return true=3B<BR>
}<BR>
buffer.reset()=3B<BR>
return false=3B<BR>
<BR>
}<BR>
<BR>
public LongWritable createKey() {<BR>
return new LongWritable()=3B<BR>
}<BR>
public Text createValue() {<BR>
return new Text()=3B<BR>
}<BR>
public long getStart() {<BR>
return start=3B<BR>
}<BR>
public long getEnd() {<BR>
return end=3B<BR>
}<BR>
public long getPos() throws IOException {<BR>
return lineRecordReader.getPos()=3B<BR>
}<BR>
<BR>
public float getProgress() throws IOException {<BR>
return lineRecordReader.getProgress()=3B<BR>
}<BR>
@Override<BR>
public void close() throws IOException {<BR>
lineRecordReader.close()=3B<BR>
<BR>
}<BR>
}<BR>
}<BR></SPAN></body>
</html>=

--_4571ff09-84d4-4253-9b28-19c1f8d9fcff_--

--_61028e06-76a2-4cc3-b861-52d80269bf67_--

From common-user-return-16842-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 15:25:11 2009
Return-Path: <common-user-return-16842-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 1951 invoked from network); 18 Aug 2009 15:25:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 15:25:11 -0000
Received: (qmail 16314 invoked by uid 500); 18 Aug 2009 15:25:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 16261 invoked by uid 500); 18 Aug 2009 15:25:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 16251 invoked by uid 99); 18 Aug 2009 15:25:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 15:25:27 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 209.85.211.198 is neither permitted nor denied by domain of kjirapinyo@biz360.com)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 15:25:19 +0000
Received: by ywh36 with SMTP id 36so5533060ywh.31
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 08:24:58 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.100.81.1 with SMTP id e1mr5610987anb.73.1250609096519; Tue, 18 
	Aug 2009 08:24:56 -0700 (PDT)
In-Reply-To: <BAY102-W2141C486C4C43CB06A4B2EBCFF0@phx.gbl>
References: <BAY102-W2141C486C4C43CB06A4B2EBCFF0@phx.gbl>
From: Kris Jirapinyo <kris.jirapinyo@biz360.com>
Date: Tue, 18 Aug 2009 08:24:36 -0700
Message-ID: <42a1925b0908180824p513b43ddw1ea95650125af55@mail.gmail.com>
Subject: Re: Customized InputFormat
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0050450176bafa6e1f04716c1e41
X-Virus-Checked: Checked by ClamAV on apache.org

--0050450176bafa6e1f04716c1e41
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Do you ever close your DataOutputBuffer?

-- Kris J.

On Tue, Aug 18, 2009 at 7:35 AM, Wasim Bari <wasimbari@msn.com> wrote:

>
> Hi,
>    I tried anotherway to implement the InputFileFormat which returns
> <Key,MultipleLines> as record to mapper.
>
> I used this logic: Used a LineRecordReader to read file line by line and
> keep storing these lines in buffer.
> when i encouters an empty string , Set the buffer to value and return the
> result. Please see the attached code.
>
>
> But i get Java Heap error. apparently its because of buffer writing, but
> data is not so big and i am unable to find the solution.
>
> Please have a look and guide me.
>
> regards,
>
> ============================================
> package initial;
> import java.io.IOException;
> import org.apache.hadoop.io.DataOutputBuffer;
> import org.apache.hadoop.io.LongWritable;
> import org.apache.hadoop.io.Text;
> import org.apache.hadoop.mapred.FileSplit;
> import org.apache.hadoop.mapred.InputSplit;
> import org.apache.hadoop.mapred.JobConf;
> import org.apache.hadoop.mapred.RecordReader;
> import org.apache.hadoop.mapred.Reporter;
> import org.apache.hadoop.mapred.TextInputFormat;
> import org.apache.log4j.Logger;
> @SuppressWarnings("deprecation")
> public class PTextInputFormat1 extends TextInputFormat {
>
> public void configure(JobConf jobConf) {
> super.configure(jobConf);
> }
> public RecordReader<LongWritable, Text> getRecordReader(InputSplit
> inputSplit, JobConf jobConf,
> Reporter reporter) throws IOException {
> return new PTextRecordReader((FileSplit) inputSplit, jobConf);
> }
> public static class PTextRecordReader implements RecordReader<LongWritable,
> Text> {
> private static final Logger sLogger =
> Logger.getLogger(PTextRecordReader.class);
>
> private DataOutputBuffer buffer = new DataOutputBuffer();
> private JobConf job;
> private FileSplit FSplit;
> private long start;
> private long end;
> private int count;
> org.apache.hadoop.mapred.LineRecordReader lineRecordReader;
> public PTextRecordReader(FileSplit split, JobConf jobConf) throws
> IOException {
>
> FSplit=split;
> start = split.getStart();
> job = jobConf;
> lineRecordReader = new
> org.apache.hadoop.mapred.LineRecordReader(job,FSplit);
> end = start + split.getLength();
> }
> public boolean next(LongWritable key, Text value) throws IOException {
>
> if (lineRecordReader.next(key, value)){
> while (value.toString().length()!=0){
> buffer.write(value.getBytes());
> numberOfLines++;
> }
> key.set(count++);
> value.set(buffer.getData(), 0, buffer.getLength());
> buffer.reset();
> return true;
> }
> buffer.reset();
> return false;
>
> }
>
> public LongWritable createKey() {
> return new LongWritable();
> }
> public Text createValue() {
> return new Text();
> }
> public long getStart() {
> return start;
> }
> public long getEnd() {
> return end;
> }
> public long getPos() throws IOException {
> return lineRecordReader.getPos();
> }
>
> public float getProgress() throws IOException {
> return lineRecordReader.getProgress();
> }
> @Override
> public void close() throws IOException {
> lineRecordReader.close();
>
> }
> }
> }
>

--0050450176bafa6e1f04716c1e41--

From common-user-return-16843-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 15:35:18 2009
Return-Path: <common-user-return-16843-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 25384 invoked from network); 18 Aug 2009 15:35:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 15:35:18 -0000
Received: (qmail 35242 invoked by uid 500); 18 Aug 2009 15:35:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35154 invoked by uid 500); 18 Aug 2009 15:35:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35144 invoked by uid 99); 18 Aug 2009 15:35:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 15:35:35 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [68.142.237.108] (HELO n1.bullet.mail.re3.yahoo.com) (68.142.237.108)
    by apache.org (qpsmtpd/0.29) with SMTP; Tue, 18 Aug 2009 15:35:24 +0000
Received: from [68.142.230.29] by n1.bullet.mail.re3.yahoo.com with NNFMP; 18 Aug 2009 15:33:52 -0000
Received: from [67.195.9.83] by t2.bullet.re2.yahoo.com with NNFMP; 18 Aug 2009 15:33:52 -0000
Received: from [67.195.9.110] by t3.bullet.mail.gq1.yahoo.com with NNFMP; 18 Aug 2009 15:33:51 -0000
Received: from [127.0.0.1] by omp114.mail.gq1.yahoo.com with NNFMP; 18 Aug 2009 15:33:51 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 882481.71918.bm@omp114.mail.gq1.yahoo.com
Received: (qmail 57873 invoked by uid 60001); 18 Aug 2009 15:33:51 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1250609631; bh=hd7hAGuLGnXHWUPBQyj1UEfJuP89oqDZ+VJUYm5UKFA=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=lbO/2SzFhCbODaEmy0cXehr8dgD2dn+ZKKm8s7XG8bbxdI7+3gWOvDI9oas9eUymxixDEelgwmeKpR4AlwbMjhl2v1WSnNEEb4BA/UzTHwHF0J1yAV23arxkL/KGjUtEGysRscP2IPkquQ2RhnMQR0QXKbjqz+Y6WoaJaQTVqpE=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=s8b1P3Y+AdZCRIcIXW2AdNRxq+IWZ4ymsbvxUhKm+QHi/oG2jqBEDnuBDej/lq3+Jo9f454yfTBDBgcX/jmk5oTE7P1fJp3Uyu1ozL/qpXce+9JRLXxE70uCzI5WUXasKRdlMq7iogLm0GGdhj566DS+zNr7vo+Rh/kXObsQiZs=;
Message-ID: <641565.57813.qm@web110113.mail.gq1.yahoo.com>
X-YMail-OSG: JlB3OAYVM1k.FzYxG1bVP7thbDZ1DLvCO_EptdgYkr0hWVLkq1ZcQbkXYc2Sqnk5TBErbODMqhzZoAPXtUO0Zc1X3fkggnG3A43uZ6jlAoTNT2W8S95qo._nZwplPShnLNTvJxYNui.lk6yY_bOy.CJmFu00xLBPNm6pWgIPRHrvvXBJcL4ofoUyg9Vz8qtJIEaCLK_4vFGPd3hS5FiL4cwYq4XSxh2Ph0dbVs.ZXkfMV3chPDHbeZ1cARJdNoT3GnGho7OFKac2rZTUiiRCHOiRjnT5nl8CwooHAbJDqEkI9w.D7FJEXOBXAUXeFoQDNdFB
Received: from [216.243.71.77] by web110113.mail.gq1.yahoo.com via HTTP; Tue, 18 Aug 2009 08:33:51 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com>  <42a1925b0908141323l5b1563fepd8205fe87834f6d3@mail.gmail.com>  <4238036a0908170129u3c3a6eafp66e756e1e41c09f6@mail.gmail.com>  <99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com>  <4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu>  <4A899499.4080902@yahoo-inc.com> <4A899803.9090108@gmail.com>  <4A89BEAC.9070306@Gmail.com> <77d4e5730908171358y19c91811kbad90fbd97e6e775@mail.gmail.com> <428663.76474.qm@web110105.mail.gq1.yahoo.com>
Date: Tue, 18 Aug 2009 08:33:51 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: Re: Hadoop - flush() files
To: common-user@hadoop.apache.org
In-Reply-To: <428663.76474.qm@web110105.mail.gq1.yahoo.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-887064049-1250609631=:57813"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-887064049-1250609631=:57813
Content-Type: text/plain; charset=us-ascii

Just checking again :-)

I have a setup where I am using Hadoop0-19.2 and the data files are kept open for a long time. I want them to be sync'd to the HDFS now and then, to avoid any data loss.

In one of the last HUG, somebody mentioned  FSDataOutputStream.sync() method. But there were some known issues with that.  

Has anyone experienced any problem while using the sync() method ? 

Arvind




________________________________


Hi,

I was wondering if anyone here have stared using (or has been using) the newer Hadoop versions (0-20.1 ??? ) - which provides API for flushing out any open files on the HDFS ?

Are there any known issues I should be aware of ?

Thanks!
Arvind


      
--0-887064049-1250609631=:57813--


From common-user-return-16844-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 16:01:04 2009
Return-Path: <common-user-return-16844-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 34486 invoked from network); 18 Aug 2009 16:01:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 16:01:04 -0000
Received: (qmail 89279 invoked by uid 500); 18 Aug 2009 16:01:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 89196 invoked by uid 500); 18 Aug 2009 16:01:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 89112 invoked by uid 99); 18 Aug 2009 16:01:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 16:01:00 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 16:00:50 +0000
Received: by fxm17 with SMTP id 17so3521633fxm.13
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 09:00:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=VoRa2R1NgTRE18EBkKhVbb/7TOiBMq2/dYkzCfmltr4=;
        b=jlq6MHAXpStpv5X9n8n+su6ThVPRjufVoMUmCcPdUOfczQ2jarWWpfGMMMdb3UppmG
         sAx2U6ONQdpSojSmkX1fVar0ik4ttZzaFFle49vZzNhHyN/VOw1qqOhwDok0sZydp5yY
         E+ERoXbsguvl42Ap3DspdCxRfxJX2LvbXvRlk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=XcO8pLUXQqWorMU0LvMGUvOtyAg9iMeHJuzUGAePEyRersGUwHdrefkRaULVycz6x8
         G25sv1dNGuF0P1e4Xz4JxRoxf5j2gpAlmVnSPPqSsja/gmF76QSKLWFDeYxcXsosoz0G
         MGQw6IfCv7cuojZkaUWBgC5RFHgRTT4xVg8Lo=
MIME-Version: 1.0
Received: by 10.239.179.97 with SMTP id c33mr486479hbg.157.1250611230216; Tue, 
	18 Aug 2009 09:00:30 -0700 (PDT)
Date: Tue, 18 Aug 2009 12:00:30 -0400
Message-ID: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
Subject: Faster alternative to FSDataInputStream
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f7d62221135004716c9ed5
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f7d62221135004716c9ed5
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I am trying to download binary files stored in Hadoop but there is like a 2
minute wait on a 20mb file when I try to execute the in.read(buf).

is there a better way to be doing this?

    private void pipe(InputStream in, OutputStream out) throws IOException
    {    System.out.println(System.currentTimeMillis()+" Starting to Pipe
Data");
        byte[] buf = new byte[1024];
        int read = 0;
        while ((read = in.read(buf)) >= 0)
        {
            out.write(buf, 0, read);
            System.out.println(System.currentTimeMillis()+" Piping Data");
        }
        out.flush();
        System.out.println(System.currentTimeMillis()+" Finished Piping
Data");

    }

public void readFile(String fileToRead, OutputStream out)
            throws IOException
    {
        System.out.println(System.currentTimeMillis()+" Start Read File");
        Path inFile = new Path(fileToRead);
        System.out.println(System.currentTimeMillis()+" Set Path");
        // Validate the input/output paths before reading/writing.

        if (!fs.exists(inFile))
        {
            throw new HadoopFileException("Specified file  " + fileToRead
                    + " not found.");
        }
        if (!fs.isFile(inFile))
        {
            throw new HadoopFileException("Specified file  " + fileToRead
                    + " not found.");
        }
        // Open inFile for reading.
        System.out.println(System.currentTimeMillis()+" Opening Data
Stream");
        FSDataInputStream in = fs.open(inFile);

        System.out.println(System.currentTimeMillis()+" Opened Data
Stream");
        // Open outFile for writing.

        // Read from input stream and write to output stream until EOF.
        pipe(in, out);

        // Close the streams when done.
        out.close();
        in.close();
    }
Ananth T Sarathy

--001485f7d62221135004716c9ed5--

From common-user-return-16845-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 17:18:42 2009
Return-Path: <common-user-return-16845-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 70898 invoked from network); 18 Aug 2009 17:18:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 17:18:42 -0000
Received: (qmail 35537 invoked by uid 500); 18 Aug 2009 17:18:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35443 invoked by uid 500); 18 Aug 2009 17:18:58 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35433 invoked by uid 99); 18 Aug 2009 17:18:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 17:18:58 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pku.gaoqin@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 17:18:49 +0000
Received: by ywh36 with SMTP id 36so5645966ywh.31
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 10:18:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:sender:received:in-reply-to
         :references:from:date:x-google-sender-auth:message-id:subject:to
         :content-type;
        bh=RAms8XZb2ClsYyeejfTzDiA6OV5lCPiVcsi2yFdThkQ=;
        b=VcOgP6C99AzIV9NtfnVNMS40XqAx6fzfZ8/opgawspiV8lFaaebcxNAgnWmgFB67NY
         wsUyHuRuad2Nwx6rjIjpQIp5/+sFq90dST4CKqSylbIGANvYs2XqmGTU4TrXD8qnCWRJ
         MMXHvM8t65anQaDIkukTqtH3J0J6uQKYQ+cK4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:sender:in-reply-to:references:from:date
         :x-google-sender-auth:message-id:subject:to:content-type;
        b=GeDsoofDmiyzM95dWiSZh43bcou7Kd0IY46IeJbafRNqhkt9ajWATpbrTj1VD8SgeT
         K/WUdPiIKs5JDbXyJEod8iWMMZTBKOoxeXZvvsjgFO111LIrx3IIstw34XS15osdWTp0
         3i5UMTUNYyWtVknqbI0tnr/itYHum5WugaJbM=
MIME-Version: 1.0
Sender: pku.gaoqin@gmail.com
Received: by 10.231.34.12 with SMTP id j12mr3336144ibd.0.1250615908087; Tue, 
	18 Aug 2009 10:18:28 -0700 (PDT)
In-Reply-To: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
From: Qin Gao <qing@cs.cmu.edu>
Date: Tue, 18 Aug 2009 13:18:08 -0400
X-Google-Sender-Auth: c2c3a9826455b65c
Message-ID: <826304a60908181018t7d2d6428hae4a0d08d93e27f2@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00032557a12ef3bb7c04716db42a
X-Virus-Checked: Checked by ClamAV on apache.org

--00032557a12ef3bb7c04716db42a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Is the code called on Mapper/Reducer? If so probably DistributedCache is a
better solution
--Q


On Tue, Aug 18, 2009 at 12:00 PM, Ananth T. Sarathy <
ananth.t.sarathy@gmail.com> wrote:

> I am trying to download binary files stored in Hadoop but there is like a 2
> minute wait on a 20mb file when I try to execute the in.read(buf).
>
> is there a better way to be doing this?
>
>    private void pipe(InputStream in, OutputStream out) throws IOException
>    {    System.out.println(System.currentTimeMillis()+" Starting to Pipe
> Data");
>        byte[] buf = new byte[1024];
>        int read = 0;
>        while ((read = in.read(buf)) >= 0)
>        {
>            out.write(buf, 0, read);
>            System.out.println(System.currentTimeMillis()+" Piping Data");
>        }
>        out.flush();
>        System.out.println(System.currentTimeMillis()+" Finished Piping
> Data");
>
>    }
>
> public void readFile(String fileToRead, OutputStream out)
>            throws IOException
>    {
>        System.out.println(System.currentTimeMillis()+" Start Read File");
>        Path inFile = new Path(fileToRead);
>        System.out.println(System.currentTimeMillis()+" Set Path");
>        // Validate the input/output paths before reading/writing.
>
>        if (!fs.exists(inFile))
>        {
>            throw new HadoopFileException("Specified file  " + fileToRead
>                    + " not found.");
>        }
>        if (!fs.isFile(inFile))
>        {
>            throw new HadoopFileException("Specified file  " + fileToRead
>                    + " not found.");
>        }
>        // Open inFile for reading.
>        System.out.println(System.currentTimeMillis()+" Opening Data
> Stream");
>        FSDataInputStream in = fs.open(inFile);
>
>        System.out.println(System.currentTimeMillis()+" Opened Data
> Stream");
>        // Open outFile for writing.
>
>        // Read from input stream and write to output stream until EOF.
>        pipe(in, out);
>
>        // Close the streams when done.
>        out.close();
>        in.close();
>    }
> Ananth T Sarathy
>

--00032557a12ef3bb7c04716db42a--

From common-user-return-16846-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 17:22:41 2009
Return-Path: <common-user-return-16846-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 73396 invoked from network); 18 Aug 2009 17:22:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 17:22:40 -0000
Received: (qmail 43803 invoked by uid 500); 18 Aug 2009 17:22:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 43730 invoked by uid 500); 18 Aug 2009 17:22:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 43720 invoked by uid 99); 18 Aug 2009 17:22:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 17:22:56 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 17:22:46 +0000
Received: from [216.145.54.158] (socks1.corp.yahoo.com [216.145.54.158])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7IHJgOo068314
	for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 10:19:43 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=PCXFS7XqmNld12WlQk7OEknZRNw65dFDy9Ovfpn9GOF5c0Xh+KoMIV2in5uRCLYK
Message-ID: <4A8AE2AE.20008@yahoo-inc.com>
Date: Tue, 18 Aug 2009 10:19:42 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090608)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Datanode-Failure..!
References: <6f72e2db0908180156w574a23a9nf7d041b5977432fb@mail.gmail.com>
In-Reply-To: <6f72e2db0908180156w574a23a9nf7d041b5977432fb@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


 > 09/08/18 14:28:43 WARN datanode.DataNode: Invalid directory in 
dfs.data.dir:
 > can not create directory: 
/home/hadoop/Softwares/hadoop-0.19.0/temp/dfs/data

The above is your problem. Mostly your DataNode process could not create 
the directory under /home/hadoop.

Raghu.

Sugandha Naolekar wrote:
> Hello!  I am trying to invoke datanode named as repository1.  But, it's
> giving me below errors. Also, I tried formatting namenode and cleaning up
> the temporary directories. But, no help. And, I am not getting the relevant
> error details or status in log file as well...
> Do help me out on this..!
> 
> 
> hadoop@repository1:~/Softwares/hadoop/hadoop-0.19.0$ bin/hadoop datanode
> 09/08/18 14:28:43 INFO datanode.DataNode: STARTUP_MSG:
> /************************************************************
> STARTUP_MSG: Starting DataNode
> STARTUP_MSG:   host = repository1/10.20.220.35
> STARTUP_MSG:   args = []
> STARTUP_MSG:   version = 0.19.0
> STARTUP_MSG:   build =
> https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.19 -r 713890;
> compiled by 'ndaley' on Fri Nov 14 03:12:29 UTC 2008
> ************************************************************/
> 09/08/18 14:28:43 WARN datanode.DataNode: Invalid directory in dfs.data.dir:
> can not create directory: /home/hadoop/Softwares/hadoop-0.19.0/temp/dfs/data
> 09/08/18 14:28:43 ERROR datanode.DataNode: All directories in dfs.data.dir
> are invalid.
> 09/08/18 14:28:43 INFO datanode.DataNode: SHUTDOWN_MSG:
> /************************************************************
> SHUTDOWN_MSG: Shutting down DataNode at repository1/10.20.220.35
> ************************************************************/
> 
> 


From common-user-return-16847-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 18:21:46 2009
Return-Path: <common-user-return-16847-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 13031 invoked from network); 18 Aug 2009 18:21:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 18:21:46 -0000
Received: (qmail 42475 invoked by uid 500); 18 Aug 2009 18:22:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 42407 invoked by uid 500); 18 Aug 2009 18:22:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 42396 invoked by uid 99); 18 Aug 2009 18:22:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 18:22:01 +0000
X-ASF-Spam-Status: No, hits=3.8 required=10.0
	tests=RCVD_NUMERIC_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 18:21:49 +0000
Received: from SNV-EXBH01.ds.corp.yahoo.com (snv-exbh01.ds.corp.yahoo.com [207.126.227.249])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7IIK6Uf095790
	for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 11:20:06 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=IeAVuEV5yy1OfLJbkMqBvvfbfJPo+FBtn9Rf9UchI7MW3wLsVcKGZCDrk6MVe7Bq
Received: from SNV-EXVS02.ds.corp.yahoo.com ([216.145.51.202]) by SNV-EXBH01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Tue, 18 Aug 2009 11:20:06 -0700
Received: from 207.126.235.30 ([207.126.235.30]) by SNV-EXVS02.ds.corp.yahoo.com ([216.145.51.163]) via Exchange Front-End Server snv-webmail.corp.yahoo.com ([207.126.227.248]) with Microsoft Exchange Server HTTP-DAV ;
 Tue, 18 Aug 2009 18:20:06 +0000
User-Agent: Microsoft-Entourage/12.19.0.090515
Date: Tue, 18 Aug 2009 11:20:05 -0700
Subject: Re: Datanode-Failure..!
From: Boris Shkolnik <borya@yahoo-inc.com>
To: <common-user@hadoop.apache.org>
Message-ID: <C6B03EE5.1F895%borya@yahoo-inc.com>
Thread-Topic: Datanode-Failure..!
Thread-Index: AcogMIJLPj8W44aLVE6IugkslwttLQ==
In-Reply-To: <6f72e2db0908180156w574a23a9nf7d041b5977432fb@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-OriginalArrivalTime: 18 Aug 2009 18:20:06.0373 (UTC) FILETIME=[831D3950:01CA2030]
X-Virus-Checked: Checked by ClamAV on apache.org

> can not create directory: /home/hadoop/Softwares/hadoop-0.19.0/temp/dfs/data
Did you check if you can create files in this directory?

Boris.


On 8/18/09 1:56 AM, "Sugandha Naolekar" <sugandha.n87@gmail.com> wrote:

> Hello!  I am trying to invoke datanode named as repository1.  But, it's
> giving me below errors. Also, I tried formatting namenode and cleaning up
> the temporary directories. But, no help. And, I am not getting the relevant
> error details or status in log file as well...
> Do help me out on this..!
> 
> 
> hadoop@repository1:~/Softwares/hadoop/hadoop-0.19.0$ bin/hadoop datanode
> 09/08/18 14:28:43 INFO datanode.DataNode: STARTUP_MSG:
> /************************************************************
> STARTUP_MSG: Starting DataNode
> STARTUP_MSG:   host = repository1/10.20.220.35
> STARTUP_MSG:   args = []
> STARTUP_MSG:   version = 0.19.0
> STARTUP_MSG:   build =
> https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.19 -r 713890;
> compiled by 'ndaley' on Fri Nov 14 03:12:29 UTC 2008
> ************************************************************/
> 09/08/18 14:28:43 WARN datanode.DataNode: Invalid directory in dfs.data.dir:
> can not create directory: /home/hadoop/Softwares/hadoop-0.19.0/temp/dfs/data
> 09/08/18 14:28:43 ERROR datanode.DataNode: All directories in dfs.data.dir
> are invalid.
> 09/08/18 14:28:43 INFO datanode.DataNode: SHUTDOWN_MSG:
> /************************************************************
> SHUTDOWN_MSG: Shutting down DataNode at repository1/10.20.220.35
> ************************************************************/
> 


From common-user-return-16848-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 18:35:06 2009
Return-Path: <common-user-return-16848-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 21786 invoked from network); 18 Aug 2009 18:35:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 18:35:06 -0000
Received: (qmail 67094 invoked by uid 500); 18 Aug 2009 18:35:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 67005 invoked by uid 500); 18 Aug 2009 18:35:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 66995 invoked by uid 99); 18 Aug 2009 18:35:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 18:35:22 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.220.217 as permitted sender)
Received: from [209.85.220.217] (HELO mail-fx0-f217.google.com) (209.85.220.217)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 18:35:12 +0000
Received: by fxm17 with SMTP id 17so3618336fxm.13
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 11:34:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=hFYyuQqViE26J8Bx+Ic39as6p1ivpxiP12LY2gN9NC0=;
        b=pypVz8Z3QRu/vY1P84na/fVIXOSxU6hzNWoOUztLtUtGJ4V6Uo1gP78t2RD2F2XrQ2
         GqWgPzNMs72YPqYrX5yMik1prrtTK+qz739hS1GI+T0W+qGIz1W2/qF4vZxswT0dmNZA
         H6+MClhRjNgHmpOvzYqmRxjjdm1btN3ImEc40=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=ZlJiZ6y46PqBxeWeb+W24Vj7oFPHN+n8Qc+zQQMatw6DhyzXdaSOedtXvRzk0RLDn7
         TgVIHkmU/szyxAkJIVwn5e3yNdTXv47YWAgRr+QnzILm0fQ95vmqebpGhl6G2QzMkxHh
         M2fAw9PNyJo1MnaRT7wxL1755dqnDVimu019M=
MIME-Version: 1.0
Received: by 10.239.139.89 with SMTP id s25mr453270hbs.113.1250620492257; Tue, 
	18 Aug 2009 11:34:52 -0700 (PDT)
In-Reply-To: <826304a60908181018t7d2d6428hae4a0d08d93e27f2@mail.gmail.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
	 <826304a60908181018t7d2d6428hae4a0d08d93e27f2@mail.gmail.com>
Date: Tue, 18 Aug 2009 14:34:52 -0400
Message-ID: <ad681e7f0908181134l4c2d5e2du8a612be33505ce02@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f6cd8c309aa304716ec6fd
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f6cd8c309aa304716ec6fd
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

it 's not called on anything. Using s3. the write method is
public void writeToFile(String fileToWrite, InputStream in)
            throws IOException
    {
        Path outFile = new Path(fileToWrite);
        outFile.makeQualified(outFile.getFileSystem(conf));
        System.out.println(outFile);
        System.out.println(outFile.toUri());
        if (fs.exists(outFile))
            throw new HadoopFileException("Specified file  " + fileToWrite
                    + " already exists.");

        // Open outFile for writing.

        FSDataOutputStream out = fs.create(outFile);

        // Read from input stream and write to output stream until EOF.
        pipe(in, out);
        // Close the streams when done.
        System.out.println(System.currentTimeMillis()+" Closing file");
        out.close();
        System.out.println(System.currentTimeMillis()+" Closing input");

        in.close();
        System.out.println(System.currentTimeMillis()+" Done Read file");

    }

maybe i am going at this wrong
Ananth T Sarathy


On Tue, Aug 18, 2009 at 1:18 PM, Qin Gao <qing@cs.cmu.edu> wrote:

> Is the code called on Mapper/Reducer? If so probably DistributedCache is a
> better solution
> --Q
>
>
> On Tue, Aug 18, 2009 at 12:00 PM, Ananth T. Sarathy <
> ananth.t.sarathy@gmail.com> wrote:
>
> > I am trying to download binary files stored in Hadoop but there is like a
> 2
> > minute wait on a 20mb file when I try to execute the in.read(buf).
> >
> > is there a better way to be doing this?
> >
> >    private void pipe(InputStream in, OutputStream out) throws IOException
> >    {    System.out.println(System.currentTimeMillis()+" Starting to Pipe
> > Data");
> >        byte[] buf = new byte[1024];
> >        int read = 0;
> >        while ((read = in.read(buf)) >= 0)
> >        {
> >            out.write(buf, 0, read);
> >            System.out.println(System.currentTimeMillis()+" Piping Data");
> >        }
> >        out.flush();
> >        System.out.println(System.currentTimeMillis()+" Finished Piping
> > Data");
> >
> >    }
> >
> > public void readFile(String fileToRead, OutputStream out)
> >            throws IOException
> >    {
> >        System.out.println(System.currentTimeMillis()+" Start Read File");
> >        Path inFile = new Path(fileToRead);
> >        System.out.println(System.currentTimeMillis()+" Set Path");
> >        // Validate the input/output paths before reading/writing.
> >
> >        if (!fs.exists(inFile))
> >        {
> >            throw new HadoopFileException("Specified file  " + fileToRead
> >                    + " not found.");
> >        }
> >        if (!fs.isFile(inFile))
> >        {
> >            throw new HadoopFileException("Specified file  " + fileToRead
> >                    + " not found.");
> >        }
> >        // Open inFile for reading.
> >        System.out.println(System.currentTimeMillis()+" Opening Data
> > Stream");
> >        FSDataInputStream in = fs.open(inFile);
> >
> >        System.out.println(System.currentTimeMillis()+" Opened Data
> > Stream");
> >        // Open outFile for writing.
> >
> >        // Read from input stream and write to output stream until EOF.
> >        pipe(in, out);
> >
> >        // Close the streams when done.
> >        out.close();
> >        in.close();
> >    }
> > Ananth T Sarathy
> >
>

--001485f6cd8c309aa304716ec6fd--

From common-user-return-16849-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 19:24:22 2009
Return-Path: <common-user-return-16849-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 36045 invoked from network); 18 Aug 2009 19:24:22 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 19:24:22 -0000
Received: (qmail 49221 invoked by uid 500); 18 Aug 2009 19:24:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 49135 invoked by uid 500); 18 Aug 2009 19:24:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 49123 invoked by uid 99); 18 Aug 2009 19:24:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 19:24:38 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 19:23:46 +0000
Received: from [172.21.148.79] (wlanvpn-mc2e-246-79.corp.yahoo.com [172.21.148.79])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7IJNGsC076321
	for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 12:23:16 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=kZzk/sl4squ7/4fqnNOsuqAnDDZRsDmyDtEjj9KzquUsnKVnxvUR5clZJGe0S/ZA
Message-ID: <4A8AFFA4.1020401@yahoo-inc.com>
Date: Tue, 18 Aug 2009 12:23:16 -0700
From: Jakob Homan <jhoman@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.12 (Macintosh/20080213)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Some issues!
References: <6f72e2db0908180058o1c0ad4c5rf80f77c5cff797ac@mail.gmail.com>
In-Reply-To: <6f72e2db0908180058o1c0ad4c5rf80f77c5cff797ac@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Sugandha-
    I would suggest you look at the FileSystem interface, which is our 
starting point for implementing a file system for use with Hadoop. 
There are several implementations, such as S3FileSystem, that you can 
look at for inspiration.

Jakob Homan
Hadoop at Yahoo!

Sugandha Naolekar wrote:
> Hello!
> 
>     I am planning to implement a DFS of that would work on the same lines of
> principle as of HDFS but, with some extra features. Like as, Encryption and
> decryption of data that would be transferred between remote client and
> Hadoop cluster.
> 
>    I want to encrypt data before or while placing it in HDFS and then while
> retreival of the same, vice versa should happen,i.e; decryption....
> 
> 
> Can you please suggest me how to approach for the entire episode?
> 
> Regards!
> Sugandha
> 


From common-user-return-16850-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 20:12:29 2009
Return-Path: <common-user-return-16850-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 48833 invoked from network); 18 Aug 2009 20:12:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 20:12:29 -0000
Received: (qmail 30974 invoked by uid 500); 18 Aug 2009 20:12:45 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 30892 invoked by uid 500); 18 Aug 2009 20:12:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 30882 invoked by uid 99); 18 Aug 2009 20:12:45 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 20:12:45 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of gmporter@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 20:12:36 +0000
Received: by iwn6 with SMTP id 6so78356iwn.5
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 13:12:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=trYj5YSA5b/QlsdQEwdx7p81JVWj+4TM5f22bQF8Lnk=;
        b=boLMczGMfOdKd2JkqEpXEAFuB493yG7jDHl6TnhmvQFwijyk+CT4dNnPDOBUx202aB
         icXU/5SdJBeLASxsS/s7L9hdzO4ml3TbIM3PKGFsM/HHBYOciGrrdjx6kUpbRzW9MVmc
         s5KkuY7mAIedqpGd5ZCcIA+msIo2YEJ5yq3Ho=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=Du1QcMgR4/6jqazul2ZeoKbDAJ4Z7DNLqgKxRGwJOce8r4O571pFEi21v5G6YXyvA6
         EKnhJLOqm6KfeVJbKmLlnD9S3f8yrE3UxLijd0J8v1M0BNcGBQgIr2pPdu7mg2UfX7sd
         dJlFIZScnLcLD18v+I/tnlk4NsOLw7C8koOo8=
MIME-Version: 1.0
Received: by 10.231.11.13 with SMTP id r13mr3511048ibr.23.1250626335346; Tue, 
	18 Aug 2009 13:12:15 -0700 (PDT)
In-Reply-To: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
Date: Tue, 18 Aug 2009 13:12:15 -0700
Message-ID: <cd40e6450908181312w59e21584id1353a2f004c8635@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: George Porter <gmporter@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

You could try changing your buffer size from 1KB to a much higher
number (like 64MB).

i.e.,

  byte[] buf =3D new byte[1024*1024*64];

-George

On Tue, Aug 18, 2009 at 9:00 AM, Ananth T.
Sarathy<ananth.t.sarathy@gmail.com> wrote:
> I am trying to download binary files stored in Hadoop but there is like a=
 2
> minute wait on a 20mb file when I try to execute the in.read(buf).
>
> is there a better way to be doing this?
>
> =A0 =A0private void pipe(InputStream in, OutputStream out) throws IOExcep=
tion
> =A0 =A0{ =A0 =A0System.out.println(System.currentTimeMillis()+" Starting =
to Pipe
> Data");
> =A0 =A0 =A0 =A0byte[] buf =3D new byte[1024];
> =A0 =A0 =A0 =A0int read =3D 0;
> =A0 =A0 =A0 =A0while ((read =3D in.read(buf)) >=3D 0)
> =A0 =A0 =A0 =A0{
> =A0 =A0 =A0 =A0 =A0 =A0out.write(buf, 0, read);
> =A0 =A0 =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Pi=
ping Data");
> =A0 =A0 =A0 =A0}
> =A0 =A0 =A0 =A0out.flush();
> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Finished P=
iping
> Data");
>
> =A0 =A0}
>
> public void readFile(String fileToRead, OutputStream out)
> =A0 =A0 =A0 =A0 =A0 =A0throws IOException
> =A0 =A0{
> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Start Read=
 File");
> =A0 =A0 =A0 =A0Path inFile =3D new Path(fileToRead);
> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Set Path")=
;
> =A0 =A0 =A0 =A0// Validate the input/output paths before reading/writing.
>
> =A0 =A0 =A0 =A0if (!fs.exists(inFile))
> =A0 =A0 =A0 =A0{
> =A0 =A0 =A0 =A0 =A0 =A0throw new HadoopFileException("Specified file =A0"=
 + fileToRead
> =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0+ " not found.");
> =A0 =A0 =A0 =A0}
> =A0 =A0 =A0 =A0if (!fs.isFile(inFile))
> =A0 =A0 =A0 =A0{
> =A0 =A0 =A0 =A0 =A0 =A0throw new HadoopFileException("Specified file =A0"=
 + fileToRead
> =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0+ " not found.");
> =A0 =A0 =A0 =A0}
> =A0 =A0 =A0 =A0// Open inFile for reading.
> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Opening Da=
ta
> Stream");
> =A0 =A0 =A0 =A0FSDataInputStream in =3D fs.open(inFile);
>
> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Opened Dat=
a
> Stream");
> =A0 =A0 =A0 =A0// Open outFile for writing.
>
> =A0 =A0 =A0 =A0// Read from input stream and write to output stream until=
 EOF.
> =A0 =A0 =A0 =A0pipe(in, out);
>
> =A0 =A0 =A0 =A0// Close the streams when done.
> =A0 =A0 =A0 =A0out.close();
> =A0 =A0 =A0 =A0in.close();
> =A0 =A0}
> Ananth T Sarathy
>

From common-user-return-16851-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 20:47:31 2009
Return-Path: <common-user-return-16851-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 58685 invoked from network); 18 Aug 2009 20:47:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 20:47:31 -0000
Received: (qmail 91758 invoked by uid 500); 18 Aug 2009 20:47:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91702 invoked by uid 500); 18 Aug 2009 20:47:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91692 invoked by uid 99); 18 Aug 2009 20:47:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 20:47:47 +0000
X-ASF-Spam-Status: No, hits=-2.1 required=10.0
	tests=HABEAS_ACCREDITED_SOI,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of andy.sautins@returnpath.net designates 38.109.196.9 as permitted sender)
Received: from [38.109.196.9] (HELO mail.corp.returnpath.net) (38.109.196.9)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 18 Aug 2009 20:47:38 +0000
Received: from mail.corp.returnpath.net (localhost.localdomain [127.0.0.1])
	by mail.corp.returnpath.net (Postfix) with ESMTP id 5B3F9250231;
	Tue, 18 Aug 2009 14:47:17 -0600 (MDT)
DKIM-Signature: v=1; a=rsa-sha1; c=relaxed; d=returnpath.net; h=from:to
	:date:subject:message-id:content-type:mime-version; s=selector1;
	 bh=97J+Cea8IL5aMT3eanthadXth98=; b=hfgF08xJJOS9Rlw5ig6AVIdKtSyg
	buSTuxIwp6APPPmMTvqROnoxTiEkAts8elGUvoVOQqyOK3dtsCm4OKHn/36shc42
	7c1+oLIhQyapkmFE5RtIBKrsE8sY5Ycyb4xBuWulCuwJcdjLcKx14Y4bofbPn5cz
	9UXdZ7fa8uQ0QGw=
DomainKey-Signature: a=rsa-sha1; c=nofws; d=returnpath.net; h=from:to
	:date:subject:message-id:content-type:mime-version; q=dns; s=
	selector1; b=bfXrLIhlfZG2KONPFIarMBSuSM5PhHXDhlwgG3h+jYd9PsDoewo
	5w+98Gj9Y1I2pcszG8BksVfBUKOO21diTasdna2T2RYTbIdizXDi1Ve4XhW0UJYj
	wdY4ed3ilbXejcvpZJt39Spdz6AjIHi6pGZdhuwjPgGYkN5fRAIt4C8o=
Received: from rpcoex01.rpcorp.local (unknown [10.0.1.142])
	by mail.corp.returnpath.net (Postfix) with ESMTP id 51F5B250078;
	Tue, 18 Aug 2009 20:47:17 +0000 (UTC)
Received: from rpcoex01.rpcorp.local ([10.0.1.142]) by rpcoex01.rpcorp.local
 ([10.0.1.142]) with mapi; Tue, 18 Aug 2009 14:47:17 -0600
From: Andy Sautins <andy.sautins@returnpath.net>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Tue, 18 Aug 2009 14:47:14 -0600
Subject: Looking for advice on file structure...
Thread-Topic: Looking for advice on file structure...
Thread-Index: AcogRRDcnrPK0ln2SvmfcXomQ6dFIw==
Message-ID: <E17A8B06D3D99B4CAA00E72B7BC41C1B0E69511FF4@rpcoex01.rpcorp.local>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
x-ems-proccessed: Yma8eInq5qTp77FzNR/WDA==
x-ems-stamp: 6cds9qVH4WCLt7c/Vr1dlA==
Content-Type: multipart/alternative;
	boundary="_000_E17A8B06D3D99B4CAA00E72B7BC41C1B0E69511FF4rpcoex01rpcor_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_E17A8B06D3D99B4CAA00E72B7BC41C1B0E69511FF4rpcoex01rpcor_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable


   All,

   I'm looking for a little bit of advice on how to format files.

   The problem I have is I have log files from a number of different source=
s.  The data elements between log files overlaps by about 80%, but there ar=
e unique data items in each of the log files that I want to keep and be abl=
e to access from my Map/Reduce jobs.  There also isn't a single obvious key=
 to the log file entries.  A quick example would be two different log files=
.  Log file a has 3 columns of data types A,B,C and is tab delimited.  Log =
file 2 has data types A,B,C,D and is pipe delimited.  I'd like to pre-proce=
ss them into files where in the map/reduce job I could consistently access =
data element A across both types of log files and also access element D if =
it exists.

    .I suspect the best answer would be to pre-process the files into a com=
mon file format that allows for variable data values within a log line.   W=
hat I'm wondering is, has anyone else solved this type of problem and did y=
ou find a solution you liked?

   Where I've been looking so far is to use SequenceFiles.  There isn't a l=
ogical key, so the key in the sequence file my thought was to just have a l=
ine number, similar to the default map file input format although that feel=
s a little weird.  For the value, since I want somewhat arbitrary key/value=
s for the SequenceFile value my thought was to just have the value as a ser=
ialized HashMap.

    Any thoughts as to if I'm trying to re-invent the wheel here or going o=
ff in a strange direction?

    Thanks

    Andy

--_000_E17A8B06D3D99B4CAA00E72B7BC41C1B0E69511FF4rpcoex01rpcor_--

From common-user-return-16852-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 18 23:09:24 2009
Return-Path: <common-user-return-16852-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 33146 invoked from network); 18 Aug 2009 23:09:24 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 18 Aug 2009 23:09:24 -0000
Received: (qmail 86573 invoked by uid 500); 18 Aug 2009 23:09:41 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 86490 invoked by uid 500); 18 Aug 2009 23:09:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 82445 invoked by uid 99); 18 Aug 2009 21:41:30 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
x-SBRS: None
X-REMOTE-IP: 10.12.10.53
X-IronPort-AV: E=Sophos;i="4.43,404,1246852800"; 
   d="scan'208,217";a="33669913"
From: "Poole, Samuel [USA]" <poole_samuel@bah.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Tue, 18 Aug 2009 17:40:59 -0400
Subject: Hadoop for Independant Tasks not using Map/Reduce?
Thread-Topic: Hadoop for Independant Tasks not using Map/Reduce?
Thread-Index: AcogTJNO/Zi/5eXvRUm1Q9qSpmPIWA==
Message-ID: <1072637276A0534CB8DE6BA57D95D39E0EF06CE0@ASHBMBX02.resource.ds.bah.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: multipart/alternative;
	boundary="_000_1072637276A0534CB8DE6BA57D95D39E0EF06CE0ASHBMBX02resour_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_1072637276A0534CB8DE6BA57D95D39E0EF06CE0ASHBMBX02resour_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

I am new to Hadoop (I have not yet installed/configured), and I want to mak=
e sure that I have the correct tool for the job.  I do not "currently" have=
 a need for the Map/Reduce functionality, but I am interested in using Hado=
op for task orchestration, task monitoring, etc. over numerous nodes in a c=
omputing cluster.  Our primary programs (written in C++ and launched via sh=
ell scripts) each run independantly on a single node, but are deployed to d=
ifferent nodes for load balancing.  I want to task/initiate these processes=
 on different nodes through a Java program located on a central server.  I =
was hoping to use Hadoop as a foundation for this.

I read the following in the FAQ section:

"How do I use Hadoop Streaming to run an arbitrary set of (semi-)independen=
t tasks?

Often you do not need the full power of Map Reduce, but only need to run mu=
ltiple instances of the same program - either on different parts of the dat=
a, or on the same data, but with different parameters. You can use Hadoop S=
treaming to do this. "

So, two questions I guess.

1.  Can I use Hadoop for this purpose without using Map/Reduce functionalit=
y?

2.  Are there any examples available on how to implement this sort of confi=
guration?

Any help would be greatly appreciated.

Sam







--_000_1072637276A0534CB8DE6BA57D95D39E0EF06CE0ASHBMBX02resour_--

From common-user-return-16853-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 01:44:20 2009
Return-Path: <common-user-return-16853-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 96457 invoked from network); 19 Aug 2009 01:44:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 01:44:20 -0000
Received: (qmail 9141 invoked by uid 500); 19 Aug 2009 01:44:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 9072 invoked by uid 500); 19 Aug 2009 01:44:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 9062 invoked by uid 500); 19 Aug 2009 01:44:37 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 9059 invoked by uid 99); 19 Aug 2009 01:44:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 01:44:37 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 01:44:27 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MdaDe-00011F-5n
	for core-user@hadoop.apache.org; Tue, 18 Aug 2009 18:44:06 -0700
Message-ID: <25036326.post@talk.nabble.com>
Date: Tue, 18 Aug 2009 18:44:06 -0700 (PDT)
From: Snehal Nagmote <nagmote.snehal@gmail.com>
To: core-user@hadoop.apache.org
Subject: Re: Hadoop-Archive Error for size of input data >2GB
In-Reply-To: <48848785.7000900@aol.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: nagmote.snehal@gmail.com
References: <48848785.7000900@aol.com>
X-Virus-Checked: Checked by ClamAV on apache.org


Hi,

 how to unarchive the logical files from the har file ?Is there anyway t o
unarchive the logical files.



Pratyush Banerjee-2 wrote:
> 
> Hi All,
> 
> I have been using hadoop archives programmatically  to generate  har 
> archives from some logfiles  which are being dumped into the hdfs.
> 
> When the input directory to Hadoop Archiving program has files of size 
> more than 2GB, strangely the archiving fails with a error message saying
> 
> INFO jvm.JvmMetrics: Initializing JVM Metrics with 
> processName=JobTracker, sessionId=   Illegal Capacity: -1
> 
> Going into the code i found out that this was due to numMaps having the 
> Value of -1.
> 
> As per the code in org.apache.hadoop.util.HadoopArchives: 
> archive(List<Path> srcPaths, String archiveName, Path dest)
> 
> the numMaps is initialized as 
> int numMaps = (int)(totalSize/partSize);
> //run atleast one map.
> conf.setNumMapTasks(numMaps == 0? 1:numMaps);
> 
> partSize has been statically assigned the value of 2GB in the beginning 
> of the class as,
> 
> static final long partSize = 2 * 1024 * 1024 * 1024
> 
> Strangely enough, the value i find assigned to partSize is  =  -
> 2147483648
> 
> Hence as a result in case of input directories of greater size, numMaps 
> is assigned -1 which leads to the code throwing up error.
> 
> I am using hadoop-0.17.1 and I got the archiving facility after applying 
> the patch hadoop-3307_4 patch.
> 
> This looks like a bug for me, so please let me know how to go about it.
> 
> Pratyush Banerjee
> 
> 
> 

-- 
View this message in context: http://www.nabble.com/Hadoop-Archive-Error-for-size-of-input-data-%3E2GB-tp18568129p25036326.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-16854-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 05:23:28 2009
Return-Path: <common-user-return-16854-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 56850 invoked from network); 19 Aug 2009 05:23:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 05:23:28 -0000
Received: (qmail 77440 invoked by uid 500); 19 Aug 2009 05:23:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 77366 invoked by uid 500); 19 Aug 2009 05:23:44 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 77356 invoked by uid 99); 19 Aug 2009 05:23:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 05:23:44 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 05:23:35 +0000
Received: by yxe15 with SMTP id 15so5643415yxe.5
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 22:23:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=hFUTFowAyZC+ye07ElfKGjHltG6U293WlKNRBJrdbdA=;
        b=RC9xga0H8B27DorlxpFpD/rSd1AY7dmaNfiSkDlnmufaUOV/ZPrilDX6CNLOdS7d1y
         qx2DZ9dy5hCnbOKAOl/cGp86JYWfBxI/yWAsz4GFV2h8zh81UWGcGjYy8tlf/VWlmoXk
         wWQjc3HItqrlmtfo3zKpVVsS6Vr4cgJptuEWI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=eBRH7OeMhs79+d93NrxMO1Qtevtjef4db439m4J6euqpfjoZ3NB1eJ5/uE3O7kGMoq
         UEO9iGRRu7lPtKND5zCM2bLyEfBQVYPhnrXKmv3zNzhSynfR7o8zo981uwNbRclXCijc
         rRSOSnwROOq/fAjp7TB20s0NOvXMr6npIC3w0=
MIME-Version: 1.0
Received: by 10.101.63.5 with SMTP id q5mr6559732ank.82.1250659394009; Tue, 18 
	Aug 2009 22:23:14 -0700 (PDT)
Date: Wed, 19 Aug 2009 13:23:13 +0800
Message-ID: <3b1311780908182223m6d75da2dxf33118c91496d08@mail.gmail.com>
Subject: How to deal with "too many fetch failures"?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636eee26dea3a22047177d486
X-Virus-Checked: Checked by ClamAV on apache.org

--001636eee26dea3a22047177d486
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello, all
    I have met the problem "too many fetch failures" when I submit a big
job(e.g. tasks>10000). And I know this error occurs when several reducers
are unable to fetch the given map output. However, I'm sure slaves can
contact each other.
    I feel puzzled and have no idea to deal with it. Maybe the network
transfer is bad, but how can I solve it? Increase
mapred.reduce.parallel.copies and mapred.reduce.copy.backoff can make
changes?
    Thank you!
    Inifok

--001636eee26dea3a22047177d486--

From common-user-return-16855-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 05:27:38 2009
Return-Path: <common-user-return-16855-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 59180 invoked from network); 19 Aug 2009 05:27:38 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 05:27:38 -0000
Received: (qmail 82746 invoked by uid 500); 19 Aug 2009 05:27:54 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82676 invoked by uid 500); 19 Aug 2009 05:27:54 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82666 invoked by uid 99); 19 Aug 2009 05:27:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 05:27:54 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.20] (HELO mrout1-b.corp.re1.yahoo.com) (69.147.107.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 05:27:43 +0000
Received: from [216.145.54.158] (socks1.corp.yahoo.com [216.145.54.158])
	by mrout1-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7J5Qf1m053273
	for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 22:26:42 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=pUTiNFT36XbVk9rjfYV4ZmEa0TCzULCVO8BN76vbtsqyfZkgEaW7lcQYHA0hFxS+
Message-ID: <4A8B8D11.8020008@yahoo-inc.com>
Date: Tue, 18 Aug 2009 22:26:41 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090608)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Faster alternative to FSDataInputStream
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
In-Reply-To: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Ananth T. Sarathy wrote:
> I am trying to download binary files stored in Hadoop but there is like a 2
> minute wait on a 20mb file when I try to execute the in.read(buf).

What does this mean : 2 min to pipe 20mb or one or your one of the 
in.read() calls took 2 minutes? Your code actually measures team for 
read and write.

There is nothing in FSInputstream to cause this slow down. Do you think 
anyone would use Hadoop otherwise? It would be as fast as underlying 
filesystem goes.

Raghu.

> is there a better way to be doing this?
> 
>     private void pipe(InputStream in, OutputStream out) throws IOException
>     {    System.out.println(System.currentTimeMillis()+" Starting to Pipe
> Data");
>         byte[] buf = new byte[1024];
>         int read = 0;
>         while ((read = in.read(buf)) >= 0)
>         {
>             out.write(buf, 0, read);
>             System.out.println(System.currentTimeMillis()+" Piping Data");
>         }
>         out.flush();
>         System.out.println(System.currentTimeMillis()+" Finished Piping
> Data");
> 
>     }
> 
> public void readFile(String fileToRead, OutputStream out)
>             throws IOException
>     {
>         System.out.println(System.currentTimeMillis()+" Start Read File");
>         Path inFile = new Path(fileToRead);
>         System.out.println(System.currentTimeMillis()+" Set Path");
>         // Validate the input/output paths before reading/writing.
> 
>         if (!fs.exists(inFile))
>         {
>             throw new HadoopFileException("Specified file  " + fileToRead
>                     + " not found.");
>         }
>         if (!fs.isFile(inFile))
>         {
>             throw new HadoopFileException("Specified file  " + fileToRead
>                     + " not found.");
>         }
>         // Open inFile for reading.
>         System.out.println(System.currentTimeMillis()+" Opening Data
> Stream");
>         FSDataInputStream in = fs.open(inFile);
> 
>         System.out.println(System.currentTimeMillis()+" Opened Data
> Stream");
>         // Open outFile for writing.
> 
>         // Read from input stream and write to output stream until EOF.
>         pipe(in, out);
> 
>         // Close the streams when done.
>         out.close();
>         in.close();
>     }
> Ananth T Sarathy
> 


From common-user-return-16856-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 05:31:32 2009
Return-Path: <common-user-return-16856-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 62201 invoked from network); 19 Aug 2009 05:31:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 05:31:31 -0000
Received: (qmail 92109 invoked by uid 500); 19 Aug 2009 05:31:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 92039 invoked by uid 500); 19 Aug 2009 05:31:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 92029 invoked by uid 99); 19 Aug 2009 05:31:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 05:31:47 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of outbackdan@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 05:31:38 +0000
Received: by ywh36 with SMTP id 36so6175063ywh.31
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 22:31:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=IKO5soBf0wauCQmoKNmcW1KwAi/b5OnJpxJAl3bCqvo=;
        b=Dk0gS7x9a4koH5STm5/GYmarCK32p/SzZDTUDaMkYCg974dPqfzgMz5z4Bq6l8pISw
         6tMCJ3qwwzaD8GqAaz6V1B+q6ojWjAmkvClrYeEYSY7g4iZArrHE2/xaRl0LVrkdKm7g
         XkwhWPlThigahzXsvvahQFpiFEN/zOn/mBaMs=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=IcOpGbEdhj9v+Oaouo9Reu4eV85BjGTPvwGxPJQV14EvGiWJz9sW3QSxhGyxTkGxAh
         pasChxA6yVJAs5iDOBHKxsNaKGfWtLjI1YG7N9de3H4kkf17J0IHzjKJi5zENS90YQQG
         S3khAAglH3Bf8FbwoWHFMaR93IuaqKCyIMdLE=
MIME-Version: 1.0
Received: by 10.151.92.20 with SMTP id u20mr9612162ybl.20.1250659878249; Tue, 
	18 Aug 2009 22:31:18 -0700 (PDT)
Date: Wed, 19 Aug 2009 15:31:18 +1000
Message-ID: <c9f8312d0908182231n64183a6fh245306384aaa873e@mail.gmail.com>
Subject: RuntimeException: Not a host:port pair: local error when running 
	bin/start-mapred.sh
From: Daniel someone <outbackdan@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd34c78c72569047177f1df
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd34c78c72569047177f1df
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi everybody,

I am after some help with the following error that I am getting when I try
to start the start-mapred.sh. To me looked like it was getting "local"
passed as the hostname:port pair but I have double checked my settings in
"core-site.xml" and they look correct to me, I have tried changing the
values of mapred.job.tracker to FQDN and IP but this had not changed the
behaviour.
I am running:
hadoop 0.20.0
Java 1.6.0._16
solaris 9

Any help appreciated
Regards
Dan

Error seen in logs:

2009-08-18 18:34:07,102 INFO org.apache.hadoop.mapred.JobTracker:
STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = xxxxxx/xxxxxx
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.0
STARTUP_MSG:   build =
https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r 763504;
compiled by 'ndale
y' on Thu Apr  9 05:18:40 UTC 2009
************************************************************/
2009-08-18 18:34:08,622 FATAL org.apache.hadoop.mapred.JobTracker:
java.lang.RuntimeException: Not a host:port pair: l
ocal
        at
org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:136)
        at
org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:123)
        at
org.apache.hadoop.mapred.JobTracker.getAddress(JobTracker.java:1756)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1521)
        at
org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:174)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:3528)

2009-08-18 18:34:08,627 INFO org.apache.hadoop.mapred.JobTracker:
SHUTDOWN_MSG:
/************************************************************

--000e0cd34c78c72569047177f1df--

From common-user-return-16857-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 06:08:29 2009
Return-Path: <common-user-return-16857-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81138 invoked from network); 19 Aug 2009 06:08:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 06:08:29 -0000
Received: (qmail 39544 invoked by uid 500); 19 Aug 2009 06:08:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 39462 invoked by uid 500); 19 Aug 2009 06:08:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 39452 invoked by uid 99); 19 Aug 2009 06:08:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 06:08:46 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.132.240 as permitted sender)
Received: from [209.85.132.240] (HELO an-out-0708.google.com) (209.85.132.240)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 06:08:37 +0000
Received: by an-out-0708.google.com with SMTP id c38so1910358ana.29
        for <common-user@hadoop.apache.org>; Tue, 18 Aug 2009 23:08:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=afDZuK1ndcUSEkQ59dZkQDoHzhZGFeUdOj/EU/8d20s=;
        b=eZKOpqHDM1vQhUtT0wefb05jPk/AhmzsGrGTvL9jIEHuaayP9do3/zuqMHFmICAv9X
         CKpr10Fd7YoSdbW8hlE4IpPkx9ygOvxvsNgs9sBk1zhMNvlp0i2g45WxDUXhgBQoFJsx
         CdimmM0QJMJCENCndjTjY3LIBvQN+2Dw2apH0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=eUQ6NGVeW3lA1yR0C8/T59UbrQdwPRGayk6RUDt9rhMKct3ps2YOHACnDMXzveLNxs
         n8lQ3KUhcWuvqbbXMLw+wa3grfug/4sFySiRI6P5/zl9/LUuVkA4gnmK+9D4I6+wbLC+
         hIk2uUkFFTB/O7yc8LaAn1AAExdWGOexW8uXY=
MIME-Version: 1.0
Received: by 10.101.125.20 with SMTP id c20mr6602245ann.101.1250662096945; 
	Tue, 18 Aug 2009 23:08:16 -0700 (PDT)
In-Reply-To: <1072637276A0534CB8DE6BA57D95D39E0EF06CE0@ASHBMBX02.resource.ds.bah.com>
References: <1072637276A0534CB8DE6BA57D95D39E0EF06CE0@ASHBMBX02.resource.ds.bah.com>
Date: Wed, 19 Aug 2009 14:08:16 +0800
Message-ID: <3b1311780908182308h153af664m128a22359dbcab07@mail.gmail.com>
Subject: Re: Hadoop for Independant Tasks not using Map/Reduce?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636ed710505c0bc0471787651
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed710505c0bc0471787651
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hadoop streaming is the utility allows you to create and run Map/Reduce jobs
with any executable or script as the mapper and/or the reducer. I'm not
familiar with it, but I think you can find something useful here
http://hadoop.apache.org/common/docs/current/streaming.html

2009/8/19 Poole, Samuel [USA] <poole_samuel@bah.com>

> I am new to Hadoop (I have not yet installed/configured), and I want to
> make sure that I have the correct tool for the job.  I do not "currently"
> have a need for the Map/Reduce functionality, but I am interested in using
> Hadoop for task orchestration, task monitoring, etc. over numerous nodes in
> a computing cluster.  Our primary programs (written in C++ and launched via
> shell scripts) each run independantly on a single node, but are deployed to
> different nodes for load balancing.  I want to task/initiate these processes
> on different nodes through a Java program located on a central server.  I
> was hoping to use Hadoop as a foundation for this.
>
> I read the following in the FAQ section:
>
> "How do I use Hadoop Streaming to run an arbitrary set of
> (semi-)independent tasks?
>
> Often you do not need the full power of Map Reduce, but only need to run
> multiple instances of the same program - either on different parts of the
> data, or on the same data, but with different parameters. You can use Hadoop
> Streaming to do this. "
>
> So, two questions I guess.
>
> 1.  Can I use Hadoop for this purpose without using Map/Reduce
> functionality?
>
> 2.  Are there any examples available on how to implement this sort of
> configuration?
>
> Any help would be greatly appreciated.
>
> Sam
>
>
>
>
>
>
>

--001636ed710505c0bc0471787651--

From common-user-return-16858-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 06:16:29 2009
Return-Path: <common-user-return-16858-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 85884 invoked from network); 19 Aug 2009 06:16:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 06:16:29 -0000
Received: (qmail 56597 invoked by uid 500); 19 Aug 2009 06:16:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 56511 invoked by uid 500); 19 Aug 2009 06:16:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 56500 invoked by uid 99); 19 Aug 2009 06:16:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 06:16:46 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [76.96.59.211] (HELO QMTA11.westchester.pa.mail.comcast.net) (76.96.59.211)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 06:16:34 +0000
Received: from OMTA10.westchester.pa.mail.comcast.net ([76.96.62.28])
	by QMTA11.westchester.pa.mail.comcast.net with comcast
	id W6Fz1c0070cZkys5B6GFiP; Wed, 19 Aug 2009 06:16:15 +0000
Received: from [10.0.0.59] ([209.131.62.115])
	by OMTA10.westchester.pa.mail.comcast.net with comcast
	id W6G51c0042VBGtd3W6G8xL; Wed, 19 Aug 2009 06:16:13 +0000
Message-Id: <EB0CE9A2-5110-43FE-B4AB-57358AA531F0@apache.org>
From: Owen O'Malley <omalley@apache.org>
To: common-user@hadoop.apache.org
In-Reply-To: <1072637276A0534CB8DE6BA57D95D39E0EF06CE0@ASHBMBX02.resource.ds.bah.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: Hadoop for Independant Tasks not using Map/Reduce?
Date: Tue, 18 Aug 2009 23:16:04 -0700
References: <1072637276A0534CB8DE6BA57D95D39E0EF06CE0@ASHBMBX02.resource.ds.bah.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org


On Aug 18, 2009, at 2:40 PM, Poole, Samuel [USA] wrote:

> I am new to Hadoop (I have not yet installed/configured), and I want  
> to make sure that I have the correct tool for the job.  I do not  
> "currently" have a need for the Map/Reduce functionality, but I am  
> interested in using Hadoop for task orchestration, task monitoring,  
> etc. over numerous nodes in a computing cluster.  Our primary  
> programs (written in C++ and launched via shell scripts) each run  
> independantly on a single node, but are deployed to different nodes  
> for load balancing.  I want to task/initiate these processes on  
> different nodes through a Java program located on a central server.   
> I was hoping to use Hadoop as a foundation for this.

Just create a job with 0 reduces. The map tasks will run independently  
across the cluster.  Take a look at RandomWriter, which just writes a  
set of random data files.

-- Owen

From common-user-return-16859-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 07:44:55 2009
Return-Path: <common-user-return-16859-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 20031 invoked from network); 19 Aug 2009 07:44:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 07:44:55 -0000
Received: (qmail 67004 invoked by uid 500); 19 Aug 2009 07:45:12 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 66945 invoked by uid 500); 19 Aug 2009 07:45:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 66935 invoked by uid 99); 19 Aug 2009 07:45:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 07:45:11 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ted.dunning@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 07:45:03 +0000
Received: by yxe15 with SMTP id 15so5695511yxe.5
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 00:44:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=O73VnSanRtOv9TuAB0KVkNVOCeT+0Uh3uQ6PyYMlTEU=;
        b=ALZmoiYiv1yher3Q3opPtAM4TTEdO+kYi816zt1Dmz8o15N2pF4UFm2q2j4JbylsXF
         xLSgUF2loke0TbGdrpqudp5gWq4gI0bUza8RL5kDbQVGx0566G4wRdXI1mvcDda6nOzS
         qtXyw0PB9HPVwuYIf9BKBz+AG7mupuRxoCla0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=gXbtBYySm3glU2IH2apLdbSOV2hfLvqcpORxwosa4KsNcdzKkI+CeWqn07D3G30ycz
         pjMGoktxpbQGrLuSGStIFf2HbqrjAaALHmYL+kutIoMWQKV5DBfyh+c+NL8PgZHYQyIA
         EpalBJIezIZIGoAv9tzy3KmuvlQr1hLdtbRHs=
MIME-Version: 1.0
Received: by 10.150.141.2 with SMTP id o2mr9827388ybd.49.1250667883085; Wed, 
	19 Aug 2009 00:44:43 -0700 (PDT)
In-Reply-To: <3b1311780908182223m6d75da2dxf33118c91496d08@mail.gmail.com>
References: <3b1311780908182223m6d75da2dxf33118c91496d08@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Wed, 19 Aug 2009 00:44:23 -0700
Message-ID: <c7d45fc70908190044u77503a5dsed88dc9a37f10cf@mail.gmail.com>
Subject: Re: How to deal with "too many fetch failures"?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd75480e741c3047179ce1c
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd75480e741c3047179ce1c
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Which version of hadoop are you running?

On Tue, Aug 18, 2009 at 10:23 PM, yang song <hadoop.inifok@gmail.com> wrote:

> Hello, all
>    I have met the problem "too many fetch failures" when I submit a big
> job(e.g. tasks>10000). And I know this error occurs when several reducers
> are unable to fetch the given map output. However, I'm sure slaves can
> contact each other.
>    I feel puzzled and have no idea to deal with it. Maybe the network
> transfer is bad, but how can I solve it? Increase
> mapred.reduce.parallel.copies and mapred.reduce.copy.backoff can make
> changes?
>    Thank you!
>    Inifok
>



-- 
Ted Dunning, CTO
DeepDyve

--000e0cd75480e741c3047179ce1c--

From common-user-return-16860-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 10:56:33 2009
Return-Path: <common-user-return-16860-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 91688 invoked from network); 19 Aug 2009 10:56:32 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 10:56:32 -0000
Received: (qmail 86205 invoked by uid 500); 19 Aug 2009 10:56:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 86141 invoked by uid 500); 19 Aug 2009 10:56:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 86131 invoked by uid 99); 19 Aug 2009 10:56:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 10:56:49 +0000
X-ASF-Spam-Status: No, hits=-4.0 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of forsberg@opera.com designates 213.236.208.81 as permitted sender)
Received: from [213.236.208.81] (HELO smtp.opera.com) (213.236.208.81)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 10:56:38 +0000
Received: from caputradii.linkoping.osa (sgw-oslo.opera.com [213.236.208.47])
	(authenticated bits=0)
	by smtp.opera.com (8.13.4/8.13.4/Debian-3sarge3) with ESMTP id n7JAuGHq008440
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NOT)
	for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 10:56:16 GMT
Date: Wed, 19 Aug 2009 12:56:14 +0200
From: Erik Forsberg <forsberg@opera.com>
To: common-user@hadoop.apache.org
Subject: Running Cloudera's distribution without their support agreement -
 is that a bad idea?
Message-ID: <20090819125614.38d18789@caputradii.linkoping.osa>
Organization: Opera Software
X-Mailer: Claws Mail 3.5.0 (GTK+ 2.14.4; i486-pc-linux-gnu)
Mime-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi!

I'm currently evaluating different Hadoop versions for a new project.
I'm tempted by the Cloudera distribution, since it's neatly packaged
into .deb files, and is the stable distribution but with some patches
applied, for example the bzip2 support.

I understand that I can get a support agreement from Cloudera to match
this distribution, but if that's not an option, will running the
Cloudera distribution put me in a position where I won't get any help
from the community because I'm not running an official Apache Hadoop
release? 

Regards,
\EF
-- 
Erik Forsberg <forsberg@opera.com>
Developer, Opera Mini - http://www.opera.com/mini/

From common-user-return-16861-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 11:07:00 2009
Return-Path: <common-user-return-16861-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 97791 invoked from network); 19 Aug 2009 11:06:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 11:06:59 -0000
Received: (qmail 8760 invoked by uid 500); 19 Aug 2009 11:07:15 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 8699 invoked by uid 500); 19 Aug 2009 11:07:15 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 8689 invoked by uid 99); 19 Aug 2009 11:07:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 11:07:15 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.200.172 as permitted sender)
Received: from [209.85.200.172] (HELO wf-out-1314.google.com) (209.85.200.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 11:07:08 +0000
Received: by wf-out-1314.google.com with SMTP id 23so1172705wfg.2
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 04:06:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=9H6kTeD5ixq3M2nxUe0lzU+rUz/ZkuCBZ6pXFSVSVrI=;
        b=cvTObBTrp04vbT+0VUUKa9n0+2pquFT0P+vtrD27VvIGI+zhfCVbdXWIEZqivshsAh
         5jfaeidWENNOf3bdlAeimJXZLnoupFbR6WDkVga3tL/0qLw0mT3s3OjGz/typImB7OvG
         QSCe3/nh9p++6mIKAYuE7sRDtLLmR8NZyR8HQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=IIhMKpRCjIP6HDHX0UAbTshpSJAAE16AovJBF+skANwgqpGpS3vEVB1nFogd66VRRd
         QHOuugzoqZqEIWoVlYAvpp1hbdmKTO2mI0LJMWWySHPjxRJNcJ19KVb7FnHQjPUtDy1F
         ACSSYIP6GxZe3X4yZDbatlLYe9EqEHDrNNr/k=
MIME-Version: 1.0
Received: by 10.143.26.36 with SMTP id d36mr1329518wfj.217.1250680008131; Wed, 
	19 Aug 2009 04:06:48 -0700 (PDT)
In-Reply-To: <20090819125614.38d18789@caputradii.linkoping.osa>
References: <20090819125614.38d18789@caputradii.linkoping.osa>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Wed, 19 Aug 2009 16:36:28 +0530
Message-ID: <e01b80590908190406l61b10b3iae3ebd37fc70209c@mail.gmail.com>
Subject: Re: Running Cloudera's distribution without their support agreement - 
	is that a bad idea?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636e0add79cc39404717ca183
X-Virus-Checked: Checked by ClamAV on apache.org

--001636e0add79cc39404717ca183
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Wed, Aug 19, 2009 at 4:26 PM, Erik Forsberg <forsberg@opera.com> wrote:
>
> I understand that I can get a support agreement from Cloudera to match
> this distribution, but if that's not an option, will running the
> Cloudera distribution put me in a position where I won't get any help
> from the community because I'm not running an official Apache Hadoop
> release?
>

That probably won't happen - the Cloudera folks (Aaron Kimball, Todd Lipcon,
etc) are highly active on these community mailing lists :)

-- 
Harish Mallipeddi
http://blog.poundbang.in

--001636e0add79cc39404717ca183--

From common-user-return-16862-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 12:20:05 2009
Return-Path: <common-user-return-16862-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 22432 invoked from network); 19 Aug 2009 12:20:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 12:20:05 -0000
Received: (qmail 58694 invoked by uid 500); 19 Aug 2009 12:20:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 58635 invoked by uid 500); 19 Aug 2009 12:20:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 58625 invoked by uid 99); 19 Aug 2009 12:20:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 12:20:22 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 12:20:14 +0000
Received: by ywh36 with SMTP id 36so6350742ywh.31
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 05:19:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=ZxlYmIT41xpAqz3fl+GU597S5vTW5eu2lMHBgF4kNr0=;
        b=UI/xulYws6Tc2J/0rVg7hJCCabvniwiiNt1n2dihyVhFSLLnsNSLGrzquEuGA5wh0Y
         6IfH+ELYznm3kcXDETOE9oSP8mzA79Z4YLaBAirBcnkotFPaFoZB7TWqM2UWJ5jGEABl
         cDoG4Wfqw8sg4l69oEn31A2jxqIkMAHI0uujI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=dw2KCXkfR2t7fv8bEWifNf2jpMYGJm3/3O3Ao+kc6xjxK3AVS9zXOw7yCXhmyCTiFG
         JheLFB7e9WcHKR9FlM+cGkg6odWFs3k2qSg6HO/vk3GuQ0F8BOg44tsgBbP7DgOVx2o7
         OOn12RdpV/0TwtStFO5ttozbK9eqw7CW58tiU=
MIME-Version: 1.0
Received: by 10.101.57.4 with SMTP id j4mr6927685ank.104.1250684393209; Wed, 
	19 Aug 2009 05:19:53 -0700 (PDT)
In-Reply-To: <c7d45fc70908190044u77503a5dsed88dc9a37f10cf@mail.gmail.com>
References: <3b1311780908182223m6d75da2dxf33118c91496d08@mail.gmail.com>
	 <c7d45fc70908190044u77503a5dsed88dc9a37f10cf@mail.gmail.com>
Date: Wed, 19 Aug 2009 20:19:53 +0800
Message-ID: <3b1311780908190519y20708a7epef6edac55e3e9981@mail.gmail.com>
Subject: Re: How to deal with "too many fetch failures"?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636ed7421fbc81304717da669
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed7421fbc81304717da669
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I'm sorry, the version is 0.19.1

2009/8/19 Ted Dunning <ted.dunning@gmail.com>

> Which version of hadoop are you running?
>
> On Tue, Aug 18, 2009 at 10:23 PM, yang song <hadoop.inifok@gmail.com>
> wrote:
>
> > Hello, all
> >    I have met the problem "too many fetch failures" when I submit a big
> > job(e.g. tasks>10000). And I know this error occurs when several reducers
> > are unable to fetch the given map output. However, I'm sure slaves can
> > contact each other.
> >    I feel puzzled and have no idea to deal with it. Maybe the network
> > transfer is bad, but how can I solve it? Increase
> > mapred.reduce.parallel.copies and mapred.reduce.copy.backoff can make
> > changes?
> >    Thank you!
> >    Inifok
> >
>
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>

--001636ed7421fbc81304717da669--

From common-user-return-16863-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 12:46:44 2009
Return-Path: <common-user-return-16863-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 35830 invoked from network); 19 Aug 2009 12:46:44 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 12:46:44 -0000
Received: (qmail 835 invoked by uid 500); 19 Aug 2009 12:47:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 759 invoked by uid 500); 19 Aug 2009 12:47:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 748 invoked by uid 99); 19 Aug 2009 12:47:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 12:47:00 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of edlinuxguru@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 12:46:51 +0000
Received: by bwz10 with SMTP id 10so3571894bwz.29
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 05:46:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=ZdqvCknlMzTjsS49m6CkpGGCTwzPeiDTBHafxFXfZBQ=;
        b=QUWG7ArSxdijBUSwiRdPMoDfFDuR1wqg3BVmD/z3707QMKeYfdpiGzCRbp9QAayS09
         51scwBK8L+esejc9x0TAmsLLoGEFgcyS7ylu9WS6LQUPW78FaompeHBeIVeoCm3mdctN
         oDD+gpSHF3iD09vumkyoYFT3eOUeBqhdOCJWo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=EsF6pbFXpqjOYLIffJbQpcphPFFQFBvZSfEQtQkdqt5nWcbdaO5G2pZg83VqmXbnY6
         2lk31+Ch+2luEwXBeUliJkn+rFG6yWgjKsGZcOskHoWSthImtMJTsuRHPwpAkz/NBilW
         fM1VE33n6sOBTOoWMeLsxFoisAU2BxS+6njR0=
MIME-Version: 1.0
Received: by 10.239.182.145 with SMTP id q17mr554657hbg.136.1250685989413; 
	Wed, 19 Aug 2009 05:46:29 -0700 (PDT)
In-Reply-To: <20090819125614.38d18789@caputradii.linkoping.osa>
References: <20090819125614.38d18789@caputradii.linkoping.osa>
Date: Wed, 19 Aug 2009 08:46:29 -0400
Message-ID: <cbbf4b570908190546u2f636250oa1b4fa048ef5723b@mail.gmail.com>
Subject: Re: Running Cloudera's distribution without their support agreement - 
	is that a bad idea?
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Generally if I have an issue I will bring it up on the forums and just
reference the hadoop major.18.3 ce your likely to get the same level
of help.

On 8/19/09, Erik Forsberg <forsberg@opera.com> wrote:
> Hi!
>
> I'm currently evaluating different Hadoop versions for a new project.
> I'm tempted by the Cloudera distribution, since it's neatly packaged
> into .deb files, and is the stable distribution but with some patches
> applied, for example the bzip2 support.
>
> I understand that I can get a support agreement from Cloudera to match
> this distribution, but if that's not an option, will running the
> Cloudera distribution put me in a position where I won't get any help
> from the community because I'm not running an official Apache Hadoop
> release?
>
> Regards,
> \EF
> --
> Erik Forsberg <forsberg@opera.com>
> Developer, Opera Mini - http://www.opera.com/mini/
>

From common-user-return-16864-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 13:53:54 2009
Return-Path: <common-user-return-16864-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 72835 invoked from network); 19 Aug 2009 13:53:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 13:53:54 -0000
Received: (qmail 49837 invoked by uid 500); 19 Aug 2009 13:54:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 49759 invoked by uid 500); 19 Aug 2009 13:54:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 49748 invoked by uid 99); 19 Aug 2009 13:54:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 13:54:10 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 13:53:59 +0000
Received: by vws40 with SMTP id 40so3665088vws.2
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 06:53:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=dxgA3vBMoUOzR7hOEFLRocCTmWmiFXw5Rb6MV9sM9YA=;
        b=JRjVQCaAASX1wE9pKieUJdSXTHiL53SVFedTEZUnT72WYOulD7/z/lEqiCGmRdaXC7
         UfxgeJgBo1SXavvPo9AxGeZ5JcMVD3y6xJbB2KOO4T10TUnDp4DAxRWbULlGZBhNsXlj
         jnlh4dC2YA8ojBAt4aeoHzaQt6ZEnhNYutiJg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=NJC3NlnBWPKv4McIa1Li2xkN7fezB9G+6r+ojr9udR5a7X1MdS/bAHI1ADKN8OQ44t
         c73Aqy9bAOFs2hvA18ehddd99g5bxSjh0xO7Y8UXcL+OyILaYbWHOFoXHaK1eOoO0/2c
         NOuRVw0tSeKOXFigo0panxSS7ZIwoJiB0v9gY=
MIME-Version: 1.0
Received: by 10.220.69.234 with SMTP id a42mr8686730vcj.78.1250690018811; Wed, 
	19 Aug 2009 06:53:38 -0700 (PDT)
In-Reply-To: <cbbf4b570908190546u2f636250oa1b4fa048ef5723b@mail.gmail.com>
References: <20090819125614.38d18789@caputradii.linkoping.osa>
	 <cbbf4b570908190546u2f636250oa1b4fa048ef5723b@mail.gmail.com>
Date: Wed, 19 Aug 2009 06:53:38 -0700
Message-ID: <314098690908190653y415d2ae3se78c20f5a0b5c8a6@mail.gmail.com>
Subject: Re: Running Cloudera's distribution without their support agreement - 
	is that a bad idea?
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64763004b9db304717ef68f
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64763004b9db304717ef68f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Cloudera submits their patches back to the projects, and people are free to
pick them up.
It is becoming a normal thing to run a patched distribution, particularly
since Yahoo made their version of 0.20 available.


On Wed, Aug 19, 2009 at 5:46 AM, Edward Capriolo <edlinuxguru@gmail.com>wrote:

> Generally if I have an issue I will bring it up on the forums and just
> reference the hadoop major.18.3 ce your likely to get the same level
> of help.
>
> On 8/19/09, Erik Forsberg <forsberg@opera.com> wrote:
> > Hi!
> >
> > I'm currently evaluating different Hadoop versions for a new project.
> > I'm tempted by the Cloudera distribution, since it's neatly packaged
> > into .deb files, and is the stable distribution but with some patches
> > applied, for example the bzip2 support.
> >
> > I understand that I can get a support agreement from Cloudera to match
> > this distribution, but if that's not an option, will running the
> > Cloudera distribution put me in a position where I won't get any help
> > from the community because I'm not running an official Apache Hadoop
> > release?
> >
> > Regards,
> > \EF
> > --
> > Erik Forsberg <forsberg@opera.com>
> > Developer, Opera Mini - http://www.opera.com/mini/
> >
>



-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--0016e64763004b9db304717ef68f--

From common-user-return-16865-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 14:05:35 2009
Return-Path: <common-user-return-16865-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 77630 invoked from network); 19 Aug 2009 14:05:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 14:05:34 -0000
Received: (qmail 70232 invoked by uid 500); 19 Aug 2009 14:05:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 70132 invoked by uid 500); 19 Aug 2009 14:05:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 70122 invoked by uid 500); 19 Aug 2009 14:05:51 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 70109 invoked by uid 99); 19 Aug 2009 14:05:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:05:51 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [156.80.1.73] (HELO mclniron02-ext.bah.com) (156.80.1.73)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:05:41 +0000
x-SBRS: None
X-REMOTE-IP: 10.12.10.50
X-IronPort-AV: E=Sophos;i="4.43,408,1246852800"; 
   d="scan'208,217";a="33778021"
Received: from unknown (HELO ASHBHUB01.resource.ds.bah.com) ([10.12.10.50])
  by mclniron02-int.bah.com with ESMTP; 19 Aug 2009 10:05:07 -0400
Received: from ASHBMBX02.resource.ds.bah.com ([169.254.1.122]) by
 ASHBHUB01.resource.ds.bah.com ([10.12.10.50]) with mapi; Wed, 19 Aug 2009
 10:05:07 -0400
From: "Poole, Samuel [USA]" <poole_samuel@bah.com>
To: "core-user@hadoop.apache.org" <core-user@hadoop.apache.org>
Date: Wed, 19 Aug 2009 10:05:07 -0400
Subject: Hadoop for Independant Tasks not using Map/Reduce?
Thread-Topic: Hadoop for Independant Tasks not using Map/Reduce?
Thread-Index: AcogTJNO/Zi/5eXvRUm1Q9qSpmPIWAAiXQdQ
Message-ID: <1072637276A0534CB8DE6BA57D95D39E0EF06E40@ASHBMBX02.resource.ds.bah.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: multipart/alternative;
	boundary="_000_1072637276A0534CB8DE6BA57D95D39E0EF06E40ASHBMBX02resour_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_1072637276A0534CB8DE6BA57D95D39E0EF06E40ASHBMBX02resour_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

I am new to Hadoop (I have not yet installed/configured), and I want to mak=
e sure that I have the correct tool for the job.  I do not "currently" have=
 a need for the Map/Reduce functionality, but I am interested in using Hado=
op for task orchestration, task monitoring, etc. over numerous nodes in a c=
omputing cluster.  Our primary programs (written in C++ and launched via sh=
ell scripts) each run independantly on a single node, but are deployed to d=
ifferent nodes for load balancing.  I want to task/initiate these processes=
 on different nodes through a Java program located on a central server.  I =
was hoping to use Hadoop as a foundation for this.

I read the following in the FAQ section:

"How do I use Hadoop Streaming to run an arbitrary set of (semi-)independen=
t tasks?

Often you do not need the full power of Map Reduce, but only need to run mu=
ltiple instances of the same program - either on different parts of the dat=
a, or on the same data, but with different parameters. You can use Hadoop S=
treaming to do this. "

So, two questions I guess.

1.  Can I use Hadoop for this purpose without using Map/Reduce functionalit=
y?

2.  Are there any examples available on how to implement this sort of confi=
guration?

Any help would be greatly appreciated.

Sam







--_000_1072637276A0534CB8DE6BA57D95D39E0EF06E40ASHBMBX02resour_--

From common-user-return-16866-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 14:06:43 2009
Return-Path: <common-user-return-16866-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 77832 invoked from network); 19 Aug 2009 14:06:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 14:06:43 -0000
Received: (qmail 72358 invoked by uid 500); 19 Aug 2009 14:07:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 72272 invoked by uid 500); 19 Aug 2009 14:07:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 72252 invoked by uid 99); 19 Aug 2009 14:07:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:07:00 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:06:49 +0000
Received: by vws40 with SMTP id 40so3672665vws.2
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 07:06:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=grSZ0s8ohz0JBaIfK6nevkf3oihaWN9pijzaS39a4mM=;
        b=vCmu8PG/wxuxq7rXQc5SjXBx6ZXP0j9QQhoOeOI1NUY8P+nHjazVbq77ZLuaC3038j
         eQz+OYL0A2ZXFZzcMB4a2G0ONqr6vLSB8ydsNYUFS80Ag4IMfu4QytiKV70kwhsp4An6
         sQod8f33nM5JYG5SG9iFwmM0jVDdOWSSK8lIw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=tpCIzVUxwiSuqAyI44d0bfuYRve/qWTMzQsZ5KlPxPtWtz9sB3v9PkKaeDJt73n4MA
         a8fBxNLWDhxISwV/idOHm6FA/TlbqrFo1az8Da9gCAhOgmg9yu1HSGRoIN+NjC5ppWWD
         rP+mEgl/+AzP6lYvKAb43MIapVyaneIOgT374=
MIME-Version: 1.0
Received: by 10.220.14.68 with SMTP id f4mr8903643vca.109.1250690788485; Wed, 
	19 Aug 2009 07:06:28 -0700 (PDT)
In-Reply-To: <3b1311780908170656k34a84c92ye057f49eb1aeaff3@mail.gmail.com>
References: <3b1311780908162336q7bcd8da6na1999982ed83aa7e@mail.gmail.com>
	 <c7d45fc70908170100t2124f221hddff79872c6809ce@mail.gmail.com>
	 <3b1311780908170656k34a84c92ye057f49eb1aeaff3@mail.gmail.com>
Date: Wed, 19 Aug 2009 07:06:28 -0700
Message-ID: <314098690908190706h4d8f2e1av4799548909b4c228@mail.gmail.com>
Subject: Re: Why the jobs are suspended when I add new nodes?
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0014853d1f682bea6104717f2401
X-Virus-Checked: Checked by ClamAV on apache.org

--0014853d1f682bea6104717f2401
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I have added small numbers of nodes into running clusters, with running jobs
without issue - when the machines were correctly configured for the cluster,
so this is known to work at least in the 0.18 release series (when I was
doing this operation).

On Mon, Aug 17, 2009 at 6:56 AM, yang song <hadoop.inifok@gmail.com> wrote:

> The situation is I can't find any unusual thing from the logs.
> Maybe there is a lot of data to transfer since so many new nodes and the
> jobs are waiting for it
>
> 2009/8/17 Ted Dunning <ted.dunning@gmail.com>
>
> > Have you looked at the logs?
> >
> > On Sun, Aug 16, 2009 at 11:36 PM, yang song <hadoop.inifok@gmail.com>
> > wrote:
> >
> > > Hi, all
> > >    When I add another 50 nodes into the current cluster(200 nodes) at
> the
> > > same time, the jobs run very smoothly at first. However, after a while,
> > all
> > > the jobs are suspended and never continue.
> > >
> > >
> >
>



-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--0014853d1f682bea6104717f2401--

From common-user-return-16867-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 14:09:34 2009
Return-Path: <common-user-return-16867-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 78810 invoked from network); 19 Aug 2009 14:09:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 14:09:34 -0000
Received: (qmail 76534 invoked by uid 500); 19 Aug 2009 14:09:50 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 76450 invoked by uid 500); 19 Aug 2009 14:09:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 76440 invoked by uid 99); 19 Aug 2009 14:09:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:09:50 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:09:40 +0000
Received: by vws40 with SMTP id 40so3674328vws.2
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 07:09:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=p08laSqDx+E4HeNBlQk4CyDwVuXFDJN4L4WAgiU/gJs=;
        b=AGZ5/AbqelBAR0uv8zLHNLmrW73Rlow2x6YDDaEhOPaqbjth4rp/gA4XF88Bkv3j6q
         +vhY256YBhhdevsc4L3i5u2kxSweHfHVckfdvPzCeYZ8G9eiGZwUlPEJ8RHix1kgEnRm
         tfo4LI+OU+MLE4k+Y+Lwyr0Msjy/RXRcPQgEM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=BJRmTerAPPUN1PetnY5D1jc5FLlTkLv75ADo+VOBb73UuypAAogFWTdumk/3dWc6ud
         4qOO8ECTqRBPJyL7Vu2pAIa4Si1rjKy+uozOeXIEISbM4s/2SYZbAhNOJpzrnHu+o873
         aXTo7aOyolXByBIH78FbqrcxGm9t6TT+O7PGI=
MIME-Version: 1.0
Received: by 10.220.68.40 with SMTP id t40mr8951598vci.2.1250690959523; Wed, 
	19 Aug 2009 07:09:19 -0700 (PDT)
In-Reply-To: <616DA47B2EF5B944B91846785B512FF4CFADEA6F56@EGL-EX07VS01.ds.corp.yahoo.com>
References: <bec373e0908171717r66a736efkbd384530718b4c86@mail.gmail.com>
	 <e01b80590908172206g1fc04218p7df876f5b7b08cab@mail.gmail.com>
	 <616DA47B2EF5B944B91846785B512FF4CFADEA6F56@EGL-EX07VS01.ds.corp.yahoo.com>
Date: Wed, 19 Aug 2009 07:09:19 -0700
Message-ID: <314098690908190709y14d4d271n589676693100b7a7@mail.gmail.com>
Subject: Re: utilizing all cores on single-node hadoop
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6475c8a5dc0f804717f2e4c
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6475c8a5dc0f804717f2e4c
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Another reason you may not see full utilization of your map tasks per
tracker is if the mean run time of a task is very short, All the slots are
being used but the setup and teardown for each task is large enough in time
compared to the run time of the task that it appears that not all the task
slots are being used.


On Mon, Aug 17, 2009 at 10:35 PM, Amogh Vasekar <amogh@yahoo-inc.com> wrote:

> While setting mapred.tasktracker.map.tasks.maximum and
> mapred.tasktracker.reduce.tasks.maximum, please consider the memory usage
> your application might have since all tasks will be competing for the same
> and might reduce overall performance.
>
> Thanks,
> Amogh
> -----Original Message-----
> From: Harish Mallipeddi [mailto:harish.mallipeddi@gmail.com]
> Sent: Tuesday, August 18, 2009 10:37 AM
> To: common-user@hadoop.apache.org
> Subject: Re: utilizing all cores on single-node hadoop
>
> Hi Vasilis,
>
> Here's some info that I know:
>
> mapred.map.tasks - this is a job-specific setting. This is just a hint to
> InputFormat as to how many InputSplits (and hence MapTasks) you want for
> your job. The default InputFormat classes usually keep each split size to
> the HDFS block size (64MB default). So if your input data is less than 64
> MB, it will just result in only 1 split and hence 1 MapTask only.
>
> mapred.reduce.tasks - this is also a job-specific setting.
>
> mapred.tasktracker.map.tasks.maximum
> mapred.tasktracker.reduce.tasks.maximum
>
> The above 2 are tasktracker-specific config options and determine how many
> "simultaneous" MapTasks and ReduceTasks run on each TT. Ideally on a 8-core
> box, you would want to set map.tasks.maximum to something like 6 and
> reduce.tasks.maximum to 4 to utilize all the 8 cores to the maximum
> (there's
> a little bit of over-subscription to account for tasks idling while doing
> I/O).
>
> In the web admin console, how many map-tasks and reduce-tasks are reported
> to have been launched for your job?
>
> Cheers,
> Harish
>
> On Tue, Aug 18, 2009 at 5:47 AM, Vasilis Liaskovitis <vliaskov@gmail.com
> >wrote:
>
> > Hi,
> >
> > I am a beginner trying to setup a few simple hadoop tests on a single
> > node before moving on to a cluster. I am just using the simple
> > wordcount example for now. My question is what's the best way to
> > guarantee utilization of all cores on a single-node? So assuming a
> > single node with 16-cores what are the suggested values for:
> >
> > mapred.map.tasks
> > mapred.reduce.tasks
> >
> mapred.tasktracker.map.tasks.maximum
> > mapred.tasktracker.map.tasks.maxium
> >
>
> > I found an old similar thread
> > http://www.mail-archive.com/hadoop-user@lucene.apache.org/msg00152.html
> > and I have followed similar settings for my 16-core system (e.g.
> > map.tasks=reduce.tasks=90 and map.tasks.maximum=100), however I always
> > see only 3-4 cores utilized using top.
> >
> > - The description for mapred.map.tasks says "Ignored when
> > mapred.job.tracker is "local" ", and in my case
> > mapred.job.tracker=hdfs://localhost:54311
> > is it possible that the map.tasks and reduce.tasks I am setting are
> > being ignored? How can I verify this? Is there a way to enforce my
> > values even on a localhost scenario like this?
> >
> > - Are there other config options/values that I need to set besides the
> > 4 I mentioned above?
> >
> > - Also is it possible that for short tasks, I won't see full
> > utilization of all cores anyway? Something along those lines is
> > mentioned in an issue a year ago:
> > http://issues.apache.org/jira/browse/HADOOP-3136
> > "If the individual tasks are very short i.e. run for less than the
> > heartbeat interval the TaskTracker serially runs one task at a time"
> >
> > I am using hadoop-0.19.2
> >
> > thanks for any guidance,
> >
> > - Vasilis
> >
>
>
>
> --
> Harish Mallipeddi
> http://blog.poundbang.in
>



-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--0016e6475c8a5dc0f804717f2e4c--

From common-user-return-16868-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 14:21:46 2009
Return-Path: <common-user-return-16868-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 84725 invoked from network); 19 Aug 2009 14:21:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 14:21:46 -0000
Received: (qmail 94762 invoked by uid 500); 19 Aug 2009 14:22:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 94671 invoked by uid 500); 19 Aug 2009 14:22:03 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 94661 invoked by uid 99); 19 Aug 2009 14:22:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:22:03 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:21:53 +0000
Received: by yxe15 with SMTP id 15so5908679yxe.5
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 07:21:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=0IBvCISEReax4Wm6HAKZiJQ+B+nVIX8rm01TQ9DIcOc=;
        b=ShU55C8z7qkU4daV8po9iyGLwyUqKx2W0U58T/5jYHTdGAAoZu5/t02sGFIMED1Xg9
         fL3upMqKFWwZ5DGlUn3r+URHcNtJLu1U9QXXB71xYDwHf0qSbhjCWPzKsMbJJ6t6FuoU
         cWaVIQct1Gn7Jd1ocdSdcCoYuY0252M7mQH5s=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=WAZPerrw3OEcRpVdRyrDANThC/qDbHyim4m0Ka3+c7WtfoHRvPzbS8OYFHHwvgxqzH
         ffqhHxbiw0x7h6DsboFfb0e85z6aChxi/RWHddAHexY5425ayCQt1EQy5yeJ+qaOpq1D
         tTThisJ4tinvbvdNbOr7+JhhueO7RGvrhc1Ew=
MIME-Version: 1.0
Received: by 10.101.51.7 with SMTP id d7mr7134446ank.106.1250691691617; Wed, 
	19 Aug 2009 07:21:31 -0700 (PDT)
Date: Wed, 19 Aug 2009 22:21:31 +0800
Message-ID: <3b1311780908190721g3814f4dft9e00e9edce1eb86b@mail.gmail.com>
Subject: How does hadoop deal with hadoop-site.xml?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636eee264009fb704717f5a3d
X-Virus-Checked: Checked by ClamAV on apache.org

--001636eee264009fb704717f5a3d
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello, everybody
    I feel puzzled about setting properties in hadoop-site.xml.
    Suppose I submit the job from machine A, and JobTracker runs on machine
B. So there are two hadoop-site.xml files. Now, I increase
"mapred.reduce.parallel.copies"(e.g. 10) on machine B since I want to make
copy phrase faster. However, "mapred.reduce.parallel.copies" from WebUI is
still 5. When I increase it on machine A, it changes. So, I feel very
puzzled. Why does it doesn't work when I change it on B? What's more, when I
add some properties on B, the certain properties will be found on WebUI. And
why I can't change properties through machine B? Does some certain
properties must be changed through A and some others must be changed through
B?
    Thank you!
    Inifok

--001636eee264009fb704717f5a3d--

From common-user-return-16869-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 14:26:58 2009
Return-Path: <common-user-return-16869-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 87409 invoked from network); 19 Aug 2009 14:26:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 14:26:58 -0000
Received: (qmail 3475 invoked by uid 500); 19 Aug 2009 14:27:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 3390 invoked by uid 500); 19 Aug 2009 14:27:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 3380 invoked by uid 99); 19 Aug 2009 14:27:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:27:14 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.211.130 as permitted sender)
Received: from [209.85.211.130] (HELO mail-yw0-f130.google.com) (209.85.211.130)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:27:04 +0000
Received: by ywh36 with SMTP id 36so481930ywh.31
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 07:26:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=DMKy4aTrIuJ3MnqDXzWxLeoKcRYJbDWUjGEq+bJ5ALs=;
        b=FLs/FgKJlfLVgTsxHUdWD5fOcpkbKPII8gYD4MdDoQDJPbuxxRnHeS9AavaiXeREKg
         3+YtB+gyLFUGwut8b1O3EnIh5LwK/Xrd0xETX46M6Ct7ak5jEIyQY4SzuqwGviUw3Jxx
         fHd91JsFpmDezhY0v84BU8oGq0J3McFam/zbg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=esL3bLjXG5JDdogirO7TwM7aRIzd9NCh5YOIUSZ0pOQqrh2qEXIWkUU9QlG0HL2Qpl
         0EV/1FvRhkfONYEWAqEi49F+a4eE9huNIgjGmTKteIKxso2aJPlAnXvtoZgLy3t1Kb2h
         ow/KY8BB0gmzVjawz+ICrPFLyEb0J0unXrQDE=
MIME-Version: 1.0
Received: by 10.100.18.15 with SMTP id 15mr7193099anr.48.1250691999249; Wed, 
	19 Aug 2009 07:26:39 -0700 (PDT)
In-Reply-To: <314098690908190706h4d8f2e1av4799548909b4c228@mail.gmail.com>
References: <3b1311780908162336q7bcd8da6na1999982ed83aa7e@mail.gmail.com>
	 <c7d45fc70908170100t2124f221hddff79872c6809ce@mail.gmail.com>
	 <3b1311780908170656k34a84c92ye057f49eb1aeaff3@mail.gmail.com>
	 <314098690908190706h4d8f2e1av4799548909b4c228@mail.gmail.com>
Date: Wed, 19 Aug 2009 22:26:39 +0800
Message-ID: <3b1311780908190726i58a603a4yfd3a0958414c3003@mail.gmail.com>
Subject: Re: Why the jobs are suspended when I add new nodes?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64764d056b92304717f6c40
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64764d056b92304717f6c40
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thank you for providing this information, and I think it may be resulted
from "too many fetch failures".  Now I have accumulated some experience and
I think I'll solve it soon. Thanks again.

2009/8/19 Jason Venner <jason.hadoop@gmail.com>

> I have added small numbers of nodes into running clusters, with running
> jobs
> without issue - when the machines were correctly configured for the
> cluster,
> so this is known to work at least in the 0.18 release series (when I was
> doing this operation).
>
> On Mon, Aug 17, 2009 at 6:56 AM, yang song <hadoop.inifok@gmail.com>
> wrote:
>
> > The situation is I can't find any unusual thing from the logs.
> > Maybe there is a lot of data to transfer since so many new nodes and the
> > jobs are waiting for it
> >
> > 2009/8/17 Ted Dunning <ted.dunning@gmail.com>
> >
> > > Have you looked at the logs?
> > >
> > > On Sun, Aug 16, 2009 at 11:36 PM, yang song <hadoop.inifok@gmail.com>
> > > wrote:
> > >
> > > > Hi, all
> > > >    When I add another 50 nodes into the current cluster(200 nodes) at
> > the
> > > > same time, the jobs run very smoothly at first. However, after a
> while,
> > > all
> > > > the jobs are suspended and never continue.
> > > >
> > > >
> > >
> >
>
>
>
> --
> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> http://www.amazon.com/dp/1430219424?tag=jewlerymall
> www.prohadoopbook.com a community for Hadoop Professionals
>

--0016e64764d056b92304717f6c40--

From common-user-return-16870-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 14:43:59 2009
Return-Path: <common-user-return-16870-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 98476 invoked from network); 19 Aug 2009 14:43:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 14:43:59 -0000
Received: (qmail 29805 invoked by uid 500); 19 Aug 2009 14:44:16 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 29731 invoked by uid 500); 19 Aug 2009 14:44:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 29719 invoked by uid 99); 19 Aug 2009 14:44:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:44:16 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [192.6.10.60] (HELO tobor.hpl.hp.com) (192.6.10.60)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 14:44:06 +0000
Received: from localhost (localhost [127.0.0.1])
	by tobor.hpl.hp.com (Postfix) with ESMTP id 18C4DB7D6B
	for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 15:43:43 +0100 (BST)
X-Virus-Scanned: amavisd-new at hplb.hpl.hp.com
Received: from tobor.hpl.hp.com ([127.0.0.1])
	by localhost (tobor.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id L0D+RLvfBN5q for <common-user@hadoop.apache.org>;
	Wed, 19 Aug 2009 15:43:37 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by tobor.hpl.hp.com (Postfix) with ESMTPS id 46031B7D57
	for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 15:43:37 +0100 (BST)
MailScanner-NULL-Check: 1251297805.07618@N+tBFQMbFRApBIuLx/RJsw
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7JEhOiH022183
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 15:43:24 +0100 (BST)
Message-ID: <4A8C0F8C.8070700@apache.org>
Date: Wed, 19 Aug 2009 15:43:24 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Running Cloudera's distribution without their support agreement
 - is that a bad idea?
References: <20090819125614.38d18789@caputradii.linkoping.osa>
In-Reply-To: <20090819125614.38d18789@caputradii.linkoping.osa>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7JEhOiH022183
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

Erik Forsberg wrote:
> Hi!
> 
> I'm currently evaluating different Hadoop versions for a new project.
> I'm tempted by the Cloudera distribution, since it's neatly packaged
> into .deb files, and is the stable distribution but with some patches
> applied, for example the bzip2 support.
> 
> I understand that I can get a support agreement from Cloudera to match
> this distribution, but if that's not an option, will running the
> Cloudera distribution put me in a position where I won't get any help
> from the community because I'm not running an official Apache Hadoop
> release? 
>

-there is no official Apache deb so you will end up using someone elses 
deb if that is how you build your cluster up.
-everyone welcomes bug reports, especially ones with stack traces.
-regardless of whether you use an official vs external release, a common 
answer to any bugrep will be "does it go away on the latest release?" 
And then "does it go away on trunk?".
-only you are going to be able to track down problems on your cluster, 
because your machines and network is different from everybody else's.
-the act of checking out and building a release locally sets you up to 
adding diagnostics and fixes to the source, fixes you can turn into 
patches to get pushed in.

what cloudera are selling, then, is not the packaging, so much as them 
taking over the work of fixing bugs for you. You are still free to track 
down and fix your own problems, on their releases and the Apache ones 
-because nobody else's network/cluster matches yours.

I am in favour of adding lots more diagnostics to hadoop, most of the 
patches of mine that have gone in help with this debugging of which 
machines are playing up -and why. Anything we can do to help debug 
hadoop, or validate an installation, is a welcome improvement.

-steve


From common-user-return-16871-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 15:11:55 2009
Return-Path: <common-user-return-16871-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11688 invoked from network); 19 Aug 2009 15:11:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 15:11:55 -0000
Received: (qmail 81135 invoked by uid 500); 19 Aug 2009 15:12:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 81052 invoked by uid 500); 19 Aug 2009 15:12:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 81042 invoked by uid 99); 19 Aug 2009 15:12:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 15:12:11 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of edlinuxguru@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 15:12:03 +0000
Received: by bwz10 with SMTP id 10so3658470bwz.29
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 08:11:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=p2NB3KJsUYXuxnAtXtsPXnouaAoBIJlR0ya+86bY6SY=;
        b=BYg3Ml1nCbs14Nt/JRtFH2qhbYxnrlmbL3kZ14zjAV2adm9+HE0VduQy5E+31jEc76
         qQpNzv5z2/4Aj+rGHNF2nHmxzgEd9rI3XWqPYuFynv+L9ZLweSHG/3A38bfIPLzoIb0C
         RUc99O6SP1XjHVqNoD1nIehYgbvhn60Smcbvw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=VjCDrFAIySbs/W0Y2m/S/+iI3gNyskL24e9KhwGfHKPa9o+Wah0YDjGwYrvpVslY13
         iD2u+AtaA6cH7ViPXRTDb7B5F+AUdrjgaIr0vRiJahghbRiZWvB2/ZV3nnjmKKXRYmFt
         GoideXPA8J6ys07vpn5JGOE53MPu+ow1A5Zkk=
MIME-Version: 1.0
Received: by 10.239.168.203 with SMTP id l11mr552391hbe.85.1250694701600; Wed, 
	19 Aug 2009 08:11:41 -0700 (PDT)
In-Reply-To: <4A8B8D11.8020008@yahoo-inc.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
	 <4A8B8D11.8020008@yahoo-inc.com>
Date: Wed, 19 Aug 2009 11:11:41 -0400
Message-ID: <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

>>It would be as fast as underlying filesystem goes.
I would not agree with that statement. There is overhead. If you have
a single threaded process writing many small files you do not get the
parallel write speed. In some testing I did writing a small file can
take 30-300 ms. So if you have 9000 small files (like I did) and you
are single threaded this takes a long time.

If you orchestrate your task to use FSDataInput and FSDataOutput in
the map or reduce phase then each mapper or reducer is writing a file
at a time. Now that is fast.

Ananth, are you doing your r/w inside a map/reduce job or are you just
using FS* in a top down program?



On Wed, Aug 19, 2009 at 1:26 AM, Raghu Angadi<rangadi@yahoo-inc.com> wrote:
> Ananth T. Sarathy wrote:
>>
>> I am trying to download binary files stored in Hadoop but there is like =
a
>> 2
>> minute wait on a 20mb file when I try to execute the in.read(buf).
>
> What does this mean : 2 min to pipe 20mb or one or your one of the in.rea=
d()
> calls took 2 minutes? Your code actually measures team for read and write=
.
>
> There is nothing in FSInputstream to cause this slow down. Do you think
> anyone would use Hadoop otherwise? It would be as fast as underlying
> filesystem goes.
>
> Raghu.
>
>> is there a better way to be doing this?
>>
>> =A0 =A0private void pipe(InputStream in, OutputStream out) throws IOExce=
ption
>> =A0 =A0{ =A0 =A0System.out.println(System.currentTimeMillis()+" Starting=
 to Pipe
>> Data");
>> =A0 =A0 =A0 =A0byte[] buf =3D new byte[1024];
>> =A0 =A0 =A0 =A0int read =3D 0;
>> =A0 =A0 =A0 =A0while ((read =3D in.read(buf)) >=3D 0)
>> =A0 =A0 =A0 =A0{
>> =A0 =A0 =A0 =A0 =A0 =A0out.write(buf, 0, read);
>> =A0 =A0 =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" P=
iping Data");
>> =A0 =A0 =A0 =A0}
>> =A0 =A0 =A0 =A0out.flush();
>> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Finished =
Piping
>> Data");
>>
>> =A0 =A0}
>>
>> public void readFile(String fileToRead, OutputStream out)
>> =A0 =A0 =A0 =A0 =A0 =A0throws IOException
>> =A0 =A0{
>> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Start Rea=
d File");
>> =A0 =A0 =A0 =A0Path inFile =3D new Path(fileToRead);
>> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Set Path"=
);
>> =A0 =A0 =A0 =A0// Validate the input/output paths before reading/writing=
.
>>
>> =A0 =A0 =A0 =A0if (!fs.exists(inFile))
>> =A0 =A0 =A0 =A0{
>> =A0 =A0 =A0 =A0 =A0 =A0throw new HadoopFileException("Specified file =A0=
" + fileToRead
>> =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0+ " not found.");
>> =A0 =A0 =A0 =A0}
>> =A0 =A0 =A0 =A0if (!fs.isFile(inFile))
>> =A0 =A0 =A0 =A0{
>> =A0 =A0 =A0 =A0 =A0 =A0throw new HadoopFileException("Specified file =A0=
" + fileToRead
>> =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0+ " not found.");
>> =A0 =A0 =A0 =A0}
>> =A0 =A0 =A0 =A0// Open inFile for reading.
>> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Opening D=
ata
>> Stream");
>> =A0 =A0 =A0 =A0FSDataInputStream in =3D fs.open(inFile);
>>
>> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Opened Da=
ta
>> Stream");
>> =A0 =A0 =A0 =A0// Open outFile for writing.
>>
>> =A0 =A0 =A0 =A0// Read from input stream and write to output stream unti=
l EOF.
>> =A0 =A0 =A0 =A0pipe(in, out);
>>
>> =A0 =A0 =A0 =A0// Close the streams when done.
>> =A0 =A0 =A0 =A0out.close();
>> =A0 =A0 =A0 =A0in.close();
>> =A0 =A0}
>> Ananth T Sarathy
>>
>
>

From common-user-return-16872-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 15:32:59 2009
Return-Path: <common-user-return-16872-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 19522 invoked from network); 19 Aug 2009 15:32:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 15:32:58 -0000
Received: (qmail 30795 invoked by uid 500); 19 Aug 2009 15:33:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 30742 invoked by uid 500); 19 Aug 2009 15:33:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 30732 invoked by uid 99); 19 Aug 2009 15:33:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 15:33:14 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.86.89.67] (HELO elasmtp-scoter.atl.sa.earthlink.net) (209.86.89.67)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 15:33:05 +0000
Received: from [99.39.4.172] (helo=gbj-laptop.earthlink.net)
	by elasmtp-scoter.atl.sa.earthlink.net with esmtpa (Exim 4.67)
	(envelope-from <hadoop@blackbirdsystems.net>)
	id 1Mdn9X-0000kr-Pi; Wed, 19 Aug 2009 11:32:44 -0400
From: hadoop@blackbirdsystems.net (George Jahad)
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
Message-ID: <19084.6937.604202.182242@gargle.gargle.HOWL>
Date: Wed, 19 Aug 2009 08:32:41 -0700
To: common-user@hadoop.apache.org
Subject: submitting multiple small jobs simultaneously
X-Mailer: VM 8.0.12 under 23.0.91.1 (i486-pc-linux-gnu)
X-ELNK-Trace: 90d8f6c2ea23b4a3e5331016acda17f9bc35fe6358b728df22cf9b0544de193d350badd9bab72f9c350badd9bab72f9c350badd9bab72f9c350badd9bab72f9c
X-Originating-IP: 99.39.4.172
X-Virus-Checked: Checked by ClamAV on apache.org



I'm importing a bunch of data into HDSF.  It involves running a bunch
of small jobs, that don't put much load on my cluster, but it would be
nice if I could do them all from the same job client. I'd submit them
all asynchronously and then wait for the results of each.

I imagine this has been done many times before, but can't find any
examples on Google.  If you know of any, please let me know.

Thanks,
George


From common-user-return-16873-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 15:39:59 2009
Return-Path: <common-user-return-16873-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 25386 invoked from network); 19 Aug 2009 15:39:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 15:39:59 -0000
Received: (qmail 64894 invoked by uid 500); 19 Aug 2009 15:40:16 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 64834 invoked by uid 500); 19 Aug 2009 15:40:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 64821 invoked by uid 99); 19 Aug 2009 15:40:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 15:40:16 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.86.89.65] (HELO elasmtp-kukur.atl.sa.earthlink.net) (209.86.89.65)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 15:40:05 +0000
Received: from [99.39.4.172] (helo=gbj-laptop.earthlink.net)
	by elasmtp-kukur.atl.sa.earthlink.net with esmtpa (Exim 4.67)
	(envelope-from <hadoop@blackbirdsystems.net>)
	id 1MdnGK-0003sj-FF
	for common-user@hadoop.apache.org; Wed, 19 Aug 2009 11:39:44 -0400
From: hadoop@blackbirdsystems.net (George Jahad)
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
Message-ID: <19084.7358.404199.841876@gargle.gargle.HOWL>
Date: Wed, 19 Aug 2009 08:39:42 -0700
To: common-user@hadoop.apache.org
Subject: submitting multiple small jobs simultaneously
X-Mailer: VM 8.0.12 under 23.0.91.1 (i486-pc-linux-gnu)
X-ELNK-Trace: 90d8f6c2ea23b4a3e5331016acda17f98a1309f5396765f99086634ed7110753350badd9bab72f9c350badd9bab72f9c350badd9bab72f9c350badd9bab72f9c
X-Originating-IP: 99.39.4.172
X-Virus-Checked: Checked by ClamAV on apache.org



I'm importing a bunch of data into HDSF.  It involves running a bunch
of small jobs, that don't put much load on my cluster, but it would be
nice if I could do them all from the same job client. I'd submit them
all asynchronously and then wait for the results of each.

I imagine this has been done many times before, but can't find any
examples on Google.  If you know of any, please let me know.

Thanks,
George




From common-user-return-16874-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 15:44:11 2009
Return-Path: <common-user-return-16874-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 28550 invoked from network); 19 Aug 2009 15:44:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 15:44:11 -0000
Received: (qmail 79816 invoked by uid 500); 19 Aug 2009 15:44:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 79752 invoked by uid 500); 19 Aug 2009 15:44:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 79728 invoked by uid 99); 19 Aug 2009 15:44:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 15:44:25 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 15:44:15 +0000
Received: by bwz10 with SMTP id 10so3678111bwz.29
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 08:43:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=AjlCjPl7SyYUzvI3aCa5TriTkCpW8+CTspVl8lOFxRY=;
        b=waOluugUM59701CjQBMpInqBTp2ReJe8VKLCxappZiKOXI2GcoDLtT2jajF+dVp27w
         8yhlsSWrZ2TbLSM5zijookZC/KOzLDQsEiBZUL0S2HHiI7mai+P/0/rujMZU0u4M3xgG
         q9SDOfrxkuyFeV7fHKlT5e77EsMC/oKXywZlA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=A4oUg/14ocr59mm/Pj/d/qyhFIIivJ+r4YwV23yYSMhHjMKxzvG1TKoCxSorOIZcYm
         5Wodxi1dFjlI//JHt1QpQEXn6wqtHOyenNMmMzWuW6z4aEuE4sy445xqPQC1ZdFIl6AY
         im7LOIkBcb8nk4KOQl1NyK6POaoGY63Hb+9LU=
MIME-Version: 1.0
Received: by 10.239.139.89 with SMTP id s25mr562271hbs.113.1250696635429; Wed, 
	19 Aug 2009 08:43:55 -0700 (PDT)
In-Reply-To: <4A8B8D11.8020008@yahoo-inc.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
	 <4A8B8D11.8020008@yahoo-inc.com>
Date: Wed, 19 Aug 2009 11:43:55 -0400
Message-ID: <ad681e7f0908190843v76792dcs5fef87b5a7199589@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f6cd8cad3569047180803f
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f6cd8cad3569047180803f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I am not saying there is a slowdown cause by hadoop. I was wondering if
there were anyother techinques that optimize speed (IE reading a little a
time and writing to the local disk).
Ananth T Sarathy


On Wed, Aug 19, 2009 at 1:26 AM, Raghu Angadi <rangadi@yahoo-inc.com> wrote:

> Ananth T. Sarathy wrote:
>
>> I am trying to download binary files stored in Hadoop but there is like a
>> 2
>> minute wait on a 20mb file when I try to execute the in.read(buf).
>>
>
> What does this mean : 2 min to pipe 20mb or one or your one of the
> in.read() calls took 2 minutes? Your code actually measures team for read
> and write.
>
> There is nothing in FSInputstream to cause this slow down. Do you think
> anyone would use Hadoop otherwise? It would be as fast as underlying
> filesystem goes.
>
> Raghu.
>
>
>  is there a better way to be doing this?
>>
>>    private void pipe(InputStream in, OutputStream out) throws IOException
>>    {    System.out.println(System.currentTimeMillis()+" Starting to Pipe
>> Data");
>>        byte[] buf = new byte[1024];
>>        int read = 0;
>>        while ((read = in.read(buf)) >= 0)
>>        {
>>            out.write(buf, 0, read);
>>            System.out.println(System.currentTimeMillis()+" Piping Data");
>>        }
>>        out.flush();
>>        System.out.println(System.currentTimeMillis()+" Finished Piping
>> Data");
>>
>>    }
>>
>> public void readFile(String fileToRead, OutputStream out)
>>            throws IOException
>>    {
>>        System.out.println(System.currentTimeMillis()+" Start Read File");
>>        Path inFile = new Path(fileToRead);
>>        System.out.println(System.currentTimeMillis()+" Set Path");
>>        // Validate the input/output paths before reading/writing.
>>
>>        if (!fs.exists(inFile))
>>        {
>>            throw new HadoopFileException("Specified file  " + fileToRead
>>                    + " not found.");
>>        }
>>        if (!fs.isFile(inFile))
>>        {
>>            throw new HadoopFileException("Specified file  " + fileToRead
>>                    + " not found.");
>>        }
>>        // Open inFile for reading.
>>        System.out.println(System.currentTimeMillis()+" Opening Data
>> Stream");
>>        FSDataInputStream in = fs.open(inFile);
>>
>>        System.out.println(System.currentTimeMillis()+" Opened Data
>> Stream");
>>        // Open outFile for writing.
>>
>>        // Read from input stream and write to output stream until EOF.
>>        pipe(in, out);
>>
>>        // Close the streams when done.
>>        out.close();
>>        in.close();
>>    }
>> Ananth T Sarathy
>>
>>
>

--001485f6cd8cad3569047180803f--

From common-user-return-16875-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 15:46:04 2009
Return-Path: <common-user-return-16875-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 30777 invoked from network); 19 Aug 2009 15:46:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 15:46:04 -0000
Received: (qmail 83907 invoked by uid 500); 19 Aug 2009 15:46:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 83830 invoked by uid 500); 19 Aug 2009 15:46:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 83820 invoked by uid 99); 19 Aug 2009 15:46:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 15:46:20 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 15:46:12 +0000
Received: by bwz10 with SMTP id 10so3679300bwz.29
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 08:45:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=CwyTR3P5SwSffDfaxjrKAjb/oOWwZM6S590fphji2Pk=;
        b=pxVsUjXfOAmegAucAKMVwOU5a5gNr13OLJOGLIC1+xVZVF90nMuRKlgLhhtEKA8zW5
         tYMerl71Cqz3eSTse09dx3HwPVxixRtPaT1u+LtYGiHgt2PkSW64bkNxdsLBp4ICHNkN
         FEGjLQ7LP0BUM/ygEiJ0eOVTjk3FFUxzVCHeE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=O0f6CZuIVapPXkszpnb9QbOM50dbu1t1+aRoQZm9MfdB/4FF6ZHagG6PBBz/wVLN15
         1GJWljZ9V0/ibp+siOV+QYUgrn9qJ5mfRdQZb6zkls3uKanlGpaLO7aFxZuBtSe635kt
         kW/V+NG5im7LtOIc8jXp1E3hP3GmEwqrMcd6E=
MIME-Version: 1.0
Received: by 10.239.182.163 with SMTP id q35mr540791hbg.70.1250696750632; Wed, 
	19 Aug 2009 08:45:50 -0700 (PDT)
In-Reply-To: <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
	 <4A8B8D11.8020008@yahoo-inc.com>
	 <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>
Date: Wed, 19 Aug 2009 11:45:50 -0400
Message-ID: <ad681e7f0908190845j59dc22aet95e9af971efa8798@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f5eda88b0fdf04718087e9
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f5eda88b0fdf04718087e9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Right now just in top down program. I am still learning this, so I need put
this in a map and reduce to optimize speed I will. Right now I am just
testing certain things, and getting a skeleton to write and pull files from
the s3 storage. Actual implementation is still being engineered.


Ananth T Sarathy


On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo <edlinuxguru@gmail.com>wrote:

> >>It would be as fast as underlying filesystem goes.
> I would not agree with that statement. There is overhead. If you have
> a single threaded process writing many small files you do not get the
> parallel write speed. In some testing I did writing a small file can
> take 30-300 ms. So if you have 9000 small files (like I did) and you
> are single threaded this takes a long time.
>
> If you orchestrate your task to use FSDataInput and FSDataOutput in
> the map or reduce phase then each mapper or reducer is writing a file
> at a time. Now that is fast.
>
> Ananth, are you doing your r/w inside a map/reduce job or are you just
> using FS* in a top down program?
>
>
>
> On Wed, Aug 19, 2009 at 1:26 AM, Raghu Angadi<rangadi@yahoo-inc.com>
> wrote:
> > Ananth T. Sarathy wrote:
> >>
> >> I am trying to download binary files stored in Hadoop but there is like
> a
> >> 2
> >> minute wait on a 20mb file when I try to execute the in.read(buf).
> >
> > What does this mean : 2 min to pipe 20mb or one or your one of the
> in.read()
> > calls took 2 minutes? Your code actually measures team for read and
> write.
> >
> > There is nothing in FSInputstream to cause this slow down. Do you think
> > anyone would use Hadoop otherwise? It would be as fast as underlying
> > filesystem goes.
> >
> > Raghu.
> >
> >> is there a better way to be doing this?
> >>
> >>    private void pipe(InputStream in, OutputStream out) throws
> IOException
> >>    {    System.out.println(System.currentTimeMillis()+" Starting to Pipe
> >> Data");
> >>        byte[] buf = new byte[1024];
> >>        int read = 0;
> >>        while ((read = in.read(buf)) >= 0)
> >>        {
> >>            out.write(buf, 0, read);
> >>            System.out.println(System.currentTimeMillis()+" Piping
> Data");
> >>        }
> >>        out.flush();
> >>        System.out.println(System.currentTimeMillis()+" Finished Piping
> >> Data");
> >>
> >>    }
> >>
> >> public void readFile(String fileToRead, OutputStream out)
> >>            throws IOException
> >>    {
> >>        System.out.println(System.currentTimeMillis()+" Start Read
> File");
> >>        Path inFile = new Path(fileToRead);
> >>        System.out.println(System.currentTimeMillis()+" Set Path");
> >>        // Validate the input/output paths before reading/writing.
> >>
> >>        if (!fs.exists(inFile))
> >>        {
> >>            throw new HadoopFileException("Specified file  " + fileToRead
> >>                    + " not found.");
> >>        }
> >>        if (!fs.isFile(inFile))
> >>        {
> >>            throw new HadoopFileException("Specified file  " + fileToRead
> >>                    + " not found.");
> >>        }
> >>        // Open inFile for reading.
> >>        System.out.println(System.currentTimeMillis()+" Opening Data
> >> Stream");
> >>        FSDataInputStream in = fs.open(inFile);
> >>
> >>        System.out.println(System.currentTimeMillis()+" Opened Data
> >> Stream");
> >>        // Open outFile for writing.
> >>
> >>        // Read from input stream and write to output stream until EOF.
> >>        pipe(in, out);
> >>
> >>        // Close the streams when done.
> >>        out.close();
> >>        in.close();
> >>    }
> >> Ananth T Sarathy
> >>
> >
> >
>

--001485f5eda88b0fdf04718087e9--

From common-user-return-16876-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 16:14:26 2009
Return-Path: <common-user-return-16876-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 48523 invoked from network); 19 Aug 2009 16:14:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 16:14:26 -0000
Received: (qmail 50894 invoked by uid 500); 19 Aug 2009 16:14:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 50832 invoked by uid 500); 19 Aug 2009 16:14:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 50822 invoked by uid 99); 19 Aug 2009 16:14:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 16:14:42 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of edlinuxguru@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 16:14:33 +0000
Received: by bwz10 with SMTP id 10so3696014bwz.29
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 09:14:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=VWaH5T7NgXjY9C/fh2+hIHKGHJMCGMpCvCS5/wQRCS8=;
        b=TQr/brem9F+4h146bZns3E3WZ0AllJb/5PI2YFMm6NIR5kPeMvBb388D8+y/6ZzpHT
         hbv2XT2JHa3xvOFWpNYYpBzkAyqFjZX3RhFXviAPnSEb2B7dDohM19lE4LcQAVqGcfTW
         TI0K2OQfjp8DZPg07m/BnHfWdBB2yd8XQnO2U=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=K6K6IxcdUcvoI7PsepjyhSk1UZh9e7nAYUBWf7uGdIGzxIsEkJDSRZ0OnY2CIfkhK1
         Yt+rM85HkUJ0ecnXt6W7QgPINrsJA/U8MDSgEMQGxFOTrbl/vahzahDvzEd1+Dkqa2Bf
         i9eXtpDviVQF6iedySUDqIK3WawwBJdA7ZFOM=
MIME-Version: 1.0
Received: by 10.239.179.94 with SMTP id c30mr599682hbg.159.1250698452627; Wed, 
	19 Aug 2009 09:14:12 -0700 (PDT)
In-Reply-To: <ad681e7f0908190845j59dc22aet95e9af971efa8798@mail.gmail.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
	 <4A8B8D11.8020008@yahoo-inc.com>
	 <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>
	 <ad681e7f0908190845j59dc22aet95e9af971efa8798@mail.gmail.com>
Date: Wed, 19 Aug 2009 12:14:12 -0400
Message-ID: <cbbf4b570908190914j206797ecrc862d06b6eccbd37@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Ananth,

That is your issue really.

For example. I have 20 web servers and I wish to download all the
weblogs from all of them into hadoop.

If you write a top down program that uses FSDataOutput. You are using
hadoop half way. You are using the distributed file system, but you
are not doing any distributed processing.

Better is to specify all the servers/files you with to download as
your input file. Tell hadoop to use NLineInput format. Move your code
inside a map function.  Now since hadoop ran run multiple mappers
using -Dmapred.map.tasks=3D6  will cause 6 fetchers to run in parallel.
You can up this as high as you are comfortable with.

Also now that you are using m/r you don't have to write files with
FSDataOuputStream , you can use output.collect() to make a sequence
file.

In my case I am using commons-FTP and FSDataOutputStream (not using
output.collect() ) as I do not want a big sequence file I want the
actual files as they exist on the web server I will merge them down
the line in my process. This works very well. I could turn the number
of mappers higher, but I don't want to beat up my web servers and
network anymore. (hint: turn off speculative execution)

Now you know all my secrets. Good luck :)


On Wed, Aug 19, 2009 at 11:45 AM, Ananth T.
Sarathy<ananth.t.sarathy@gmail.com> wrote:
> Right now just in top down program. I am still learning this, so I need p=
ut
> this in a map and reduce to optimize speed I will. Right now I am just
> testing certain things, and getting a skeleton to write and pull files fr=
om
> the s3 storage. Actual implementation is still being engineered.
>
>
> Ananth T Sarathy
>
>
> On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo <edlinuxguru@gmail.com>=
wrote:
>
>> >>It would be as fast as underlying filesystem goes.
>> I would not agree with that statement. There is overhead. If you have
>> a single threaded process writing many small files you do not get the
>> parallel write speed. In some testing I did writing a small file can
>> take 30-300 ms. So if you have 9000 small files (like I did) and you
>> are single threaded this takes a long time.
>>
>> If you orchestrate your task to use FSDataInput and FSDataOutput in
>> the map or reduce phase then each mapper or reducer is writing a file
>> at a time. Now that is fast.
>>
>> Ananth, are you doing your r/w inside a map/reduce job or are you just
>> using FS* in a top down program?
>>
>>
>>
>> On Wed, Aug 19, 2009 at 1:26 AM, Raghu Angadi<rangadi@yahoo-inc.com>
>> wrote:
>> > Ananth T. Sarathy wrote:
>> >>
>> >> I am trying to download binary files stored in Hadoop but there is li=
ke
>> a
>> >> 2
>> >> minute wait on a 20mb file when I try to execute the in.read(buf).
>> >
>> > What does this mean : 2 min to pipe 20mb or one or your one of the
>> in.read()
>> > calls took 2 minutes? Your code actually measures team for read and
>> write.
>> >
>> > There is nothing in FSInputstream to cause this slow down. Do you thin=
k
>> > anyone would use Hadoop otherwise? It would be as fast as underlying
>> > filesystem goes.
>> >
>> > Raghu.
>> >
>> >> is there a better way to be doing this?
>> >>
>> >> =A0 =A0private void pipe(InputStream in, OutputStream out) throws
>> IOException
>> >> =A0 =A0{ =A0 =A0System.out.println(System.currentTimeMillis()+" Start=
ing to Pipe
>> >> Data");
>> >> =A0 =A0 =A0 =A0byte[] buf =3D new byte[1024];
>> >> =A0 =A0 =A0 =A0int read =3D 0;
>> >> =A0 =A0 =A0 =A0while ((read =3D in.read(buf)) >=3D 0)
>> >> =A0 =A0 =A0 =A0{
>> >> =A0 =A0 =A0 =A0 =A0 =A0out.write(buf, 0, read);
>> >> =A0 =A0 =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+=
" Piping
>> Data");
>> >> =A0 =A0 =A0 =A0}
>> >> =A0 =A0 =A0 =A0out.flush();
>> >> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Finish=
ed Piping
>> >> Data");
>> >>
>> >> =A0 =A0}
>> >>
>> >> public void readFile(String fileToRead, OutputStream out)
>> >> =A0 =A0 =A0 =A0 =A0 =A0throws IOException
>> >> =A0 =A0{
>> >> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Start =
Read
>> File");
>> >> =A0 =A0 =A0 =A0Path inFile =3D new Path(fileToRead);
>> >> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Set Pa=
th");
>> >> =A0 =A0 =A0 =A0// Validate the input/output paths before reading/writ=
ing.
>> >>
>> >> =A0 =A0 =A0 =A0if (!fs.exists(inFile))
>> >> =A0 =A0 =A0 =A0{
>> >> =A0 =A0 =A0 =A0 =A0 =A0throw new HadoopFileException("Specified file =
=A0" + fileToRead
>> >> =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0+ " not found.");
>> >> =A0 =A0 =A0 =A0}
>> >> =A0 =A0 =A0 =A0if (!fs.isFile(inFile))
>> >> =A0 =A0 =A0 =A0{
>> >> =A0 =A0 =A0 =A0 =A0 =A0throw new HadoopFileException("Specified file =
=A0" + fileToRead
>> >> =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0+ " not found.");
>> >> =A0 =A0 =A0 =A0}
>> >> =A0 =A0 =A0 =A0// Open inFile for reading.
>> >> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Openin=
g Data
>> >> Stream");
>> >> =A0 =A0 =A0 =A0FSDataInputStream in =3D fs.open(inFile);
>> >>
>> >> =A0 =A0 =A0 =A0System.out.println(System.currentTimeMillis()+" Opened=
 Data
>> >> Stream");
>> >> =A0 =A0 =A0 =A0// Open outFile for writing.
>> >>
>> >> =A0 =A0 =A0 =A0// Read from input stream and write to output stream u=
ntil EOF.
>> >> =A0 =A0 =A0 =A0pipe(in, out);
>> >>
>> >> =A0 =A0 =A0 =A0// Close the streams when done.
>> >> =A0 =A0 =A0 =A0out.close();
>> >> =A0 =A0 =A0 =A0in.close();
>> >> =A0 =A0}
>> >> Ananth T Sarathy
>> >>
>> >
>> >
>>
>

From common-user-return-16877-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 16:32:31 2009
Return-Path: <common-user-return-16877-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61907 invoked from network); 19 Aug 2009 16:32:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 16:32:30 -0000
Received: (qmail 95115 invoked by uid 500); 19 Aug 2009 16:32:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95055 invoked by uid 500); 19 Aug 2009 16:32:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95045 invoked by uid 99); 19 Aug 2009 16:32:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 16:32:46 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 16:32:34 +0000
Received: from walkduty-lm.corp.yahoo.com (walkduty-lm.corp.yahoo.com [10.72.104.13])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7JGVLNH005527
	for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 09:31:21 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:from:to:in-reply-to:content-type:
	content-transfer-encoding:mime-version:subject:date:references:x-mailer;
	b=lhSuVJfbGGpMedB9WZdTqU+/quynxiVw8RPAcNHHoyTkyasMVaMferUDsAcTvBNE
Message-Id: <072CBF6A-9D3C-4D1B-90A1-9C4B89B8F67C@yahoo-inc.com>
From: Arun C Murthy <acm@yahoo-inc.com>
To: common-user@hadoop.apache.org
In-Reply-To: <3b1311780908182223m6d75da2dxf33118c91496d08@mail.gmail.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: How to deal with "too many fetch failures"?
Date: Wed, 19 Aug 2009 09:31:21 -0700
References: <3b1311780908182223m6d75da2dxf33118c91496d08@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

I'd dig around a bit more to check if it's there it's caused by a  
specific set of nodes... i.e. are maps on specific tasktrackers  
failing in this manner?

Arun

On Aug 18, 2009, at 10:23 PM, yang song wrote:

> Hello, all
>    I have met the problem "too many fetch failures" when I submit a  
> big
> job(e.g. tasks>10000). And I know this error occurs when several  
> reducers
> are unable to fetch the given map output. However, I'm sure slaves can
> contact each other.
>    I feel puzzled and have no idea to deal with it. Maybe the network
> transfer is bad, but how can I solve it? Increase
> mapred.reduce.parallel.copies and mapred.reduce.copy.backoff can make
> changes?
>    Thank you!
>    Inifok


From common-user-return-16879-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 16:43:30 2009
Return-Path: <common-user-return-16879-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 67394 invoked from network); 19 Aug 2009 16:43:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 16:43:30 -0000
Received: (qmail 11825 invoked by uid 500); 19 Aug 2009 16:43:43 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 11707 invoked by uid 500); 19 Aug 2009 16:43:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 11688 invoked by uid 500); 19 Aug 2009 16:43:42 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 11683 invoked by uid 99); 19 Aug 2009 16:43:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 16:43:42 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 16:43:30 +0000
Received: from SNV-EXPF01.ds.corp.yahoo.com (snv-expf01.ds.corp.yahoo.com [207.126.227.250])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7JGfBZP013245;
	Wed, 19 Aug 2009 09:41:12 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=IQaNJKokUBU/Xi5I0qdrGxk1qSLxAgf/l093BHkdyXNCMUhuN097lGlH36tNGveE
Received: from SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.87]) by SNV-EXPF01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Wed, 19 Aug 2009 09:41:10 -0700
Received: from 10.72.112.117 ([10.72.112.117]) by SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.84]) via Exchange Front-End Server snv-webmail.corp.yahoo.com ([207.126.227.60]) with Microsoft Exchange Server HTTP-DAV ;
 Wed, 19 Aug 2009 16:40:57 +0000
User-Agent: Microsoft-Entourage/12.20.0.090605
Date: Wed, 19 Aug 2009 09:40:55 -0700
Subject: Re: Hadoop-Archive Error for size of input data >2GB
From: Koji Noguchi <knoguchi@yahoo-inc.com>
To: <common-user@hadoop.apache.org>, <core-user@hadoop.apache.org>
Message-ID: <C6B17927.16F29%knoguchi@yahoo-inc.com>
Thread-Topic: Hadoop-Archive Error for size of input data >2GB
Thread-Index: Acog69I74L0ct1aTU0GWGU93h+renQ==
In-Reply-To: <25036326.post@talk.nabble.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-OriginalArrivalTime: 19 Aug 2009 16:41:10.0667 (UTC) FILETIME=[DB921DB0:01CA20EB]
X-Virus-Checked: Checked by ClamAV on apache.org

>  how to unarchive the logical files from the har file ?Is there anyway t o
> unarchive the logical files.
> 
Opened https://issues.apache.org/jira/browse/MAPREDUCE-883 for documenting,
but the idea is you just need to copy :)


+
+        <section>
+        <title> How to unarchive an archive?</title>
+        <p> Since all the fs shell commands in the archives work
transparently,
+            unarchiving is just a matter of copying </p>
+        <p> To unarchive sequentially:</p>
+        <p><code> hadoop dfs -cp har:///user/zoo/foo.har/dir1
hdfs:/user/zoo/newdir </code></p>
+        <p> To unarchive in parallel, use distcp: </p>
+          <p><code> hadoop distcp har:///user/zoo/foo.har/dir1
hdfs:/user/zoo/newdir </code></p>
+        </section>


As for the original email,
somehow I was able to archive files larger than 2G in 0.18.3.
Maybe there's additional condition I'm missing?

Koji     


On 8/18/09 6:44 PM, "Snehal Nagmote" <nagmote.snehal@gmail.com> wrote:

> 
> Hi,
> 
>  how to unarchive the logical files from the har file ?Is there anyway t o
> unarchive the logical files.
> 
> 
> 
> Pratyush Banerjee-2 wrote:
>> 
>> Hi All,
>> 
>> I have been using hadoop archives programmatically  to generate  har
>> archives from some logfiles  which are being dumped into the hdfs.
>> 
>> When the input directory to Hadoop Archiving program has files of size
>> more than 2GB, strangely the archiving fails with a error message saying
>> 
>> INFO jvm.JvmMetrics: Initializing JVM Metrics with
>> processName=JobTracker, sessionId=   Illegal Capacity: -1
>> 
>> Going into the code i found out that this was due to numMaps having the
>> Value of -1.
>> 
>> As per the code in org.apache.hadoop.util.HadoopArchives:
>> archive(List<Path> srcPaths, String archiveName, Path dest)
>> 
>> the numMaps is initialized as
>> int numMaps = (int)(totalSize/partSize);
>> //run atleast one map.
>> conf.setNumMapTasks(numMaps == 0? 1:numMaps);
>> 
>> partSize has been statically assigned the value of 2GB in the beginning
>> of the class as,
>> 
>> static final long partSize = 2 * 1024 * 1024 * 1024
>> 
>> Strangely enough, the value i find assigned to partSize is  =  -
>> 2147483648
>> 
>> Hence as a result in case of input directories of greater size, numMaps
>> is assigned -1 which leads to the code throwing up error.
>> 
>> I am using hadoop-0.17.1 and I got the archiving facility after applying
>> the patch hadoop-3307_4 patch.
>> 
>> This looks like a bug for me, so please let me know how to go about it.
>> 
>> Pratyush Banerjee
>> 
>> 
>> 


From common-user-return-16878-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 16:43:30 2009
Return-Path: <common-user-return-16878-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 67365 invoked from network); 19 Aug 2009 16:43:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 16:43:30 -0000
Received: (qmail 11794 invoked by uid 500); 19 Aug 2009 16:43:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 11705 invoked by uid 500); 19 Aug 2009 16:43:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 11683 invoked by uid 99); 19 Aug 2009 16:43:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 16:43:42 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 16:43:30 +0000
Received: from SNV-EXPF01.ds.corp.yahoo.com (snv-expf01.ds.corp.yahoo.com [207.126.227.250])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7JGfBZP013245;
	Wed, 19 Aug 2009 09:41:12 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=IQaNJKokUBU/Xi5I0qdrGxk1qSLxAgf/l093BHkdyXNCMUhuN097lGlH36tNGveE
Received: from SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.87]) by SNV-EXPF01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Wed, 19 Aug 2009 09:41:10 -0700
Received: from 10.72.112.117 ([10.72.112.117]) by SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.84]) via Exchange Front-End Server snv-webmail.corp.yahoo.com ([207.126.227.60]) with Microsoft Exchange Server HTTP-DAV ;
 Wed, 19 Aug 2009 16:40:57 +0000
User-Agent: Microsoft-Entourage/12.20.0.090605
Date: Wed, 19 Aug 2009 09:40:55 -0700
Subject: Re: Hadoop-Archive Error for size of input data >2GB
From: Koji Noguchi <knoguchi@yahoo-inc.com>
To: <common-user@hadoop.apache.org>, <core-user@hadoop.apache.org>
Message-ID: <C6B17927.16F29%knoguchi@yahoo-inc.com>
Thread-Topic: Hadoop-Archive Error for size of input data >2GB
Thread-Index: Acog69I74L0ct1aTU0GWGU93h+renQ==
In-Reply-To: <25036326.post@talk.nabble.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-OriginalArrivalTime: 19 Aug 2009 16:41:10.0667 (UTC) FILETIME=[DB921DB0:01CA20EB]
X-Virus-Checked: Checked by ClamAV on apache.org

>  how to unarchive the logical files from the har file ?Is there anyway t o
> unarchive the logical files.
> 
Opened https://issues.apache.org/jira/browse/MAPREDUCE-883 for documenting,
but the idea is you just need to copy :)


+
+        <section>
+        <title> How to unarchive an archive?</title>
+        <p> Since all the fs shell commands in the archives work
transparently,
+            unarchiving is just a matter of copying </p>
+        <p> To unarchive sequentially:</p>
+        <p><code> hadoop dfs -cp har:///user/zoo/foo.har/dir1
hdfs:/user/zoo/newdir </code></p>
+        <p> To unarchive in parallel, use distcp: </p>
+          <p><code> hadoop distcp har:///user/zoo/foo.har/dir1
hdfs:/user/zoo/newdir </code></p>
+        </section>


As for the original email,
somehow I was able to archive files larger than 2G in 0.18.3.
Maybe there's additional condition I'm missing?

Koji     


On 8/18/09 6:44 PM, "Snehal Nagmote" <nagmote.snehal@gmail.com> wrote:

> 
> Hi,
> 
>  how to unarchive the logical files from the har file ?Is there anyway t o
> unarchive the logical files.
> 
> 
> 
> Pratyush Banerjee-2 wrote:
>> 
>> Hi All,
>> 
>> I have been using hadoop archives programmatically  to generate  har
>> archives from some logfiles  which are being dumped into the hdfs.
>> 
>> When the input directory to Hadoop Archiving program has files of size
>> more than 2GB, strangely the archiving fails with a error message saying
>> 
>> INFO jvm.JvmMetrics: Initializing JVM Metrics with
>> processName=JobTracker, sessionId=   Illegal Capacity: -1
>> 
>> Going into the code i found out that this was due to numMaps having the
>> Value of -1.
>> 
>> As per the code in org.apache.hadoop.util.HadoopArchives:
>> archive(List<Path> srcPaths, String archiveName, Path dest)
>> 
>> the numMaps is initialized as
>> int numMaps = (int)(totalSize/partSize);
>> //run atleast one map.
>> conf.setNumMapTasks(numMaps == 0? 1:numMaps);
>> 
>> partSize has been statically assigned the value of 2GB in the beginning
>> of the class as,
>> 
>> static final long partSize = 2 * 1024 * 1024 * 1024
>> 
>> Strangely enough, the value i find assigned to partSize is  =  -
>> 2147483648
>> 
>> Hence as a result in case of input directories of greater size, numMaps
>> is assigned -1 which leads to the code throwing up error.
>> 
>> I am using hadoop-0.17.1 and I got the archiving facility after applying
>> the patch hadoop-3307_4 patch.
>> 
>> This looks like a bug for me, so please let me know how to go about it.
>> 
>> Pratyush Banerjee
>> 
>> 
>> 


From common-user-return-16880-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 17:46:22 2009
Return-Path: <common-user-return-16880-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 5143 invoked from network); 19 Aug 2009 17:46:22 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 17:46:22 -0000
Received: (qmail 39516 invoked by uid 500); 19 Aug 2009 17:46:39 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 39429 invoked by uid 500); 19 Aug 2009 17:46:39 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 39419 invoked by uid 99); 19 Aug 2009 17:46:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 17:46:39 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ananth.t.sarathy@gmail.com designates 72.14.220.157 as permitted sender)
Received: from [72.14.220.157] (HELO fg-out-1718.google.com) (72.14.220.157)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 17:46:29 +0000
Received: by fg-out-1718.google.com with SMTP id 22so834309fge.12
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 10:46:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=A0/bba27OgGZ6uu1585/fKnkVX9WH+Q2xwKRg6pa7/s=;
        b=G1RGkUxs1wq15wo9Tw42vsOC/MKWznSge4GWTo8tIEgt/W8spDMFv8Wkkm8knZUycA
         38b5SinRCFHUzza7Dbss+pmGujwQkGdKyPJsrqcY8ESBWfw88JzkEmzp3SgSe0fU9F5j
         d100XwPZiAm2TW7hnH+5hg40ICmnPqxXSxOYU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=EI5G5d6NCqQFKAHftSCpAtUyuvOExmXCC4hTULz4Vgkl99HtoiaAWO4k5ozEER14ic
         84Khk/cGqBQIWeqW/P8cSFsSMimSFIPfeRcy32B6SK+5uHpNZswWTQ3yl0ZAMR8yUWPR
         rdRq1f6eeMgjSe9Z4jacQoQ+8Ya4QcX4UcHbM=
MIME-Version: 1.0
Received: by 10.239.134.226 with SMTP id a34mr622727hba.7.1250703968790; Wed, 
	19 Aug 2009 10:46:08 -0700 (PDT)
In-Reply-To: <cbbf4b570908190914j206797ecrc862d06b6eccbd37@mail.gmail.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
	 <4A8B8D11.8020008@yahoo-inc.com>
	 <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>
	 <ad681e7f0908190845j59dc22aet95e9af971efa8798@mail.gmail.com>
	 <cbbf4b570908190914j206797ecrc862d06b6eccbd37@mail.gmail.com>
Date: Wed, 19 Aug 2009 13:46:08 -0400
Message-ID: <ad681e7f0908191046n289ca68dwdb1737325fdb874b@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f6da14c76b59047182353a
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f6da14c76b59047182353a
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Well, we are using it store large binary files. I get the distributing the
processing will allow faster times when doing multiple read/writes, but
didn't realize that the map and reduce would help when writing one file.
Ananth T Sarathy


On Wed, Aug 19, 2009 at 12:14 PM, Edward Capriolo <edlinuxguru@gmail.com>wrote:

> Ananth,
>
> That is your issue really.
>
> For example. I have 20 web servers and I wish to download all the
> weblogs from all of them into hadoop.
>
> If you write a top down program that uses FSDataOutput. You are using
> hadoop half way. You are using the distributed file system, but you
> are not doing any distributed processing.
>
> Better is to specify all the servers/files you with to download as
> your input file. Tell hadoop to use NLineInput format. Move your code
> inside a map function.  Now since hadoop ran run multiple mappers
> using -Dmapred.map.tasks=6  will cause 6 fetchers to run in parallel.
> You can up this as high as you are comfortable with.
>
> Also now that you are using m/r you don't have to write files with
> FSDataOuputStream , you can use output.collect() to make a sequence
> file.
>
> In my case I am using commons-FTP and FSDataOutputStream (not using
> output.collect() ) as I do not want a big sequence file I want the
> actual files as they exist on the web server I will merge them down
> the line in my process. This works very well. I could turn the number
> of mappers higher, but I don't want to beat up my web servers and
> network anymore. (hint: turn off speculative execution)
>
> Now you know all my secrets. Good luck :)
>
>
> On Wed, Aug 19, 2009 at 11:45 AM, Ananth T.
> Sarathy<ananth.t.sarathy@gmail.com> wrote:
> > Right now just in top down program. I am still learning this, so I need
> put
> > this in a map and reduce to optimize speed I will. Right now I am just
> > testing certain things, and getting a skeleton to write and pull files
> from
> > the s3 storage. Actual implementation is still being engineered.
> >
> >
> > Ananth T Sarathy
> >
> >
> > On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo <edlinuxguru@gmail.com
> >wrote:
> >
> >> >>It would be as fast as underlying filesystem goes.
> >> I would not agree with that statement. There is overhead. If you have
> >> a single threaded process writing many small files you do not get the
> >> parallel write speed. In some testing I did writing a small file can
> >> take 30-300 ms. So if you have 9000 small files (like I did) and you
> >> are single threaded this takes a long time.
> >>
> >> If you orchestrate your task to use FSDataInput and FSDataOutput in
> >> the map or reduce phase then each mapper or reducer is writing a file
> >> at a time. Now that is fast.
> >>
> >> Ananth, are you doing your r/w inside a map/reduce job or are you just
> >> using FS* in a top down program?
> >>
> >>
> >>
> >> On Wed, Aug 19, 2009 at 1:26 AM, Raghu Angadi<rangadi@yahoo-inc.com>
> >> wrote:
> >> > Ananth T. Sarathy wrote:
> >> >>
> >> >> I am trying to download binary files stored in Hadoop but there is
> like
> >> a
> >> >> 2
> >> >> minute wait on a 20mb file when I try to execute the in.read(buf).
> >> >
> >> > What does this mean : 2 min to pipe 20mb or one or your one of the
> >> in.read()
> >> > calls took 2 minutes? Your code actually measures team for read and
> >> write.
> >> >
> >> > There is nothing in FSInputstream to cause this slow down. Do you
> think
> >> > anyone would use Hadoop otherwise? It would be as fast as underlying
> >> > filesystem goes.
> >> >
> >> > Raghu.
> >> >
> >> >> is there a better way to be doing this?
> >> >>
> >> >>    private void pipe(InputStream in, OutputStream out) throws
> >> IOException
> >> >>    {    System.out.println(System.currentTimeMillis()+" Starting to
> Pipe
> >> >> Data");
> >> >>        byte[] buf = new byte[1024];
> >> >>        int read = 0;
> >> >>        while ((read = in.read(buf)) >= 0)
> >> >>        {
> >> >>            out.write(buf, 0, read);
> >> >>            System.out.println(System.currentTimeMillis()+" Piping
> >> Data");
> >> >>        }
> >> >>        out.flush();
> >> >>        System.out.println(System.currentTimeMillis()+" Finished
> Piping
> >> >> Data");
> >> >>
> >> >>    }
> >> >>
> >> >> public void readFile(String fileToRead, OutputStream out)
> >> >>            throws IOException
> >> >>    {
> >> >>        System.out.println(System.currentTimeMillis()+" Start Read
> >> File");
> >> >>        Path inFile = new Path(fileToRead);
> >> >>        System.out.println(System.currentTimeMillis()+" Set Path");
> >> >>        // Validate the input/output paths before reading/writing.
> >> >>
> >> >>        if (!fs.exists(inFile))
> >> >>        {
> >> >>            throw new HadoopFileException("Specified file  " +
> fileToRead
> >> >>                    + " not found.");
> >> >>        }
> >> >>        if (!fs.isFile(inFile))
> >> >>        {
> >> >>            throw new HadoopFileException("Specified file  " +
> fileToRead
> >> >>                    + " not found.");
> >> >>        }
> >> >>        // Open inFile for reading.
> >> >>        System.out.println(System.currentTimeMillis()+" Opening Data
> >> >> Stream");
> >> >>        FSDataInputStream in = fs.open(inFile);
> >> >>
> >> >>        System.out.println(System.currentTimeMillis()+" Opened Data
> >> >> Stream");
> >> >>        // Open outFile for writing.
> >> >>
> >> >>        // Read from input stream and write to output stream until
> EOF.
> >> >>        pipe(in, out);
> >> >>
> >> >>        // Close the streams when done.
> >> >>        out.close();
> >> >>        in.close();
> >> >>    }
> >> >> Ananth T Sarathy
> >> >>
> >> >
> >> >
> >>
> >
>

--001485f6da14c76b59047182353a--

From common-user-return-16881-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 18:00:34 2009
Return-Path: <common-user-return-16881-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 14880 invoked from network); 19 Aug 2009 18:00:33 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 18:00:33 -0000
Received: (qmail 62774 invoked by uid 500); 19 Aug 2009 18:00:50 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 62686 invoked by uid 500); 19 Aug 2009 18:00:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 62676 invoked by uid 99); 19 Aug 2009 18:00:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 18:00:50 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 18:00:37 +0000
Received: from [10.72.106.226] (heighthigh-lx.corp.yahoo.com [10.72.106.226])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7JHwAXp096729
	for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 10:58:10 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=USatc46gnRwV/01MYI0rQHtIznuDuIvKmgoZsJe8DJVvlPYQDz9gFMsX2xQjIAD0
Message-ID: <4A8C3D32.3010905@yahoo-inc.com>
Date: Wed, 19 Aug 2009 10:58:10 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Faster alternative to FSDataInputStream
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>	 <4A8B8D11.8020008@yahoo-inc.com>	 <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>	 <ad681e7f0908190845j59dc22aet95e9af971efa8798@mail.gmail.com> <cbbf4b570908190914j206797ecrc862d06b6eccbd37@mail.gmail.com>
In-Reply-To: <cbbf4b570908190914j206797ecrc862d06b6eccbd37@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Edward Capriolo wrote:
>> On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo <edlinuxguru@gmail.com>wrote:
>>
>>>>> It would be as fast as underlying filesystem goes.
>>> I would not agree with that statement. There is overhead. 

You might be misinterpreting my comment. There is of course some over 
head (at the least the procedure calls).. depending on you underlying 
filesystem, there could be extra buffer copies and CRC overhead. But 
none of that explains transfer as slow as 1 MBps (if my interpretation 
of of results is correct).

Raghu.

>>> In some testing I did writing a small file can
>>> take 30-300 ms. So if you have 9000 small files (like I did) and you
>>> are single threaded this takes a long time.
>>>
>>> If you orchestrate your task to use FSDataInput and FSDataOutput in
>>> the map or reduce phase then each mapper or reducer is writing a file
>>> at a time. Now that is fast.
>>>
>>> Ananth, are you doing your r/w inside a map/reduce job or are you just
>>> using FS* in a top down program?
>>>
>>>
>>>
>>> On Wed, Aug 19, 2009 at 1:26 AM, Raghu Angadi<rangadi@yahoo-inc.com>
>>> wrote:
>>>> Ananth T. Sarathy wrote:
>>>>> I am trying to download binary files stored in Hadoop but there is like
>>> a
>>>>> 2
>>>>> minute wait on a 20mb file when I try to execute the in.read(buf).
>>>> What does this mean : 2 min to pipe 20mb or one or your one of the
>>> in.read()
>>>> calls took 2 minutes? Your code actually measures team for read and
>>> write.
>>>> There is nothing in FSInputstream to cause this slow down. Do you think
>>>> anyone would use Hadoop otherwise? It would be as fast as underlying
>>>> filesystem goes.
>>>>
>>>> Raghu.
>>>>
>>>>> is there a better way to be doing this?
>>>>>
>>>>>    private void pipe(InputStream in, OutputStream out) throws
>>> IOException
>>>>>    {    System.out.println(System.currentTimeMillis()+" Starting to Pipe
>>>>> Data");
>>>>>        byte[] buf = new byte[1024];
>>>>>        int read = 0;
>>>>>        while ((read = in.read(buf)) >= 0)
>>>>>        {
>>>>>            out.write(buf, 0, read);
>>>>>            System.out.println(System.currentTimeMillis()+" Piping
>>> Data");
>>>>>        }
>>>>>        out.flush();
>>>>>        System.out.println(System.currentTimeMillis()+" Finished Piping
>>>>> Data");
>>>>>
>>>>>    }
>>>>>
>>>>> public void readFile(String fileToRead, OutputStream out)
>>>>>            throws IOException
>>>>>    {
>>>>>        System.out.println(System.currentTimeMillis()+" Start Read
>>> File");
>>>>>        Path inFile = new Path(fileToRead);
>>>>>        System.out.println(System.currentTimeMillis()+" Set Path");
>>>>>        // Validate the input/output paths before reading/writing.
>>>>>
>>>>>        if (!fs.exists(inFile))
>>>>>        {
>>>>>            throw new HadoopFileException("Specified file  " + fileToRead
>>>>>                    + " not found.");
>>>>>        }
>>>>>        if (!fs.isFile(inFile))
>>>>>        {
>>>>>            throw new HadoopFileException("Specified file  " + fileToRead
>>>>>                    + " not found.");
>>>>>        }
>>>>>        // Open inFile for reading.
>>>>>        System.out.println(System.currentTimeMillis()+" Opening Data
>>>>> Stream");
>>>>>        FSDataInputStream in = fs.open(inFile);
>>>>>
>>>>>        System.out.println(System.currentTimeMillis()+" Opened Data
>>>>> Stream");
>>>>>        // Open outFile for writing.
>>>>>
>>>>>        // Read from input stream and write to output stream until EOF.
>>>>>        pipe(in, out);
>>>>>
>>>>>        // Close the streams when done.
>>>>>        out.close();
>>>>>        in.close();
>>>>>    }
>>>>> Ananth T Sarathy
>>>>>
>>>>


From common-user-return-16882-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 18:04:03 2009
Return-Path: <common-user-return-16882-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 17162 invoked from network); 19 Aug 2009 18:04:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 18:04:03 -0000
Received: (qmail 67826 invoked by uid 500); 19 Aug 2009 18:04:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 67730 invoked by uid 500); 19 Aug 2009 18:04:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 67720 invoked by uid 99); 19 Aug 2009 18:04:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 18:04:20 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [192.139.80.206] (HELO mx1.casalemedia.com) (192.139.80.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 18:04:10 +0000
Received: from exchange.casalemedia.com (unknown [10.3.10.15])
	by mx1.casalemedia.com (Postfix) with ESMTP id 167AF588011
	for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 14:03:50 -0400 (EDT)
Received: from mayuran.casalemedia.com (10.3.10.40) by
 exchange.casalemedia.com (10.3.10.15) with Microsoft SMTP Server id
 8.1.240.5; Wed, 19 Aug 2009 14:03:49 -0400
Message-ID: <4A8C3E7B.7020700@casalemedia.com>
Date: Wed, 19 Aug 2009 14:03:39 -0400
From: Mayuran Yogarajah <mayuran.yogarajah@casalemedia.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: Loading data failed with timeout
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello, we were importing several TB of data overnight and it seemed one 
of the loads
failed.  We're running Hadoop 0.18.3, and there are 6 nodes in the 
cluster, all are
dual quad core with 6 gigs of ram.  We were using hadoop dfs -put to 
load the data
from both the namenode server and the secondary namenode server in 
parallel.  Space
is not the issue as we have many terabytes of space still remaining.

The load from the namenode is still going, the load from the secondary 
namenode failed.

This is the error we got:

dfs.DFSClient: Exception in createBlockOutputStream java.net.SocketTimeoutException: 69000 millis
timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/x.x.x.x:55748 remote=/x.x.x.x:50010]
09/08/19 07:50:45 INFO dfs.DFSClient: Abandoning block blk_8258931159385721568_6046
09/08/19 07:50:59 INFO dfs.DFSClient: Waiting to find target node: x.x.x.x:50010
09/08/19 07:55:19 INFO dfs.DFSClient: Exception in createBlockOutputStream java.net.SocketTimeoutException: 69000 millis timeout while waiting for
channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/x.x.x.x:47409 remote=/x.x.x.x:50010]
09/08/19 07:55:19 INFO dfs.DFSClient: Abandoning block blk_-6648842835159477749_6046
09/08/19 07:55:41 INFO dfs.DFSClient: Waiting to find target node: x.x.x.x:50010


I thought maybe whatever configuration value set to 69000 was too low, 
but there is nothing in hadoop-site or hadoop-default
using a value of 69000.

Can anyone shed some light on this?

thanks,
M

From common-user-return-16883-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 18:17:58 2009
Return-Path: <common-user-return-16883-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 25604 invoked from network); 19 Aug 2009 18:17:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 18:17:58 -0000
Received: (qmail 86081 invoked by uid 500); 19 Aug 2009 18:18:15 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 86002 invoked by uid 500); 19 Aug 2009 18:18:15 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 85992 invoked by uid 99); 19 Aug 2009 18:18:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 18:18:15 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ted.dunning@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 18:18:07 +0000
Received: by yxe15 with SMTP id 15so6123557yxe.5
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 11:17:46 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=Zk/BgxEbmuWwXAYjTcM6KsDkqjnCy0yvMSnNVkkhiYo=;
        b=OGxldlnFHOpjoboVOYS3vf/XU6Ql1Z/G6ipdNEXQ1zgblKwVX1bNKqhr5a24vEPF6P
         ZlRV2poNCgSA+7jxqrP01Wv0cEl0DvtvObSpc7I+UiCJl/nK0l6lsdrVeOTqjNQ1sMQ2
         9I4oKer7JvIkP4x/LT7li5b3whkxKpfJxmv3U=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=vVq3JUFk+WfHRkoLwNFZzsuxcuqF/nlfPWWmn9kNOP7FfYBtM5U3KJYuyWQeFSwiBp
         BjlL2PNuDpwMZAuAsh+FhKaqjLmjtYuNhfOOQf5/zU9wAIhtADDXCya/FaPq98iEX1j0
         2xDxp2yVplcgaWe7tl/J4otnhakqzVG0VyhUY=
MIME-Version: 1.0
Received: by 10.150.117.25 with SMTP id p25mr9782936ybc.139.1250705866395; 
	Wed, 19 Aug 2009 11:17:46 -0700 (PDT)
In-Reply-To: <3b1311780908190519y20708a7epef6edac55e3e9981@mail.gmail.com>
References: <3b1311780908182223m6d75da2dxf33118c91496d08@mail.gmail.com> 
	<c7d45fc70908190044u77503a5dsed88dc9a37f10cf@mail.gmail.com> 
	<3b1311780908190519y20708a7epef6edac55e3e9981@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Wed, 19 Aug 2009 11:17:26 -0700
Message-ID: <c7d45fc70908191117g399ebb44l7f95e372c25449ee@mail.gmail.com>
Subject: Re: How to deal with "too many fetch failures"?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd72836e291e1047182a62c
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd72836e291e1047182a62c
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

I think I remember something about 19.1 in which certain failures would
cause this.  Consider using an updated 19 or moving to 20 as well.

On Wed, Aug 19, 2009 at 5:19 AM, yang song <hadoop.inifok@gmail.com> wrote:

> I'm sorry, the version is 0.19.1
>
>

--000e0cd72836e291e1047182a62c--

From common-user-return-16884-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 18:22:57 2009
Return-Path: <common-user-return-16884-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 34759 invoked from network); 19 Aug 2009 18:22:57 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 18:22:57 -0000
Received: (qmail 93056 invoked by uid 500); 19 Aug 2009 18:23:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 92993 invoked by uid 500); 19 Aug 2009 18:23:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 92980 invoked by uid 99); 19 Aug 2009 18:23:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 18:23:13 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 18:23:01 +0000
Received: from [172.21.149.159] (wlanvpn-mc2e-247-159.corp.yahoo.com [172.21.149.159])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7JILhFk085482
	for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 11:21:43 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=XKJhSD38CwuBAiZatv+fiq4VWzX+LdhwVtySAuze8WjjLUdZVzxrKRQVUAHrCYt7
Message-ID: <4A8C42B7.7020804@yahoo-inc.com>
Date: Wed, 19 Aug 2009 11:21:43 -0700
From: Jakob Homan <jhoman@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.12 (Macintosh/20080213)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: submitting multiple small jobs simultaneously
References: <19084.7358.404199.841876@gargle.gargle.HOWL>
In-Reply-To: <19084.7358.404199.841876@gargle.gargle.HOWL>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

George-
    You can certainly submit jobs asynchronously via the 
JobClient.submitJob() method 
(http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/mapred/JobClient.html). 
  This will return a handle (a RunningJob instance) that you can poll 
for  completion.  This is what the JobClient.runJob() method does.

You can submit multiple jobs using the submitJob() method and wait for 
all of them to finish through their RunningJobs, as it seems you want to 
do.

Is this what you're looking for?

-Jakob Homan
Hadoop at Yahoo!

George Jahad wrote:
> 
> I'm importing a bunch of data into HDSF.  It involves running a bunch
> of small jobs, that don't put much load on my cluster, but it would be
> nice if I could do them all from the same job client. I'd submit them
> all asynchronously and then wait for the results of each.
> 
> I imagine this has been done many times before, but can't find any
> examples on Google.  If you know of any, please let me know.
> 
> Thanks,
> George
> 
> 
> 


From common-user-return-16885-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 20:24:56 2009
Return-Path: <common-user-return-16885-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 84585 invoked from network); 19 Aug 2009 20:24:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 20:24:56 -0000
Received: (qmail 64404 invoked by uid 500); 19 Aug 2009 20:25:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 64326 invoked by uid 500); 19 Aug 2009 20:25:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 64316 invoked by uid 99); 19 Aug 2009 20:25:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 20:25:12 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 20:25:04 +0000
Received: by bwz10 with SMTP id 10so3826869bwz.29
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 13:24:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=BM6wfNKha0mJ9VaHwGOZPA/rxMnu6KsxovcYPV291VI=;
        b=Aem9Qhb6czhB3x+pUxXfdMsroXLeM2Vii3PwCLPCdae49qUnSEKIgH6IQKCET7HhNu
         MIeS6oV8KAJzDuk/YnQdlK2UDy/0Y5k0dNv6LgY3ht3EoOkY03jfNz6HYcVXKbqSeS+M
         A+TLaSEWvd58fOgCKmM4H/9XgJCQV3siwasRI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=uRkOkALkEhhVYVStwDDrETkGTXQGjzuxKFT7yZGmMpb4Ra40ZBO/Jkce9cAG4Uu4WN
         Q5j/m3VnSO2716nW5SDI+HGkydBIEmrjTumwvAUI6IGwNsxQXYcBdRnZDJGxnRGNkYSZ
         8RNPsxOJ3RDqPLv5LXbbScLlv6KYI1j8PWzq0=
MIME-Version: 1.0
Received: by 10.239.181.136 with SMTP id m8mr588571hbg.131.1250713482853; Wed, 
	19 Aug 2009 13:24:42 -0700 (PDT)
In-Reply-To: <4A8C3D32.3010905@yahoo-inc.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
	 <4A8B8D11.8020008@yahoo-inc.com>
	 <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>
	 <ad681e7f0908190845j59dc22aet95e9af971efa8798@mail.gmail.com>
	 <cbbf4b570908190914j206797ecrc862d06b6eccbd37@mail.gmail.com>
	 <4A8C3D32.3010905@yahoo-inc.com>
Date: Wed, 19 Aug 2009 16:24:42 -0400
Message-ID: <ad681e7f0908191324n1e04a72fo9ebbd436e89aef20@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f7cc0adc7ebb0471846c8b
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f7cc0adc7ebb0471846c8b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Also, I just want to clear... the delay seems to at the intial

(read = in.read(buf))

after the first time into the loop it flies...

Ananth T Sarathy


On Wed, Aug 19, 2009 at 1:58 PM, Raghu Angadi <rangadi@yahoo-inc.com> wrote:

> Edward Capriolo wrote:
>
>> On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo <edlinuxguru@gmail.com
>>> >wrote:
>>>
>>>  It would be as fast as underlying filesystem goes.
>>>>>>
>>>>> I would not agree with that statement. There is overhead.
>>>>
>>>
> You might be misinterpreting my comment. There is of course some over head
> (at the least the procedure calls).. depending on you underlying filesystem,
> there could be extra buffer copies and CRC overhead. But none of that
> explains transfer as slow as 1 MBps (if my interpretation of of results is
> correct).
>
> Raghu.
>
>
>  In some testing I did writing a small file can
>>>> take 30-300 ms. So if you have 9000 small files (like I did) and you
>>>> are single threaded this takes a long time.
>>>>
>>>> If you orchestrate your task to use FSDataInput and FSDataOutput in
>>>> the map or reduce phase then each mapper or reducer is writing a file
>>>> at a time. Now that is fast.
>>>>
>>>> Ananth, are you doing your r/w inside a map/reduce job or are you just
>>>> using FS* in a top down program?
>>>>
>>>>
>>>>
>>>> On Wed, Aug 19, 2009 at 1:26 AM, Raghu Angadi<rangadi@yahoo-inc.com>
>>>> wrote:
>>>>
>>>>> Ananth T. Sarathy wrote:
>>>>>
>>>>>> I am trying to download binary files stored in Hadoop but there is
>>>>>> like
>>>>>>
>>>>> a
>>>>
>>>>> 2
>>>>>> minute wait on a 20mb file when I try to execute the in.read(buf).
>>>>>>
>>>>> What does this mean : 2 min to pipe 20mb or one or your one of the
>>>>>
>>>> in.read()
>>>>
>>>>> calls took 2 minutes? Your code actually measures team for read and
>>>>>
>>>> write.
>>>>
>>>>> There is nothing in FSInputstream to cause this slow down. Do you think
>>>>> anyone would use Hadoop otherwise? It would be as fast as underlying
>>>>> filesystem goes.
>>>>>
>>>>> Raghu.
>>>>>
>>>>>  is there a better way to be doing this?
>>>>>>
>>>>>>   private void pipe(InputStream in, OutputStream out) throws
>>>>>>
>>>>> IOException
>>>>
>>>>>   {    System.out.println(System.currentTimeMillis()+" Starting to Pipe
>>>>>> Data");
>>>>>>       byte[] buf = new byte[1024];
>>>>>>       int read = 0;
>>>>>>       while ((read = in.read(buf)) >= 0)
>>>>>>       {
>>>>>>           out.write(buf, 0, read);
>>>>>>           System.out.println(System.currentTimeMillis()+" Piping
>>>>>>
>>>>> Data");
>>>>
>>>>>       }
>>>>>>       out.flush();
>>>>>>       System.out.println(System.currentTimeMillis()+" Finished Piping
>>>>>> Data");
>>>>>>
>>>>>>   }
>>>>>>
>>>>>> public void readFile(String fileToRead, OutputStream out)
>>>>>>           throws IOException
>>>>>>   {
>>>>>>       System.out.println(System.currentTimeMillis()+" Start Read
>>>>>>
>>>>> File");
>>>>
>>>>>       Path inFile = new Path(fileToRead);
>>>>>>       System.out.println(System.currentTimeMillis()+" Set Path");
>>>>>>       // Validate the input/output paths before reading/writing.
>>>>>>
>>>>>>       if (!fs.exists(inFile))
>>>>>>       {
>>>>>>           throw new HadoopFileException("Specified file  " +
>>>>>> fileToRead
>>>>>>                   + " not found.");
>>>>>>       }
>>>>>>       if (!fs.isFile(inFile))
>>>>>>       {
>>>>>>           throw new HadoopFileException("Specified file  " +
>>>>>> fileToRead
>>>>>>                   + " not found.");
>>>>>>       }
>>>>>>       // Open inFile for reading.
>>>>>>       System.out.println(System.currentTimeMillis()+" Opening Data
>>>>>> Stream");
>>>>>>       FSDataInputStream in = fs.open(inFile);
>>>>>>
>>>>>>       System.out.println(System.currentTimeMillis()+" Opened Data
>>>>>> Stream");
>>>>>>       // Open outFile for writing.
>>>>>>
>>>>>>       // Read from input stream and write to output stream until EOF.
>>>>>>       pipe(in, out);
>>>>>>
>>>>>>       // Close the streams when done.
>>>>>>       out.close();
>>>>>>       in.close();
>>>>>>   }
>>>>>> Ananth T Sarathy
>>>>>>
>>>>>>
>>>>>
>

--001485f7cc0adc7ebb0471846c8b--

From common-user-return-16886-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 20:31:09 2009
Return-Path: <common-user-return-16886-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 86121 invoked from network); 19 Aug 2009 20:31:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 20:31:09 -0000
Received: (qmail 73476 invoked by uid 500); 19 Aug 2009 20:31:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 73409 invoked by uid 500); 19 Aug 2009 20:31:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 73399 invoked by uid 99); 19 Aug 2009 20:31:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 20:31:25 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [64.78.17.16] (HELO EXHUB018-1.exch018.msoutlookonline.net) (64.78.17.16)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 20:31:15 +0000
Received: from EXVMBX018-1.exch018.msoutlookonline.net ([64.78.17.47]) by
 EXHUB018-1.exch018.msoutlookonline.net ([64.78.17.16]) with mapi; Wed, 19 Aug
 2009 13:30:54 -0700
From: Scott Carey <scott@richrelevance.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Wed, 19 Aug 2009 13:30:52 -0700
Subject: Re: Faster alternative to FSDataInputStream
Thread-Topic: Faster alternative to FSDataInputStream
Thread-Index: Acog9wAVhZq9f3jSTZalB/7VvijWWQAFPHND
Message-ID: <C6B1AF0C.F322%scott@richrelevance.com>
In-Reply-To: <4A8C3D32.3010905@yahoo-inc.com>
Accept-Language: en-US
Content-Language: en
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org


On 8/19/09 10:58 AM, "Raghu Angadi" <rangadi@yahoo-inc.com> wrote:

> Edward Capriolo wrote:
>>> On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo
>>> <edlinuxguru@gmail.com>wrote:
>>>=20
>>>>>> It would be as fast as underlying filesystem goes.
>>>> I would not agree with that statement. There is overhead.
>=20
> You might be misinterpreting my comment. There is of course some over
> head (at the least the procedure calls).. depending on you underlying
> filesystem, there could be extra buffer copies and CRC overhead. But
> none of that explains transfer as slow as 1 MBps (if my interpretation
> of of results is correct).
>=20
> Raghu.


Yes, there is nothing about distributing work for parallel execution that i=
s
going to make a single 20MB file transfer faster.   That is very slow, and
should be on the order of a second or so, not multiple minutes.
 Something else is wrong.



From common-user-return-16887-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 20:36:53 2009
Return-Path: <common-user-return-16887-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 87155 invoked from network); 19 Aug 2009 20:36:53 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 20:36:53 -0000
Received: (qmail 79852 invoked by uid 500); 19 Aug 2009 20:37:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 79753 invoked by uid 500); 19 Aug 2009 20:37:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 79611 invoked by uid 99); 19 Aug 2009 20:37:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 20:37:04 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 20:36:31 +0000
Received: from [10.72.106.226] (heighthigh-lx.corp.yahoo.com [10.72.106.226])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7JKZHR8009752
	for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 13:35:17 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=LoMUTQ0LS4kFodh3HuVb1x/qmUeIWKPTfFKRj2jgBbSrKfZxspwIQ5rxiLfZzABM
Message-ID: <4A8C6205.6000306@yahoo-inc.com>
Date: Wed, 19 Aug 2009 13:35:17 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Faster alternative to FSDataInputStream
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>	 <4A8B8D11.8020008@yahoo-inc.com>	 <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>	 <ad681e7f0908190845j59dc22aet95e9af971efa8798@mail.gmail.com>	 <cbbf4b570908190914j206797ecrc862d06b6eccbd37@mail.gmail.com>	 <4A8C3D32.3010905@yahoo-inc.com> <ad681e7f0908191324n1e04a72fo9ebbd436e89aef20@mail.gmail.com>
In-Reply-To: <ad681e7f0908191324n1e04a72fo9ebbd436e89aef20@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Ananth T. Sarathy wrote:
> Also, I just want to clear... the delay seems to at the intial
> 
> (read = in.read(buf))

It the file on HDFS (over S3) or S3?

Does it always happen?

Raghu.

> after the first time into the loop it flies...
> 
> Ananth T Sarathy
> 
> 
> On Wed, Aug 19, 2009 at 1:58 PM, Raghu Angadi <rangadi@yahoo-inc.com> wrote:
> 
>> Edward Capriolo wrote:
>>
>>> On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo <edlinuxguru@gmail.com
>>>>> wrote:
>>>>  It would be as fast as underlying filesystem goes.
>>>>>> I would not agree with that statement. There is overhead.
>> You might be misinterpreting my comment. There is of course some over head
>> (at the least the procedure calls).. depending on you underlying filesystem,
>> there could be extra buffer copies and CRC overhead. But none of that
>> explains transfer as slow as 1 MBps (if my interpretation of of results is
>> correct).
>>
>> Raghu.
>>
>>

From common-user-return-16888-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 21:48:43 2009
Return-Path: <common-user-return-16888-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 23260 invoked from network); 19 Aug 2009 21:48:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 21:48:43 -0000
Received: (qmail 99679 invoked by uid 500); 19 Aug 2009 21:49:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 99598 invoked by uid 500); 19 Aug 2009 21:49:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 99584 invoked by uid 500); 19 Aug 2009 21:49:00 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 99578 invoked by uid 99); 19 Aug 2009 21:48:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 21:48:59 +0000
X-ASF-Spam-Status: No, hits=1.4 required=10.0
	tests=ASF_LIST_OPS,HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 209.85.210.185 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 21:48:52 +0000
Received: by yxe15 with SMTP id 15so6300412yxe.5
        for <multiple recipients>; Wed, 19 Aug 2009 14:48:30 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.101.81.12 with SMTP id i12mr7815941anl.151.1250718509351; Wed, 
	19 Aug 2009 14:48:29 -0700 (PDT)
Date: Wed, 19 Aug 2009 14:48:29 -0700
Message-ID: <77f4f8890908191448q67970d40sabb0e54ec55ad3c8@mail.gmail.com>
Subject: Location of the source code for the fair scheduler
From: Mithila Nagendra <mnagendr@asu.edu>
To: core-user@hadoop.apache.org, core-user-subscribe@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636ed65f776c3540471859822
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed65f776c3540471859822
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello

I was wondering how I could locate the source code files for the fair
scheduler.

Thanks
Mithila

--001636ed65f776c3540471859822--

From common-user-return-16889-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:29:31 2009
Return-Path: <common-user-return-16889-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61290 invoked from network); 19 Aug 2009 23:29:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:29:29 -0000
Received: (qmail 16927 invoked by uid 500); 19 Aug 2009 23:29:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 16830 invoked by uid 500); 19 Aug 2009 23:29:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 16811 invoked by uid 99); 19 Aug 2009 23:29:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:29:45 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:29:35 +0000
Received: by qyk26 with SMTP id 26so3628679qyk.5
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 16:29:13 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.22.212 with SMTP id o20mr6979700qab.164.1250724553112; 
	Wed, 19 Aug 2009 16:29:13 -0700 (PDT)
In-Reply-To: <4A8C0F8C.8070700@apache.org>
References: <20090819125614.38d18789@caputradii.linkoping.osa> 
	<4A8C0F8C.8070700@apache.org>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 19 Aug 2009 16:28:53 -0700
Message-ID: <d6d7c4410908191628x141439bcrc3f27e94b43026b8@mail.gmail.com>
Subject: Re: Running Cloudera's distribution without their support agreement - 
	is that a bad idea?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000feaeb44a5b3419b0471870093
X-Virus-Checked: Checked by ClamAV on apache.org

--000feaeb44a5b3419b0471870093
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Erik,

We built our distribution to make it easy for you to get started using
Hadoop -- not to force you into buying a support agreement. (Though if
you're running Hadoop in a production environment, we're certainly happy to
talk to you about that later! ;)

You're just as likely to get help from this mailing list with any Hadoop
questions, bugs, etc. here whether you're running our packages, or whether
you download a "stock" package from Apache. An advantage of our distribution
is that we tend to backport bugfixes more aggressively than Apache does. So
our release of 0.18.3 contains some bugfixes that aren't present in Apache's
0.18.3 tarball. (They're all contributed to 0.19 or 0.20, or on the
development trunk, though.) And if you report a bug on our distribution,
we'll fix it and you just 'apt-get upgrade hadoop' when it's ready. Rather
than get too high on my soapbox, I'll just point you toward
www.cloudera.com/hadoop if you're interested in learning more.

If you've got specific questions or bug reports about installing our
packages, like apt-get throws a strange message at you, we also have a
separate community support forum at
http://getsatisfaction.com/clouderawhere we'll help you resolve these
issues, support contract or no. This is
in a separate forum to prevent Cloudera-specific issues from becoming a
distraction on this list.

Welcome to Hadoop :)
Cheers,
- Aaron

On Wed, Aug 19, 2009 at 7:43 AM, Steve Loughran <stevel@apache.org> wrote:

> Erik Forsberg wrote:
>
>> Hi!
>>
>> I'm currently evaluating different Hadoop versions for a new project.
>> I'm tempted by the Cloudera distribution, since it's neatly packaged
>> into .deb files, and is the stable distribution but with some patches
>> applied, for example the bzip2 support.
>>
>> I understand that I can get a support agreement from Cloudera to match
>> this distribution, but if that's not an option, will running the
>> Cloudera distribution put me in a position where I won't get any help
>> from the community because I'm not running an official Apache Hadoop
>> release?
>>
>
> -there is no official Apache deb so you will end up using someone elses deb
> if that is how you build your cluster up.
> -everyone welcomes bug reports, especially ones with stack traces.
> -regardless of whether you use an official vs external release, a common
> answer to any bugrep will be "does it go away on the latest release?" And
> then "does it go away on trunk?".
> -only you are going to be able to track down problems on your cluster,
> because your machines and network is different from everybody else's.
> -the act of checking out and building a release locally sets you up to
> adding diagnostics and fixes to the source, fixes you can turn into patches
> to get pushed in.
>
> what cloudera are selling, then, is not the packaging, so much as them
> taking over the work of fixing bugs for you. You are still free to track
> down and fix your own problems, on their releases and the Apache ones
> -because nobody else's network/cluster matches yours.
>
> I am in favour of adding lots more diagnostics to hadoop, most of the
> patches of mine that have gone in help with this debugging of which machines
> are playing up -and why. Anything we can do to help debug hadoop, or
> validate an installation, is a welcome improvement.
>
> -steve
>
>

--000feaeb44a5b3419b0471870093--

From common-user-return-16890-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:30:23 2009
Return-Path: <common-user-return-16890-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61785 invoked from network); 19 Aug 2009 23:30:16 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:30:16 -0000
Received: (qmail 19209 invoked by uid 500); 19 Aug 2009 23:30:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 19131 invoked by uid 500); 19 Aug 2009 23:30:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 19121 invoked by uid 99); 19 Aug 2009 23:30:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:30:32 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 209.85.221.188 is neither permitted nor denied by domain of aaron@cloudera.com)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:30:24 +0000
Received: by mail-qy0-f188.google.com with SMTP id 26so3628679qyk.5
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 16:30:04 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.90.129 with SMTP id i1mr7090460qam.201.1250724604200; Wed, 
	19 Aug 2009 16:30:04 -0700 (PDT)
In-Reply-To: <77f4f8890908191448q67970d40sabb0e54ec55ad3c8@mail.gmail.com>
References: <77f4f8890908191448q67970d40sabb0e54ec55ad3c8@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 19 Aug 2009 16:29:43 -0700
Message-ID: <d6d7c4410908191629n7ec630f9j867ca5a1db155dbf@mail.gmail.com>
Subject: Re: Location of the source code for the fair scheduler
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00c09f88d0e4bec791047187032b
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09f88d0e4bec791047187032b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Mithila,

In the Mapreduce svn tree, it's under src/contrib/fairscheduler/
- Aaron

On Wed, Aug 19, 2009 at 2:48 PM, Mithila Nagendra <mnagendr@asu.edu> wrote:

> Hello
>
> I was wondering how I could locate the source code files for the fair
> scheduler.
>
> Thanks
> Mithila
>

--00c09f88d0e4bec791047187032b--

From common-user-return-16892-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:30:58 2009
Return-Path: <common-user-return-16892-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 62189 invoked from network); 19 Aug 2009 23:30:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:30:58 -0000
Received: (qmail 21184 invoked by uid 500); 19 Aug 2009 23:31:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21046 invoked by uid 500); 19 Aug 2009 23:31:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21025 invoked by uid 500); 19 Aug 2009 23:31:10 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 21018 invoked by uid 99); 19 Aug 2009 23:31:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:31:10 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=ASF_LIST_OPS,HTML_MESSAGE,NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:30:59 +0000
Received: from sp1-ex07cas01.ds.corp.yahoo.com (sp1-ex07cas01.ds.corp.yahoo.com [216.252.116.137])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7JNUZ83053786;
	Wed, 19 Aug 2009 16:30:36 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:in-reply-to:accept-language:content-language:
	x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:content-type:mime-version;
	b=y7nPB5JLZw/PZFpt8+tMnVAELT9EdAR1ut6Kza1aKjddznk60tbT0PBxSrr4dqYU
Received: from SP1-EX07VS02.ds.corp.yahoo.com ([216.252.116.135]) by
 sp1-ex07cas01.ds.corp.yahoo.com ([216.252.116.137]) with mapi; Wed, 19 Aug
 2009 16:30:35 -0700
From: Ravi Phulari <rphulari@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>,
        Mithila
 Nagendra <mnagendr@asu.edu>,
        "core-user@hadoop.apache.org"
	<core-user@hadoop.apache.org>,
        "core-user-subscribe@hadoop.apache.org"
	<core-user-subscribe@hadoop.apache.org>
Date: Wed, 19 Aug 2009 16:30:35 -0700
Subject: Re: Location of the source code for the fair scheduler
Thread-Topic: Location of the source code for the fair scheduler
Thread-Index: AcohFvSMReN0p/AJQE6s4LmXD0vgAAADhiDJ
Message-ID: <C6B1D92B.11978%rphulari@yahoo-inc.com>
In-Reply-To: <77f4f8890908191448q67970d40sabb0e54ec55ad3c8@mail.gmail.com>
Accept-Language: en-US
Content-Language: en
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: multipart/alternative;
	boundary="_000_C6B1D92B11978rphulariyahooinccom_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_C6B1D92B11978rphulariyahooinccom_
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Currently Fairscheduler source is in              hadoop-mapreduce/src/cont=
rib/fairscheduler/

Download mapreduce source from.
http://hadoop.apache.org/mapreduce/

-
Ravi

On 8/19/09 2:48 PM, "Mithila Nagendra" <mnagendr@asu.edu> wrote:

Hello

I was wondering how I could locate the source code files for the fair
scheduler.

Thanks
Mithila




--_000_C6B1D92B11978rphulariyahooinccom_--

From common-user-return-16891-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:30:58 2009
Return-Path: <common-user-return-16891-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 62216 invoked from network); 19 Aug 2009 23:30:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:30:58 -0000
Received: (qmail 21171 invoked by uid 500); 19 Aug 2009 23:31:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21043 invoked by uid 500); 19 Aug 2009 23:31:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21018 invoked by uid 99); 19 Aug 2009 23:31:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:31:10 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=ASF_LIST_OPS,HTML_MESSAGE,NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:30:59 +0000
Received: from sp1-ex07cas01.ds.corp.yahoo.com (sp1-ex07cas01.ds.corp.yahoo.com [216.252.116.137])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7JNUZ83053786;
	Wed, 19 Aug 2009 16:30:36 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:in-reply-to:accept-language:content-language:
	x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:content-type:mime-version;
	b=y7nPB5JLZw/PZFpt8+tMnVAELT9EdAR1ut6Kza1aKjddznk60tbT0PBxSrr4dqYU
Received: from SP1-EX07VS02.ds.corp.yahoo.com ([216.252.116.135]) by
 sp1-ex07cas01.ds.corp.yahoo.com ([216.252.116.137]) with mapi; Wed, 19 Aug
 2009 16:30:35 -0700
From: Ravi Phulari <rphulari@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>,
        Mithila
 Nagendra <mnagendr@asu.edu>,
        "core-user@hadoop.apache.org"
	<core-user@hadoop.apache.org>,
        "core-user-subscribe@hadoop.apache.org"
	<core-user-subscribe@hadoop.apache.org>
Date: Wed, 19 Aug 2009 16:30:35 -0700
Subject: Re: Location of the source code for the fair scheduler
Thread-Topic: Location of the source code for the fair scheduler
Thread-Index: AcohFvSMReN0p/AJQE6s4LmXD0vgAAADhiDJ
Message-ID: <C6B1D92B.11978%rphulari@yahoo-inc.com>
In-Reply-To: <77f4f8890908191448q67970d40sabb0e54ec55ad3c8@mail.gmail.com>
Accept-Language: en-US
Content-Language: en
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: multipart/alternative;
	boundary="_000_C6B1D92B11978rphulariyahooinccom_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_C6B1D92B11978rphulariyahooinccom_
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Currently Fairscheduler source is in              hadoop-mapreduce/src/cont=
rib/fairscheduler/

Download mapreduce source from.
http://hadoop.apache.org/mapreduce/

-
Ravi

On 8/19/09 2:48 PM, "Mithila Nagendra" <mnagendr@asu.edu> wrote:

Hello

I was wondering how I could locate the source code files for the fair
scheduler.

Thanks
Mithila




--_000_C6B1D92B11978rphulariyahooinccom_--

From common-user-return-16894-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:32:19 2009
Return-Path: <common-user-return-16894-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 62464 invoked from network); 19 Aug 2009 23:32:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:32:18 -0000
Received: (qmail 25172 invoked by uid 500); 19 Aug 2009 23:32:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25023 invoked by uid 500); 19 Aug 2009 23:32:31 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25005 invoked by uid 500); 19 Aug 2009 23:32:31 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 24999 invoked by uid 99); 19 Aug 2009 23:32:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:32:31 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saidtherobot@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:32:23 +0000
Received: by ywh36 with SMTP id 36so6938646ywh.31
        for <multiple recipients>; Wed, 19 Aug 2009 16:32:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:sender:received:date
         :x-google-sender-auth:message-id:subject:from:to:content-type;
        bh=bU1eZmzLyCwfQwzzl666R+fygzEnUgwhai38d23aHbM=;
        b=UvWcM7kiaNPjnc8PYIfauRLV6iZlO1FPf0a1vqXsxy5xAunkJ2OX+DQdUiIiGI0Fgu
         BJqCDsem6UArOwq8UL9kuammS7RFcChQySNuaacrytWn739xxOltC579f3fS+lCTJW1p
         IPNPBE/A0a5TzM97L9e2dRz91JsNez49z4vFQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:sender:date:x-google-sender-auth:message-id:subject
         :from:to:content-type;
        b=wcAI5nCLPyD8F/dmR+xyIKeNvHV0+GXV6G0EdRF77KwP75vxKuZBzFgATzSPOCSkLm
         O/j2EUo5sYJFNm0zqWa04ROUIAVxRgQF6pC7WPjeGg0KxPj1d4eceWTStr4VuzioqNPK
         p5JcL1q4+yHHNrQG2tMhZy8E0lsySa0ccB1xk=
MIME-Version: 1.0
Sender: saidtherobot@gmail.com
Received: by 10.151.5.21 with SMTP id h21mr11484425ybi.26.1250724722863; Wed, 
	19 Aug 2009 16:32:02 -0700 (PDT)
Date: Wed, 19 Aug 2009 19:32:02 -0400
X-Google-Sender-Auth: d08957403dc63b36
Message-ID: <2986c2f30908191632u74dcad9dt9073fc84eb7d849e@mail.gmail.com>
Subject: syslog-ng and hadoop
From: Mike Anderson <mike_a@mit.edu>
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd48276d16f750471870ac9
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd48276d16f750471870ac9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Has anybody had any luck setting up the log4j.properties file to send logs
to a syslog-ng server?
My log4j.properties excerpt:
log4j.appender.SYSLOG=org.apache.log4j.net.SyslogAppender
log4j.appender.SYSLOG.syslogHost=10.0.20.164
log4j.appender.SYSLOG.layout=org.apache.log4j.PatternLayout
log4j.appender.SYSLOG.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
log4j.appender.SYSLOG.Facility=HADOOP

and my syslog-ng.conf file running on 10.0.20.164

source s_hadoop {
        # message generated by Syslog-NG
        internal();
        # standard Linux log source (this is the default place for the
syslog()
        # function to send logs to)
        unix-stream("/dev/log");
        udp();
};
destination df_hadoop { file("/var/log/hadoop/hadoop.log");};
filter f_hadoop {facility(hadoop);};
log {
source(s_hadoop);
filter(f_hadoop);
destination(df_hadoop);
};


Thanks in advance,
Mike

--000e0cd48276d16f750471870ac9--

From common-user-return-16893-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:32:18 2009
Return-Path: <common-user-return-16893-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 62455 invoked from network); 19 Aug 2009 23:32:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:32:18 -0000
Received: (qmail 25116 invoked by uid 500); 19 Aug 2009 23:32:31 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25018 invoked by uid 500); 19 Aug 2009 23:32:31 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 24999 invoked by uid 99); 19 Aug 2009 23:32:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:32:31 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saidtherobot@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:32:23 +0000
Received: by ywh36 with SMTP id 36so6938646ywh.31
        for <multiple recipients>; Wed, 19 Aug 2009 16:32:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:sender:received:date
         :x-google-sender-auth:message-id:subject:from:to:content-type;
        bh=bU1eZmzLyCwfQwzzl666R+fygzEnUgwhai38d23aHbM=;
        b=UvWcM7kiaNPjnc8PYIfauRLV6iZlO1FPf0a1vqXsxy5xAunkJ2OX+DQdUiIiGI0Fgu
         BJqCDsem6UArOwq8UL9kuammS7RFcChQySNuaacrytWn739xxOltC579f3fS+lCTJW1p
         IPNPBE/A0a5TzM97L9e2dRz91JsNez49z4vFQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:sender:date:x-google-sender-auth:message-id:subject
         :from:to:content-type;
        b=wcAI5nCLPyD8F/dmR+xyIKeNvHV0+GXV6G0EdRF77KwP75vxKuZBzFgATzSPOCSkLm
         O/j2EUo5sYJFNm0zqWa04ROUIAVxRgQF6pC7WPjeGg0KxPj1d4eceWTStr4VuzioqNPK
         p5JcL1q4+yHHNrQG2tMhZy8E0lsySa0ccB1xk=
MIME-Version: 1.0
Sender: saidtherobot@gmail.com
Received: by 10.151.5.21 with SMTP id h21mr11484425ybi.26.1250724722863; Wed, 
	19 Aug 2009 16:32:02 -0700 (PDT)
Date: Wed, 19 Aug 2009 19:32:02 -0400
X-Google-Sender-Auth: d08957403dc63b36
Message-ID: <2986c2f30908191632u74dcad9dt9073fc84eb7d849e@mail.gmail.com>
Subject: syslog-ng and hadoop
From: Mike Anderson <mike_a@mit.edu>
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd48276d16f750471870ac9
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd48276d16f750471870ac9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Has anybody had any luck setting up the log4j.properties file to send logs
to a syslog-ng server?
My log4j.properties excerpt:
log4j.appender.SYSLOG=org.apache.log4j.net.SyslogAppender
log4j.appender.SYSLOG.syslogHost=10.0.20.164
log4j.appender.SYSLOG.layout=org.apache.log4j.PatternLayout
log4j.appender.SYSLOG.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
log4j.appender.SYSLOG.Facility=HADOOP

and my syslog-ng.conf file running on 10.0.20.164

source s_hadoop {
        # message generated by Syslog-NG
        internal();
        # standard Linux log source (this is the default place for the
syslog()
        # function to send logs to)
        unix-stream("/dev/log");
        udp();
};
destination df_hadoop { file("/var/log/hadoop/hadoop.log");};
filter f_hadoop {facility(hadoop);};
log {
source(s_hadoop);
filter(f_hadoop);
destination(df_hadoop);
};


Thanks in advance,
Mike

--000e0cd48276d16f750471870ac9--

From common-user-return-16895-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:39:29 2009
Return-Path: <common-user-return-16895-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63804 invoked from network); 19 Aug 2009 23:39:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:39:28 -0000
Received: (qmail 34533 invoked by uid 500); 19 Aug 2009 23:39:45 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 34445 invoked by uid 500); 19 Aug 2009 23:39:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 34435 invoked by uid 99); 19 Aug 2009 23:39:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:39:45 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [74.125.92.26] (HELO qw-out-2122.google.com) (74.125.92.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:39:36 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1476430qwh.35
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 16:39:15 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.30.6 with SMTP id s6mr7033978qac.101.1250725153242; Wed, 
	19 Aug 2009 16:39:13 -0700 (PDT)
In-Reply-To: <3b1311780908190721g3814f4dft9e00e9edce1eb86b@mail.gmail.com>
References: <3b1311780908190721g3814f4dft9e00e9edce1eb86b@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 19 Aug 2009 16:38:53 -0700
Message-ID: <d6d7c4410908191638g6c9452f7h104cad20ba604f7e@mail.gmail.com>
Subject: Re: How does hadoop deal with hadoop-site.xml?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00c09f88cee57885fe04718724a6
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09f88cee57885fe04718724a6
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Inifok,

This is a confusing aspect of Hadoop, I'm afraid.

Settings are divided into two categories: "per-job" and "per-node."
Unfortunately, which are which, isn't documented.

Some settings are applied to the node that is being used. So for example, if
you set fs.default.name on a node to be "hdfs://some.namenode:8020/", then
any FS connections you make from that node will go to some.namenode. If a
different machine in your cluster has fs.default.name set to
hdfs://other.namenode, then that machine will connect to a different
namenode.

Another example of a per-machine setting is
mapred.tasktracker.map.tasks.maximum; this tells a tasktracker the maximum
number of tasks it should run in parallel. Each tasktracker is free to
configure this value differently. e.g., if you have some quad-core and some
eight-core machines. dfs.data.dir tells a datanode where its data
directories should be kept. Naturally, this can vary machine-to-machine.

Other settings are applied to a job as a whole. These settings are
configured when you submit the job. So if you write
conf.set("mapred.reduce.parallel.copies", 20) in your code, this will be the
setting for the job. Settings that you don't explicitly put in your code,
are drawn from the hadoop-site.xml file on the machine where the job is
submitted from.

In general, I strongly recommend you save yourself some pain by keeping your
configuration files as identical as possible :)
Good luck,
- Aaron


On Wed, Aug 19, 2009 at 7:21 AM, yang song <hadoop.inifok@gmail.com> wrote:

> Hello, everybody
>    I feel puzzled about setting properties in hadoop-site.xml.
>    Suppose I submit the job from machine A, and JobTracker runs on machine
> B. So there are two hadoop-site.xml files. Now, I increase
> "mapred.reduce.parallel.copies"(e.g. 10) on machine B since I want to make
> copy phrase faster. However, "mapred.reduce.parallel.copies" from WebUI is
> still 5. When I increase it on machine A, it changes. So, I feel very
> puzzled. Why does it doesn't work when I change it on B? What's more, when
> I
> add some properties on B, the certain properties will be found on WebUI.
> And
> why I can't change properties through machine B? Does some certain
> properties must be changed through A and some others must be changed
> through
> B?
>    Thank you!
>    Inifok
>

--00c09f88cee57885fe04718724a6--

From common-user-return-16896-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:44:11 2009
Return-Path: <common-user-return-16896-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 65284 invoked from network); 19 Aug 2009 23:44:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:44:09 -0000
Received: (qmail 39050 invoked by uid 500); 19 Aug 2009 23:44:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 38935 invoked by uid 500); 19 Aug 2009 23:44:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 38913 invoked by uid 99); 19 Aug 2009 23:44:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:44:23 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:44:13 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1477265qwh.35
        for <multiple recipients>; Wed, 19 Aug 2009 16:43:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.78.22 with SMTP id i22mr6031341qak.280.1250725431310; Wed, 
	19 Aug 2009 16:43:51 -0700 (PDT)
In-Reply-To: <1072637276A0534CB8DE6BA57D95D39E0EF06E40@ASHBMBX02.resource.ds.bah.com>
References: <1072637276A0534CB8DE6BA57D95D39E0EF06E40@ASHBMBX02.resource.ds.bah.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 19 Aug 2009 16:43:31 -0700
Message-ID: <d6d7c4410908191643v6fd22f06j407cddcceaed4c6f@mail.gmail.com>
Subject: Re: Hadoop for Independant Tasks not using Map/Reduce?
To: common-user@hadoop.apache.org
Cc: "core-user@hadoop.apache.org" <core-user@hadoop.apache.org>
Content-Type: multipart/alternative; boundary=00c09f9c981e0b79f004718735dc
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09f9c981e0b79f004718735dc
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hadoop Streaming still expects to be doing "MapReduce". But you can hack
that definition, e.g., by emitting no output data and disabling reducing.

The number of map tasks to run will be controlled by the number of
"InputSplits" -- divisions of some arbitrary piece of input -- that a job
contains. By default, InputSplits are created based on the number of files
used. This is controlled by the InputFormat you select. You might want to
look at NLineInputFormat. This lets you write out a file where each line of
the file is a separate split. So you write a file to HDFS with a line (maybe
containing some arguments) for each instance of your program you want to
run. When you launch your job, point it at this input, and it'll launch the
desired number of copies of your program on a bunch of randomly selected
nodes from your cluster.

I don't know of any specific examples of this in use to point you to, but
you can certainly make a start of this.

- Aaron

On Wed, Aug 19, 2009 at 7:05 AM, Poole, Samuel [USA]
<poole_samuel@bah.com>wrote:

> I am new to Hadoop (I have not yet installed/configured), and I want to
> make sure that I have the correct tool for the job.  I do not "currently"
> have a need for the Map/Reduce functionality, but I am interested in using
> Hadoop for task orchestration, task monitoring, etc. over numerous nodes in
> a computing cluster.  Our primary programs (written in C++ and launched via
> shell scripts) each run independantly on a single node, but are deployed to
> different nodes for load balancing.  I want to task/initiate these processes
> on different nodes through a Java program located on a central server.  I
> was hoping to use Hadoop as a foundation for this.
>
> I read the following in the FAQ section:
>
> "How do I use Hadoop Streaming to run an arbitrary set of
> (semi-)independent tasks?
>
> Often you do not need the full power of Map Reduce, but only need to run
> multiple instances of the same program - either on different parts of the
> data, or on the same data, but with different parameters. You can use Hadoop
> Streaming to do this. "
>
> So, two questions I guess.
>
> 1.  Can I use Hadoop for this purpose without using Map/Reduce
> functionality?
>
> 2.  Are there any examples available on how to implement this sort of
> configuration?
>
> Any help would be greatly appreciated.
>
> Sam
>
>
>
>
>
>
>

--00c09f9c981e0b79f004718735dc--

From common-user-return-16897-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:44:11 2009
Return-Path: <common-user-return-16897-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 65272 invoked from network); 19 Aug 2009 23:44:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:44:09 -0000
Received: (qmail 39066 invoked by uid 500); 19 Aug 2009 23:44:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 38937 invoked by uid 500); 19 Aug 2009 23:44:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 38919 invoked by uid 500); 19 Aug 2009 23:44:23 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 38913 invoked by uid 99); 19 Aug 2009 23:44:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:44:23 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:44:13 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1477265qwh.35
        for <multiple recipients>; Wed, 19 Aug 2009 16:43:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.78.22 with SMTP id i22mr6031341qak.280.1250725431310; Wed, 
	19 Aug 2009 16:43:51 -0700 (PDT)
In-Reply-To: <1072637276A0534CB8DE6BA57D95D39E0EF06E40@ASHBMBX02.resource.ds.bah.com>
References: <1072637276A0534CB8DE6BA57D95D39E0EF06E40@ASHBMBX02.resource.ds.bah.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 19 Aug 2009 16:43:31 -0700
Message-ID: <d6d7c4410908191643v6fd22f06j407cddcceaed4c6f@mail.gmail.com>
Subject: Re: Hadoop for Independant Tasks not using Map/Reduce?
To: common-user@hadoop.apache.org
Cc: "core-user@hadoop.apache.org" <core-user@hadoop.apache.org>
Content-Type: multipart/alternative; boundary=00c09f9c981e0b79f004718735dc
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09f9c981e0b79f004718735dc
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hadoop Streaming still expects to be doing "MapReduce". But you can hack
that definition, e.g., by emitting no output data and disabling reducing.

The number of map tasks to run will be controlled by the number of
"InputSplits" -- divisions of some arbitrary piece of input -- that a job
contains. By default, InputSplits are created based on the number of files
used. This is controlled by the InputFormat you select. You might want to
look at NLineInputFormat. This lets you write out a file where each line of
the file is a separate split. So you write a file to HDFS with a line (maybe
containing some arguments) for each instance of your program you want to
run. When you launch your job, point it at this input, and it'll launch the
desired number of copies of your program on a bunch of randomly selected
nodes from your cluster.

I don't know of any specific examples of this in use to point you to, but
you can certainly make a start of this.

- Aaron

On Wed, Aug 19, 2009 at 7:05 AM, Poole, Samuel [USA]
<poole_samuel@bah.com>wrote:

> I am new to Hadoop (I have not yet installed/configured), and I want to
> make sure that I have the correct tool for the job.  I do not "currently"
> have a need for the Map/Reduce functionality, but I am interested in using
> Hadoop for task orchestration, task monitoring, etc. over numerous nodes in
> a computing cluster.  Our primary programs (written in C++ and launched via
> shell scripts) each run independantly on a single node, but are deployed to
> different nodes for load balancing.  I want to task/initiate these processes
> on different nodes through a Java program located on a central server.  I
> was hoping to use Hadoop as a foundation for this.
>
> I read the following in the FAQ section:
>
> "How do I use Hadoop Streaming to run an arbitrary set of
> (semi-)independent tasks?
>
> Often you do not need the full power of Map Reduce, but only need to run
> multiple instances of the same program - either on different parts of the
> data, or on the same data, but with different parameters. You can use Hadoop
> Streaming to do this. "
>
> So, two questions I guess.
>
> 1.  Can I use Hadoop for this purpose without using Map/Reduce
> functionality?
>
> 2.  Are there any examples available on how to implement this sort of
> configuration?
>
> Any help would be greatly appreciated.
>
> Sam
>
>
>
>
>
>
>

--00c09f9c981e0b79f004718735dc--

From common-user-return-16898-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:46:02 2009
Return-Path: <common-user-return-16898-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 65639 invoked from network); 19 Aug 2009 23:46:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:46:02 -0000
Received: (qmail 45906 invoked by uid 500); 19 Aug 2009 23:46:19 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 45811 invoked by uid 500); 19 Aug 2009 23:46:19 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 45801 invoked by uid 99); 19 Aug 2009 23:46:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:46:19 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:46:11 +0000
Received: by qyk26 with SMTP id 26so3634961qyk.5
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 16:45:50 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.5.213 with SMTP id 21mr7048773qaw.272.1250725550320; Wed, 
	19 Aug 2009 16:45:50 -0700 (PDT)
In-Reply-To: <641565.57813.qm@web110113.mail.gq1.yahoo.com>
References: <4238036a0908140711v16937bc9v7bec67aa857d734e@mail.gmail.com> 
	<99484d560908171000n5a97b51ayc37fe762e5bc0089@mail.gmail.com> 
	<4A8991E5.8000102@Gmail.com> <000301ca1f5f$d5adece0$8109c6a0$@edu> 
	<4A899499.4080902@yahoo-inc.com> <4A899803.9090108@gmail.com> 
	<4A89BEAC.9070306@Gmail.com> <77d4e5730908171358y19c91811kbad90fbd97e6e775@mail.gmail.com> 
	<428663.76474.qm@web110105.mail.gq1.yahoo.com> <641565.57813.qm@web110113.mail.gq1.yahoo.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 19 Aug 2009 16:45:30 -0700
Message-ID: <d6d7c4410908191645i2d734a46l1fce899ce56f9169@mail.gmail.com>
Subject: Re: Hadoop - flush() files
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0014850442d22373950471873c71
X-Virus-Checked: Checked by ClamAV on apache.org

--0014850442d22373950471873c71
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

sync doesn't work. See http://issues.apache.org/jira/browse/HDFS-200
- Aaron


On Tue, Aug 18, 2009 at 8:33 AM, Arvind Sharma <arvind321@yahoo.com> wrote:

> Just checking again :-)
>
> I have a setup where I am using Hadoop0-19.2 and the data files are kept
> open for a long time. I want them to be sync'd to the HDFS now and then, to
> avoid any data loss.
>
> In one of the last HUG, somebody mentioned  FSDataOutputStream.sync()
> method. But there were some known issues with that.
>
> Has anyone experienced any problem while using the sync() method ?
>
> Arvind
>
>
>
>
> ________________________________
>
>
> Hi,
>
> I was wondering if anyone here have stared using (or has been using) the
> newer Hadoop versions (0-20.1 ??? ) - which provides API for flushing out
> any open files on the HDFS ?
>
> Are there any known issues I should be aware of ?
>
> Thanks!
> Arvind
>
>
>
>

--0014850442d22373950471873c71--

From common-user-return-16899-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 19 23:47:22 2009
Return-Path: <common-user-return-16899-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 65900 invoked from network); 19 Aug 2009 23:47:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 19 Aug 2009 23:47:21 -0000
Received: (qmail 48215 invoked by uid 500); 19 Aug 2009 23:47:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 48117 invoked by uid 500); 19 Aug 2009 23:47:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 48107 invoked by uid 99); 19 Aug 2009 23:47:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:47:38 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [74.125.92.26] (HELO qw-out-2122.google.com) (74.125.92.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 19 Aug 2009 23:47:29 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1477841qwh.35
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 16:47:08 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.109.137 with SMTP id j9mr7069114qap.270.1250725628107; 
	Wed, 19 Aug 2009 16:47:08 -0700 (PDT)
In-Reply-To: <c9f8312d0908182231n64183a6fh245306384aaa873e@mail.gmail.com>
References: <c9f8312d0908182231n64183a6fh245306384aaa873e@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Wed, 19 Aug 2009 16:46:48 -0700
Message-ID: <d6d7c4410908191646u3824a167naf4f38a6d976835b@mail.gmail.com>
Subject: Re: RuntimeException: Not a host:port pair: local error when running 
	bin/start-mapred.sh
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00c09f9b060fc65c44047187400e
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09f9b060fc65c44047187400e
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

You need to put this in mapred-site.xml too, I think.
- Aaron

On Tue, Aug 18, 2009 at 10:31 PM, Daniel someone <outbackdan@gmail.com>wrote:

> Hi everybody,
>
> I am after some help with the following error that I am getting when I try
> to start the start-mapred.sh. To me looked like it was getting "local"
> passed as the hostname:port pair but I have double checked my settings in
> "core-site.xml" and they look correct to me, I have tried changing the
> values of mapred.job.tracker to FQDN and IP but this had not changed the
> behaviour.
> I am running:
> hadoop 0.20.0
> Java 1.6.0._16
> solaris 9
>
> Any help appreciated
> Regards
> Dan
>
> Error seen in logs:
>
> 2009-08-18 18:34:07,102 INFO org.apache.hadoop.mapred.JobTracker:
> STARTUP_MSG:
> /************************************************************
> STARTUP_MSG: Starting JobTracker
> STARTUP_MSG:   host = xxxxxx/xxxxxx
> STARTUP_MSG:   args = []
> STARTUP_MSG:   version = 0.20.0
> STARTUP_MSG:   build =
> https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.20 -r
> 763504;
> compiled by 'ndale
> y' on Thu Apr  9 05:18:40 UTC 2009
> ************************************************************/
> 2009-08-18 18:34:08,622 FATAL org.apache.hadoop.mapred.JobTracker:
> java.lang.RuntimeException: Not a host:port pair: l
> ocal
>        at
> org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:136)
>        at
> org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:123)
>        at
> org.apache.hadoop.mapred.JobTracker.getAddress(JobTracker.java:1756)
>        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1521)
>        at
> org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:174)
>        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:3528)
>
> 2009-08-18 18:34:08,627 INFO org.apache.hadoop.mapred.JobTracker:
> SHUTDOWN_MSG:
> /************************************************************
>

--00c09f9b060fc65c44047187400e--

From common-user-return-16900-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 01:55:31 2009
Return-Path: <common-user-return-16900-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 8475 invoked from network); 20 Aug 2009 01:55:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 01:55:31 -0000
Received: (qmail 12541 invoked by uid 500); 20 Aug 2009 01:55:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 12464 invoked by uid 500); 20 Aug 2009 01:55:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 12454 invoked by uid 99); 20 Aug 2009 01:55:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 01:55:47 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of roman.wsmo@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 01:55:38 +0000
Received: by fxm25 with SMTP id 25so3966558fxm.29
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 18:55:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=F/Vp8TEyfEIff44wRcBF5oZgM9cMAbfI4IGByMmC4iI=;
        b=ZqAgb3SAk0gYJ1b1IWiKT6axQ9v2tHc68fAhZB3TpxMa+knbhDZKs25ATiDF7KxFkE
         qQf1Zt9ceoAVxXcx4wM6BrNHOd4B/Bi+NvOIuKnowY03e+IlxOLxv3oeBdOS4VJVXLD/
         C4jDi7Jx6ZFVmiatQWYAQ6+5k27A92Qx7tVEs=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=qUhk3lw8yvFFBjhs4Q+oH9p86ZDa6SFueF6eHtJbUnaUIdP3fXayeJ8FyUHqBVjNbV
         2gxuGqIIBvxeUjQDJd4bN9m/WnC5+jS8J4xb0OEHv2N6Gtn5C8P6exelTa+6v/bpk7lA
         YRm0OkDHJ/Kb/cgqosTf5sqXwyOeoaDOs0jgI=
MIME-Version: 1.0
Received: by 10.223.57.66 with SMTP id b2mr88077fah.33.1250733318113; Wed, 19 
	Aug 2009 18:55:18 -0700 (PDT)
Date: Thu, 20 Aug 2009 02:55:14 +0100
Message-ID: <597eea000908191855v579b9c4r8baeb638630cfb27@mail.gmail.com>
Subject: File Chunk to Map Thread Association
From: roman kolcun <roman.wsmo@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001517473434228bbd0471890b9d
X-Virus-Checked: Checked by ClamAV on apache.org

--001517473434228bbd0471890b9d
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello everyone,
could anyone please tell me in which class and which method does Hadoop
download the file chunk from HDFS and associate it with the thread that
executes the Map function on given chunk and process it?
I would like to extend the Hadoop so one "Task" may have more chunks
associated and one Map thread will process these two (or more chunks)
sequentially as if it was just a single file.

Thank you in advance.

Your Sincerely,
Roman

--001517473434228bbd0471890b9d--

From common-user-return-16901-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 03:35:46 2009
Return-Path: <common-user-return-16901-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 39040 invoked from network); 20 Aug 2009 03:35:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 03:35:46 -0000
Received: (qmail 65402 invoked by uid 500); 20 Aug 2009 03:36:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 65150 invoked by uid 500); 20 Aug 2009 03:36:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 65124 invoked by uid 99); 20 Aug 2009 03:35:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 03:35:59 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.210.185 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 03:35:47 +0000
Received: by yxe15 with SMTP id 15so6511732yxe.5
        for <multiple recipients>; Wed, 19 Aug 2009 20:35:24 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.101.107.2 with SMTP id j2mr8070404anm.135.1250739324103; Wed, 
	19 Aug 2009 20:35:24 -0700 (PDT)
In-Reply-To: <C6B1D92B.11978%rphulari@yahoo-inc.com>
References: <77f4f8890908191448q67970d40sabb0e54ec55ad3c8@mail.gmail.com>
	 <C6B1D92B.11978%rphulari@yahoo-inc.com>
Date: Thu, 20 Aug 2009 06:35:24 +0300
Message-ID: <77f4f8890908192035j7d1f7943kfd37e6bc079950e7@mail.gmail.com>
Subject: Re: Location of the source code for the fair scheduler
From: Mithila Nagendra <mnagendr@asu.edu>
To: Ravi Phulari <rphulari@yahoo-inc.com>
Cc: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>, 
	"core-user@hadoop.apache.org" <core-user@hadoop.apache.org>, 
	"core-user-subscribe@hadoop.apache.org" <core-user-subscribe@hadoop.apache.org>
Content-Type: multipart/alternative; boundary=001636ed75dd1eac9304718a71b3
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed75dd1eac9304718a71b3
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks! But How do I know which version to work with?
Mithila


On Thu, Aug 20, 2009 at 2:30 AM, Ravi Phulari <rphulari@yahoo-inc.com>wrote:

>  Currently Fairscheduler source is in
>              hadoop-mapreduce/src/contrib/fairscheduler/
>
> Download mapreduce source from.
> http://hadoop.apache.org/mapreduce/
>
> -
> Ravi
>
>
> On 8/19/09 2:48 PM, "Mithila Nagendra" <mnagendr@asu.edu> wrote:
>
> Hello
>
> I was wondering how I could locate the source code files for the fair
> scheduler.
>
> Thanks
> Mithila
>
>
>
>

--001636ed75dd1eac9304718a71b3--

From common-user-return-16902-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 03:35:46 2009
Return-Path: <common-user-return-16902-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 39044 invoked from network); 20 Aug 2009 03:35:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 03:35:46 -0000
Received: (qmail 65401 invoked by uid 500); 20 Aug 2009 03:36:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 65152 invoked by uid 500); 20 Aug 2009 03:36:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 65131 invoked by uid 500); 20 Aug 2009 03:35:59 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 65124 invoked by uid 99); 20 Aug 2009 03:35:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 03:35:59 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.210.185 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 03:35:47 +0000
Received: by yxe15 with SMTP id 15so6511732yxe.5
        for <multiple recipients>; Wed, 19 Aug 2009 20:35:24 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.101.107.2 with SMTP id j2mr8070404anm.135.1250739324103; Wed, 
	19 Aug 2009 20:35:24 -0700 (PDT)
In-Reply-To: <C6B1D92B.11978%rphulari@yahoo-inc.com>
References: <77f4f8890908191448q67970d40sabb0e54ec55ad3c8@mail.gmail.com>
	 <C6B1D92B.11978%rphulari@yahoo-inc.com>
Date: Thu, 20 Aug 2009 06:35:24 +0300
Message-ID: <77f4f8890908192035j7d1f7943kfd37e6bc079950e7@mail.gmail.com>
Subject: Re: Location of the source code for the fair scheduler
From: Mithila Nagendra <mnagendr@asu.edu>
To: Ravi Phulari <rphulari@yahoo-inc.com>
Cc: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>, 
	"core-user@hadoop.apache.org" <core-user@hadoop.apache.org>, 
	"core-user-subscribe@hadoop.apache.org" <core-user-subscribe@hadoop.apache.org>
Content-Type: multipart/alternative; boundary=001636ed75dd1eac9304718a71b3
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed75dd1eac9304718a71b3
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks! But How do I know which version to work with?
Mithila


On Thu, Aug 20, 2009 at 2:30 AM, Ravi Phulari <rphulari@yahoo-inc.com>wrote:

>  Currently Fairscheduler source is in
>              hadoop-mapreduce/src/contrib/fairscheduler/
>
> Download mapreduce source from.
> http://hadoop.apache.org/mapreduce/
>
> -
> Ravi
>
>
> On 8/19/09 2:48 PM, "Mithila Nagendra" <mnagendr@asu.edu> wrote:
>
> Hello
>
> I was wondering how I could locate the source code files for the fair
> scheduler.
>
> Thanks
> Mithila
>
>
>
>

--001636ed75dd1eac9304718a71b3--

From common-user-return-16903-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 03:40:01 2009
Return-Path: <common-user-return-16903-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 39684 invoked from network); 20 Aug 2009 03:39:57 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 03:39:57 -0000
Received: (qmail 73136 invoked by uid 500); 20 Aug 2009 03:40:15 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 72642 invoked by uid 500); 20 Aug 2009 03:40:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 72632 invoked by uid 99); 20 Aug 2009 03:40:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 03:40:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 03:40:03 +0000
Received: by yxe15 with SMTP id 15so6513878yxe.5
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 20:39:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=4ks6Ll320a8WQC4bT4Bef9FkKrQ9siRnYU/t2uZEj/8=;
        b=QXGZ/t2+14CxQWc+R+f4/9Brq4OsF0tiMcfA5NLhvrsxv+trPXGQSDJqx6W/Peo1eM
         X4ccmXEUA7xuXtxp1kw2I5eJQsJAuJqadMgk/szn443w9vX1d9/ejCWEc4133Qfpq/Ga
         fxAIma66Ui3yGKF6XI9kVW6mEEJUmp5X0BKjE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=rTmBCN8uB6s6a3y+pWZu1xB0JHiTV9v0m5mltfRijf6y4xdXd5sq9CAqvGPMN6tQ6+
         e96vDS742cpOdl+s7eOFVjb4U1b1xw972YSPNmyptGQXQ+K20HIFQ538fffy/PlL3kGc
         Eo/3fVPaRPAoqzvPxxoJ6fFGNKh2IhWtlT5rU=
MIME-Version: 1.0
Received: by 10.100.236.21 with SMTP id j21mr8087663anh.75.1250739580410; Wed, 
	19 Aug 2009 20:39:40 -0700 (PDT)
In-Reply-To: <d6d7c4410908191638g6c9452f7h104cad20ba604f7e@mail.gmail.com>
References: <3b1311780908190721g3814f4dft9e00e9edce1eb86b@mail.gmail.com>
	 <d6d7c4410908191638g6c9452f7h104cad20ba604f7e@mail.gmail.com>
Date: Thu, 20 Aug 2009 11:39:40 +0800
Message-ID: <3b1311780908192039p441bb4eciaf877e67dca6786f@mail.gmail.com>
Subject: Re: How does hadoop deal with hadoop-site.xml?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636b2b5ea659a2104718a8030
X-Virus-Checked: Checked by ClamAV on apache.org

--001636b2b5ea659a2104718a8030
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

    Thank you, Aaron. I've benefited a lot. "per-node" means some settings
associated with the node. e.g., "fs.default.name", "mapred.job.tracker",
etc. "per-job" means some settings associated with the jobs which are
submited from the node. e.g., "mapred.reduce.tasks". That means, if I set
"per-job" properties on JobTracker, it will doesn't work. Is my
understanding right?
    In addition, when I add some new properties, e.g.,
"mapred.inifok.setting" on JobTracker, I can find it in every job.xml from
WebUI. I think all jobs will use the new properties. Is it right?
    Thanks again.
    Inifok

2009/8/20 Aaron Kimball <aaron@cloudera.com>

> Hi Inifok,
>
> This is a confusing aspect of Hadoop, I'm afraid.
>
> Settings are divided into two categories: "per-job" and "per-node."
> Unfortunately, which are which, isn't documented.
>
> Some settings are applied to the node that is being used. So for example,
> if
> you set fs.default.name on a node to be "hdfs://some.namenode:8020/", then
> any FS connections you make from that node will go to some.namenode. If a
> different machine in your cluster has fs.default.name set to
> hdfs://other.namenode, then that machine will connect to a different
> namenode.
>
> Another example of a per-machine setting is
> mapred.tasktracker.map.tasks.maximum; this tells a tasktracker the maximum
> number of tasks it should run in parallel. Each tasktracker is free to
> configure this value differently. e.g., if you have some quad-core and some
> eight-core machines. dfs.data.dir tells a datanode where its data
> directories should be kept. Naturally, this can vary machine-to-machine.
>
> Other settings are applied to a job as a whole. These settings are
> configured when you submit the job. So if you write
> conf.set("mapred.reduce.parallel.copies", 20) in your code, this will be
> the
> setting for the job. Settings that you don't explicitly put in your code,
> are drawn from the hadoop-site.xml file on the machine where the job is
> submitted from.
>
> In general, I strongly recommend you save yourself some pain by keeping
> your
> configuration files as identical as possible :)
> Good luck,
> - Aaron
>
>
> On Wed, Aug 19, 2009 at 7:21 AM, yang song <hadoop.inifok@gmail.com>
> wrote:
>
> > Hello, everybody
> >    I feel puzzled about setting properties in hadoop-site.xml.
> >    Suppose I submit the job from machine A, and JobTracker runs on
> machine
> > B. So there are two hadoop-site.xml files. Now, I increase
> > "mapred.reduce.parallel.copies"(e.g. 10) on machine B since I want to
> make
> > copy phrase faster. However, "mapred.reduce.parallel.copies" from WebUI
> is
> > still 5. When I increase it on machine A, it changes. So, I feel very
> > puzzled. Why does it doesn't work when I change it on B? What's more,
> when
> > I
> > add some properties on B, the certain properties will be found on WebUI.
> > And
> > why I can't change properties through machine B? Does some certain
> > properties must be changed through A and some others must be changed
> > through
> > B?
> >    Thank you!
> >    Inifok
> >
>

--001636b2b5ea659a2104718a8030--

From common-user-return-16904-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 03:51:07 2009
Return-Path: <common-user-return-16904-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 42425 invoked from network); 20 Aug 2009 03:51:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 03:51:06 -0000
Received: (qmail 77929 invoked by uid 500); 20 Aug 2009 03:51:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 77757 invoked by uid 500); 20 Aug 2009 03:51:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 77734 invoked by uid 99); 20 Aug 2009 03:51:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 03:51:22 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 03:51:11 +0000
Received: from [10.0.0.39] ([12.185.110.66])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7K3oILG029000
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT);
	Wed, 19 Aug 2009 22:50:47 -0500
Cc: core-user@hadoop.apache.org
Message-Id: <480D7E03-6E9F-4917-BE31-A82D2A42D9C8@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <2986c2f30908191632u74dcad9dt9073fc84eb7d849e@mail.gmail.com>
Content-Type: multipart/signed; boundary=Apple-Mail-120--297376096; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: syslog-ng and hadoop
Date: Wed, 19 Aug 2009 22:50:47 -0500
References: <2986c2f30908191632u74dcad9dt9073fc84eb7d849e@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-120--297376096
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Hey Mike,

Yup.  We find the stock log4j needs two things:

1) Set the rootLogger manually.  The way 0.19.x has the root logger  
set up breaks when adding new appenders.  I.e., do:

log4j.rootLogger=INFO,SYSLOG,console,DRFA,EventCounter

2) Add the headers; otherwise log4j is not compatible with syslog:

log4j.appender.SYSLOG=org.apache.log4j.net.SyslogAppender
log4j.appender.SYSLOG.facility=local0
log4j.appender.SYSLOG.layout=org.apache.log4j.PatternLayout
log4j.appender.SYSLOG.layout.ConversionPattern=%p %c{2}: %m%n
log4j.appender.SYSLOG.SyslogHost=red
log4j.appender.SYSLOG.threshold=ERROR
log4j.appender.SYSLOG.Header=true
log4j.appender.SYSLOG.FacilityPrinting=true

Brian

On Aug 19, 2009, at 6:32 PM, Mike Anderson wrote:

> Has anybody had any luck setting up the log4j.properties file to  
> send logs
> to a syslog-ng server?
> My log4j.properties excerpt:
> log4j.appender.SYSLOG=org.apache.log4j.net.SyslogAppender
> log4j.appender.SYSLOG.syslogHost=10.0.20.164
> log4j.appender.SYSLOG.layout=org.apache.log4j.PatternLayout
> log4j.appender.SYSLOG.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
> log4j.appender.SYSLOG.Facility=HADOOP
>
> and my syslog-ng.conf file running on 10.0.20.164
>
> source s_hadoop {
>        # message generated by Syslog-NG
>        internal();
>        # standard Linux log source (this is the default place for the
> syslog()
>        # function to send logs to)
>        unix-stream("/dev/log");
>        udp();
> };
> destination df_hadoop { file("/var/log/hadoop/hadoop.log");};
> filter f_hadoop {facility(hadoop);};
> log {
> source(s_hadoop);
> filter(f_hadoop);
> destination(df_hadoop);
> };
>
>
> Thanks in advance,
> Mike


--Apple-Mail-120--297376096
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-120--297376096--

From common-user-return-16905-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 03:51:09 2009
Return-Path: <common-user-return-16905-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 42487 invoked from network); 20 Aug 2009 03:51:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 03:51:09 -0000
Received: (qmail 78227 invoked by uid 500); 20 Aug 2009 03:51:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 77759 invoked by uid 500); 20 Aug 2009 03:51:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 77739 invoked by uid 500); 20 Aug 2009 03:51:22 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 77734 invoked by uid 99); 20 Aug 2009 03:51:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 03:51:22 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 03:51:11 +0000
Received: from [10.0.0.39] ([12.185.110.66])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7K3oILG029000
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT);
	Wed, 19 Aug 2009 22:50:47 -0500
Cc: core-user@hadoop.apache.org
Message-Id: <480D7E03-6E9F-4917-BE31-A82D2A42D9C8@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <2986c2f30908191632u74dcad9dt9073fc84eb7d849e@mail.gmail.com>
Content-Type: multipart/signed; boundary=Apple-Mail-120--297376096; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: syslog-ng and hadoop
Date: Wed, 19 Aug 2009 22:50:47 -0500
References: <2986c2f30908191632u74dcad9dt9073fc84eb7d849e@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-120--297376096
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Hey Mike,

Yup.  We find the stock log4j needs two things:

1) Set the rootLogger manually.  The way 0.19.x has the root logger  
set up breaks when adding new appenders.  I.e., do:

log4j.rootLogger=INFO,SYSLOG,console,DRFA,EventCounter

2) Add the headers; otherwise log4j is not compatible with syslog:

log4j.appender.SYSLOG=org.apache.log4j.net.SyslogAppender
log4j.appender.SYSLOG.facility=local0
log4j.appender.SYSLOG.layout=org.apache.log4j.PatternLayout
log4j.appender.SYSLOG.layout.ConversionPattern=%p %c{2}: %m%n
log4j.appender.SYSLOG.SyslogHost=red
log4j.appender.SYSLOG.threshold=ERROR
log4j.appender.SYSLOG.Header=true
log4j.appender.SYSLOG.FacilityPrinting=true

Brian

On Aug 19, 2009, at 6:32 PM, Mike Anderson wrote:

> Has anybody had any luck setting up the log4j.properties file to  
> send logs
> to a syslog-ng server?
> My log4j.properties excerpt:
> log4j.appender.SYSLOG=org.apache.log4j.net.SyslogAppender
> log4j.appender.SYSLOG.syslogHost=10.0.20.164
> log4j.appender.SYSLOG.layout=org.apache.log4j.PatternLayout
> log4j.appender.SYSLOG.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
> log4j.appender.SYSLOG.Facility=HADOOP
>
> and my syslog-ng.conf file running on 10.0.20.164
>
> source s_hadoop {
>        # message generated by Syslog-NG
>        internal();
>        # standard Linux log source (this is the default place for the
> syslog()
>        # function to send logs to)
>        unix-stream("/dev/log");
>        udp();
> };
> destination df_hadoop { file("/var/log/hadoop/hadoop.log");};
> filter f_hadoop {facility(hadoop);};
> log {
> source(s_hadoop);
> filter(f_hadoop);
> destination(df_hadoop);
> };
>
>
> Thanks in advance,
> Mike


--Apple-Mail-120--297376096
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-120--297376096--

From common-user-return-16906-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 05:40:05 2009
Return-Path: <common-user-return-16906-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 64798 invoked from network); 20 Aug 2009 05:40:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 05:40:04 -0000
Received: (qmail 53681 invoked by uid 500); 20 Aug 2009 05:40:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 53596 invoked by uid 500); 20 Aug 2009 05:40:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 53586 invoked by uid 99); 20 Aug 2009 05:40:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 05:40:20 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 05:40:12 +0000
Received: by ywh36 with SMTP id 36so7143578ywh.31
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 22:39:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=GzqmRV8smRhoeAMev0RLbh6g6eTCbdLbuYo5wN+pkrA=;
        b=gPpvA5YTHJ2Z54dYgdNdCOscYfRQJEnHN6/balcJvEq/THwvHhwmi9VOfsjHYZQ7ON
         gD/C9e+qxQCzyVK9D9oeEUS4PHLUGTu3gz5AcTbWBceAz5aQndX9xBhEle75e0+S/fUh
         ecXlrHKWcjBLYMXJ8XUa8B2F1yKxTvoCwQKzA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=nvXQbTDVjjew9jR2fqQZ/3wVyPP0iSFvF5jrIcH+f1BIpemMOrAOEFgHwzy7NyaQt6
         PiW4WCiRyOsG5q5whiygkGcu5ZXQi9m0RJkC1+TVNZMsdJ4OCowtEk2dAC++UIV0Pml8
         QJ3j6dDkzRh/CzfpHiDe4MQ0sIz6pAr2KIVE0=
MIME-Version: 1.0
Received: by 10.100.236.21 with SMTP id j21mr8167820anh.75.1250746791871; Wed, 
	19 Aug 2009 22:39:51 -0700 (PDT)
In-Reply-To: <c7d45fc70908191117g399ebb44l7f95e372c25449ee@mail.gmail.com>
References: <3b1311780908182223m6d75da2dxf33118c91496d08@mail.gmail.com>
	 <c7d45fc70908190044u77503a5dsed88dc9a37f10cf@mail.gmail.com>
	 <3b1311780908190519y20708a7epef6edac55e3e9981@mail.gmail.com>
	 <c7d45fc70908191117g399ebb44l7f95e372c25449ee@mail.gmail.com>
Date: Thu, 20 Aug 2009 13:39:51 +0800
Message-ID: <3b1311780908192239q7c07374awcb220e2d8514da8c@mail.gmail.com>
Subject: Re: How to deal with "too many fetch failures"?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636b2b5ea3bdc2304718c2e14
X-Virus-Checked: Checked by ClamAV on apache.org

--001636b2b5ea3bdc2304718c2e14
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

    Thank you Ted. Update current cluster is a huge work, we don't want to
do so. Could you tell me how 0.19.1 causes certain failures in detail?
    Thanks again.

2009/8/20 Ted Dunning <ted.dunning@gmail.com>

> I think I remember something about 19.1 in which certain failures would
> cause this.  Consider using an updated 19 or moving to 20 as well.
>
> On Wed, Aug 19, 2009 at 5:19 AM, yang song <hadoop.inifok@gmail.com>
> wrote:
>
> > I'm sorry, the version is 0.19.1
> >
> >
>

--001636b2b5ea3bdc2304718c2e14--

From common-user-return-16907-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 05:49:37 2009
Return-Path: <common-user-return-16907-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 69346 invoked from network); 20 Aug 2009 05:49:36 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 05:49:36 -0000
Received: (qmail 60833 invoked by uid 500); 20 Aug 2009 05:49:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 60769 invoked by uid 500); 20 Aug 2009 05:49:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 60759 invoked by uid 99); 20 Aug 2009 05:49:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 05:49:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.216.190 as permitted sender)
Received: from [209.85.216.190] (HELO mail-px0-f190.google.com) (209.85.216.190)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 05:49:44 +0000
Received: by pxi28 with SMTP id 28so2996649pxi.2
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 22:49:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=kBLlNvbIzrwr9kswQZxOIYs+QcHUzywxRD6oCP4ZhZA=;
        b=Ao+2krf7XDTSwHVYeTDHUDMlk2nfEE8kBDumnH7raig0Q7ExAOqyNKEXESKWb9w7OX
         25GeOvA5N1ogzZwRLc0wjTyXBp0mavd+dU8yBwDe7p/5sz/QTggpKA/0J1xfcNSuIpwS
         chHArgRgHDiOlAUKiFWeO06LRB8HGn0BmF11Q=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=ulnaP0Ql+Pmm6kAjtBUIKUxsdw9mfVaWN2bmld1DPx0rgqqygY90ytWx/sW8sZPpOk
         BMr1w8NCrHI1dmKynXHe6TyiDWZ+6950IC1z1OOvvxIkk0YbJsFdHiJh0F4qttwgJn64
         +t94Zc/2CAWQR0rmQgnLcyl0ffoydIWAH1M74=
MIME-Version: 1.0
Received: by 10.142.7.3 with SMTP id 3mr1419798wfg.126.1250747363097; Wed, 19 
	Aug 2009 22:49:23 -0700 (PDT)
In-Reply-To: <597eea000908191855v579b9c4r8baeb638630cfb27@mail.gmail.com>
References: <597eea000908191855v579b9c4r8baeb638630cfb27@mail.gmail.com>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Thu, 20 Aug 2009 11:19:03 +0530
Message-ID: <e01b80590908192249s5302cd26m7984a32816c0d58c@mail.gmail.com>
Subject: Re: File Chunk to Map Thread Association
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00504502b08947fbaf04718c5026
X-Virus-Checked: Checked by ClamAV on apache.org

--00504502b08947fbaf04718c5026
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 20, 2009 at 7:25 AM, roman kolcun <roman.wsmo@gmail.com> wrote:

> Hello everyone,
> could anyone please tell me in which class and which method does Hadoop
> download the file chunk from HDFS and associate it with the thread that
> executes the Map function on given chunk and process it?
>

Hi Roman,

First of all the map() function is executed in a MapTask (a separate child
JVM is spawned by the TaskTracker). So it doesn't run inside a thread in the
TaskTracker process.


> I would like to extend the Hadoop so one "Task" may have more chunks
> associated and one Map thread will process these two (or more chunks)
> sequentially as if it was just a single file.
>

You don't really have to change anything inside Hadoop to increase the size
of InputSplits that MapTasks consume. Just modify 'mapred.min.split.size' if
you want the splits to be larger. You could also write your own custom
InputFormat class.

-- 
Harish Mallipeddi
http://blog.poundbang.in

--00504502b08947fbaf04718c5026--

From common-user-return-16908-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 06:26:30 2009
Return-Path: <common-user-return-16908-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 89375 invoked from network); 20 Aug 2009 06:26:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 06:26:30 -0000
Received: (qmail 87872 invoked by uid 500); 20 Aug 2009 06:26:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87792 invoked by uid 500); 20 Aug 2009 06:26:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87777 invoked by uid 99); 20 Aug 2009 06:26:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 06:26:46 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 06:26:36 +0000
Received: by ywh36 with SMTP id 36so7161749ywh.31
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 23:26:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=eOLwmEPQOChni53vWLbE2Tdipo5nCufrJSTy+V9782Y=;
        b=Z0qAX+vfaC9SKPC1PmOG/rr03GHl3aWYYEtu+mLTzZcYwt0FBo59BSUMYG7fPCy5dp
         bU2f5VuzK8/od6iAs2ExvtzVBe1MR435bTxptI3aMfsV1ZaPCOWaXOvk2ZvQTp4FU8H7
         ZIRHqp23GVjbmDI7MHsZYs2Fip/e6ZlsseBzk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=ecSa4pjqKRA8XhM5hzGxW4KDY4uplu5JZelqN42a6xfyoPxMNoN4m0cwVe34S+Hjn8
         uYsWko0bp5Thby6DZJvuUuABd0t/lMoHVc+icGH8JXZraADC34xK20iMIhd/Ng9nHrvm
         ulaa1+VUdWPV04+Ozl0rqhpamqIEUsHNmk1hE=
MIME-Version: 1.0
Received: by 10.150.173.39 with SMTP id v39mr11977006ybe.154.1250749575082; 
	Wed, 19 Aug 2009 23:26:15 -0700 (PDT)
In-Reply-To: <3b1311780908192239q7c07374awcb220e2d8514da8c@mail.gmail.com>
References: <3b1311780908182223m6d75da2dxf33118c91496d08@mail.gmail.com> 
	<c7d45fc70908190044u77503a5dsed88dc9a37f10cf@mail.gmail.com> 
	<3b1311780908190519y20708a7epef6edac55e3e9981@mail.gmail.com> 
	<c7d45fc70908191117g399ebb44l7f95e372c25449ee@mail.gmail.com> 
	<3b1311780908192239q7c07374awcb220e2d8514da8c@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Wed, 19 Aug 2009 23:25:55 -0700
Message-ID: <c7d45fc70908192325v230c3100t239ab0d8f3865488@mail.gmail.com>
Subject: Re: How to deal with "too many fetch failures"?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd5c6fe2032c004718cd484
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd5c6fe2032c004718cd484
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

I think that the problem that I am remembering was due to poor recovery from
this problem.  The underlying fault is likely due to poor connectivity
between your machines.  Test that all members of your cluster can access all
others on all ports used by hadoop.

See here for hints: http://markmail.org/message/lgafou6d434n2dvx

On Wed, Aug 19, 2009 at 10:39 PM, yang song <hadoop.inifok@gmail.com> wrote:

>    Thank you Ted. Update current cluster is a huge work, we don't want to
> do so. Could you tell me how 0.19.1 causes certain failures in detail?
>    Thanks again.
>
> 2009/8/20 Ted Dunning <ted.dunning@gmail.com>
>
> > I think I remember something about 19.1 in which certain failures would
> > cause this.  Consider using an updated 19 or moving to 20 as well.
> >
> > On Wed, Aug 19, 2009 at 5:19 AM, yang song <hadoop.inifok@gmail.com>
> > wrote:
> >
> > > I'm sorry, the version is 0.19.1
> > >
> > >
> >
>



-- 
Ted Dunning, CTO
DeepDyve

--000e0cd5c6fe2032c004718cd484--

From common-user-return-16909-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 06:52:07 2009
Return-Path: <common-user-return-16909-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 2821 invoked from network); 20 Aug 2009 06:52:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 06:52:07 -0000
Received: (qmail 15447 invoked by uid 500); 20 Aug 2009 06:52:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 15362 invoked by uid 500); 20 Aug 2009 06:52:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 6803 invoked by uid 99); 20 Aug 2009 06:45:02 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of thethethethethethe@gmail.com designates 209.85.223.176 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=hio4zOwXMRQYXGrDU7UzDxIBKSVvxSEuemMv39mvPJE=;
        b=kr9twHEnqekeUtqdrCvp01zs0KAabSTyJkp08JCmT9DuPqkLXwZ68Ca/kE9PAB4bub
         5TNeoDbzDoKvm7JFCLEy5KhEGXSfxwjgGT2KvYy7qEg4NEjlnsPSFeU6ZrdEhPj69Ivv
         xgakvmp0lxxh67ebx6ly/zOXy2qDmEfKKgtCs=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=dCmloBQdOHG0P0QOJDT3azRim2D4EfVKX4qie90we4sWVOmjzvRaiitf1Wq0zl1ZNi
         LenEf61Gy+8s9jgITZ2DsKOCMm3O/4y+Fw/dGKilyE/eYfK5dG7kWbyFSov/6IpFMjPx
         oC4G3OovcwJVnGKvpvfM8zrApXnPVDRiCIr+8=
MIME-Version: 1.0
Date: Thu, 20 Aug 2009 14:44:32 +0800
Message-ID: <824489110908192344g77e822f1rf64d4c05831cee75@mail.gmail.com>
Subject: Re: How to deal with "too many fetch failures"?
From: =?UTF-8?B?6LCt5Lic?= <thethethethethethe@gmail.com>
To: ted.dunning@gmail.com, common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000325574c1688921104718d1594
X-Virus-Checked: Checked by ClamAV on apache.org

--000325574c1688921104718d1594
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

More fewer reducers there are, More data each reducer will deal with, More
network transmission each reducer will attached to, and more probably one
reducer will fail.
SO INCREMENT your reducers, then try again.

> I think that the problem that I am remembering was due to poor recovery
from
> this problem.  The underlying fault is likely due to poor connectivity
> between your machines.  Test that all members of your cluster can access
all
> others on all ports used by hadoop.

> See here for hints: http://markmail.org/message/lgafou6d434n2dvx

> On Wed, Aug 19, 2009 at 10:39 PM, yang song <hadoop.inifok@gmail.com>
wrote:

>    Thank you Ted. Update current cluster is a huge work, we don't want to
> do so. Could you tell me how 0.19.1 causes certain failures in detail?
>    Thanks again.
>
> 2009/8/20 Ted Dunning <ted.dunning@gmail.com>
>
> > I think I remember something about 19.1 in which certain failures would
> > cause this.  Consider using an updated 19 or moving to 20 as well.
> >
> > On Wed, Aug 19, 2009 at 5:19 AM, yang song <hadoop.inifok@gmail.com>
> > wrote:
> >
> > > I'm sorry, the version is 0.19.1
> > >
> > >
> >
>



>>--
>>Ted Dunning, CTO
>>DeepDyve

--000325574c1688921104718d1594--

From common-user-return-16910-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 06:56:26 2009
Return-Path: <common-user-return-16910-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 6072 invoked from network); 20 Aug 2009 06:56:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 06:56:26 -0000
Received: (qmail 24129 invoked by uid 500); 20 Aug 2009 06:56:43 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 24057 invoked by uid 500); 20 Aug 2009 06:56:43 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 24047 invoked by uid 99); 20 Aug 2009 06:56:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 06:56:43 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of thethethethethethe@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 06:56:33 +0000
Received: by iwn6 with SMTP id 6so406837iwn.5
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 23:56:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=vX3/9CXNcODBwqH1ufPFKpoZS/TfvKsiio5zXUJ7cok=;
        b=mQwPnErjl9/1bRSRolDiDHeabWZ+/3Mk1YDEtK/UeslVAvBMDdiAfZnSKM7EqQYBEW
         DSOHKWdY/ox8gxtO98UQ5S2+9chvldb1YdtBDMG3rTPFTHBRSGis1wRA3TEbR28GbjOg
         bS6S4tUH/325XjW3pbfeil+llyoW658iNb6Ks=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=amDhwch6VeID6cd5tX6ex2xJ8E+eY7B0Q0VbTputui91zuqj83geaBzd1PfRlIolPQ
         A2r9JMiUAnaHaDw90qtrDIzb05i36+valmLmDZbuR42OwF/9qqJm80nyKjCY/PBvo6cC
         ZBqZHl48gm8x3o4yrGE/2kj+cGUlTHZHGXQic=
MIME-Version: 1.0
Received: by 10.231.31.13 with SMTP id w13mr4367147ibc.9.1250751372698; Wed, 
	19 Aug 2009 23:56:12 -0700 (PDT)
Date: Thu, 20 Aug 2009 14:56:12 +0800
Message-ID: <824489110908192356y6021d52w91f6256d8c5264f2@mail.gmail.com>
Subject: Re: How to deal with "too many fetch failures"?
From: =?UTF-8?B?6LCt5Lic?= <thethethethethethe@gmail.com>
To: ted.dunning@gmail.com, common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0022152d6d7d45a62004718d3fc2
X-Virus-Checked: Checked by ClamAV on apache.org

--0022152d6d7d45a62004718d3fc2
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Fewer reducers there are, More data each reducer will deal with, More
network transmission each reducer will be attached to, and more probably one
reducer will fail.
SO INCREMENT your reducers, then try again.

> I think that the problem that I am remembering was due to poor recovery
from
> this problem.  The underlying fault is likely due to poor connectivity
> between your machines.  Test that all members of your cluster can access
all
> others on all ports used by hadoop.

> See here for hints: http://markmail.org/message/lgafou6d434n2dvx

> On Wed, Aug 19, 2009 at 10:39 PM, yang song <hadoop.inifok@gmail.com>
wrote:

>    Thank you Ted. Update current cluster is a huge work, we don't want to
> do so. Could you tell me how 0.19.1 causes certain failures in detail?
>    Thanks again.
>
> 2009/8/20 Ted Dunning <ted.dunning@gmail.com>
>
> > I think I remember something about 19.1 in which certain failures would
> > cause this.  Consider using an updated 19 or moving to 20 as well.
> >
> > On Wed, Aug 19, 2009 at 5:19 AM, yang song <hadoop.inifok@gmail.com>
> > wrote:
> >
> > > I'm sorry, the version is 0.19.1
> > >
> > >
> >
>



>>--
>>Ted Dunning, CTO
>>DeepDyve

--0022152d6d7d45a62004718d3fc2--

From common-user-return-16911-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 06:59:23 2009
Return-Path: <common-user-return-16911-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7350 invoked from network); 20 Aug 2009 06:59:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 06:59:23 -0000
Received: (qmail 27906 invoked by uid 500); 20 Aug 2009 06:59:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 27829 invoked by uid 500); 20 Aug 2009 06:59:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 27819 invoked by uid 99); 20 Aug 2009 06:59:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 06:59:40 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 06:59:28 +0000
Received: by vws40 with SMTP id 40so4153209vws.2
        for <common-user@hadoop.apache.org>; Wed, 19 Aug 2009 23:59:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=/zxw8PhEdyMBu6STK9jQjovQ8xQWro6wXOoN/B7CFzY=;
        b=T1uis8oMPHqkNdJvNrpfFkcXhD0DGJd99DtzeSD16eYUGi+6tYa6nwoG9r4qDSLYg4
         3k/TLx9gg5Oe8sMNgaXoCrtgIXYmCzwxvNP334oHyLZ1kWtvGygBVHhjz51VoedeO34d
         6L6dWVfZ9ofJPeLxvadgHvrnkAv/vMlxgQdgc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=N5pYMGYvXgKMQ5B9yn6DSVFAgfZcSPt8K6AaUkLpvs24q4CFVHOY0fllgZH7b9hYEt
         ZFz4qJ6ZUdbzyq1q7lEAB4CgaLVNKAuKAPbsvW/2J26QHF7Ihlk2jufC67c/dcpGRQRr
         YpDYrUUu9Ba7Z9di1imZYGHndXvj+KCqghB7k=
MIME-Version: 1.0
Received: by 10.220.110.84 with SMTP id m20mr10304007vcp.37.1250751546973; 
	Wed, 19 Aug 2009 23:59:06 -0700 (PDT)
In-Reply-To: <c7d45fc70908192325v230c3100t239ab0d8f3865488@mail.gmail.com>
References: <3b1311780908182223m6d75da2dxf33118c91496d08@mail.gmail.com>
	 <c7d45fc70908190044u77503a5dsed88dc9a37f10cf@mail.gmail.com>
	 <3b1311780908190519y20708a7epef6edac55e3e9981@mail.gmail.com>
	 <c7d45fc70908191117g399ebb44l7f95e372c25449ee@mail.gmail.com>
	 <3b1311780908192239q7c07374awcb220e2d8514da8c@mail.gmail.com>
	 <c7d45fc70908192325v230c3100t239ab0d8f3865488@mail.gmail.com>
Date: Wed, 19 Aug 2009 23:59:06 -0700
Message-ID: <314098690908192359y27fe344ci62e715b10c0a5194@mail.gmail.com>
Subject: Re: How to deal with "too many fetch failures"?
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636832ad6a8deaf04718d498d
X-Virus-Checked: Checked by ClamAV on apache.org

--001636832ad6a8deaf04718d498d
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

The number 1 cause of this is something that causes a connection to get a
map output to fail. I have seen:
1) firewall
2) misconfigured ip addresses (ie: the task tracker attempting the fetch
received an incorrect ip address when it looked up the name of the
tasktracker with the map segment)
3) rare, the http server on the serving tasktracker is overloaded due to
insufficient threads or listen backlog, this can happen if the number of
fetches per reduce is large and the number of reduces or the number of maps
is very large

There are probably other cases, this recently happened to me when I had 6000
maps and 20 reducers on a 10 node cluster, which I believe was case 3 above.
Since I didn't actually need to reduce ( I got my summary data via counters
in the map phase) I never re-tuned the cluster.

On Wed, Aug 19, 2009 at 11:25 PM, Ted Dunning <ted.dunning@gmail.com> wrote:

> I think that the problem that I am remembering was due to poor recovery
> from
> this problem.  The underlying fault is likely due to poor connectivity
> between your machines.  Test that all members of your cluster can access
> all
> others on all ports used by hadoop.
>
> See here for hints: http://markmail.org/message/lgafou6d434n2dvx
>
> On Wed, Aug 19, 2009 at 10:39 PM, yang song <hadoop.inifok@gmail.com>
> wrote:
>
> >    Thank you Ted. Update current cluster is a huge work, we don't want to
> > do so. Could you tell me how 0.19.1 causes certain failures in detail?
> >    Thanks again.
> >
> > 2009/8/20 Ted Dunning <ted.dunning@gmail.com>
> >
> > > I think I remember something about 19.1 in which certain failures would
> > > cause this.  Consider using an updated 19 or moving to 20 as well.
> > >
> > > On Wed, Aug 19, 2009 at 5:19 AM, yang song <hadoop.inifok@gmail.com>
> > > wrote:
> > >
> > > > I'm sorry, the version is 0.19.1
> > > >
> > > >
> > >
> >
>
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>



-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--001636832ad6a8deaf04718d498d--

From common-user-return-16912-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 07:07:05 2009
Return-Path: <common-user-return-16912-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 10801 invoked from network); 20 Aug 2009 07:07:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 07:07:03 -0000
Received: (qmail 33834 invoked by uid 500); 20 Aug 2009 07:07:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 33777 invoked by uid 500); 20 Aug 2009 07:07:19 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 33767 invoked by uid 99); 20 Aug 2009 07:07:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 07:07:19 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 07:07:08 +0000
Received: by qyk26 with SMTP id 26so3771452qyk.5
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 00:06:47 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.51.231 with SMTP id e39mr7229681qag.337.1250752006117; 
	Thu, 20 Aug 2009 00:06:46 -0700 (PDT)
In-Reply-To: <3b1311780908192039p441bb4eciaf877e67dca6786f@mail.gmail.com>
References: <3b1311780908190721g3814f4dft9e00e9edce1eb86b@mail.gmail.com> 
	<d6d7c4410908191638g6c9452f7h104cad20ba604f7e@mail.gmail.com> 
	<3b1311780908192039p441bb4eciaf877e67dca6786f@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Thu, 20 Aug 2009 00:06:26 -0700
Message-ID: <d6d7c4410908200006k762e70aapc428c0ddf71778d@mail.gmail.com>
Subject: Re: How does hadoop deal with hadoop-site.xml?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00c09f99e04b06dc5904718d6508
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09f99e04b06dc5904718d6508
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Wed, Aug 19, 2009 at 8:39 PM, yang song <hadoop.inifok@gmail.com> wrote:

>    Thank you, Aaron. I've benefited a lot. "per-node" means some settings
> associated with the node. e.g., "fs.default.name", "mapred.job.tracker",
> etc. "per-job" means some settings associated with the jobs which are
> submited from the node. e.g., "mapred.reduce.tasks". That means, if I set
> "per-job" properties on JobTracker, it will doesn't work. Is my
> understanding right?


It will work if you submit your job (run "hadoop jar ....") from the
JobTracker node :) It won't if you submit your job from elsewhere.


>
>    In addition, when I add some new properties, e.g.,
> "mapred.inifok.setting" on JobTracker, I can find it in every job.xml from
> WebUI. I think all jobs will use the new properties. Is it right?


If you set a property programmatically when configuring your job, that will
be available in the JobConf on all machines for that job only. If you set a
property in your hadoop-site.xml on the submitting machine, then I think
that will also be available for the job on all nodes.

- Aaron


>
>    Thanks again.
>    Inifok
>
> 2009/8/20 Aaron Kimball <aaron@cloudera.com>
>
> > Hi Inifok,
> >
> > This is a confusing aspect of Hadoop, I'm afraid.
> >
> > Settings are divided into two categories: "per-job" and "per-node."
> > Unfortunately, which are which, isn't documented.
> >
> > Some settings are applied to the node that is being used. So for example,
> > if
> > you set fs.default.name on a node to be "hdfs://some.namenode:8020/",
> then
> > any FS connections you make from that node will go to some.namenode. If a
> > different machine in your cluster has fs.default.name set to
> > hdfs://other.namenode, then that machine will connect to a different
> > namenode.
> >
> > Another example of a per-machine setting is
> > mapred.tasktracker.map.tasks.maximum; this tells a tasktracker the
> maximum
> > number of tasks it should run in parallel. Each tasktracker is free to
> > configure this value differently. e.g., if you have some quad-core and
> some
> > eight-core machines. dfs.data.dir tells a datanode where its data
> > directories should be kept. Naturally, this can vary machine-to-machine.
> >
> > Other settings are applied to a job as a whole. These settings are
> > configured when you submit the job. So if you write
> > conf.set("mapred.reduce.parallel.copies", 20) in your code, this will be
> > the
> > setting for the job. Settings that you don't explicitly put in your code,
> > are drawn from the hadoop-site.xml file on the machine where the job is
> > submitted from.
> >
> > In general, I strongly recommend you save yourself some pain by keeping
> > your
> > configuration files as identical as possible :)
> > Good luck,
> > - Aaron
> >
> >
> > On Wed, Aug 19, 2009 at 7:21 AM, yang song <hadoop.inifok@gmail.com>
> > wrote:
> >
> > > Hello, everybody
> > >    I feel puzzled about setting properties in hadoop-site.xml.
> > >    Suppose I submit the job from machine A, and JobTracker runs on
> > machine
> > > B. So there are two hadoop-site.xml files. Now, I increase
> > > "mapred.reduce.parallel.copies"(e.g. 10) on machine B since I want to
> > make
> > > copy phrase faster. However, "mapred.reduce.parallel.copies" from WebUI
> > is
> > > still 5. When I increase it on machine A, it changes. So, I feel very
> > > puzzled. Why does it doesn't work when I change it on B? What's more,
> > when
> > > I
> > > add some properties on B, the certain properties will be found on
> WebUI.
> > > And
> > > why I can't change properties through machine B? Does some certain
> > > properties must be changed through A and some others must be changed
> > > through
> > > B?
> > >    Thank you!
> > >    Inifok
> > >
> >
>

--00c09f99e04b06dc5904718d6508--

From common-user-return-16913-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 07:09:04 2009
Return-Path: <common-user-return-16913-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11686 invoked from network); 20 Aug 2009 07:09:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 07:09:03 -0000
Received: (qmail 37851 invoked by uid 500); 20 Aug 2009 07:09:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 37774 invoked by uid 500); 20 Aug 2009 07:09:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 37764 invoked by uid 99); 20 Aug 2009 07:09:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 07:09:20 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 07:09:08 +0000
Received: from [216.145.54.158] (socks1.corp.yahoo.com [216.145.54.158])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7K77aqJ039981
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 00:07:36 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=zOukoixY+JlBR3d60GocG+HDBWo3E984fD6pRv+RvzZ7nASgHqQSq9sycdKW7m4T
Message-ID: <4A8CF633.7030907@yahoo-inc.com>
Date: Thu, 20 Aug 2009 00:07:31 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (X11/20090608)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Loading data failed with timeout
References: <4A8C3E7B.7020700@casalemedia.com>
In-Reply-To: <4A8C3E7B.7020700@casalemedia.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


There is a config "socket.read.timeout" or "socket.timeout" set to 60000 
(60s). 69000 is based on that.

Mayuran Yogarajah wrote:
> Hello, we were importing several TB of data overnight and it seemed one 
> of the loads
> failed.  We're running Hadoop 0.18.3, and there are 6 nodes in the 
> cluster, all are
> dual quad core with 6 gigs of ram.  We were using hadoop dfs -put to 
> load the data
> from both the namenode server and the secondary namenode server in 
> parallel.  Space
> is not the issue as we have many terabytes of space still remaining.
> 
> The load from the namenode is still going, the load from the secondary 
> namenode failed.
> 
> This is the error we got:
> 
> dfs.DFSClient: Exception in createBlockOutputStream 
> java.net.SocketTimeoutException: 69000 millis
> timeout while waiting for channel to be ready for read. ch : 
> java.nio.channels.SocketChannel[connected local=/x.x.x.x:55748 
> remote=/x.x.x.x:50010]
> 09/08/19 07:50:45 INFO dfs.DFSClient: Abandoning block 
> blk_8258931159385721568_6046
> 09/08/19 07:50:59 INFO dfs.DFSClient: Waiting to find target node: 
> x.x.x.x:50010
> 09/08/19 07:55:19 INFO dfs.DFSClient: Exception in 
> createBlockOutputStream java.net.SocketTimeoutException: 69000 millis 
> timeout while waiting for
> channel to be ready for read. ch : 
> java.nio.channels.SocketChannel[connected local=/x.x.x.x:47409 
> remote=/x.x.x.x:50010]
> 09/08/19 07:55:19 INFO dfs.DFSClient: Abandoning block 
> blk_-6648842835159477749_6046
> 09/08/19 07:55:41 INFO dfs.DFSClient: Waiting to find target node: 
> x.x.x.x:50010
> 
> 
> I thought maybe whatever configuration value set to 69000 was too low, 
> but there is nothing in hadoop-site or hadoop-default
> using a value of 69000.
> 
> Can anyone shed some light on this?
> 
> thanks,
> M


From common-user-return-16915-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 07:10:08 2009
Return-Path: <common-user-return-16915-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 12226 invoked from network); 20 Aug 2009 07:10:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 07:10:07 -0000
Received: (qmail 40072 invoked by uid 500); 20 Aug 2009 07:10:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 39936 invoked by uid 500); 20 Aug 2009 07:10:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 39916 invoked by uid 500); 20 Aug 2009 07:10:21 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 39908 invoked by uid 99); 20 Aug 2009 07:10:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 07:10:21 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 07:10:13 +0000
Received: by qyk26 with SMTP id 26so3772168qyk.5
        for <multiple recipients>; Thu, 20 Aug 2009 00:09:52 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.29.203 with SMTP id r11mr7215984qac.110.1250752192096; 
	Thu, 20 Aug 2009 00:09:52 -0700 (PDT)
In-Reply-To: <77f4f8890908192035j7d1f7943kfd37e6bc079950e7@mail.gmail.com>
References: <77f4f8890908191448q67970d40sabb0e54ec55ad3c8@mail.gmail.com> 
	<C6B1D92B.11978%rphulari@yahoo-inc.com> <77f4f8890908192035j7d1f7943kfd37e6bc079950e7@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Thu, 20 Aug 2009 00:09:32 -0700
Message-ID: <d6d7c4410908200009n3c2abdb4ufb05bd760112b2db@mail.gmail.com>
Subject: Re: Location of the source code for the fair scheduler
To: common-user@hadoop.apache.org
Cc: Ravi Phulari <rphulari@yahoo-inc.com>, 
	"core-user@hadoop.apache.org" <core-user@hadoop.apache.org>, 
	"core-user-subscribe@hadoop.apache.org" <core-user-subscribe@hadoop.apache.org>
Content-Type: multipart/alternative; boundary=000feaef44701cad7904718d7098
X-Virus-Checked: Checked by ClamAV on apache.org

--000feaef44701cad7904718d7098
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

What do you mean?
- Aaron

On Wed, Aug 19, 2009 at 8:35 PM, Mithila Nagendra <mnagendr@asu.edu> wrote:

> Thanks! But How do I know which version to work with?
> Mithila
>
>
> On Thu, Aug 20, 2009 at 2:30 AM, Ravi Phulari <rphulari@yahoo-inc.com
> >wrote:
>
> >  Currently Fairscheduler source is in
> >              hadoop-mapreduce/src/contrib/fairscheduler/
> >
> > Download mapreduce source from.
> > http://hadoop.apache.org/mapreduce/
> >
> > -
> > Ravi
> >
> >
> > On 8/19/09 2:48 PM, "Mithila Nagendra" <mnagendr@asu.edu> wrote:
> >
> > Hello
> >
> > I was wondering how I could locate the source code files for the fair
> > scheduler.
> >
> > Thanks
> > Mithila
> >
> >
> >
> >
>

--000feaef44701cad7904718d7098--

From common-user-return-16914-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 07:10:08 2009
Return-Path: <common-user-return-16914-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 12224 invoked from network); 20 Aug 2009 07:10:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 07:10:07 -0000
Received: (qmail 40043 invoked by uid 500); 20 Aug 2009 07:10:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 39933 invoked by uid 500); 20 Aug 2009 07:10:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 39908 invoked by uid 99); 20 Aug 2009 07:10:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 07:10:21 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.221.188] (HELO mail-qy0-f188.google.com) (209.85.221.188)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 07:10:13 +0000
Received: by qyk26 with SMTP id 26so3772168qyk.5
        for <multiple recipients>; Thu, 20 Aug 2009 00:09:52 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.29.203 with SMTP id r11mr7215984qac.110.1250752192096; 
	Thu, 20 Aug 2009 00:09:52 -0700 (PDT)
In-Reply-To: <77f4f8890908192035j7d1f7943kfd37e6bc079950e7@mail.gmail.com>
References: <77f4f8890908191448q67970d40sabb0e54ec55ad3c8@mail.gmail.com> 
	<C6B1D92B.11978%rphulari@yahoo-inc.com> <77f4f8890908192035j7d1f7943kfd37e6bc079950e7@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Thu, 20 Aug 2009 00:09:32 -0700
Message-ID: <d6d7c4410908200009n3c2abdb4ufb05bd760112b2db@mail.gmail.com>
Subject: Re: Location of the source code for the fair scheduler
To: common-user@hadoop.apache.org
Cc: Ravi Phulari <rphulari@yahoo-inc.com>, 
	"core-user@hadoop.apache.org" <core-user@hadoop.apache.org>, 
	"core-user-subscribe@hadoop.apache.org" <core-user-subscribe@hadoop.apache.org>
Content-Type: multipart/alternative; boundary=000feaef44701cad7904718d7098
X-Virus-Checked: Checked by ClamAV on apache.org

--000feaef44701cad7904718d7098
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

What do you mean?
- Aaron

On Wed, Aug 19, 2009 at 8:35 PM, Mithila Nagendra <mnagendr@asu.edu> wrote:

> Thanks! But How do I know which version to work with?
> Mithila
>
>
> On Thu, Aug 20, 2009 at 2:30 AM, Ravi Phulari <rphulari@yahoo-inc.com
> >wrote:
>
> >  Currently Fairscheduler source is in
> >              hadoop-mapreduce/src/contrib/fairscheduler/
> >
> > Download mapreduce source from.
> > http://hadoop.apache.org/mapreduce/
> >
> > -
> > Ravi
> >
> >
> > On 8/19/09 2:48 PM, "Mithila Nagendra" <mnagendr@asu.edu> wrote:
> >
> > Hello
> >
> > I was wondering how I could locate the source code files for the fair
> > scheduler.
> >
> > Thanks
> > Mithila
> >
> >
> >
> >
>

--000feaef44701cad7904718d7098--

From common-user-return-16916-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 07:19:04 2009
Return-Path: <common-user-return-16916-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 16539 invoked from network); 20 Aug 2009 07:19:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 07:19:04 -0000
Received: (qmail 51823 invoked by uid 500); 20 Aug 2009 07:19:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 51744 invoked by uid 500); 20 Aug 2009 07:19:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 51734 invoked by uid 99); 20 Aug 2009 07:19:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 07:19:21 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 07:19:10 +0000
Received: by ywh36 with SMTP id 36so7182241ywh.31
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 00:18:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=iLqgBPnyRQPomlkplIDXZJxyZQ7/xIc5yM4Cg2IfT6A=;
        b=P6ILtLDtfFGEuOGpQIepAvnaua1wKYo/1zWeGNw2wuDLXHvglb8kP9inrZxib/Vq+Z
         WARIyqkC7B+Cz5MhEwDnjoFwva52O8KdjXRmJiw1q5/GBk/25l7ttTjhVF2bWQZ+5G2Y
         XHNP4p2Zf9XuYoJvjYoa+UG47ahnD4ZmdHiuo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=DUtE6i1XBoc8Ar1I1/WR37Sm16pi92e976sszTgycSjfQXWgKI2qHApzjQiT4wFfDR
         k97pBEHRVjjEYE+JJpGOsQxvRuUOwscLLLN8/RR0XBSyZEHdf76ZT/ZeKACQTXU1gX8L
         UeeJWI2FU7QQKsEA2DDLIvy93xOrOTRCsjvlA=
MIME-Version: 1.0
Received: by 10.101.180.33 with SMTP id h33mr8228938anp.155.1250752728624; 
	Thu, 20 Aug 2009 00:18:48 -0700 (PDT)
In-Reply-To: <d6d7c4410908200006k762e70aapc428c0ddf71778d@mail.gmail.com>
References: <3b1311780908190721g3814f4dft9e00e9edce1eb86b@mail.gmail.com>
	 <d6d7c4410908191638g6c9452f7h104cad20ba604f7e@mail.gmail.com>
	 <3b1311780908192039p441bb4eciaf877e67dca6786f@mail.gmail.com>
	 <d6d7c4410908200006k762e70aapc428c0ddf71778d@mail.gmail.com>
Date: Thu, 20 Aug 2009 15:18:48 +0800
Message-ID: <3b1311780908200018l3fb2007ft532d1acdaf703f75@mail.gmail.com>
Subject: Re: How does hadoop deal with hadoop-site.xml?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c926cd176e4d04718d9090
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c926cd176e4d04718d9090
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thank you very much! I'm clear about it now.

2009/8/20 Aaron Kimball <aaron@cloudera.com>

> On Wed, Aug 19, 2009 at 8:39 PM, yang song <hadoop.inifok@gmail.com>
> wrote:
>
> >    Thank you, Aaron. I've benefited a lot. "per-node" means some settings
> > associated with the node. e.g., "fs.default.name", "mapred.job.tracker",
> > etc. "per-job" means some settings associated with the jobs which are
> > submited from the node. e.g., "mapred.reduce.tasks". That means, if I set
> > "per-job" properties on JobTracker, it will doesn't work. Is my
> > understanding right?
>
>
> It will work if you submit your job (run "hadoop jar ....") from the
> JobTracker node :) It won't if you submit your job from elsewhere.
>
>
> >
> >    In addition, when I add some new properties, e.g.,
> > "mapred.inifok.setting" on JobTracker, I can find it in every job.xml
> from
> > WebUI. I think all jobs will use the new properties. Is it right?
>
>
> If you set a property programmatically when configuring your job, that will
> be available in the JobConf on all machines for that job only. If you set a
> property in your hadoop-site.xml on the submitting machine, then I think
> that will also be available for the job on all nodes.
>
> - Aaron
>
>
> >
> >    Thanks again.
> >    Inifok
> >
> > 2009/8/20 Aaron Kimball <aaron@cloudera.com>
> >
> > > Hi Inifok,
> > >
> > > This is a confusing aspect of Hadoop, I'm afraid.
> > >
> > > Settings are divided into two categories: "per-job" and "per-node."
> > > Unfortunately, which are which, isn't documented.
> > >
> > > Some settings are applied to the node that is being used. So for
> example,
> > > if
> > > you set fs.default.name on a node to be "hdfs://some.namenode:8020/",
> > then
> > > any FS connections you make from that node will go to some.namenode. If
> a
> > > different machine in your cluster has fs.default.name set to
> > > hdfs://other.namenode, then that machine will connect to a different
> > > namenode.
> > >
> > > Another example of a per-machine setting is
> > > mapred.tasktracker.map.tasks.maximum; this tells a tasktracker the
> > maximum
> > > number of tasks it should run in parallel. Each tasktracker is free to
> > > configure this value differently. e.g., if you have some quad-core and
> > some
> > > eight-core machines. dfs.data.dir tells a datanode where its data
> > > directories should be kept. Naturally, this can vary
> machine-to-machine.
> > >
> > > Other settings are applied to a job as a whole. These settings are
> > > configured when you submit the job. So if you write
> > > conf.set("mapred.reduce.parallel.copies", 20) in your code, this will
> be
> > > the
> > > setting for the job. Settings that you don't explicitly put in your
> code,
> > > are drawn from the hadoop-site.xml file on the machine where the job is
> > > submitted from.
> > >
> > > In general, I strongly recommend you save yourself some pain by keeping
> > > your
> > > configuration files as identical as possible :)
> > > Good luck,
> > > - Aaron
> > >
> > >
> > > On Wed, Aug 19, 2009 at 7:21 AM, yang song <hadoop.inifok@gmail.com>
> > > wrote:
> > >
> > > > Hello, everybody
> > > >    I feel puzzled about setting properties in hadoop-site.xml.
> > > >    Suppose I submit the job from machine A, and JobTracker runs on
> > > machine
> > > > B. So there are two hadoop-site.xml files. Now, I increase
> > > > "mapred.reduce.parallel.copies"(e.g. 10) on machine B since I want to
> > > make
> > > > copy phrase faster. However, "mapred.reduce.parallel.copies" from
> WebUI
> > > is
> > > > still 5. When I increase it on machine A, it changes. So, I feel very
> > > > puzzled. Why does it doesn't work when I change it on B? What's more,
> > > when
> > > > I
> > > > add some properties on B, the certain properties will be found on
> > WebUI.
> > > > And
> > > > why I can't change properties through machine B? Does some certain
> > > > properties must be changed through A and some others must be changed
> > > > through
> > > > B?
> > > >    Thank you!
> > > >    Inifok
> > > >
> > >
> >
>

--001636c926cd176e4d04718d9090--

From common-user-return-16917-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 09:09:44 2009
Return-Path: <common-user-return-16917-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 54162 invoked from network); 20 Aug 2009 09:09:44 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 09:09:44 -0000
Received: (qmail 18350 invoked by uid 500); 20 Aug 2009 09:10:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 18263 invoked by uid 500); 20 Aug 2009 09:10:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 18253 invoked by uid 99); 20 Aug 2009 09:10:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 09:10:00 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of roman.wsmo@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 09:09:50 +0000
Received: by fxm25 with SMTP id 25so4092216fxm.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 02:09:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=HpCiAE2/DtsBSz2ohrVUPk6vuAG3ovEH7em0oBbiG+E=;
        b=OcWOXABSLo+3/xoU4LrXq1x/RyVCURSVqZoPYL2ImmGAc1kzaCbs9pM90jnSxbKIiL
         S9joTyZ29rR/bCYDTElxU3OUs0rxxB0/0pH32dArjA5xDIDxQJ5u827nv9DQlientxfY
         QScXjUHNcs2vQBZvPnLXzMNFyIYsCHAL7GnRE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=FjyrkqV95bwZwyBvfR3YFSS10u2pBy5Wx5VysIIwKg9qi42oXQ+HrYPh4nyWBvTZA+
         lXoJftpR/GBlUbAww6CnpiifABj5bbgP1hdpvZ0NpKP/k/SHao7FoZPBRhRGwU9888fB
         Rtl3yCkWWFRsQtat0uSMskj9+dWrp2e2jcIBo=
MIME-Version: 1.0
Received: by 10.223.29.193 with SMTP id r1mr620667fac.29.1250759370509; Thu, 
	20 Aug 2009 02:09:30 -0700 (PDT)
In-Reply-To: <e01b80590908192249s5302cd26m7984a32816c0d58c@mail.gmail.com>
References: <597eea000908191855v579b9c4r8baeb638630cfb27@mail.gmail.com>
	 <e01b80590908192249s5302cd26m7984a32816c0d58c@mail.gmail.com>
Date: Thu, 20 Aug 2009 10:09:30 +0100
Message-ID: <597eea000908200209o176aefacjca2a45369301c296@mail.gmail.com>
Subject: Re: File Chunk to Map Thread Association
From: roman kolcun <roman.wsmo@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00151747b76efa8de504718f1b93
X-Virus-Checked: Checked by ClamAV on apache.org

--00151747b76efa8de504718f1b93
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 20, 2009 at 6:49 AM, Harish Mallipeddi <
harish.mallipeddi@gmail.com> wrote:

> On Thu, Aug 20, 2009 at 7:25 AM, roman kolcun <roman.wsmo@gmail.com>
> wrote:
>
> > Hello everyone,
> > could anyone please tell me in which class and which method does Hadoop
> > download the file chunk from HDFS and associate it with the thread that
> > executes the Map function on given chunk and process it?
> >
>
> Hi Roman,
>
> First of all the map() function is executed in a MapTask (a separate child
> JVM is spawned by the TaskTracker). So it doesn't run inside a thread in
> the
> TaskTracker process.


Hello Harish,

I know that TaskTracker creates separate threads (up to
mapred.tasktracker.map.tasks.maximum) which execute the map() function.
However, I haven't found the piece of code which associate FileSplit with
the given map thread. Is it downloaded locally in the TaskTracker function
or in MapTask?


> >
> > I would like to extend the Hadoop so one "Task" may have more chunks
> > associated and one Map thread will process these two (or more chunks)
> > sequentially as if it was just a single file.
>
>
> You don't really have to change anything inside Hadoop to increase the size
> of InputSplits that MapTasks consume. Just modify 'mapred.min.split.size'
> if
> you want the splits to be larger. You could also write your own custom
> InputFormat class.
>

I know I can increase the input file size by changing
'mapred.min.split.size' , however, the file is split sequentially and very
rarely two consecutive HDFS blocks are stored on a single node. This means
that the data locality will not be exploited cause every map() will have to
download part of the file from network.

Roman Kolcun

--00151747b76efa8de504718f1b93--

From common-user-return-16918-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 09:31:07 2009
Return-Path: <common-user-return-16918-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 60471 invoked from network); 20 Aug 2009 09:31:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 09:31:07 -0000
Received: (qmail 63647 invoked by uid 500); 20 Aug 2009 09:31:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 63579 invoked by uid 500); 20 Aug 2009 09:31:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 63569 invoked by uid 99); 20 Aug 2009 09:31:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 09:31:23 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.198.237 as permitted sender)
Received: from [209.85.198.237] (HELO rv-out-0506.google.com) (209.85.198.237)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 09:31:16 +0000
Received: by rv-out-0506.google.com with SMTP id k40so1487258rvb.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 02:30:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=T2/gr0OUGbcDmbXApE5CUU3Rgo3lxvAg0ZsphMd2OsA=;
        b=kryKxXnm0yFYrLm68EXBGk9E5UEvRyJB/ur75+0u1FLRAcaO1n0otiI1lkTsGvSuD8
         VKv8P1i6d9zBS3qZ9dDLOq5e5b0ME2IMweHmz71Zkbmy5nPU1U7Bz/PWelPdTSpja74I
         4geiAfLFXmQQEaFX3aZFBYy0EnwmQSRjeyxEI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=nInipk3x0cUwC+PquuB40Q011lMx4LbdNxcJ5GJ1QLz3h0eWRRhuDM+e6sS4tXSObK
         7fM/XeKMttDw2vouGDTJ00LsKL1ZdOnZVJRv2hP5LhywBZdndzbN5E2ggVtVZLs6Dl1n
         S4dgi8w14sAxg6SUTpOTckx03w3I4VPbCnNFs=
MIME-Version: 1.0
Received: by 10.143.27.37 with SMTP id e37mr1792348wfj.234.1250760656096; Thu, 
	20 Aug 2009 02:30:56 -0700 (PDT)
In-Reply-To: <597eea000908200209o176aefacjca2a45369301c296@mail.gmail.com>
References: <597eea000908191855v579b9c4r8baeb638630cfb27@mail.gmail.com> 
	<e01b80590908192249s5302cd26m7984a32816c0d58c@mail.gmail.com> 
	<597eea000908200209o176aefacjca2a45369301c296@mail.gmail.com>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Thu, 20 Aug 2009 15:00:36 +0530
Message-ID: <e01b80590908200230x608ad35en5f372a9fd5aba325@mail.gmail.com>
Subject: Re: File Chunk to Map Thread Association
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00504502cd549b0f5f04718f6838
X-Virus-Checked: Checked by ClamAV on apache.org

--00504502cd549b0f5f04718f6838
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 20, 2009 at 2:39 PM, roman kolcun <roman.wsmo@gmail.com> wrote:

>
> Hello Harish,
>
> I know that TaskTracker creates separate threads (up to
> mapred.tasktracker.map.tasks.maximum) which execute the map() function.
> However, I haven't found the piece of code which associate FileSplit with
> the given map thread. Is it downloaded locally in the TaskTracker function
> or in MapTask?
>
>
>
Yes this is done by the MapTask.


>
> I know I can increase the input file size by changing
> 'mapred.min.split.size' , however, the file is split sequentially and very
> rarely two consecutive HDFS blocks are stored on a single node. This means
> that the data locality will not be exploited cause every map() will have to
> download part of the file from network.
>
> Roman Kolcun
>

I see what you mean - you want to modify the hadoop code to allocate
multiple (non-sequential) data-local blocks to one MapTask. I don't know if
you'll achieve much by doing all that work. Hadoop lets you reuse the
launched JVMs for multiple MapTasks. That should minimize the overhead of
launching MapTasks.
Increasing the DFS blocksize for the input files is another means to achieve
the same effect.


-- 
Harish Mallipeddi
http://blog.poundbang.in

--00504502cd549b0f5f04718f6838--

From common-user-return-16919-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 09:52:36 2009
Return-Path: <common-user-return-16919-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 72158 invoked from network); 20 Aug 2009 09:52:36 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 09:52:36 -0000
Received: (qmail 94678 invoked by uid 500); 20 Aug 2009 09:52:52 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 94595 invoked by uid 500); 20 Aug 2009 09:52:52 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 94585 invoked by uid 99); 20 Aug 2009 09:52:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 09:52:52 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [140.203.201.100] (HELO mx1.nuigalway.ie) (140.203.201.100)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 09:52:42 +0000
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: ApoEACe5jEoKhJ0L/2dsb2JhbADVYIQaBQ
X-IronPort-AV: E=Sophos;i="4.43,413,1246834800"; 
   d="scan'208";a="18661691"
Received: from unknown (HELO EVS1.ac.nuigalway.ie) ([10.132.157.11])
  by mx1.nuigalway.ie with ESMTP; 20 Aug 2009 10:52:20 +0100
Received: from EVS1.ac.nuigalway.ie ([10.132.157.14]) by EVS1.ac.nuigalway.ie with Microsoft SMTPSVC(6.0.3790.3959);
	 Thu, 20 Aug 2009 10:52:19 +0100
Received: from [10.2.18.121] ([140.203.154.11]) by EVS1.ac.nuigalway.ie over TLS secured channel with Microsoft SMTPSVC(6.0.3790.3959);
	 Thu, 20 Aug 2009 10:52:19 +0100
Message-ID: <4A8D1CD2.9000703@deri.org>
Date: Thu, 20 Aug 2009 10:52:18 +0100
From: stephen mulcahy <stephen.mulcahy@deri.org>
User-Agent: Mozilla-Thunderbird 2.0.0.22 (X11/20090706)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Running hadoop jobs from a client and tuning  (was Re: How does hadoop
 deal with hadoop-site.xml?)
References: <3b1311780908190721g3814f4dft9e00e9edce1eb86b@mail.gmail.com> 	<d6d7c4410908191638g6c9452f7h104cad20ba604f7e@mail.gmail.com> 	<3b1311780908192039p441bb4eciaf877e67dca6786f@mail.gmail.com> <d6d7c4410908200006k762e70aapc428c0ddf71778d@mail.gmail.com>
In-Reply-To: <d6d7c4410908200006k762e70aapc428c0ddf71778d@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-OriginalArrivalTime: 20 Aug 2009 09:52:19.0264 (UTC) FILETIME=[E820D400:01CA217B]
X-Virus-Checked: Checked by ClamAV on apache.org

Hi folks,

Sorry to cut across this discussion but I'm experiencing some similar 
confusion about where to change some parameters.

In particular, I'm not entirely clear on how the following should be 
used - clarification welcome (I'm happy to pull some of this together on 
a blog once I get some clarity).

In hadoop/conf/hadoop-site.xml

hadoop.tmp.dir - when submitting a job from a client (not one of the 
hadoop cluster machines), does this specify a directory local to the 
client in which hadoop creates temporary files or is it a directory that 
on each hadoop machine on which the job runs? I notice that the cloudera 
configurator specifies this as /tmp/hadoop-${user.name} - this seems 
like a nice approach to use, is it safe for this tmp.dir to be blown 
away when a machine is rebooted?

mapred.child.java.opts (-Xmx) and mapred.child.ulimit

presumably these should be set totally differently on the namenode, data 
nodes and client machine (assuming they are different?). In the case of 
the namenode and data nodes, I assume they should be set quite large. In 
the case of the client, should they be set so that the number of tasks * 
allocated memory is roughly equal to the amount of memory free on each 
data node?

mapred.map.tasks and mapred.reduce.tasks

My understanding on the namenode and data nodes is that these should be 
set to less than the number of cores or less. Is that correct? For the 
client, should these be bumped closer to the total number of cores that 
are available in the overall cluster?

mapred.tasktracker.tasks.maximum

Does this work as a cap on mapred.map.tasks and mapred.reduce.tasks? Is 
it neccesary to use this as well as mapred.map.tasks and 
mapred.reduce.tasks?


Finally, in hadoop/conf/hadoop-env.sh

export HADOOP_HEAPSIZE=xxxx

Should this be changed normally? If so, how large should it normally be? 
50% of total system memory?

Thanks for any input,

-stephen

-- 
Stephen Mulcahy, DI2, Digital Enterprise Research Institute,
NUI Galway, IDA Business Park, Lower Dangan, Galway, Ireland
http://di2.deri.ie    http://webstar.deri.ie    http://sindice.com

From common-user-return-16920-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 09:59:59 2009
Return-Path: <common-user-return-16920-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75577 invoked from network); 20 Aug 2009 09:59:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 09:59:59 -0000
Received: (qmail 7228 invoked by uid 500); 20 Aug 2009 10:00:16 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 7166 invoked by uid 500); 20 Aug 2009 10:00:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 7156 invoked by uid 99); 20 Aug 2009 10:00:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 10:00:16 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of roman.wsmo@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 10:00:08 +0000
Received: by fxm25 with SMTP id 25so4112791fxm.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 02:59:46 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=td3qyXWdDZETs3zPTp5XFClXXehkK9U2DA/HIdb8eHk=;
        b=too5M5qN/qHVid6ag/Q00+f7VeD0ddzAlw+LCVomAz7a8UP64vHxvFUNh0QOYe7Ks0
         KutwbXs3ZR5wHmvkZXoQX9EXkip+ta0RFZUVdvpnRRq3T+/5PJn+v1TlOC4oRTgG/YcD
         f8NqCzNQovMzCw2xcOZGxTRnDCnrguOGXdpwM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=r8PgF/7eXUQBJljHi81lFgzNpdIG8jbfAmFTvy4UfKDB5UYzq9myoJXhD4beIGKWVc
         O2Cac0VkrkZZhbG3aWXxrnS1DZEB3sILjT+90K8/zAzO1bIlyMDyPcfAPGiyVLVuBL1o
         eWzjK7Tyv4a2Tn/LT8iK/drEEJ+Ag2ar606eQ=
MIME-Version: 1.0
Received: by 10.102.178.11 with SMTP id a11mr2995820muf.129.1250762386408; 
	Thu, 20 Aug 2009 02:59:46 -0700 (PDT)
In-Reply-To: <e01b80590908200230x608ad35en5f372a9fd5aba325@mail.gmail.com>
References: <597eea000908191855v579b9c4r8baeb638630cfb27@mail.gmail.com>
	 <e01b80590908192249s5302cd26m7984a32816c0d58c@mail.gmail.com>
	 <597eea000908200209o176aefacjca2a45369301c296@mail.gmail.com>
	 <e01b80590908200230x608ad35en5f372a9fd5aba325@mail.gmail.com>
Date: Thu, 20 Aug 2009 10:59:46 +0100
Message-ID: <597eea000908200259o8e3bd78l385059f2b5d31555@mail.gmail.com>
Subject: Re: File Chunk to Map Thread Association
From: roman kolcun <roman.wsmo@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163641797dbd857b04718fcf89
X-Virus-Checked: Checked by ClamAV on apache.org

--00163641797dbd857b04718fcf89
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 20, 2009 at 10:30 AM, Harish Mallipeddi <
harish.mallipeddi@gmail.com> wrote:

> On Thu, Aug 20, 2009 at 2:39 PM, roman kolcun <roman.wsmo@gmail.com>
> wrote:
>
> >
> > Hello Harish,
> >
> > I know that TaskTracker creates separate threads (up to
> > mapred.tasktracker.map.tasks.maximum) which execute the map() function.
> > However, I haven't found the piece of code which associate FileSplit with
> > the given map thread. Is it downloaded locally in the TaskTracker
> function
> > or in MapTask?
> >
> >
> >
> Yes this is done by the MapTask.


Thanks, I will have a better look into it.

>
>
> >
> > I know I can increase the input file size by changing
> > 'mapred.min.split.size' , however, the file is split sequentially and
> very
> > rarely two consecutive HDFS blocks are stored on a single node. This
> means
> > that the data locality will not be exploited cause every map() will have
> to
> > download part of the file from network.
> >
> > Roman Kolcun
> >
>
> I see what you mean - you want to modify the hadoop code to allocate
> multiple (non-sequential) data-local blocks to one MapTask.


That's exactly what I want to do.


> I don't know if you'll achieve much by doing all that work.


Basically I would like to emulate larger DFS blocksize. I've performed 2
word count benchmarks on a cluster of 10 machines with 100GB file. With 64MB
blocksize it took 2035 seconds, when I've increased it to 256MB it took 1694
seconds - which is 16.76% increase.


> Hadoop lets you reuse the
> launched JVMs for multiple MapTasks. That should minimize the overhead of
> launching MapTasks.
> Increasing the DFS blocksize for the input files is another means to
> achieve
> the same effect.
>
> Do you think that this could be eliminated by reusing JVMs?
I am doing it as a project for my university degree so I really hope it will
lower the processing time significantly. I would like to make it general for
different block sizes.

Thank you for your help.

Roman Kolcun

--00163641797dbd857b04718fcf89--

From common-user-return-16921-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 10:41:08 2009
Return-Path: <common-user-return-16921-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 90514 invoked from network); 20 Aug 2009 10:41:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 10:41:04 -0000
Received: (qmail 64178 invoked by uid 500); 20 Aug 2009 10:41:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 64091 invoked by uid 500); 20 Aug 2009 10:41:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 64081 invoked by uid 99); 20 Aug 2009 10:41:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 10:41:21 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [192.6.10.60] (HELO tobor.hpl.hp.com) (192.6.10.60)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 10:41:09 +0000
Received: from localhost (localhost [127.0.0.1])
	by tobor.hpl.hp.com (Postfix) with ESMTP id 81F15B7D00
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 11:40:47 +0100 (BST)
X-Virus-Scanned: amavisd-new at hplb.hpl.hp.com
Received: from tobor.hpl.hp.com ([127.0.0.1])
	by localhost (tobor.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id 6Ir9bMQre9WZ for <common-user@hadoop.apache.org>;
	Thu, 20 Aug 2009 11:40:41 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by tobor.hpl.hp.com (Postfix) with ESMTPS id DE996B7CBB
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 11:40:40 +0100 (BST)
MailScanner-NULL-Check: 1251369628.7953@vTqqN/wDTDWbjhe9pJPfOA
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7KAeRgH011618
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 11:40:27 +0100 (BST)
Message-ID: <4A8D281B.9070006@apache.org>
Date: Thu, 20 Aug 2009 11:40:27 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: NN memory consumption on 0.20/0.21 with compressed pointers/
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7KAeRgH011618
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org


does anyone have any up to date data on the memory consumption per 
block/file on the NN on a 64-bit JVM with compressed pointers?

The best documentation on consumption is 
http://issues.apache.org/jira/browse/HADOOP-1687 -I'm just wondering if 
anyone has looked at the memory footprint on the latest Hadoop releases, 
on those latest JVMs? -and which JVM the numbers from HADOOP-1687 came from?

Those compressed pointers (which BEA JRockit had for a while) save RAM 
when the pointer references are within a couple of GB of the other refs, 
and which are discussed in some papers
http://rappist.elis.ugent.be/~leeckhou/papers/cgo06.pdf
http://www.elis.ugent.be/~kvenster/papers/VenstermansKris_ORA.pdf

sun's commentary is up here
http://wikis.sun.com/display/HotSpotInternals/CompressedOops

I'm just not sure what it means for the NameNode, and as there is no 
sizeof() operator in Java, something that will take a bit of effort to 
work out. From what I read of the Sun wiki, when you go compressed, 
while your heap is <3-4GB, there is no decompress operation; once you go 
above that there is a shift and an add, which is probably faster than 
fetching another 32 bits from $L2 or main RAM. The result could be 
-could be- that your NN takes up much less space on 64 bit JVMs than it 
did before, but is no slower.

Has anyone worked out the numbers yet?

-steve

From common-user-return-16922-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 11:32:59 2009
Return-Path: <common-user-return-16922-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 9126 invoked from network); 20 Aug 2009 11:32:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 11:32:59 -0000
Received: (qmail 33215 invoked by uid 500); 20 Aug 2009 11:33:15 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 33166 invoked by uid 500); 20 Aug 2009 11:33:15 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 33156 invoked by uid 99); 20 Aug 2009 11:33:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 11:33:15 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 11:33:02 +0000
Received: from EGL-EX07CAS02.ds.corp.yahoo.com (egl-ex07cas02.eglbp.corp.yahoo.com [203.83.248.209])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7KBW5E3079015
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 04:32:06 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=053x0SJ6V4O0szXasjJcLMCLOjoSrFw1Qp+zkn71pGalzPkv6VrB3C3xgmohGChU
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.206]) by
 EGL-EX07CAS02.ds.corp.yahoo.com ([203.83.248.216]) with mapi; Thu, 20 Aug
 2009 17:02:04 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Thu, 20 Aug 2009 17:00:55 +0530
Subject: RE: Running hadoop jobs from a client and tuning  (was Re: How does
 hadoop deal with hadoop-site.xml?)
Thread-Topic: Running hadoop jobs from a client and tuning  (was Re: How
 does hadoop deal with hadoop-site.xml?)
Thread-Index: AcohfBI9q70tPu7cQ1WsSqBpnYlAigACabzg
Message-ID: <616DA47B2EF5B944B91846785B512FF4CFADEA7046@EGL-EX07VS01.ds.corp.yahoo.com>
References: <3b1311780908190721g3814f4dft9e00e9edce1eb86b@mail.gmail.com>
 	<d6d7c4410908191638g6c9452f7h104cad20ba604f7e@mail.gmail.com>
 	<3b1311780908192039p441bb4eciaf877e67dca6786f@mail.gmail.com>
 <d6d7c4410908200006k762e70aapc428c0ddf71778d@mail.gmail.com>
 <4A8D1CD2.9000703@deri.org>
In-Reply-To: <4A8D1CD2.9000703@deri.org>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

AFAIK,
hadoop.tmp.dir : Used by NN and DN for directory listings and metadata ( do=
n't have much info on this )

java.opts & ulimit : ulimit defines the maximum limit of virtual mem for ta=
sk launched. java.opts is the amount of memory reserved for a task.=20
When setting you need to account for memory set aside for hadoop daemons li=
ke tasktracker etc.

mapred.map.tasks and mapred.reduce.tasks : these are job wide configuration=
s and not per-task configurations for a node. Acts as a hint to the hadoop =
framework and explicitly setting them might not be always recommended, unle=
ss you want to run a no-reducer job.

mapred.tasktracker.(map | reduce )tasks.maximum : Limit on concurrent tasks=
 running on a machine, typically set according to cores & memory each map/r=
educe task will be using.

Also, typically client and datanodes will be the same.

Thanks,
Amogh
-----Original Message-----
From: stephen mulcahy [mailto:stephen.mulcahy@deri.org]=20
Sent: Thursday, August 20, 2009 3:22 PM
To: common-user@hadoop.apache.org
Subject: Running hadoop jobs from a client and tuning (was Re: How does had=
oop deal with hadoop-site.xml?)

Hi folks,

Sorry to cut across this discussion but I'm experiencing some similar=20
confusion about where to change some parameters.

In particular, I'm not entirely clear on how the following should be=20
used - clarification welcome (I'm happy to pull some of this together on=20
a blog once I get some clarity).

In hadoop/conf/hadoop-site.xml

hadoop.tmp.dir - when submitting a job from a client (not one of the=20
hadoop cluster machines), does this specify a directory local to the=20
client in which hadoop creates temporary files or is it a directory that=20
on each hadoop machine on which the job runs? I notice that the cloudera=20
configurator specifies this as /tmp/hadoop-${user.name} - this seems=20
like a nice approach to use, is it safe for this tmp.dir to be blown=20
away when a machine is rebooted?

mapred.child.java.opts (-Xmx) and mapred.child.ulimit

presumably these should be set totally differently on the namenode, data=20
nodes and client machine (assuming they are different?). In the case of=20
the namenode and data nodes, I assume they should be set quite large. In=20
the case of the client, should they be set so that the number of tasks *=20
allocated memory is roughly equal to the amount of memory free on each=20
data node?

mapred.map.tasks and mapred.reduce.tasks

My understanding on the namenode and data nodes is that these should be=20
set to less than the number of cores or less. Is that correct? For the=20
client, should these be bumped closer to the total number of cores that=20
are available in the overall cluster?

mapred.tasktracker.tasks.maximum

Does this work as a cap on mapred.map.tasks and mapred.reduce.tasks? Is=20
it neccesary to use this as well as mapred.map.tasks and=20
mapred.reduce.tasks?


Finally, in hadoop/conf/hadoop-env.sh

export HADOOP_HEAPSIZE=3Dxxxx

Should this be changed normally? If so, how large should it normally be?=20
50% of total system memory?

Thanks for any input,

-stephen

--=20
Stephen Mulcahy, DI2, Digital Enterprise Research Institute,
NUI Galway, IDA Business Park, Lower Dangan, Galway, Ireland
http://di2.deri.ie    http://webstar.deri.ie    http://sindice.com

From common-user-return-16923-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 14:02:59 2009
Return-Path: <common-user-return-16923-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 83137 invoked from network); 20 Aug 2009 14:02:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 14:02:58 -0000
Received: (qmail 23328 invoked by uid 500); 20 Aug 2009 14:03:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 23266 invoked by uid 500); 20 Aug 2009 14:03:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 23254 invoked by uid 99); 20 Aug 2009 14:03:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 14:03:14 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [209.85.219.209] (HELO mail-ew0-f209.google.com) (209.85.219.209)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 14:03:05 +0000
Received: by ewy5 with SMTP id 5so181532ewy.36
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 07:02:45 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.216.39.85 with SMTP id c63mr1821542web.103.1250776964866; Thu, 
	20 Aug 2009 07:02:44 -0700 (PDT)
In-Reply-To: <597eea000908200259o8e3bd78l385059f2b5d31555@mail.gmail.com>
References: <597eea000908191855v579b9c4r8baeb638630cfb27@mail.gmail.com>
	 <e01b80590908192249s5302cd26m7984a32816c0d58c@mail.gmail.com>
	 <597eea000908200209o176aefacjca2a45369301c296@mail.gmail.com>
	 <e01b80590908200230x608ad35en5f372a9fd5aba325@mail.gmail.com>
	 <597eea000908200259o8e3bd78l385059f2b5d31555@mail.gmail.com>
Date: Thu, 20 Aug 2009 15:02:44 +0100
Message-ID: <ac79ea400908200702u309a4fcey9ab1a7b358f313ce@mail.gmail.com>
Subject: Re: File Chunk to Map Thread Association
From: Tom White <tom@cloudera.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Roman,

Have a look at CombineFileInputFormat - it might be related to what
you are trying to do.

Cheers,
Tom

On Thu, Aug 20, 2009 at 10:59 AM, roman kolcun<roman.wsmo@gmail.com> wrote:
> On Thu, Aug 20, 2009 at 10:30 AM, Harish Mallipeddi <
> harish.mallipeddi@gmail.com> wrote:
>
>> On Thu, Aug 20, 2009 at 2:39 PM, roman kolcun <roman.wsmo@gmail.com>
>> wrote:
>>
>> >
>> > Hello Harish,
>> >
>> > I know that TaskTracker creates separate threads (up to
>> > mapred.tasktracker.map.tasks.maximum) which execute the map() function.
>> > However, I haven't found the piece of code which associate FileSplit with
>> > the given map thread. Is it downloaded locally in the TaskTracker
>> function
>> > or in MapTask?
>> >
>> >
>> >
>> Yes this is done by the MapTask.
>
>
> Thanks, I will have a better look into it.
>
>>
>>
>> >
>> > I know I can increase the input file size by changing
>> > 'mapred.min.split.size' , however, the file is split sequentially and
>> very
>> > rarely two consecutive HDFS blocks are stored on a single node. This
>> means
>> > that the data locality will not be exploited cause every map() will have
>> to
>> > download part of the file from network.
>> >
>> > Roman Kolcun
>> >
>>
>> I see what you mean - you want to modify the hadoop code to allocate
>> multiple (non-sequential) data-local blocks to one MapTask.
>
>
> That's exactly what I want to do.
>
>
>> I don't know if you'll achieve much by doing all that work.
>
>
> Basically I would like to emulate larger DFS blocksize. I've performed 2
> word count benchmarks on a cluster of 10 machines with 100GB file. With 64MB
> blocksize it took 2035 seconds, when I've increased it to 256MB it took 1694
> seconds - which is 16.76% increase.
>
>
>> Hadoop lets you reuse the
>> launched JVMs for multiple MapTasks. That should minimize the overhead of
>> launching MapTasks.
>> Increasing the DFS blocksize for the input files is another means to
>> achieve
>> the same effect.
>>
>> Do you think that this could be eliminated by reusing JVMs?
> I am doing it as a project for my university degree so I really hope it will
> lower the processing time significantly. I would like to make it general for
> different block sizes.
>
> Thank you for your help.
>
> Roman Kolcun
>

From common-user-return-16924-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 14:04:40 2009
Return-Path: <common-user-return-16924-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 84756 invoked from network); 20 Aug 2009 14:04:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 14:04:40 -0000
Received: (qmail 32480 invoked by uid 500); 20 Aug 2009 14:04:56 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 32391 invoked by uid 500); 20 Aug 2009 14:04:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 32381 invoked by uid 99); 20 Aug 2009 14:04:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 14:04:56 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of roman.wsmo@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 14:04:46 +0000
Received: by bwz10 with SMTP id 10so4210493bwz.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 07:04:26 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=p7R28ka9Wm8KBDcSMKdUG5rtahy5/GFjA+g75TFPn1Q=;
        b=uLdJxVJZ5FU5HYxrzIOZQY02JqoewOynniwMvQCNHjXpp+W4iELITZbOKGwLYD2RUt
         hG+4azES2Dw357HHu7jYFdnPnIkgu/HAmkwxFcRJFSosgVw9aiiVoLpJwh6+yW3394Te
         mrrVvDjReEMetsRxi8IIVKVwcEv+fnEK7JqPg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=nyhad1O/Ufp2Rhu/gg8h1+p8F1by2KxgwqJBOJajJ8mR5yngFwVisvK2kzeUAC+jo8
         0qk8r2RAKXIE38C7iTtXLn6UdhP7yTMz62ahkZ/5SBpK/nhHj9Y8h/PKQHDjcAyVlNTQ
         DXGpsPYC6172aGSf9rqYJjU+y+tSF7fj1Tl4M=
MIME-Version: 1.0
Received: by 10.103.76.21 with SMTP id d21mr3127834mul.78.1250777066486; Thu, 
	20 Aug 2009 07:04:26 -0700 (PDT)
In-Reply-To: <ac79ea400908200702u309a4fcey9ab1a7b358f313ce@mail.gmail.com>
References: <597eea000908191855v579b9c4r8baeb638630cfb27@mail.gmail.com>
	 <e01b80590908192249s5302cd26m7984a32816c0d58c@mail.gmail.com>
	 <597eea000908200209o176aefacjca2a45369301c296@mail.gmail.com>
	 <e01b80590908200230x608ad35en5f372a9fd5aba325@mail.gmail.com>
	 <597eea000908200259o8e3bd78l385059f2b5d31555@mail.gmail.com>
	 <ac79ea400908200702u309a4fcey9ab1a7b358f313ce@mail.gmail.com>
Date: Thu, 20 Aug 2009 15:04:26 +0100
Message-ID: <597eea000908200704k591e8993nbe2b536a7c38701f@mail.gmail.com>
Subject: Re: File Chunk to Map Thread Association
From: roman kolcun <roman.wsmo@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e65aeea4bdbd160471933af3
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e65aeea4bdbd160471933af3
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks Tom,
I will have a look at it.

Cheers,
Roman

On Thu, Aug 20, 2009 at 3:02 PM, Tom White <tom@cloudera.com> wrote:

> Hi Roman,
>
> Have a look at CombineFileInputFormat - it might be related to what
> you are trying to do.
>
> Cheers,
> Tom
>
> On Thu, Aug 20, 2009 at 10:59 AM, roman kolcun<roman.wsmo@gmail.com>
> wrote:
> > On Thu, Aug 20, 2009 at 10:30 AM, Harish Mallipeddi <
> > harish.mallipeddi@gmail.com> wrote:
> >
> >> On Thu, Aug 20, 2009 at 2:39 PM, roman kolcun <roman.wsmo@gmail.com>
> >> wrote:
> >>
> >> >
> >> > Hello Harish,
> >> >
> >> > I know that TaskTracker creates separate threads (up to
> >> > mapred.tasktracker.map.tasks.maximum) which execute the map()
> function.
> >> > However, I haven't found the piece of code which associate FileSplit
> with
> >> > the given map thread. Is it downloaded locally in the TaskTracker
> >> function
> >> > or in MapTask?
> >> >
> >> >
> >> >
> >> Yes this is done by the MapTask.
> >
> >
> > Thanks, I will have a better look into it.
> >
> >>
> >>
> >> >
> >> > I know I can increase the input file size by changing
> >> > 'mapred.min.split.size' , however, the file is split sequentially and
> >> very
> >> > rarely two consecutive HDFS blocks are stored on a single node. This
> >> means
> >> > that the data locality will not be exploited cause every map() will
> have
> >> to
> >> > download part of the file from network.
> >> >
> >> > Roman Kolcun
> >> >
> >>
> >> I see what you mean - you want to modify the hadoop code to allocate
> >> multiple (non-sequential) data-local blocks to one MapTask.
> >
> >
> > That's exactly what I want to do.
> >
> >
> >> I don't know if you'll achieve much by doing all that work.
> >
> >
> > Basically I would like to emulate larger DFS blocksize. I've performed 2
> > word count benchmarks on a cluster of 10 machines with 100GB file. With
> 64MB
> > blocksize it took 2035 seconds, when I've increased it to 256MB it took
> 1694
> > seconds - which is 16.76% increase.
> >
> >
> >> Hadoop lets you reuse the
> >> launched JVMs for multiple MapTasks. That should minimize the overhead
> of
> >> launching MapTasks.
> >> Increasing the DFS blocksize for the input files is another means to
> >> achieve
> >> the same effect.
> >>
> >> Do you think that this could be eliminated by reusing JVMs?
> > I am doing it as a project for my university degree so I really hope it
> will
> > lower the processing time significantly. I would like to make it general
> for
> > different block sizes.
> >
> > Thank you for your help.
> >
> > Roman Kolcun
> >
>

--0016e65aeea4bdbd160471933af3--

From common-user-return-16925-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 14:45:52 2009
Return-Path: <common-user-return-16925-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 5707 invoked from network); 20 Aug 2009 14:45:49 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 14:45:49 -0000
Received: (qmail 19786 invoked by uid 500); 20 Aug 2009 14:46:05 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 19714 invoked by uid 500); 20 Aug 2009 14:46:05 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 19631 invoked by uid 99); 20 Aug 2009 14:46:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 14:46:05 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of edlinuxguru@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 14:44:58 +0000
Received: by fxm25 with SMTP id 25so4256890fxm.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 07:44:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=W6hB+U9yaUZI22xjus21W5jdmoZ1CFMesy7OYFtHWwg=;
        b=Iftb+iaVOqvysJUneTbGbjg4AHiBPPqbtYc6+sBPYVduVjtd4YwgUKUrP9Xxjt4eNE
         rAY89J6odMXKB+t7Bvma1bIeCp3sGeEA/k2zRAzcrpDOSkrjqbt3hNmQSSNHZuPl64zp
         ZYQHOLAWQT+lZuq9Kc+SA/S6rMwP6WVa6+oJM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=KlYl6p2umTiuYLvk0l3OQAjMDp8eqC3yzuh0PkwVJ8FEjF57/zr3LSqJoq8ukXV/JI
         RX26w9rVCz3viT2hTMH/FAE5hYgAmKdhRAGdCE8vh4+6qpUc6cSEWFV4REGmGiP4lItW
         dQov1VWzD+llgnmp4ns/eDsd2XM7rszK0Zzm0=
MIME-Version: 1.0
Received: by 10.239.130.150 with SMTP id 22mr652222hbj.59.1250779478361; Thu, 
	20 Aug 2009 07:44:38 -0700 (PDT)
In-Reply-To: <480D7E03-6E9F-4917-BE31-A82D2A42D9C8@cse.unl.edu>
References: <2986c2f30908191632u74dcad9dt9073fc84eb7d849e@mail.gmail.com>
	 <480D7E03-6E9F-4917-BE31-A82D2A42D9C8@cse.unl.edu>
Date: Thu, 20 Aug 2009 10:44:38 -0400
Message-ID: <cbbf4b570908200744l5e206ea1hbb8fe5d439fbfc77@mail.gmail.com>
Subject: Re: syslog-ng and hadoop
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Wed, Aug 19, 2009 at 11:50 PM, Brian Bockelman<bbockelm@cse.unl.edu> wro=
te:
> Hey Mike,
>
> Yup. =A0We find the stock log4j needs two things:
>
> 1) Set the rootLogger manually. =A0The way 0.19.x has the root logger set=
 up
> breaks when adding new appenders. =A0I.e., do:
>
> log4j.rootLogger=3DINFO,SYSLOG,console,DRFA,EventCounter
>
> 2) Add the headers; otherwise log4j is not compatible with syslog:
>
> log4j.appender.SYSLOG=3Dorg.apache.log4j.net.SyslogAppender
> log4j.appender.SYSLOG.facility=3Dlocal0
> log4j.appender.SYSLOG.layout=3Dorg.apache.log4j.PatternLayout
> log4j.appender.SYSLOG.layout.ConversionPattern=3D%p %c{2}: %m%n
> log4j.appender.SYSLOG.SyslogHost=3Dred
> log4j.appender.SYSLOG.threshold=3DERROR
> log4j.appender.SYSLOG.Header=3Dtrue
> log4j.appender.SYSLOG.FacilityPrinting=3Dtrue
>
> Brian
>
> On Aug 19, 2009, at 6:32 PM, Mike Anderson wrote:
>
>> Has anybody had any luck setting up the log4j.properties file to send lo=
gs
>> to a syslog-ng server?
>> My log4j.properties excerpt:
>> log4j.appender.SYSLOG=3Dorg.apache.log4j.net.SyslogAppender
>> log4j.appender.SYSLOG.syslogHost=3D10.0.20.164
>> log4j.appender.SYSLOG.layout=3Dorg.apache.log4j.PatternLayout
>> log4j.appender.SYSLOG.layout.ConversionPattern=3D%d{ISO8601} %p %c: %m%n
>> log4j.appender.SYSLOG.Facility=3DHADOOP
>>
>> and my syslog-ng.conf file running on 10.0.20.164
>>
>> source s_hadoop {
>> =A0 =A0 =A0 # message generated by Syslog-NG
>> =A0 =A0 =A0 internal();
>> =A0 =A0 =A0 # standard Linux log source (this is the default place for t=
he
>> syslog()
>> =A0 =A0 =A0 # function to send logs to)
>> =A0 =A0 =A0 unix-stream("/dev/log");
>> =A0 =A0 =A0 udp();
>> };
>> destination df_hadoop { file("/var/log/hadoop/hadoop.log");};
>> filter f_hadoop {facility(hadoop);};
>> log {
>> source(s_hadoop);
>> filter(f_hadoop);
>> destination(df_hadoop);
>> };
>>
>>
>> Thanks in advance,
>> Mike
>
>

Mike slightly off topic but you can also run a Log 4J server which
perfectly transports the messages fired off by LOG4j. The
log4J->syslog loses/ changes some information. If anyone is interested
in this let me know and I will write up something about it.

From common-user-return-16926-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 14:50:46 2009
Return-Path: <common-user-return-16926-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7592 invoked from network); 20 Aug 2009 14:50:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 14:50:46 -0000
Received: (qmail 29310 invoked by uid 500); 20 Aug 2009 14:51:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 29230 invoked by uid 500); 20 Aug 2009 14:51:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 29220 invoked by uid 99); 20 Aug 2009 14:51:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 14:51:02 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of saidtherobot@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 14:50:01 +0000
Received: by yxe15 with SMTP id 15so6843962yxe.5
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 07:49:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=tfjwpMI0x6onyZJm2LwrJVE9vUwtE/USzLM0jTwTSzE=;
        b=jmKOUGOQFfJAWWZv+9Osu/pIMm3fjhrv+yKKHh+1MK5M85Um52Lt+nb3z0/C/KGVG+
         BPvafq4uxmS0wvR5sktDAcQYx2Xo7ZI61ifh0CmKNcEmTMLf7Hk8X0H4lROajz88AXkx
         A7sRAAORkW/fpiMjRqeMnXfBQ1M1kiTX1AU9A=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=RngPsDIDUvCNLMOCVUmAa/T7c3NRPam/W3PMUHM2Vu9ovVPhL3mVgWUgaoXGcTvULN
         LGy7X/3/um4FHMnwVtkjyjHnz7tKyzUhdi93/SpwesvdqWYiYNfu4GuDdaMKTvcaH7+H
         UGaFrYahlfx3uG+7iokkLJ98HmQ/uYWH1p+Ms=
MIME-Version: 1.0
Received: by 10.150.174.13 with SMTP id w13mr12898936ybe.94.1250779780232; 
	Thu, 20 Aug 2009 07:49:40 -0700 (PDT)
In-Reply-To: <cbbf4b570908200744l5e206ea1hbb8fe5d439fbfc77@mail.gmail.com>
References: <2986c2f30908191632u74dcad9dt9073fc84eb7d849e@mail.gmail.com>
	 <480D7E03-6E9F-4917-BE31-A82D2A42D9C8@cse.unl.edu>
	 <cbbf4b570908200744l5e206ea1hbb8fe5d439fbfc77@mail.gmail.com>
Date: Thu, 20 Aug 2009 10:49:40 -0400
Message-ID: <2986c2f30908200749y553337b2xf75f39ed764ac744@mail.gmail.com>
Subject: Re: syslog-ng and hadoop
From: mike anderson <saidtherobot@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd5ca127e35f7047193dcb3
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd5ca127e35f7047193dcb3
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Yeah, that is interesting Edward. I don't need syslog-ng for any particular
reason, other than that I'm familiar with it. If there were another way to
get all my logs collated into one log file that would be great.
mike

On Thu, Aug 20, 2009 at 10:44 AM, Edward Capriolo <edlinuxguru@gmail.com>wrote:

> On Wed, Aug 19, 2009 at 11:50 PM, Brian Bockelman<bbockelm@cse.unl.edu>
> wrote:
> > Hey Mike,
> >
> > Yup.  We find the stock log4j needs two things:
> >
> > 1) Set the rootLogger manually.  The way 0.19.x has the root logger set
> up
> > breaks when adding new appenders.  I.e., do:
> >
> > log4j.rootLogger=INFO,SYSLOG,console,DRFA,EventCounter
> >
> > 2) Add the headers; otherwise log4j is not compatible with syslog:
> >
> > log4j.appender.SYSLOG=org.apache.log4j.net.SyslogAppender
> > log4j.appender.SYSLOG.facility=local0
> > log4j.appender.SYSLOG.layout=org.apache.log4j.PatternLayout
> > log4j.appender.SYSLOG.layout.ConversionPattern=%p %c{2}: %m%n
> > log4j.appender.SYSLOG.SyslogHost=red
> > log4j.appender.SYSLOG.threshold=ERROR
> > log4j.appender.SYSLOG.Header=true
> > log4j.appender.SYSLOG.FacilityPrinting=true
> >
> > Brian
> >
> > On Aug 19, 2009, at 6:32 PM, Mike Anderson wrote:
> >
> >> Has anybody had any luck setting up the log4j.properties file to send
> logs
> >> to a syslog-ng server?
> >> My log4j.properties excerpt:
> >> log4j.appender.SYSLOG=org.apache.log4j.net.SyslogAppender
> >> log4j.appender.SYSLOG.syslogHost=10.0.20.164
> >> log4j.appender.SYSLOG.layout=org.apache.log4j.PatternLayout
> >> log4j.appender.SYSLOG.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
> >> log4j.appender.SYSLOG.Facility=HADOOP
> >>
> >> and my syslog-ng.conf file running on 10.0.20.164
> >>
> >> source s_hadoop {
> >>       # message generated by Syslog-NG
> >>       internal();
> >>       # standard Linux log source (this is the default place for the
> >> syslog()
> >>       # function to send logs to)
> >>       unix-stream("/dev/log");
> >>       udp();
> >> };
> >> destination df_hadoop { file("/var/log/hadoop/hadoop.log");};
> >> filter f_hadoop {facility(hadoop);};
> >> log {
> >> source(s_hadoop);
> >> filter(f_hadoop);
> >> destination(df_hadoop);
> >> };
> >>
> >>
> >> Thanks in advance,
> >> Mike
> >
> >
>
> Mike slightly off topic but you can also run a Log 4J server which
> perfectly transports the messages fired off by LOG4j. The
> log4J->syslog loses/ changes some information. If anyone is interested
> in this let me know and I will write up something about it.
>

--000e0cd5ca127e35f7047193dcb3--

From common-user-return-16927-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 15:02:38 2009
Return-Path: <common-user-return-16927-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 14835 invoked from network); 20 Aug 2009 15:02:13 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 15:02:13 -0000
Received: (qmail 75628 invoked by uid 500); 20 Aug 2009 15:02:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 75571 invoked by uid 500); 20 Aug 2009 15:02:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 75560 invoked by uid 99); 20 Aug 2009 15:02:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 15:02:29 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 15:02:21 +0000
Received: by fxm25 with SMTP id 25so4267733fxm.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 08:02:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=kni87mmkGGkEAOEZuuRBlKK70FmWZmhKr36Qk1ljtN0=;
        b=wAWnDznwu24nUEXuRd2a3YMMAiwykLGKA2g6pBwlujvTVVrDyWD+f2JXDNK6G/TdpF
         NyZvHi3+JgYqtAqtudQ6EcsZSRDcSi85FtYd3cATqB5LROr7qKriXvbkQOBH5awxyaR+
         372urf/kdOob48b23M7mQViJ743K/8h4b9HoU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=EiOJDU0VJZra0ZYJbGPh0LlYypHRgF8dd2igAjQsdhcFsc0hFNfiSXOni6qu0QIrXd
         9kO3lzQlxz/k/BDWzCybqPk6GAyN71QxdY4J/UHsTbUAfqaut5EfWJEqh/P6ySz40Cz/
         zlahC5PNXsDGlrkGn9+qEZRiWIwwda/I8Byhg=
MIME-Version: 1.0
Received: by 10.239.144.79 with SMTP id n15mr614292hba.107.1250780519884; Thu, 
	20 Aug 2009 08:01:59 -0700 (PDT)
In-Reply-To: <4A8C6205.6000306@yahoo-inc.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
	 <4A8B8D11.8020008@yahoo-inc.com>
	 <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>
	 <ad681e7f0908190845j59dc22aet95e9af971efa8798@mail.gmail.com>
	 <cbbf4b570908190914j206797ecrc862d06b6eccbd37@mail.gmail.com>
	 <4A8C3D32.3010905@yahoo-inc.com>
	 <ad681e7f0908191324n1e04a72fo9ebbd436e89aef20@mail.gmail.com>
	 <4A8C6205.6000306@yahoo-inc.com>
Date: Thu, 20 Aug 2009 11:01:59 -0400
Message-ID: <ad681e7f0908200801r52a0baa4mfd71af42263d8174@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f7258e94684104719408e9
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f7258e94684104719408e9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

it's on s3. and it always happens.

Ananth T Sarathy


On Wed, Aug 19, 2009 at 4:35 PM, Raghu Angadi <rangadi@yahoo-inc.com> wrote:

> Ananth T. Sarathy wrote:
>
>> Also, I just want to clear... the delay seems to at the intial
>>
>> (read = in.read(buf))
>>
>
> It the file on HDFS (over S3) or S3?
>
> Does it always happen?
>
> Raghu.
>
>
>  after the first time into the loop it flies...
>>
>> Ananth T Sarathy
>>
>>
>> On Wed, Aug 19, 2009 at 1:58 PM, Raghu Angadi <rangadi@yahoo-inc.com>
>> wrote:
>>
>>  Edward Capriolo wrote:
>>>
>>>  On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo <
>>>> edlinuxguru@gmail.com
>>>>
>>>>> wrote:
>>>>>>
>>>>>  It would be as fast as underlying filesystem goes.
>>>>>
>>>>>> I would not agree with that statement. There is overhead.
>>>>>>>
>>>>>> You might be misinterpreting my comment. There is of course some over
>>> head
>>> (at the least the procedure calls).. depending on you underlying
>>> filesystem,
>>> there could be extra buffer copies and CRC overhead. But none of that
>>> explains transfer as slow as 1 MBps (if my interpretation of of results
>>> is
>>> correct).
>>>
>>> Raghu.
>>>
>>>
>>>

--001485f7258e94684104719408e9--

From common-user-return-16928-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 15:02:49 2009
Return-Path: <common-user-return-16928-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 15309 invoked from network); 20 Aug 2009 15:02:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 15:02:42 -0000
Received: (qmail 79535 invoked by uid 500); 20 Aug 2009 15:02:58 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 79475 invoked by uid 500); 20 Aug 2009 15:02:58 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 79465 invoked by uid 99); 20 Aug 2009 15:02:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 15:02:58 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 15:02:49 +0000
Received: by bwz10 with SMTP id 10so4246848bwz.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 08:02:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=+LIPbGOY8v0sKOwVuPEeBLn8kxfaYZ86hok06u89bmg=;
        b=beg6aWgbwUaYaHGXF+fhxktItxvGyasaM7OU9SK832SzmpjkOUixU8oEN9zpJZvVF6
         lFALH6xDnZ/gQIJeZCP2V2PFTSgMTz5pQkjfRbUOv0Ulqg5xLnbsYWu9ewfUTPd9bbup
         oD+kNiV+HFJDBM0gP2LTDVb9lKGufz+b/17pM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=v5usLQwM2xO/LM7VU7aOUxZAQZsGu+uPpwFU4B1iGlO2OeaBu9frYODiXo1o7g3E4z
         Dw7S6fYt/6IBopDCJ7XyYJOgo6WYaEmQ7BlLBLt4XyaNWu7zTvZL4tI7C4o6MJPCXT3r
         051vanbl+VbNCCTcQ1qZz2spSovrMSeYNOoJ4=
MIME-Version: 1.0
Received: by 10.239.168.211 with SMTP id l19mr682522hbe.119.1250780548823; 
	Thu, 20 Aug 2009 08:02:28 -0700 (PDT)
In-Reply-To: <C6B1AF0C.F322%scott@richrelevance.com>
References: <4A8C3D32.3010905@yahoo-inc.com>
	 <C6B1AF0C.F322%scott@richrelevance.com>
Date: Thu, 20 Aug 2009 11:02:28 -0400
Message-ID: <ad681e7f0908200802k36acf528mcb9b7b6acc0cd316@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636499e0d4dfd810471940a13
X-Virus-Checked: Checked by ClamAV on apache.org

--001636499e0d4dfd810471940a13
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

it's not really 1 mbps so much it takes 2 minutes to start doing the
reads.....

Ananth T Sarathy


On Wed, Aug 19, 2009 at 4:30 PM, Scott Carey <scott@richrelevance.com>wrote:

>
> On 8/19/09 10:58 AM, "Raghu Angadi" <rangadi@yahoo-inc.com> wrote:
>
> > Edward Capriolo wrote:
> >>> On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo
> >>> <edlinuxguru@gmail.com>wrote:
> >>>
> >>>>>> It would be as fast as underlying filesystem goes.
> >>>> I would not agree with that statement. There is overhead.
> >
> > You might be misinterpreting my comment. There is of course some over
> > head (at the least the procedure calls).. depending on you underlying
> > filesystem, there could be extra buffer copies and CRC overhead. But
> > none of that explains transfer as slow as 1 MBps (if my interpretation
> > of of results is correct).
> >
> > Raghu.
>
>
> Yes, there is nothing about distributing work for parallel execution that
> is
> going to make a single 20MB file transfer faster.   That is very slow, and
> should be on the order of a second or so, not multiple minutes.
>  Something else is wrong.
>
>
>

--001636499e0d4dfd810471940a13--

From common-user-return-16929-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 15:16:49 2009
Return-Path: <common-user-return-16929-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 21741 invoked from network); 20 Aug 2009 15:16:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 15:16:48 -0000
Received: (qmail 23979 invoked by uid 500); 20 Aug 2009 15:17:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 23877 invoked by uid 500); 20 Aug 2009 15:17:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 23867 invoked by uid 99); 20 Aug 2009 15:17:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 15:17:04 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of edlinuxguru@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 15:16:54 +0000
Received: by fxm25 with SMTP id 25so4276626fxm.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 08:16:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=NwkUJ4NeDDBR43B25y1ebfpbnh5OeXK1BMxvi+rVn90=;
        b=YdhBKJgo2Mo8+ZV0+g/kh0wvrpNIP+S0Z7KzW9StVZvvvpqtXZUrdvqWskNWbQSuTf
         AXXCXq5oJTxv6OF7h99mUmdlSrOFXjSHwl3jY89FZLcy/k9pldJt3Lm7r4UPXfiMCxtK
         bSQsGs+lQrBWXuM49wyrz/ENt1BejaYvKpOuQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=OOl41WOZ4eUN+1z5U3zQEGJkl0elbnHnSrqq3U8xRI0daW4hCTsUvUybCGc2lcEc81
         PKQxtKz7JVxwKm0Yc6lMLlSRhl4lLU0OKB2OVN3jGFnpk6xGq+9Ileqp+7/HSDMNMbBD
         PsOt/kuOicqVZ1yRhDg3sWKjR5c0yfKWfYB7s=
MIME-Version: 1.0
Received: by 10.239.168.157 with SMTP id k29mr729021hbe.67.1250781392202; Thu, 
	20 Aug 2009 08:16:32 -0700 (PDT)
In-Reply-To: <2986c2f30908200749y553337b2xf75f39ed764ac744@mail.gmail.com>
References: <2986c2f30908191632u74dcad9dt9073fc84eb7d849e@mail.gmail.com>
	 <480D7E03-6E9F-4917-BE31-A82D2A42D9C8@cse.unl.edu>
	 <cbbf4b570908200744l5e206ea1hbb8fe5d439fbfc77@mail.gmail.com>
	 <2986c2f30908200749y553337b2xf75f39ed764ac744@mail.gmail.com>
Date: Thu, 20 Aug 2009 11:16:32 -0400
Message-ID: <cbbf4b570908200816h493e7e04ue4c2679cb464d2cb@mail.gmail.com>
Subject: Re: syslog-ng and hadoop
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Thu, Aug 20, 2009 at 10:49 AM, mike anderson<saidtherobot@gmail.com> wro=
te:
> Yeah, that is interesting Edward. I don't need syslog-ng for any particul=
ar
> reason, other than that I'm familiar with it. If there were another way t=
o
> get all my logs collated into one log file that would be great.
> mike
>
> On Thu, Aug 20, 2009 at 10:44 AM, Edward Capriolo <edlinuxguru@gmail.com>=
wrote:
>
>> On Wed, Aug 19, 2009 at 11:50 PM, Brian Bockelman<bbockelm@cse.unl.edu>
>> wrote:
>> > Hey Mike,
>> >
>> > Yup. =A0We find the stock log4j needs two things:
>> >
>> > 1) Set the rootLogger manually. =A0The way 0.19.x has the root logger =
set
>> up
>> > breaks when adding new appenders. =A0I.e., do:
>> >
>> > log4j.rootLogger=3DINFO,SYSLOG,console,DRFA,EventCounter
>> >
>> > 2) Add the headers; otherwise log4j is not compatible with syslog:
>> >
>> > log4j.appender.SYSLOG=3Dorg.apache.log4j.net.SyslogAppender
>> > log4j.appender.SYSLOG.facility=3Dlocal0
>> > log4j.appender.SYSLOG.layout=3Dorg.apache.log4j.PatternLayout
>> > log4j.appender.SYSLOG.layout.ConversionPattern=3D%p %c{2}: %m%n
>> > log4j.appender.SYSLOG.SyslogHost=3Dred
>> > log4j.appender.SYSLOG.threshold=3DERROR
>> > log4j.appender.SYSLOG.Header=3Dtrue
>> > log4j.appender.SYSLOG.FacilityPrinting=3Dtrue
>> >
>> > Brian
>> >
>> > On Aug 19, 2009, at 6:32 PM, Mike Anderson wrote:
>> >
>> >> Has anybody had any luck setting up the log4j.properties file to send
>> logs
>> >> to a syslog-ng server?
>> >> My log4j.properties excerpt:
>> >> log4j.appender.SYSLOG=3Dorg.apache.log4j.net.SyslogAppender
>> >> log4j.appender.SYSLOG.syslogHost=3D10.0.20.164
>> >> log4j.appender.SYSLOG.layout=3Dorg.apache.log4j.PatternLayout
>> >> log4j.appender.SYSLOG.layout.ConversionPattern=3D%d{ISO8601} %p %c: %=
m%n
>> >> log4j.appender.SYSLOG.Facility=3DHADOOP
>> >>
>> >> and my syslog-ng.conf file running on 10.0.20.164
>> >>
>> >> source s_hadoop {
>> >> =A0 =A0 =A0 # message generated by Syslog-NG
>> >> =A0 =A0 =A0 internal();
>> >> =A0 =A0 =A0 # standard Linux log source (this is the default place fo=
r the
>> >> syslog()
>> >> =A0 =A0 =A0 # function to send logs to)
>> >> =A0 =A0 =A0 unix-stream("/dev/log");
>> >> =A0 =A0 =A0 udp();
>> >> };
>> >> destination df_hadoop { file("/var/log/hadoop/hadoop.log");};
>> >> filter f_hadoop {facility(hadoop);};
>> >> log {
>> >> source(s_hadoop);
>> >> filter(f_hadoop);
>> >> destination(df_hadoop);
>> >> };
>> >>
>> >>
>> >> Thanks in advance,
>> >> Mike
>> >
>> >
>>
>> Mike slightly off topic but you can also run a Log 4J server which
>> perfectly transports the messages fired off by LOG4j. The
>> log4J->syslog loses/ changes some information. If anyone is interested
>> in this let me know and I will write up something about it.
>>
>

Mike,
I just put this up for you.
http://www.edwardcapriolo.com/wiki/en/Log4j_Server

All of the functionality is in the class
org.apache.log4j.net.SocketServer which ships as part of Log4j.

I pretty much followed this http://timarcher.com/node/10

I started with the syslog appender but it had some quirks. Mostly the
syslog appender can only write a syslog so it loses some information.
The Log4jserver transfers the log.error("whatever" ) as is and can
handle it on the server end though the servers logging properties.
Cool stuff.

From common-user-return-16930-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 16:01:57 2009
Return-Path: <common-user-return-16930-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 40701 invoked from network); 20 Aug 2009 16:01:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 16:01:52 -0000
Received: (qmail 35460 invoked by uid 500); 20 Aug 2009 16:02:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35271 invoked by uid 500); 20 Aug 2009 16:02:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35244 invoked by uid 99); 20 Aug 2009 16:02:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 16:02:04 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bharathvissapragada1990@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 16:00:57 +0000
Received: by vws40 with SMTP id 40so4402644vws.2
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 09:00:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:sender:received:from:date
         :x-google-sender-auth:message-id:subject:to:content-type;
        bh=6ZB8S7yucRszKxyMtyC2KVK4ibYnjjLsG2MEXYWkB+4=;
        b=g6B5erz2QywQFMQJENiH6Y6rOXR3ERYWu8bKawRKkdap09lZpaPTxI2bkGHo1f/0UX
         /VcYhZxAIrdnxtfwjV1Mnuf1Ib1M3NmdH/VQVmu7Jam6037K1VDKybu7swd7QheN3OyP
         OVlQ8drQYWKJr6e+/4cMWg1zJVMcOLsVcHn8U=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:sender:from:date:x-google-sender-auth:message-id
         :subject:to:content-type;
        b=X7zQvphsa8kqHrK4Ma2gsKm+BZvvMbomH/j+jiWVXvs1cHMwb+glJRXlGOxxTfeDxD
         is/dGbMBtbv9sptc7cHtXhYKLSgPhh6FaSZtbWtnA+OOXXApwlw3o36NII7vx3dF8NAS
         oRLkBpqEguQqynANufPiwCwcYWMTttm1x76E8=
MIME-Version: 1.0
Sender: bharathvissapragada1990@gmail.com
Received: by 10.229.15.1 with SMTP id i1mr3171256qca.30.1250784036283; Thu, 20 
	Aug 2009 09:00:36 -0700 (PDT)
From: bharath vissapragada <bharat_v@students.iiit.ac.in>
Date: Thu, 20 Aug 2009 21:30:16 +0530
X-Google-Sender-Auth: 6689cabf47c20e36
Message-ID: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com>
Subject: MR job scheduler
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175770ea2c66d7047194da2d
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175770ea2c66d7047194da2d
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi all,

Can anyone tell me how the MR scheduler schedule the MR jobs?
How does it decide where t create MAP tasks and how many to create.
Once the MAP tasks are over how does it decide to move the keys to the
reducer efficiently(minimizing the data movement across the network).
Is there any doc available which describes this scheduling process quite
efficiently

Kindly respond to this mail.

Thanks in advance.

--0015175770ea2c66d7047194da2d--

From common-user-return-16931-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 16:02:00 2009
Return-Path: <common-user-return-16931-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 40789 invoked from network); 20 Aug 2009 16:01:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 16:01:52 -0000
Received: (qmail 35496 invoked by uid 500); 20 Aug 2009 16:02:05 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35273 invoked by uid 500); 20 Aug 2009 16:02:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35259 invoked by uid 500); 20 Aug 2009 16:02:04 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 35254 invoked by uid 99); 20 Aug 2009 16:02:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 16:02:04 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bharathvissapragada1990@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 15:59:40 +0000
Received: by vws40 with SMTP id 40so4401337vws.2
        for <core-user@hadoop.apache.org>; Thu, 20 Aug 2009 08:59:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:from:date:message-id
         :subject:to:content-type;
        bh=H3wfIBDcEcBOP58Qi9/VqV+vnrjIpFWQSrE14r9tZHc=;
        b=cz056re8iNIsQmkfeec5IjyrfYggn7Ry/OYu20DXwKAxWiE/zWbfs7EDQLM7oIDT7L
         UubY+3kmTCQu481Pgyyy4otLeF+j5BXENi5bMTYwGQ0SYXDzmveO1hLLsFdu3z3g2/S7
         t4G8FMZl8ZAKKVFUuXZJM5hPkbL3KzC3lnfNA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:from:date:message-id:subject:to:content-type;
        b=V8DlGohg2fozQmoONYlkpEy+fwNUrLVuA9Z8SAhWjjpMWRkL2sPz8rbZGFRzjzyhPl
         Iv+rzW5gJ7ZttXQI0Edw59Suj3UWKzpjOBvEAtnbj1ZNUghRUxAmJx7XDSEyLZxQU+n+
         5JZ8Ifcdaml7Hw5fyFFNyOUWYWVmLFknrlJNM=
MIME-Version: 1.0
Received: by 10.229.54.143 with SMTP id q15mr3135223qcg.74.1250783959222; Thu, 
	20 Aug 2009 08:59:19 -0700 (PDT)
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Thu, 20 Aug 2009 21:28:59 +0530
Message-ID: <73d592f60908200858v2ae9b314hcd7a8a18c46d2956@mail.gmail.com>
Subject: MR job scheduler
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00151773e2d6948d40047194d55c
X-Virus-Checked: Checked by ClamAV on apache.org

--00151773e2d6948d40047194d55c
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi all,

Can anyone tell me how the MR scheduler schedule the MR jobs?
How does it decide where t create MAP tasks and how many to create.
Once the MAP tasks are over how does it decide to move the keys to the
reducer efficiently(minimizing the data movement across the network).
Is there any doc available which describes this scheduling process quite
efficiently

Kindly respond to this mail.

Thanks in advance.

--00151773e2d6948d40047194d55c--

From common-user-return-16932-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 16:12:29 2009
Return-Path: <common-user-return-16932-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 45495 invoked from network); 20 Aug 2009 16:12:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 16:12:28 -0000
Received: (qmail 53008 invoked by uid 500); 20 Aug 2009 16:12:45 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52938 invoked by uid 500); 20 Aug 2009 16:12:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52928 invoked by uid 99); 20 Aug 2009 16:12:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 16:12:45 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.86.89.67] (HELO elasmtp-scoter.atl.sa.earthlink.net) (209.86.89.67)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 16:12:35 +0000
Received: from [99.39.4.172] (helo=gbj-laptop.earthlink.net)
	by elasmtp-scoter.atl.sa.earthlink.net with esmtpa (Exim 4.67)
	(envelope-from <hadoop@blackbirdsystems.net>)
	id 1MeAFK-00020m-C6
	for common-user@hadoop.apache.org; Thu, 20 Aug 2009 12:12:14 -0400
From: hadoop@blackbirdsystems.net (George Jahad)
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
Message-ID: <19085.30171.655759.240954@gargle.gargle.HOWL>
Date: Thu, 20 Aug 2009 09:12:11 -0700
To: common-user@hadoop.apache.org
Subject: Re: submitting multiple small jobs simultaneously
In-Reply-To: <4A8C42B7.7020804@yahoo-inc.com>
References: <19084.7358.404199.841876@gargle.gargle.HOWL>
	<4A8C42B7.7020804@yahoo-inc.com>
X-Mailer: VM 8.0.12 under 23.0.91.1 (i486-pc-linux-gnu)
X-ELNK-Trace: 90d8f6c2ea23b4a3e5331016acda17f9b6b813f45079831075b0c02b4639e6ca350badd9bab72f9c350badd9bab72f9c350badd9bab72f9c350badd9bab72f9c
X-Originating-IP: 99.39.4.172
X-Virus-Checked: Checked by ClamAV on apache.org

On Wednesday, August 19, 2009 11:21 
Jakob Homan wrote:
 > George-
 >     You can certainly submit jobs asynchronously via the 
 > JobClient.submitJob() method 
 > (http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/mapred/JobClient.html). 
 >   This will return a handle (a RunningJob instance) that you can poll 
 > for  completion.  This is what the JobClient.runJob() method does.
 > 
 > You can submit multiple jobs using the submitJob() method and wait for 
 > all of them to finish through their RunningJobs, as it seems you want to 
 > do.
 > 
 > Is this what you're looking for?

Thanks for the reply Jakob.

I was hoping for a bit more. I am familiar with submitJob(), and was
about to write something up using it, when I thought maybe someone on
the list has a template.   Seemed like a fairly common need.  Maybe
not though.  

Thanks again,
George


From common-user-return-16933-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 16:26:41 2009
Return-Path: <common-user-return-16933-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 52660 invoked from network); 20 Aug 2009 16:26:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 16:26:41 -0000
Received: (qmail 82433 invoked by uid 500); 20 Aug 2009 16:26:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82356 invoked by uid 500); 20 Aug 2009 16:26:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 33822 invoked by uid 99); 20 Aug 2009 15:58:23 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hkumar.arora@gmail.com designates 209.85.223.176 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=kycNp2u5E6gDH2z9F8GF7fo7pjZpttZGkaEd3Xq/uwQ=;
        b=XT7jgUdBQPxP8OLioOvZqVj+BghyDPOoQAaR2ElqC4d1C/wh0m/XYj0fL0qgiLd/XL
         /TUIRIdhX0tkXwWm12j5viLzXZJbrw/4nGB/8tJwkPGQ77TNkr4UYTJbfowfmEPIw/uU
         lsPSJ4k+kCLuUrS9Y4DDbsMT0R2+v96SJNFck=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=vkojFHk6BkMtoZ87MNNk6IDlHf7QQ+Y+sSloDbX1anfm8JDSEEbBGxPPIaEVyCNFMJ
         jK4nOCwI7vhptJ//WnREvwcIvE23+okl9+Jh2o6K/WpO3psqsFjOdd+02zb+Y4NL2vRJ
         2SD4vaJnLw0iyB0g55QfbIvQGismYzAX/Okf0=
MIME-Version: 1.0
In-Reply-To: <e497591c0908200654kb6ba97gb2b8a63fc2d263d6@mail.gmail.com>
References: <e497591c0908200654kb6ba97gb2b8a63fc2d263d6@mail.gmail.com>
Date: Thu, 20 Aug 2009 18:57:49 +0300
Message-ID: <e497591c0908200857h3705a02eh62a31f213bb7f242@mail.gmail.com>
Subject: Invalid argument for option USER_DATA_FILE
From: Harshit Kumar <hkumar.arora@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0022152d7bf938568f047194d0c0
X-Virus-Checked: Checked by ClamAV on apache.org

--0022152d7bf938568f047194d0c0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hi
When I try to execute *hadoop-ec2 launch-cluster test-cluster 2*, it
executes, but keep waiting at "Waiting for instance to start", find below
the exact display as it shows on my screen


$ bin/hadoop-ec2 launch-cluster test-cluster 2
Testing for existing master in group: test-cluster
Creating group test-cluster-master
GROUP   test-cluster-master     Group for Hadoop Master.
GROUP           test-cluster-master
PERMISSION              test-cluster-master     ALLOWS  all
FROM    USER    5282-1142-6451  GRPNAME test-cluster-master
GROUP           test-cluster-master
PERMISSION              test-cluster-master     ALLOWS  tcp     22      22
FROM    CIDR    0.0.0.0/0
GROUP           test-cluster-master
PERMISSION              test-cluster-master     ALLOWS  tcp     50030
50030
FROM    CIDR    0.0.0.0/0
GROUP           test-cluster-master
PERMISSION              test-cluster-master     ALLOWS  tcp     50060
50060
FROM    CIDR    0.0.0.0/0
Creating group test-cluster
GROUP   test-cluster    Group for Hadoop Slaves.
GROUP           test-cluster
PERMISSION              test-cluster    ALLOWS  all                     FROM
USER    5282-1142-6451  GRPNAME test-cluster
GROUP           test-cluster
PERMISSION              test-cluster    ALLOWS  tcp     22      22      FROM
CIDR    0.0.0.0/0
GROUP           test-cluster
PERMISSION              test-cluster    ALLOWS  tcp     50030   50030   FROM
CIDR    0.0.0.0/0
GROUP           test-cluster
PERMISSION              test-cluster    ALLOWS  tcp     50060   50060   FROM
CIDR    0.0.0.0/0
GROUP           test-cluster-master
PERMISSION              test-cluster-master     ALLOWS  all
FROM    USER    5282-1142-6451  GRPNAME test-cluster
GROUP           test-cluster
PERMISSION              test-cluster    ALLOWS  all                     FROM
USER    5282-1142-6451  GRPNAME test-cluster-master
Starting master with AMI ami-fa6a8e93
Invalid argument for option '-f, --user-data-file DATA-FILE':
'/home/bike/hadoop-0.19.2/src/contrib/ec2/bin/hadoop-ec2-init-remote.sh' (-h
for usage)
Waiting for instance  to start
...............................................................................
...............................................................................

It just keeps on producing new dots, thats it and i guess this process will
never finish,

I tried hours to search for the solution on the net, but unsuccessful.

I will appreciate if anyone can  help me with this problem?

H. Kumar
Phone(Mobile): +82-10-2892-9663
Phone(Office): +82-31-
skype: harshit900
Blog: http://harshitkumar.wordpress.com
Website: http:/kumarharmuscat.tripod.com

--0022152d7bf938568f047194d0c0--

From common-user-return-16934-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 16:31:55 2009
Return-Path: <common-user-return-16934-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 55945 invoked from network); 20 Aug 2009 16:31:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 16:31:55 -0000
Received: (qmail 89604 invoked by uid 500); 20 Aug 2009 16:32:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 89525 invoked by uid 500); 20 Aug 2009 16:32:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 89515 invoked by uid 99); 20 Aug 2009 16:32:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 16:32:11 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [64.78.17.18] (HELO EXHUB018-3.exch018.msoutlookonline.net) (64.78.17.18)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 16:32:01 +0000
Received: from EXVMBX018-1.exch018.msoutlookonline.net ([64.78.17.47]) by
 EXHUB018-3.exch018.msoutlookonline.net ([64.78.17.18]) with mapi; Thu, 20 Aug
 2009 09:31:39 -0700
From: Scott Carey <scott@richrelevance.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Thu, 20 Aug 2009 09:31:37 -0700
Subject: Re: Faster alternative to FSDataInputStream
Thread-Topic: Faster alternative to FSDataInputStream
Thread-Index: Acohp1GaLiP39S3TT9Wn9g0NDT1eSgADF5yy
Message-ID: <C6B2C879.F417%scott@richrelevance.com>
In-Reply-To: <ad681e7f0908200802k36acf528mcb9b7b6acc0cd316@mail.gmail.com>
Accept-Language: en-US
Content-Language: en
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

If it always takes a very long time to start transferring data, get a few
stack dumps (jstack or kill -e) during this period to see what it is doing
during this time.

Most likely, the client is doing nothing but waiting on the remote side.


On 8/20/09 8:02 AM, "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com> wrote:

> it's not really 1 mbps so much it takes 2 minutes to start doing the
> reads.....
>=20
> Ananth T Sarathy
>=20
>=20
> On Wed, Aug 19, 2009 at 4:30 PM, Scott Carey <scott@richrelevance.com>wro=
te:
>=20
>>=20
>> On 8/19/09 10:58 AM, "Raghu Angadi" <rangadi@yahoo-inc.com> wrote:
>>=20
>>> Edward Capriolo wrote:
>>>>> On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo
>>>>> <edlinuxguru@gmail.com>wrote:
>>>>>=20
>>>>>>>> It would be as fast as underlying filesystem goes.
>>>>>> I would not agree with that statement. There is overhead.
>>>=20
>>> You might be misinterpreting my comment. There is of course some over
>>> head (at the least the procedure calls).. depending on you underlying
>>> filesystem, there could be extra buffer copies and CRC overhead. But
>>> none of that explains transfer as slow as 1 MBps (if my interpretation
>>> of of results is correct).
>>>=20
>>> Raghu.
>>=20
>>=20
>> Yes, there is nothing about distributing work for parallel execution tha=
t
>> is
>> going to make a single 20MB file transfer faster.   That is very slow, a=
nd
>> should be on the order of a second or so, not multiple minutes.
>>  Something else is wrong.
>>=20
>>=20
>>=20
>=20


From common-user-return-16935-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 16:49:02 2009
Return-Path: <common-user-return-16935-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 64036 invoked from network); 20 Aug 2009 16:49:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 16:49:02 -0000
Received: (qmail 20375 invoked by uid 500); 20 Aug 2009 16:49:18 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20308 invoked by uid 500); 20 Aug 2009 16:49:18 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20298 invoked by uid 99); 20 Aug 2009 16:49:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 16:49:18 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ananth.t.sarathy@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 16:49:09 +0000
Received: by bwz10 with SMTP id 10so22868bwz.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 09:48:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=49k8I9AA0JfIcBuLZMy2Fs7gyF/mm1RQ6AfWaN5i91Q=;
        b=wgZJpFt6DLkfrUvhjOPnjw4NO+LIancZrSwqOpAwSuEIcyfGRSAaZuQqQSzeus+pPx
         WlKhmQF3+eEqfwZYsSNbjaSu2USK8AEjz2Ahng1c/Q8Bvc8lL4VLs9UGJJC0ssJWRR+Z
         8/463gLTvT3iXFy+5tBXR7uFqpDJSZ4AkP2GE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=b10Uj+RiulxXAoexs+FLDISHaYPRKvEdzdR6Nj2ewDrNXRxN2QPtv8e/pNt08L/wy6
         4yWtFPsFmOfi5VtcIy3ER/vAJy3XSqETGhpDwgU/Mx+dyGuhQnocznv7yRL4OYutANkL
         p9djfRU8keIEMWqBEVO2ThMFL7l6cp7D+O44s=
MIME-Version: 1.0
Received: by 10.239.179.99 with SMTP id c35mr724682hbg.161.1250786928540; Thu, 
	20 Aug 2009 09:48:48 -0700 (PDT)
In-Reply-To: <C6B2C879.F417%scott@richrelevance.com>
References: <ad681e7f0908200802k36acf528mcb9b7b6acc0cd316@mail.gmail.com>
	 <C6B2C879.F417%scott@richrelevance.com>
Date: Thu, 20 Aug 2009 12:48:48 -0400
Message-ID: <ad681e7f0908200948o35f2d2e3g6dc5a25875837605@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f7d8de90bddc047195865d
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f7d8de90bddc047195865d
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

ok.. i seems that's the case.  that seems kind of  selfdefeating though.

Ananth T Sarathy


On Thu, Aug 20, 2009 at 12:31 PM, Scott Carey <scott@richrelevance.com>wrote:

> If it always takes a very long time to start transferring data, get a few
> stack dumps (jstack or kill -e) during this period to see what it is doing
> during this time.
>
> Most likely, the client is doing nothing but waiting on the remote side.
>
>
> On 8/20/09 8:02 AM, "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
> wrote:
>
> > it's not really 1 mbps so much it takes 2 minutes to start doing the
> > reads.....
> >
> > Ananth T Sarathy
> >
> >
> > On Wed, Aug 19, 2009 at 4:30 PM, Scott Carey <scott@richrelevance.com
> >wrote:
> >
> >>
> >> On 8/19/09 10:58 AM, "Raghu Angadi" <rangadi@yahoo-inc.com> wrote:
> >>
> >>> Edward Capriolo wrote:
> >>>>> On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo
> >>>>> <edlinuxguru@gmail.com>wrote:
> >>>>>
> >>>>>>>> It would be as fast as underlying filesystem goes.
> >>>>>> I would not agree with that statement. There is overhead.
> >>>
> >>> You might be misinterpreting my comment. There is of course some over
> >>> head (at the least the procedure calls).. depending on you underlying
> >>> filesystem, there could be extra buffer copies and CRC overhead. But
> >>> none of that explains transfer as slow as 1 MBps (if my interpretation
> >>> of of results is correct).
> >>>
> >>> Raghu.
> >>
> >>
> >> Yes, there is nothing about distributing work for parallel execution
> that
> >> is
> >> going to make a single 20MB file transfer faster.   That is very slow,
> and
> >> should be on the order of a second or so, not multiple minutes.
> >>  Something else is wrong.
> >>
> >>
> >>
> >
>
>

--001485f7d8de90bddc047195865d--

From common-user-return-16936-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 17:15:36 2009
Return-Path: <common-user-return-16936-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80547 invoked from network); 20 Aug 2009 17:15:36 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 17:15:36 -0000
Received: (qmail 66231 invoked by uid 500); 20 Aug 2009 17:15:52 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 66157 invoked by uid 500); 20 Aug 2009 17:15:52 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 66147 invoked by uid 99); 20 Aug 2009 17:15:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 17:15:52 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 17:15:41 +0000
Received: from SNV-EXPF01.ds.corp.yahoo.com (snv-expf01.ds.corp.yahoo.com [207.126.227.250])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7KHElT5094794
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 10:14:47 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=ruZDVRRhijfZf29WPB4jmqTrEdBA+ewtDbQILnkwKXt6uZFCooYYCOvLeGjmIyfC
Received: from SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.87]) by SNV-EXPF01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Thu, 20 Aug 2009 10:14:46 -0700
Received: from 10.72.112.117 ([10.72.112.117]) by SNV-EXVS09.ds.corp.yahoo.com ([207.126.227.84]) via Exchange Front-End Server snv-webmail.corp.yahoo.com ([207.126.227.60]) with Microsoft Exchange Server HTTP-DAV ;
 Thu, 20 Aug 2009 17:14:17 +0000
User-Agent: Microsoft-Entourage/12.20.0.090605
Date: Thu, 20 Aug 2009 10:14:17 -0700
Subject: Re: How to deal with "too many fetch failures"?
From: Koji Noguchi <knoguchi@yahoo-inc.com>
To: <common-user@hadoop.apache.org>
Message-ID: <C6B2D279.172E0%knoguchi@yahoo-inc.com>
Thread-Topic: How to deal with "too many fetch failures"?
Thread-Index: AcohuaXusKDiwlDc7UqbHMpGR/NsPg==
In-Reply-To: <314098690908192359y27fe344ci62e715b10c0a5194@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-OriginalArrivalTime: 20 Aug 2009 17:14:46.0988 (UTC) FILETIME=[B7CE08C0:01CA21B9]
X-Virus-Checked: Checked by ClamAV on apache.org

Probably unrelated to your problem, but one extreme case I've seen,
a user's job with large gzip inputs (non-splittable),
20 mappers 800 reducers. Each map outputted like 20G.
Too many reducers were hitting a single node as soon as a mapper finished.

I think we tried something like

mapred.reduce.parallel.copies=1
(to reduce number of reducer copier threads)
mapred.reduce.slowstart.completed.maps=1.0
(so that reducers would have 20 mappers to pull from, instead of 800
reducers hitting 1 mapper node as soon as it finishes.)


Koji

On 8/19/09 11:59 PM, "Jason Venner" <jason.hadoop@gmail.com> wrote:

> The number 1 cause of this is something that causes a connection to get a
> map output to fail. I have seen:
> 1) firewall
> 2) misconfigured ip addresses (ie: the task tracker attempting the fetch
> received an incorrect ip address when it looked up the name of the
> tasktracker with the map segment)
> 3) rare, the http server on the serving tasktracker is overloaded due to
> insufficient threads or listen backlog, this can happen if the number of
> fetches per reduce is large and the number of reduces or the number of maps
> is very large
> 
> There are probably other cases, this recently happened to me when I had 6000
> maps and 20 reducers on a 10 node cluster, which I believe was case 3 above.
> Since I didn't actually need to reduce ( I got my summary data via counters
> in the map phase) I never re-tuned the cluster.
> 
> On Wed, Aug 19, 2009 at 11:25 PM, Ted Dunning <ted.dunning@gmail.com> wrote:
> 
>> I think that the problem that I am remembering was due to poor recovery
>> from
>> this problem.  The underlying fault is likely due to poor connectivity
>> between your machines.  Test that all members of your cluster can access
>> all
>> others on all ports used by hadoop.
>> 
>> See here for hints: http://markmail.org/message/lgafou6d434n2dvx
>> 
>> On Wed, Aug 19, 2009 at 10:39 PM, yang song <hadoop.inifok@gmail.com>
>> wrote:
>> 
>>>    Thank you Ted. Update current cluster is a huge work, we don't want to
>>> do so. Could you tell me how 0.19.1 causes certain failures in detail?
>>>    Thanks again.
>>> 
>>> 2009/8/20 Ted Dunning <ted.dunning@gmail.com>
>>> 
>>>> I think I remember something about 19.1 in which certain failures would
>>>> cause this.  Consider using an updated 19 or moving to 20 as well.
>>>> 
>>>> On Wed, Aug 19, 2009 at 5:19 AM, yang song <hadoop.inifok@gmail.com>
>>>> wrote:
>>>> 
>>>>> I'm sorry, the version is 0.19.1
>>>>> 
>>>>> 
>>>> 
>>> 
>> 
>> 
>> 
>> --
>> Ted Dunning, CTO
>> DeepDyve
>> 
> 
> 


From common-user-return-16937-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 17:25:41 2009
Return-Path: <common-user-return-16937-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 98514 invoked from network); 20 Aug 2009 17:25:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 17:25:41 -0000
Received: (qmail 83593 invoked by uid 500); 20 Aug 2009 17:25:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 83518 invoked by uid 500); 20 Aug 2009 17:25:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 83508 invoked by uid 99); 20 Aug 2009 17:25:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 17:25:57 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [64.78.17.17] (HELO EXHUB018-2.exch018.msoutlookonline.net) (64.78.17.17)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 17:25:47 +0000
Received: from EXVMBX018-1.exch018.msoutlookonline.net ([64.78.17.47]) by
 EXHUB018-2.exch018.msoutlookonline.net ([64.78.17.17]) with mapi; Thu, 20 Aug
 2009 10:25:26 -0700
From: Scott Carey <scott@richrelevance.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Thu, 20 Aug 2009 10:25:22 -0700
Subject: Re: Faster alternative to FSDataInputStream
Thread-Topic: Faster alternative to FSDataInputStream
Thread-Index: AcohtivEHi/2Jbo7QNK5Vq76Wto3DgABQaKk
Message-ID: <C6B2D512.F42E%scott@richrelevance.com>
In-Reply-To: <ad681e7f0908200948o35f2d2e3g6dc5a25875837605@mail.gmail.com>
Accept-Language: en-US
Content-Language: en
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org


On 8/20/09 9:48 AM, "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com> wrote:

> ok.. i seems that's the case.  that seems kind of  selfdefeating though.
>=20
> Ananth T Sarathy

Then something is wrong with S3.  It may be misconfigured, or just poor
performance.  I have no experience with S3 but 20 seconds to connect
(authenticate?) and open a file seems very slow for any file system.

>=20
>=20
> On Thu, Aug 20, 2009 at 12:31 PM, Scott Carey <scott@richrelevance.com>wr=
ote:
>=20
>> If it always takes a very long time to start transferring data, get a fe=
w
>> stack dumps (jstack or kill -e) during this period to see what it is doi=
ng
>> during this time.
>>=20
>> Most likely, the client is doing nothing but waiting on the remote side.
>>=20
>>=20
>> On 8/20/09 8:02 AM, "Ananth T. Sarathy" <ananth.t.sarathy@gmail.com>
>> wrote:
>>=20
>>> it's not really 1 mbps so much it takes 2 minutes to start doing the
>>> reads.....
>>>=20
>>> Ananth T Sarathy
>>>=20
>>>=20
>>> On Wed, Aug 19, 2009 at 4:30 PM, Scott Carey <scott@richrelevance.com
>>> wrote:
>>>=20
>>>>=20
>>>> On 8/19/09 10:58 AM, "Raghu Angadi" <rangadi@yahoo-inc.com> wrote:
>>>>=20
>>>>> Edward Capriolo wrote:
>>>>>>> On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo
>>>>>>> <edlinuxguru@gmail.com>wrote:
>>>>>>>=20
>>>>>>>>>> It would be as fast as underlying filesystem goes.
>>>>>>>> I would not agree with that statement. There is overhead.
>>>>>=20
>>>>> You might be misinterpreting my comment. There is of course some over
>>>>> head (at the least the procedure calls).. depending on you underlying
>>>>> filesystem, there could be extra buffer copies and CRC overhead. But
>>>>> none of that explains transfer as slow as 1 MBps (if my interpretatio=
n
>>>>> of of results is correct).
>>>>>=20
>>>>> Raghu.
>>>>=20
>>>>=20
>>>> Yes, there is nothing about distributing work for parallel execution
>> that
>>>> is
>>>> going to make a single 20MB file transfer faster.   That is very slow,
>> and
>>>> should be on the order of a second or so, not multiple minutes.
>>>>  Something else is wrong.
>>>>=20
>>>>=20
>>>>=20
>>>=20
>>=20
>>=20
>=20


From common-user-return-16938-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 17:32:09 2009
Return-Path: <common-user-return-16938-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 17953 invoked from network); 20 Aug 2009 17:32:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 17:32:09 -0000
Received: (qmail 92965 invoked by uid 500); 20 Aug 2009 17:32:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 92892 invoked by uid 500); 20 Aug 2009 17:32:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 89775 invoked by uid 500); 20 Aug 2009 17:30:36 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jnekanayake@gmail.com designates 209.85.216.190 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:from:to:cc:subject:date
         :message-id:mime-version:content-type:x-mailer:thread-index
         :content-language;
        bh=GHsK04IZL1gIGdjpuORjccfn8c1K7+/nRnAwjbewMfI=;
        b=UqEPkUBAFBtD6MQmSdeCq+BDRagd1+4g5E32X/hLWphChgIXdMBWkIPeoBYTsXI9HU
         6bm9VVRzu4PmD6yfybH94YhCZPta/1IFlgp4MgZx6YahFjLcxCmamV+ICbOHUfj9PUTD
         XLTmaUXHipC+XwfhYtKTmbhNoFwPbgZ5/+Yiw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=from:to:cc:subject:date:message-id:mime-version:content-type
         :x-mailer:thread-index:content-language;
        b=Ot0RAALnzfAnG5MY9onRGCXg+1/GtwC5XwUseBKulGzO9RMprrvB1iHP2Zulszq4SD
         05AdS44dv+pMItlpBAeJlgxS6BjRwckvQm5lTQJ+p78Yhq06AkGCAeKP4XQx+dCVcdrw
         rMkFvEh1sUHxRjhVcV3XbVCDPG/5OQXJY0kwI=
From: "Jaliya Ekanayake" <jnekanayake@gmail.com>
To: <core-dev@hadoop.apache.org>,
	<core-user@hadoop.apache.org>
Cc: <spodxx@gmail.com>
Subject: Re: Using Hadoop with executables and binary data
Date: Thu, 20 Aug 2009 10:29:55 -0700
Message-ID: <002c01ca21bb$d897d2f0$89c778d0$@com>
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----=_NextPart_000_002D_01CA2181.2C38FAF0"
X-Mailer: Microsoft Office Outlook 12.0
Thread-Index: Acohu9VE1rYtUT3iQd6e2asmoWpPCQ==
Content-Language: en-us
X-Virus-Checked: Checked by ClamAV on apache.org

------=_NextPart_000_002D_01CA2181.2C38FAF0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: 7bit

Hi Stefan,

 

I am sorry, for the late reply. Somehow the response email has slipped my
eyes.

Could you explain a bit on how to use Hadoop streaming with binary data
formats.

I can see, explanations on using it with text data formats, but not for
binary files.


Thank you,

Jaliya

Stefan Podkowinski
Mon, 10 Aug 2009 01:40:05 -0700

Jaliya,
 
did you consider Hadoop Streaming for your case?
http://wiki.apache.org/hadoop/HadoopStreaming
 
 
On Wed, Jul 29, 2009 at 8:35 AM, Jaliya
Ekanayake<jekan...@cs.indiana.edu> wrote:
> Dear Hadoop devs,
> 
> 
> 
> Please help me to figure out a way to program the following problem using
> Hadoop.
> 
> I have a program which I need to invoke in parallel using Hadoop. The
> program takes an input file(binary) and produce an output file (binary)
> 
> 
> 
> Input.bin ->prog.exe-> output.bin
> 
> 
> 
> The input data set is about 1TB in size. Each input data file is about
33MB
> in size. (So I have about 31000 files)
> 
> The output binary file is about 9KBs in size.
> 
> 
> 
> I have implemented this program using Hadoop in the following way.
> 
> 
> 
> I keep the input data in a shared parallel file system (Lustre File
System).
> 
> Then, I collect the input file names and write them to a collection of
files
> in HDFS (let's say hdfs_input_0.txt ..).
> 
> Each hdfs_input file contains roughly the equal number of files URIs to
the
> original input file.
> 
> The map task, simply take a string Value which is a URI to an original
input
> data file and execute the program as an external program.
> 
> The output of the program is also written to the shared file system
(Lustre
> File System).
> 
> 
> 
> The problem in this approach is I am not utilizing the true benefit of
> MapReduce. The use of local disks.
> 
> Could  you please suggest me a way to use local disks for the above
> problem.?
> 
> 
> 
> I thought, of the following way, but would like to verify from you if
there
> is a better way.
> 
> 
> 
> 1.       Upload the original data files in HDFS
> 
> 2.       In the map task, read the data file as an binary object.
> 
> 3.       Save it in the local file system.
> 
> 4.       Call the executable
> 
> 5.       Push the output from the local file system to HDFS.
> 
> 
> 
> Any suggestion is greatly appreciated.
> 
> 
> Thank you,
> 
> Jaliya
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 

 


------=_NextPart_000_002D_01CA2181.2C38FAF0--


From common-user-return-16939-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 17:37:30 2009
Return-Path: <common-user-return-16939-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 42101 invoked from network); 20 Aug 2009 17:37:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 17:37:30 -0000
Received: (qmail 434 invoked by uid 500); 20 Aug 2009 17:37:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 366 invoked by uid 500); 20 Aug 2009 17:37:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 356 invoked by uid 99); 20 Aug 2009 17:37:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 17:37:46 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.210.185 as permitted sender)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 17:37:37 +0000
Received: by yxe15 with SMTP id 15so80182yxe.5
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 10:37:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=2qITPBpJtYlpQBfqfX8sihNWq84OOKc3vLZ6mxFIkcs=;
        b=Dl29w2YY1ZEWLN9Cn64JtKyGnYJFGIUSoOIj7SVGbdPAYYl5ekpZ4GZEQ4aXUxzJRJ
         BH9zqocAT7CuyUa9CKGV16sx1rTzfFILJDnv/9CF3jWTW8x+glUxoDNYikbPv2JDsCvz
         UbAu11p+p06g/zuJRiuItuiojMjB5OjD7/4I8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=HTmdAuFUSXMbMFH20ZIdGFEUj8DtcSuI/pbUQU/oe9b6qIMDj6T6oALPXC/eDKUew2
         5rCsOZau57i1CWwGoTZTBlP1biXDptc5K693yq/0I31vnwNYX3Mmauo6BEFH5QUqCfRN
         2iOq+U5tIji08ycYrTF6KIElT6dyPyUcP8rrw=
MIME-Version: 1.0
Received: by 10.150.89.2 with SMTP id m2mr278218ybb.73.1250789836100; Thu, 20 
	Aug 2009 10:37:16 -0700 (PDT)
In-Reply-To: <e01b80590908200230x608ad35en5f372a9fd5aba325@mail.gmail.com>
References: <597eea000908191855v579b9c4r8baeb638630cfb27@mail.gmail.com> 
	<e01b80590908192249s5302cd26m7984a32816c0d58c@mail.gmail.com> 
	<597eea000908200209o176aefacjca2a45369301c296@mail.gmail.com> 
	<e01b80590908200230x608ad35en5f372a9fd5aba325@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Thu, 20 Aug 2009 10:36:56 -0700
Message-ID: <c7d45fc70908201036h329217b1jecef477908523e08@mail.gmail.com>
Subject: Re: File Chunk to Map Thread Association
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd5f0acde92a80471963300
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd5f0acde92a80471963300
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Uhh.... hadoop already goes to considerable lengths to make sure that
computation is local.  In my experience it is common for 90% of the map
invocations to be working from local data.  Hadoop doesn't know about record
boundaries so a little bit of slop into a non-local block is possible to
finish reading a record, but the locality achieved is already quite high.

Are you sure that what you are trying to fix is actually broken?

On Thu, Aug 20, 2009 at 2:30 AM, Harish Mallipeddi <
harish.mallipeddi@gmail.com> wrote:

> >
> > I know I can increase the input file size by changing
> > 'mapred.min.split.size' , however, the file is split sequentially and
> very
> > rarely two consecutive HDFS blocks are stored on a single node. This
> means
> > that the data locality will not be exploited cause every map() will have
> to
> > download part of the file from network.
> >
> > Roman Kolcun
> >
>
> I see what you mean - you want to modify the hadoop code to allocate
> multiple (non-sequential) data-local blocks to one MapTask. I don't know if
> you'll achieve much by doing all that work. Hadoop lets you reuse the
> launched JVMs for multiple MapTasks. That should minimize the overhead of
> launching MapTasks.
> Increasing the DFS blocksize for the input files is another means to
> achieve
> the same effect.
>



-- 
Ted Dunning, CTO
DeepDyve

--000e0cd5f0acde92a80471963300--

From common-user-return-16940-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 17:46:33 2009
Return-Path: <common-user-return-16940-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 45795 invoked from network); 20 Aug 2009 17:46:33 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 17:46:33 -0000
Received: (qmail 17003 invoked by uid 500); 20 Aug 2009 17:46:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 16937 invoked by uid 500); 20 Aug 2009 17:46:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 16927 invoked by uid 99); 20 Aug 2009 17:46:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 17:46:49 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 17:46:37 +0000
Received: from [10.72.106.226] (heighthigh-lx.corp.yahoo.com [10.72.106.226])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7KHhos9005844
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 10:43:50 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=manKrVuUh64cjbK6MptYLOYxZo3np2ecptqu7wSaBeJdRRrRGhLQ8BWruVu+pGfI
Message-ID: <4A8D8B55.8080400@yahoo-inc.com>
Date: Thu, 20 Aug 2009 10:43:49 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Faster alternative to FSDataInputStream
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>	 <4A8B8D11.8020008@yahoo-inc.com>	 <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>	 <ad681e7f0908190845j59dc22aet95e9af971efa8798@mail.gmail.com>	 <cbbf4b570908190914j206797ecrc862d06b6eccbd37@mail.gmail.com>	 <4A8C3D32.3010905@yahoo-inc.com>	 <ad681e7f0908191324n1e04a72fo9ebbd436e89aef20@mail.gmail.com>	 <4A8C6205.6000306@yahoo-inc.com> <ad681e7f0908200801r52a0baa4mfd71af42263d8174@mail.gmail.com>
In-Reply-To: <ad681e7f0908200801r52a0baa4mfd71af42263d8174@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Ananth T. Sarathy wrote:
> it's on s3. and it always happens.

I have no experience with S3. You might want to check out S3 forums. It 
can't be normal for S3 either.. there must be something missing 
(configuration, ACLs... ).

Raghu.

> Ananth T Sarathy
> 
> 
> On Wed, Aug 19, 2009 at 4:35 PM, Raghu Angadi <rangadi@yahoo-inc.com> wrote:
> 
>> Ananth T. Sarathy wrote:
>>
>>> Also, I just want to clear... the delay seems to at the intial
>>>
>>> (read = in.read(buf))
>>>
>> It the file on HDFS (over S3) or S3?
>>
>> Does it always happen?
>>
>> Raghu.
>>
>>
>>  after the first time into the loop it flies...
>>> Ananth T Sarathy
>>>
>>>
>>> On Wed, Aug 19, 2009 at 1:58 PM, Raghu Angadi <rangadi@yahoo-inc.com>
>>> wrote:
>>>
>>>  Edward Capriolo wrote:
>>>>  On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo <
>>>>> edlinuxguru@gmail.com
>>>>>
>>>>>> wrote:
>>>>>>  It would be as fast as underlying filesystem goes.
>>>>>>
>>>>>>> I would not agree with that statement. There is overhead.
>>>>>>> You might be misinterpreting my comment. There is of course some over
>>>> head
>>>> (at the least the procedure calls).. depending on you underlying
>>>> filesystem,
>>>> there could be extra buffer copies and CRC overhead. But none of that
>>>> explains transfer as slow as 1 MBps (if my interpretation of of results
>>>> is
>>>> correct).
>>>>
>>>> Raghu.
>>>>
>>>>
>>>>
> 


From common-user-return-16941-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 17:53:27 2009
Return-Path: <common-user-return-16941-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 60472 invoked from network); 20 Aug 2009 17:53:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 17:53:26 -0000
Received: (qmail 29907 invoked by uid 500); 20 Aug 2009 17:53:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 29804 invoked by uid 500); 20 Aug 2009 17:53:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 29794 invoked by uid 99); 20 Aug 2009 17:53:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 17:53:42 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 17:53:31 +0000
Received: from [10.72.106.226] (heighthigh-lx.corp.yahoo.com [10.72.106.226])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7KHpvSe008793
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 10:51:57 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=G3cc2LXBUHv5BNiONIFpm4u5tWo0hCaNQ6hQMD4LIJGZ0aalIqTGKP0Xw0pjOC5g
Message-ID: <4A8D8D3D.5070404@yahoo-inc.com>
Date: Thu, 20 Aug 2009 10:51:57 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: NN memory consumption on 0.20/0.21 with compressed pointers/
References: <4A8D281B.9070006@apache.org>
In-Reply-To: <4A8D281B.9070006@apache.org>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


Suresh had made an spreadsheet for memory consumption.. will check.

A large portion of NN memory is taken by references. I would expect 
memory savings to be very substantial (same as going from 64bit to 
32bit), could be on the order of 40%.

The last I heard from Sun was that compressed pointers will be in very 
near future JVM (certainly JDK 1.6_x). It can use compressed pointers 
upto 32GB of heap.

I would expect runtime over head on NN would be minimal in practice.

Raghu.

Steve Loughran wrote:
> 
> does anyone have any up to date data on the memory consumption per 
> block/file on the NN on a 64-bit JVM with compressed pointers?
> 
> The best documentation on consumption is 
> http://issues.apache.org/jira/browse/HADOOP-1687 -I'm just wondering if 
> anyone has looked at the memory footprint on the latest Hadoop releases, 
> on those latest JVMs? -and which JVM the numbers from HADOOP-1687 came 
> from?
> 
> Those compressed pointers (which BEA JRockit had for a while) save RAM 
> when the pointer references are within a couple of GB of the other refs, 
> and which are discussed in some papers
> http://rappist.elis.ugent.be/~leeckhou/papers/cgo06.pdf
> http://www.elis.ugent.be/~kvenster/papers/VenstermansKris_ORA.pdf
> 
> sun's commentary is up here
> http://wikis.sun.com/display/HotSpotInternals/CompressedOops
> 
> I'm just not sure what it means for the NameNode, and as there is no 
> sizeof() operator in Java, something that will take a bit of effort to 
> work out. From what I read of the Sun wiki, when you go compressed, 
> while your heap is <3-4GB, there is no decompress operation; once you go 
> above that there is a shift and an add, which is probably faster than 
> fetching another 32 bits from $L2 or main RAM. The result could be 
> -could be- that your NN takes up much less space on 64 bit JVMs than it 
> did before, but is no slower.
> 
> Has anyone worked out the numbers yet?
> 
> -steve


From common-user-return-16942-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 18:00:52 2009
Return-Path: <common-user-return-16942-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 62667 invoked from network); 20 Aug 2009 18:00:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 18:00:52 -0000
Received: (qmail 36513 invoked by uid 500); 20 Aug 2009 18:01:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 36438 invoked by uid 500); 20 Aug 2009 18:01:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 36428 invoked by uid 99); 20 Aug 2009 18:01:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 18:01:08 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 209.85.210.185 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.210.185] (HELO mail-yx0-f185.google.com) (209.85.210.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 18:01:00 +0000
Received: by yxe15 with SMTP id 15so99367yxe.5
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 11:00:37 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.101.43.8 with SMTP id v8mr125861anj.60.1250791237167; Thu, 20 
	Aug 2009 11:00:37 -0700 (PDT)
In-Reply-To: <d6d7c4410908200009n3c2abdb4ufb05bd760112b2db@mail.gmail.com>
References: <77f4f8890908191448q67970d40sabb0e54ec55ad3c8@mail.gmail.com>
	 <C6B1D92B.11978%rphulari@yahoo-inc.com>
	 <77f4f8890908192035j7d1f7943kfd37e6bc079950e7@mail.gmail.com>
	 <d6d7c4410908200009n3c2abdb4ufb05bd760112b2db@mail.gmail.com>
Date: Thu, 20 Aug 2009 11:00:37 -0700
Message-ID: <77f4f8890908201100t49afc20exc4b277c9e19a31a1@mail.gmail.com>
Subject: Re: Location of the source code for the fair scheduler
From: Mithila Nagendra <mnagendr@asu.edu>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636ed6def6129340471968740
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed6def6129340471968740
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

If you go to
http://svn.apache.org/viewvc/hadoop/mapreduce/trunk/src/contrib/fairscheduler/src/java/org/apache/hadoop/mapred/AllocationConfigurationException.java?view=log
it
shows many revisions for the source
file AllocationConfigurationException.java, so I was wondering which can be
used to make changes on.
Mithila

On Thu, Aug 20, 2009 at 12:09 AM, Aaron Kimball <aaron@cloudera.com> wrote:

> What do you mean?
> - Aaron
>
> On Wed, Aug 19, 2009 at 8:35 PM, Mithila Nagendra <mnagendr@asu.edu>
> wrote:
>
> > Thanks! But How do I know which version to work with?
> > Mithila
> >
> >
> > On Thu, Aug 20, 2009 at 2:30 AM, Ravi Phulari <rphulari@yahoo-inc.com
> > >wrote:
> >
> > >  Currently Fairscheduler source is in
> > >              hadoop-mapreduce/src/contrib/fairscheduler/
> > >
> > > Download mapreduce source from.
> > > http://hadoop.apache.org/mapreduce/
> > >
> > > -
> > > Ravi
> > >
> > >
> > > On 8/19/09 2:48 PM, "Mithila Nagendra" <mnagendr@asu.edu> wrote:
> > >
> > > Hello
> > >
> > > I was wondering how I could locate the source code files for the fair
> > > scheduler.
> > >
> > > Thanks
> > > Mithila
> > >
> > >
> > >
> > >
> >
>

--001636ed6def6129340471968740--

From common-user-return-16943-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 18:04:26 2009
Return-Path: <common-user-return-16943-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 64023 invoked from network); 20 Aug 2009 18:04:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 18:04:26 -0000
Received: (qmail 44405 invoked by uid 500); 20 Aug 2009 18:04:43 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 44338 invoked by uid 500); 20 Aug 2009 18:04:43 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 44328 invoked by uid 99); 20 Aug 2009 18:04:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 18:04:43 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of roman.wsmo@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 18:04:33 +0000
Received: by fxm25 with SMTP id 25so60624fxm.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 11:04:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=zQzjKg5tDkbCRfJWYeiCmH8T0NgbodkaZlr5SNTOhfs=;
        b=S6PBmjWafSMZouZtcyTkv6vzJ6stA+sbLY/xGbv5jAf8Qq+awLpgtU5CMUl7voawNx
         RckXJ6uyR/jk4DeYX6ZvFu84p9WaAR0BifkmyDc4cbYpdBad0Bo2+haaGfVFCACMlKgd
         bmMsWZgGecZYBtgbcS4LtFrJnlisHTUAvgOTA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=WPcT688G7h0mr7R6RU9F2AR3QliawetVw53KUmO8pni9qlTtEQPrFJxNPXoYB/24nw
         jfyg9vw4saV79Tyff/Ol+cV+FBczMolND7ssN7zuufGYWnr8YIDEg3UtgYtrIOucNgmM
         pnCG0V/T3NEsKCtCy6A2R5a6A1ZNrmz5CePro=
MIME-Version: 1.0
Received: by 10.103.80.36 with SMTP id h36mr42461mul.18.1250791453367; Thu, 20 
	Aug 2009 11:04:13 -0700 (PDT)
In-Reply-To: <c7d45fc70908201036h329217b1jecef477908523e08@mail.gmail.com>
References: <597eea000908191855v579b9c4r8baeb638630cfb27@mail.gmail.com>
	 <e01b80590908192249s5302cd26m7984a32816c0d58c@mail.gmail.com>
	 <597eea000908200209o176aefacjca2a45369301c296@mail.gmail.com>
	 <e01b80590908200230x608ad35en5f372a9fd5aba325@mail.gmail.com>
	 <c7d45fc70908201036h329217b1jecef477908523e08@mail.gmail.com>
Date: Thu, 20 Aug 2009 19:04:13 +0100
Message-ID: <597eea000908201104q70226a9bpce315e23d6f8f4d4@mail.gmail.com>
Subject: Re: File Chunk to Map Thread Association
From: roman kolcun <roman.wsmo@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e65b6176441d670471969476
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e65b6176441d670471969476
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello Ted,
I know that Hadoop tries to exploit data locality and it is pretty high.
However, the data locality cannot be exploited in case when
'mapred.min.split.size' is set to much higher than DFS blocksize - because
consecutive blocks are not stored on a single machine.
I have found out that there is a pretty high overhead when starting new map
task. When I set the DFS block size to 64MB one map task took on average 21
seconds. With DFS blocksize set to 256MB on average one map task took  63
seconds. If we consider that the blocksize is 4 times larger than processing
256 MB with 64MB chunks takes 84 seconds which is 21 seconds longer than
processing it with 256MB chunks.
Therefore I would like to merge several smaller local chunks into a larger
one and process it with one mapper.

Roman Kolcun

On Thu, Aug 20, 2009 at 6:36 PM, Ted Dunning <ted.dunning@gmail.com> wrote:

> Uhh.... hadoop already goes to considerable lengths to make sure that
> computation is local.  In my experience it is common for 90% of the map
> invocations to be working from local data.  Hadoop doesn't know about
> record
> boundaries so a little bit of slop into a non-local block is possible to
> finish reading a record, but the locality achieved is already quite high.
>
> Are you sure that what you are trying to fix is actually broken?
>
> On Thu, Aug 20, 2009 at 2:30 AM, Harish Mallipeddi <
> harish.mallipeddi@gmail.com> wrote:
>
> > >
> > > I know I can increase the input file size by changing
> > > 'mapred.min.split.size' , however, the file is split sequentially and
> > very
> > > rarely two consecutive HDFS blocks are stored on a single node. This
> > means
> > > that the data locality will not be exploited cause every map() will
> have
> > to
> > > download part of the file from network.
> > >
> > > Roman Kolcun
> > >
> >
> > I see what you mean - you want to modify the hadoop code to allocate
> > multiple (non-sequential) data-local blocks to one MapTask. I don't know
> if
> > you'll achieve much by doing all that work. Hadoop lets you reuse the
> > launched JVMs for multiple MapTasks. That should minimize the overhead of
> > launching MapTasks.
> > Increasing the DFS blocksize for the input files is another means to
> > achieve
> > the same effect.
> >
>
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>

--0016e65b6176441d670471969476--

From common-user-return-16944-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 18:43:19 2009
Return-Path: <common-user-return-16944-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 74598 invoked from network); 20 Aug 2009 18:43:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 18:43:19 -0000
Received: (qmail 659 invoked by uid 500); 20 Aug 2009 18:43:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 592 invoked by uid 500); 20 Aug 2009 18:43:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 582 invoked by uid 99); 20 Aug 2009 18:43:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 18:43:34 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 18:43:23 +0000
Received: from walkduty-lm.corp.yahoo.com (walkduty-lm.corp.yahoo.com [10.72.104.13])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7KIfQgT032027
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 11:41:26 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:from:to:in-reply-to:content-type:
	content-transfer-encoding:mime-version:subject:date:references:x-mailer;
	b=fEF9+snyXos6hSryGaQkPfF3HiE4ctAa3BdIlWAntOkmDJyWQa1ndpCRePc7ERYw
Message-Id: <65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com>
From: Arun C Murthy <acm@yahoo-inc.com>
To: common-user@hadoop.apache.org
In-Reply-To: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: MR job scheduler
Date: Thu, 20 Aug 2009 11:41:26 -0700
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org


On Aug 20, 2009, at 9:00 AM, bharath vissapragada wrote:

> Hi all,
>
> Can anyone tell me how the MR scheduler schedule the MR jobs?
> How does it decide where t create MAP tasks and how many to create.
> Once the MAP tasks are over how does it decide to move the keys to the
> reducer efficiently(minimizing the data movement across the network).
> Is there any doc available which describes this scheduling process  
> quite
> efficiently
>

The #maps is decided by the application. The scheduler decides where  
to execute them.

Once the map is done, the reduce tasks connect to the tasktracker (on  
the node where the map-task executed) and copies the entire output  
over http.

Arun

From common-user-return-16945-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 19:59:34 2009
Return-Path: <common-user-return-16945-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 98527 invoked from network); 20 Aug 2009 19:59:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 19:59:34 -0000
Received: (qmail 9193 invoked by uid 500); 20 Aug 2009 19:59:50 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 9105 invoked by uid 500); 20 Aug 2009 19:59:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 9095 invoked by uid 99); 20 Aug 2009 19:59:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 19:59:50 +0000
X-ASF-Spam-Status: No, hits=4.2 required=10.0
	tests=HTML_MESSAGE,NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 19:59:38 +0000
Received: from sp1-ex07cas01.ds.corp.yahoo.com (sp1-ex07cas01.ds.corp.yahoo.com [216.252.116.137])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7KJvXSE055904;
	Thu, 20 Aug 2009 12:57:33 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:in-reply-to:accept-language:content-language:
	x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:content-type:mime-version;
	b=EpQHyRp2YV7zd9e6kwfwn0YwSWRqUYpaGYM0mODJPrX73wEJvflKW8g+F+2X1FFd
Received: from SP1-EX07VS02.ds.corp.yahoo.com ([216.252.116.135]) by
 sp1-ex07cas01.ds.corp.yahoo.com ([216.252.116.137]) with mapi; Thu, 20 Aug
 2009 12:57:33 -0700
From: Ravi Phulari <rphulari@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>,
        Mithila
 Nagendra <mnagendr@asu.edu>
Date: Thu, 20 Aug 2009 12:57:32 -0700
Subject: Re: Location of the source code for the fair scheduler
Thread-Topic: Location of the source code for the fair scheduler
Thread-Index: AcohwUgnIrLhLF8URGKLwuHsnojydgADywMX
Message-ID: <C6B2F8BC.119F8%rphulari@yahoo-inc.com>
In-Reply-To: <77f4f8890908201100t49afc20exc4b277c9e19a31a1@mail.gmail.com>
Accept-Language: en-US
Content-Language: en
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: multipart/alternative;
	boundary="_000_C6B2F8BC119F8rphulariyahooinccom_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_C6B2F8BC119F8rphulariyahooinccom_
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Mithila ,
   It depends on which version of Hadoop you want to work on .

If you want to work on Hadoop 0.20 then you should check out Hadoop 0.20 so=
urce code .

If you want to work on trunk then check out Hadoop mapreduce source .

svn checkout http://svn.apache.org/repos/asf/hadoop/mapreduce/trunk/ hadoop=
-mapreduce-trunk

Hope this answers your questions .
-
Ravi

On 8/20/09 11:00 AM, "Mithila Nagendra" <mnagendr@asu.edu> wrote:

If you go to
http://svn.apache.org/viewvc/hadoop/mapreduce/trunk/src/contrib/fairschedul=
er/src/java/org/apache/hadoop/mapred/AllocationConfigurationException.java?=
view=3Dlog
it
shows many revisions for the source
file AllocationConfigurationException.java, so I was wondering which can be
used to make changes on.
Mithila

On Thu, Aug 20, 2009 at 12:09 AM, Aaron Kimball <aaron@cloudera.com> wrote:

> What do you mean?
> - Aaron
>
> On Wed, Aug 19, 2009 at 8:35 PM, Mithila Nagendra <mnagendr@asu.edu>
> wrote:
>
> > Thanks! But How do I know which version to work with?
> > Mithila
> >
> >
> > On Thu, Aug 20, 2009 at 2:30 AM, Ravi Phulari <rphulari@yahoo-inc.com
> > >wrote:
> >
> > >  Currently Fairscheduler source is in
> > >              hadoop-mapreduce/src/contrib/fairscheduler/
> > >
> > > Download mapreduce source from.
> > > http://hadoop.apache.org/mapreduce/
> > >
> > > -
> > > Ravi
> > >
> > >
> > > On 8/19/09 2:48 PM, "Mithila Nagendra" <mnagendr@asu.edu> wrote:
> > >
> > > Hello
> > >
> > > I was wondering how I could locate the source code files for the fair
> > > scheduler.
> > >
> > > Thanks
> > > Mithila
> > >
> > >
> > >
> > >
> >
>


Ravi
--


--_000_C6B2F8BC119F8rphulariyahooinccom_--

From common-user-return-16946-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 20:08:04 2009
Return-Path: <common-user-return-16946-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 2481 invoked from network); 20 Aug 2009 20:08:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 20:08:04 -0000
Received: (qmail 24990 invoked by uid 500); 20 Aug 2009 20:08:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 24910 invoked by uid 500); 20 Aug 2009 20:08:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 24900 invoked by uid 99); 20 Aug 2009 20:08:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 20:08:20 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rvmishwar@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 20:08:11 +0000
Received: by fxm25 with SMTP id 25so124504fxm.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 13:07:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=CObGHZqaoo+oS30pl+GvM9gKhlktP7KMd5E0DHSstXw=;
        b=i4OCSgD3QWvmjpkPeEvT+1x2wR5DNVEm1oDDKWn6OfsWUd3Hje7koxe291UT7aVDMq
         JgGp2ng8B33O+BK+k8b+SHl2B/2lS3RrBJ/rt4yCkg921bJT0EmjG4eel1mzF9+EVFBU
         mP/PKoOR3K79xdk+dGIpXXxCf4yK7pF12zNU4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=AEio8F9jAOQps1iqaJJAqvUktczvUa92ZyOpW/t2xF3w4UDX5u3kYNRrAQ+SiSIUSQ
         8YXvmiuCch17DU2mPTnN+3AfBbBn12xryeEGxrfX7EnPGg+egyXGh9C0EIVUoPuGr6r2
         2j49wpGr6WF+KGKDrf5uQLxo9CaRKRCWGZZaQ=
MIME-Version: 1.0
Received: by 10.103.37.38 with SMTP id p38mr72454muj.134.1250798871198; Thu, 
	20 Aug 2009 13:07:51 -0700 (PDT)
Date: Thu, 20 Aug 2009 13:07:51 -0700
Message-ID: <fe35e3c40908201307n2b0c4066o95ae09d90b9cc086@mail.gmail.com>
Subject: passing job arguments as an xml file
From: ishwar ramani <rvmishwar@gmail.com>
To: common-user <common-user@hadoop.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

I am looking at an easy way to passing the job arguments trough a config file.
The genericoptionsparser seems to parse only the hadoop options.

Normally i use jsap but that would not co-exist with  genericoptionsparser ....

thanks
ishwar

From common-user-return-16947-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 20:29:52 2009
Return-Path: <common-user-return-16947-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11798 invoked from network); 20 Aug 2009 20:29:51 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 20:29:51 -0000
Received: (qmail 63074 invoked by uid 500); 20 Aug 2009 20:30:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 63017 invoked by uid 500); 20 Aug 2009 20:30:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 63007 invoked by uid 99); 20 Aug 2009 20:30:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 20:30:08 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saidtherobot@gmail.com designates 209.85.211.198 as permitted sender)
Received: from [209.85.211.198] (HELO mail-yw0-f198.google.com) (209.85.211.198)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 20:29:58 +0000
Received: by ywh36 with SMTP id 36so225627ywh.31
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 13:29:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=HkxniLFN5l0Dg5gNm0O7t0kNdRlhhxg8LXW/WcAwr1A=;
        b=AW3TY2a3N7wfnNvHoXXKJkOATyV9TeTNK1uKgPDyD8Jpg7rNu/hOGq6eE+HOoKNbSP
         X/Nss043eZG7wKe9JWTD3zhBNHF6J90lhnCVVTfMBRiWRtFdfCALqch7eQMhffvzpOsd
         5KgAxfPX1RjrosvxdDjPci7J65qf2yKgas95g=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=eERIkvnsrvITTCTUBZ/Xzq12dDRbPaibyLU7wS/UzKRfYYMQlL/yuzq3BvNz5erqG3
         E54Uy9uKFPoc+wMUS5VnjQs6WCNvZPYN9vsQ/kh9wXL+VIYVR2NNgu2MWLn6if1l36si
         vafOsqbb13ScOvL1CfXOmMhI0Z5W9yrAlDSl4=
MIME-Version: 1.0
Received: by 10.150.116.19 with SMTP id o19mr568126ybc.110.1250800177574; Thu, 
	20 Aug 2009 13:29:37 -0700 (PDT)
In-Reply-To: <cbbf4b570908200816h493e7e04ue4c2679cb464d2cb@mail.gmail.com>
References: <2986c2f30908191632u74dcad9dt9073fc84eb7d849e@mail.gmail.com>
	 <480D7E03-6E9F-4917-BE31-A82D2A42D9C8@cse.unl.edu>
	 <cbbf4b570908200744l5e206ea1hbb8fe5d439fbfc77@mail.gmail.com>
	 <2986c2f30908200749y553337b2xf75f39ed764ac744@mail.gmail.com>
	 <cbbf4b570908200816h493e7e04ue4c2679cb464d2cb@mail.gmail.com>
Date: Thu, 20 Aug 2009 16:29:37 -0400
Message-ID: <2986c2f30908201329g26a2c84ew5352fec5237b4c4a@mail.gmail.com>
Subject: Re: syslog-ng and hadoop
From: mike anderson <saidtherobot@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd5c72a44f5f50471989c78
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd5c72a44f5f50471989c78
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I got it working! fantastic. One thing that hung me up for a while was how
picky the log4j.properties files are about syntax. For future reference to
others, I used this in log4j.properties:
# Define the root logger to the system property "hadoop.root.logger".
log4j.rootLogger=${hadoop.root.logger}, EventCounter, Socket


On Thu, Aug 20, 2009 at 11:16 AM, Edward Capriolo <edlinuxguru@gmail.com>wrote:

> On Thu, Aug 20, 2009 at 10:49 AM, mike anderson<saidtherobot@gmail.com>
> wrote:
> > Yeah, that is interesting Edward. I don't need syslog-ng for any
> particular
> > reason, other than that I'm familiar with it. If there were another way
> to
> > get all my logs collated into one log file that would be great.
> > mike
> >
> > On Thu, Aug 20, 2009 at 10:44 AM, Edward Capriolo <edlinuxguru@gmail.com
> >wrote:
> >
> >> On Wed, Aug 19, 2009 at 11:50 PM, Brian Bockelman<bbockelm@cse.unl.edu>
> >> wrote:
> >> > Hey Mike,
> >> >
> >> > Yup.  We find the stock log4j needs two things:
> >> >
> >> > 1) Set the rootLogger manually.  The way 0.19.x has the root logger
> set
> >> up
> >> > breaks when adding new appenders.  I.e., do:
> >> >
> >> > log4j.rootLogger=INFO,SYSLOG,console,DRFA,EventCounter
> >> >
> >> > 2) Add the headers; otherwise log4j is not compatible with syslog:
> >> >
> >> > log4j.appender.SYSLOG=org.apache.log4j.net.SyslogAppender
> >> > log4j.appender.SYSLOG.facility=local0
> >> > log4j.appender.SYSLOG.layout=org.apache.log4j.PatternLayout
> >> > log4j.appender.SYSLOG.layout.ConversionPattern=%p %c{2}: %m%n
> >> > log4j.appender.SYSLOG.SyslogHost=red
> >> > log4j.appender.SYSLOG.threshold=ERROR
> >> > log4j.appender.SYSLOG.Header=true
> >> > log4j.appender.SYSLOG.FacilityPrinting=true
> >> >
> >> > Brian
> >> >
> >> > On Aug 19, 2009, at 6:32 PM, Mike Anderson wrote:
> >> >
> >> >> Has anybody had any luck setting up the log4j.properties file to send
> >> logs
> >> >> to a syslog-ng server?
> >> >> My log4j.properties excerpt:
> >> >> log4j.appender.SYSLOG=org.apache.log4j.net.SyslogAppender
> >> >> log4j.appender.SYSLOG.syslogHost=10.0.20.164
> >> >> log4j.appender.SYSLOG.layout=org.apache.log4j.PatternLayout
> >> >> log4j.appender.SYSLOG.layout.ConversionPattern=%d{ISO8601} %p %c:
> %m%n
> >> >> log4j.appender.SYSLOG.Facility=HADOOP
> >> >>
> >> >> and my syslog-ng.conf file running on 10.0.20.164
> >> >>
> >> >> source s_hadoop {
> >> >>       # message generated by Syslog-NG
> >> >>       internal();
> >> >>       # standard Linux log source (this is the default place for the
> >> >> syslog()
> >> >>       # function to send logs to)
> >> >>       unix-stream("/dev/log");
> >> >>       udp();
> >> >> };
> >> >> destination df_hadoop { file("/var/log/hadoop/hadoop.log");};
> >> >> filter f_hadoop {facility(hadoop);};
> >> >> log {
> >> >> source(s_hadoop);
> >> >> filter(f_hadoop);
> >> >> destination(df_hadoop);
> >> >> };
> >> >>
> >> >>
> >> >> Thanks in advance,
> >> >> Mike
> >> >
> >> >
> >>
> >> Mike slightly off topic but you can also run a Log 4J server which
> >> perfectly transports the messages fired off by LOG4j. The
> >> log4J->syslog loses/ changes some information. If anyone is interested
> >> in this let me know and I will write up something about it.
> >>
> >
>
> Mike,
> I just put this up for you.
> http://www.edwardcapriolo.com/wiki/en/Log4j_Server
>
> All of the functionality is in the class
> org.apache.log4j.net.SocketServer which ships as part of Log4j.
>
> I pretty much followed this http://timarcher.com/node/10
>
> I started with the syslog appender but it had some quirks. Mostly the
> syslog appender can only write a syslog so it loses some information.
> The Log4jserver transfers the log.error("whatever" ) as is and can
> handle it on the server end though the servers logging properties.
> Cool stuff.
>

--000e0cd5c72a44f5f50471989c78--

From common-user-return-16948-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 22:01:03 2009
Return-Path: <common-user-return-16948-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 46019 invoked from network); 20 Aug 2009 22:01:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 22:01:03 -0000
Received: (qmail 87825 invoked by uid 500); 20 Aug 2009 22:01:17 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87687 invoked by uid 500); 20 Aug 2009 22:01:17 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87620 invoked by uid 500); 20 Aug 2009 22:01:16 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 87612 invoked by uid 99); 20 Aug 2009 22:01:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 22:01:16 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [74.125.92.24] (HELO qw-out-2122.google.com) (74.125.92.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 22:01:08 +0000
Received: by qw-out-2122.google.com with SMTP id 8so161398qwh.35
        for <multiple recipients>; Thu, 20 Aug 2009 15:00:46 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.81.66 with SMTP id w2mr310597qak.98.1250805646148; Thu, 20 
	Aug 2009 15:00:46 -0700 (PDT)
In-Reply-To: <002c01ca21bb$d897d2f0$89c778d0$@com>
References: <002c01ca21bb$d897d2f0$89c778d0$@com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Thu, 20 Aug 2009 15:00:26 -0700
Message-ID: <d6d7c4410908201500n20844f3ao5c29fc1ec496d9d8@mail.gmail.com>
Subject: Re: Using Hadoop with executables and binary data
To: common-dev@hadoop.apache.org
Cc: core-dev@hadoop.apache.org, core-user@hadoop.apache.org, spodxx@gmail.com
Content-Type: multipart/alternative; boundary=00163602762238c681047199e2ef
X-Virus-Checked: Checked by ClamAV on apache.org

--00163602762238c681047199e2ef
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Look into "typed bytes":
http://dumbotics.com/2009/02/24/hadoop-1722-and-typed-bytes/

On Thu, Aug 20, 2009 at 10:29 AM, Jaliya Ekanayake <jnekanayake@gmail.com>wrote:

> Hi Stefan,
>
>
>
> I am sorry, for the late reply. Somehow the response email has slipped my
> eyes.
>
> Could you explain a bit on how to use Hadoop streaming with binary data
> formats.
>
> I can see, explanations on using it with text data formats, but not for
> binary files.
>
>
> Thank you,
>
> Jaliya
>
> Stefan Podkowinski
> Mon, 10 Aug 2009 01:40:05 -0700
>
> Jaliya,
>
> did you consider Hadoop Streaming for your case?
> http://wiki.apache.org/hadoop/HadoopStreaming
>
>
> On Wed, Jul 29, 2009 at 8:35 AM, Jaliya
> Ekanayake<jekan...@cs.indiana.edu> wrote:
> > Dear Hadoop devs,
> >
> >
> >
> > Please help me to figure out a way to program the following problem using
> > Hadoop.
> >
> > I have a program which I need to invoke in parallel using Hadoop. The
> > program takes an input file(binary) and produce an output file (binary)
> >
> >
> >
> > Input.bin ->prog.exe-> output.bin
> >
> >
> >
> > The input data set is about 1TB in size. Each input data file is about
> 33MB
> > in size. (So I have about 31000 files)
> >
> > The output binary file is about 9KBs in size.
> >
> >
> >
> > I have implemented this program using Hadoop in the following way.
> >
> >
> >
> > I keep the input data in a shared parallel file system (Lustre File
> System).
> >
> > Then, I collect the input file names and write them to a collection of
> files
> > in HDFS (let's say hdfs_input_0.txt ..).
> >
> > Each hdfs_input file contains roughly the equal number of files URIs to
> the
> > original input file.
> >
> > The map task, simply take a string Value which is a URI to an original
> input
> > data file and execute the program as an external program.
> >
> > The output of the program is also written to the shared file system
> (Lustre
> > File System).
> >
> >
> >
> > The problem in this approach is I am not utilizing the true benefit of
> > MapReduce. The use of local disks.
> >
> > Could  you please suggest me a way to use local disks for the above
> > problem.?
> >
> >
> >
> > I thought, of the following way, but would like to verify from you if
> there
> > is a better way.
> >
> >
> >
> > 1.       Upload the original data files in HDFS
> >
> > 2.       In the map task, read the data file as an binary object.
> >
> > 3.       Save it in the local file system.
> >
> > 4.       Call the executable
> >
> > 5.       Push the output from the local file system to HDFS.
> >
> >
> >
> > Any suggestion is greatly appreciated.
> >
> >
> > Thank you,
> >
> > Jaliya
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
>
>
>
>

--00163602762238c681047199e2ef--

From common-user-return-16949-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 22:05:05 2009
Return-Path: <common-user-return-16949-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 46792 invoked from network); 20 Aug 2009 22:05:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 22:05:05 -0000
Received: (qmail 93442 invoked by uid 500); 20 Aug 2009 22:05:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 93350 invoked by uid 500); 20 Aug 2009 22:05:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 93340 invoked by uid 99); 20 Aug 2009 22:05:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 22:05:21 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.221.178] (HELO mail-qy0-f178.google.com) (209.85.221.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 22:05:09 +0000
Received: by qyk8 with SMTP id 8so4200qyk.2
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 15:04:47 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.91.74 with SMTP id l10mr290337qam.241.1250805887107; Thu, 
	20 Aug 2009 15:04:47 -0700 (PDT)
In-Reply-To: <4A8D8D3D.5070404@yahoo-inc.com>
References: <4A8D281B.9070006@apache.org> <4A8D8D3D.5070404@yahoo-inc.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Thu, 20 Aug 2009 15:04:27 -0700
Message-ID: <d6d7c4410908201504l6b855055s34983ca95f468796@mail.gmail.com>
Subject: Re: NN memory consumption on 0.20/0.21 with compressed pointers/
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000feaee5d7d9582d5047199f047
X-Virus-Checked: Checked by ClamAV on apache.org

--000feaee5d7d9582d5047199f047
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Compressed OOPs are available now in 1.6.0u14:
https://jdk6.dev.java.net/6uNea.html
- Aaron

On Thu, Aug 20, 2009 at 10:51 AM, Raghu Angadi <rangadi@yahoo-inc.com>wrote:

>
> Suresh had made an spreadsheet for memory consumption.. will check.
>
> A large portion of NN memory is taken by references. I would expect memory
> savings to be very substantial (same as going from 64bit to 32bit), could be
> on the order of 40%.
>
> The last I heard from Sun was that compressed pointers will be in very near
> future JVM (certainly JDK 1.6_x). It can use compressed pointers upto 32GB
> of heap.
>
> I would expect runtime over head on NN would be minimal in practice.
>
> Raghu.
>
>
> Steve Loughran wrote:
>
>>
>> does anyone have any up to date data on the memory consumption per
>> block/file on the NN on a 64-bit JVM with compressed pointers?
>>
>> The best documentation on consumption is
>> http://issues.apache.org/jira/browse/HADOOP-1687 -I'm just wondering if
>> anyone has looked at the memory footprint on the latest Hadoop releases, on
>> those latest JVMs? -and which JVM the numbers from HADOOP-1687 came from?
>>
>> Those compressed pointers (which BEA JRockit had for a while) save RAM
>> when the pointer references are within a couple of GB of the other refs, and
>> which are discussed in some papers
>> http://rappist.elis.ugent.be/~leeckhou/papers/cgo06.pdf<http://rappist.elis.ugent.be/%7Eleeckhou/papers/cgo06.pdf>
>> http://www.elis.ugent.be/~kvenster/papers/VenstermansKris_ORA.pdf<http://www.elis.ugent.be/%7Ekvenster/papers/VenstermansKris_ORA.pdf>
>>
>> sun's commentary is up here
>> http://wikis.sun.com/display/HotSpotInternals/CompressedOops
>>
>> I'm just not sure what it means for the NameNode, and as there is no
>> sizeof() operator in Java, something that will take a bit of effort to work
>> out. From what I read of the Sun wiki, when you go compressed, while your
>> heap is <3-4GB, there is no decompress operation; once you go above that
>> there is a shift and an add, which is probably faster than fetching another
>> 32 bits from $L2 or main RAM. The result could be -could be- that your NN
>> takes up much less space on 64 bit JVMs than it did before, but is no
>> slower.
>>
>> Has anyone worked out the numbers yet?
>>
>> -steve
>>
>
>

--000feaee5d7d9582d5047199f047--

From common-user-return-16950-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 22:23:43 2009
Return-Path: <common-user-return-16950-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 51789 invoked from network); 20 Aug 2009 22:23:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 22:23:43 -0000
Received: (qmail 14767 invoked by uid 500); 20 Aug 2009 22:24:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 14691 invoked by uid 500); 20 Aug 2009 22:24:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 14681 invoked by uid 99); 20 Aug 2009 22:24:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 22:23:59 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [64.78.17.18] (HELO EXHUB018-3.exch018.msoutlookonline.net) (64.78.17.18)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 22:23:47 +0000
Received: from EXVMBX018-1.exch018.msoutlookonline.net ([64.78.17.47]) by
 EXHUB018-3.exch018.msoutlookonline.net ([64.78.17.18]) with mapi; Thu, 20 Aug
 2009 15:23:26 -0700
From: Scott Carey <scott@richrelevance.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Thu, 20 Aug 2009 15:23:24 -0700
Subject: Re: NN memory consumption on 0.20/0.21 with compressed pointers/
Thread-Topic: NN memory consumption on 0.20/0.21 with compressed pointers/
Thread-Index: AcohgsU8bqWrv36BST+Sta9uaJAcNAAYg+R4
Message-ID: <C6B31AEC.F4A9%scott@richrelevance.com>
In-Reply-To: <4A8D281B.9070006@apache.org>
Accept-Language: en-US
Content-Language: en
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org



On 8/20/09 3:40 AM, "Steve Loughran" <stevel@apache.org> wrote:

>=20
>=20
> does anyone have any up to date data on the memory consumption per
> block/file on the NN on a 64-bit JVM with compressed pointers?
>=20
> The best documentation on consumption is
> http://issues.apache.org/jira/browse/HADOOP-1687 -I'm just wondering if
> anyone has looked at the memory footprint on the latest Hadoop releases,
> on those latest JVMs? -and which JVM the numbers from HADOOP-1687 came fr=
om?
>=20
> Those compressed pointers (which BEA JRockit had for a while) save RAM
> when the pointer references are within a couple of GB of the other refs,
> and which are discussed in some papers
> http://rappist.elis.ugent.be/~leeckhou/papers/cgo06.pdf
> http://www.elis.ugent.be/~kvenster/papers/VenstermansKris_ORA.pdf
>=20
> sun's commentary is up here
> http://wikis.sun.com/display/HotSpotInternals/CompressedOops
>=20
> I'm just not sure what it means for the NameNode, and as there is no
> sizeof() operator in Java, something that will take a bit of effort to
> work out. From what I read of the Sun wiki, when you go compressed,
> while your heap is <3-4GB, there is no decompress operation; once you go
> above that there is a shift and an add, which is probably faster than
> fetching another 32 bits from $L2 or main RAM. The result could be
> -could be- that your NN takes up much less space on 64 bit JVMs than it
> did before, but is no slower.

The implementation in JRE 6u14 uses a shift for all heap sizes, the
optimization to remove that for heaps less than 4GB is not in the hotspot
version there (but will be later).

The size advantage is there either way.

I have not tested an app myself that was not faster using
-XX:+UseCompressedOops on a 64 bit JVM.
The extra bit shifting is overshadowed by how much faster and less frequent
GC is with a smaller dataset.


>=20
> Has anyone worked out the numbers yet?
>=20
> -steve
>=20

Every Java reference is 4 bytes instead of 8, and for several types --
arrays in particular -- the object is also 4 bytes smaller.  Given that the
NN data structures have plenty of references, a 30% reduction in memory use=
d
would not be a surprise.

Collection classes in particular are near half the size.


From common-user-return-16951-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 22:57:13 2009
Return-Path: <common-user-return-16951-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61649 invoked from network); 20 Aug 2009 22:57:12 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 22:57:12 -0000
Received: (qmail 56009 invoked by uid 500); 20 Aug 2009 22:57:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 55948 invoked by uid 500); 20 Aug 2009 22:57:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 55914 invoked by uid 99); 20 Aug 2009 22:57:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 22:57:25 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [98.136.44.42] (HELO n78.bullet.mail.sp1.yahoo.com) (98.136.44.42)
    by apache.org (qpsmtpd/0.29) with SMTP; Thu, 20 Aug 2009 22:57:14 +0000
Received: from [216.252.122.216] by n78.bullet.mail.sp1.yahoo.com with NNFMP; 20 Aug 2009 22:56:54 -0000
Received: from [67.195.9.81] by t1.bullet.sp1.yahoo.com with NNFMP; 20 Aug 2009 22:56:54 -0000
Received: from [67.195.9.99] by t1.bullet.mail.gq1.yahoo.com with NNFMP; 20 Aug 2009 22:56:54 -0000
Received: from [127.0.0.1] by omp103.mail.gq1.yahoo.com with NNFMP; 20 Aug 2009 22:56:54 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 205319.62342.bm@omp103.mail.gq1.yahoo.com
Received: (qmail 89186 invoked by uid 60001); 20 Aug 2009 22:56:54 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1250809014; bh=OlGgX7sXzCkmJg4m3vghVa7jp2DNBuWZKQDL3l0xnZM=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=s8zQu7TUPKiao5ZcVXsazRi7xg8wTsXdsx1eZ5F2dAoFyRFt4KmpgOpL7hxoe1UYqD6NGhN2fXWv4sylYV2qGjyHp5CbWbiXOb5xg8VyqhBL8GQ2NnI/CT+JRk4K2dv8TDgLDjvd3oR9PPjANfkPZx4V2sUb3w1G78bKrUjzJDk=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=D1CNHl5MOVKx+xZtgviIqDlvf5Zt8ZO2f6Q9WfDj/Swgws5eWjtmxaTobcMqQJ+8L1FyMIO8zLQNaB/oftdizfMs9ePUSc6Jac1m8Gure2rbfeOE0i/3ABol7LTCGNCLh6H094gjMBEsT6l3mqGRoCiEVUUitpQyY305E7Ovppc=;
Message-ID: <51284.88272.qm@web110107.mail.gq1.yahoo.com>
X-YMail-OSG: Ya77dfgVM1npEsp91e4FwzpKeRRuXzE8cAvisaQ9pdbtqQYRagE-
Received: from [216.243.71.77] by web110107.mail.gq1.yahoo.com via HTTP; Thu, 20 Aug 2009 15:56:53 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <69035570908131902o32deaa8cv147f753a7e741f55@mail.gmail.com>
Date: Thu, 20 Aug 2009 15:56:53 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: Cluster Disk Usage
To: common-user@hadoop.apache.org
In-Reply-To: <69035570908131902o32deaa8cv147f753a7e741f55@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-1645879454-1250809013=:88272"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-1645879454-1250809013=:88272
Content-Type: text/plain; charset=us-ascii

Is there a way to find out how much disk space - overall or per Datanode basis - is available before creating a file ?

I am trying to address an issue where the disk got full (config error) and the client was not able to create a file on the HDFS.

I want to be able to check if  there space left on the grid before trying to create the file.

Arvind



      
--0-1645879454-1250809013=:88272--


From common-user-return-16952-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 23:01:18 2009
Return-Path: <common-user-return-16952-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63273 invoked from network); 20 Aug 2009 23:01:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 23:01:18 -0000
Received: (qmail 61638 invoked by uid 500); 20 Aug 2009 23:01:34 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 61570 invoked by uid 500); 20 Aug 2009 23:01:34 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 61560 invoked by uid 99); 20 Aug 2009 23:01:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 23:01:34 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [98.136.44.37] (HELO n61.bullet.mail.sp1.yahoo.com) (98.136.44.37)
    by apache.org (qpsmtpd/0.29) with SMTP; Thu, 20 Aug 2009 23:01:23 +0000
Received: from [216.252.122.216] by n61.bullet.mail.sp1.yahoo.com with NNFMP; 20 Aug 2009 23:01:03 -0000
Received: from [67.195.9.83] by t1.bullet.sp1.yahoo.com with NNFMP; 20 Aug 2009 23:01:03 -0000
Received: from [67.195.9.97] by t3.bullet.mail.gq1.yahoo.com with NNFMP; 20 Aug 2009 23:01:03 -0000
Received: from [127.0.0.1] by omp101.mail.gq1.yahoo.com with NNFMP; 20 Aug 2009 23:01:03 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 5932.65589.bm@omp101.mail.gq1.yahoo.com
Received: (qmail 2666 invoked by uid 60001); 20 Aug 2009 23:01:02 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1250809262; bh=2DjjdHVfgZcXqQac5bFMolE84RC5+OZbJ88hhvWfb60=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=g81dZmSdWhyO//yX0Oi9rdrVKwN1crad4K2kedouladDQ+N3hQoEsyD0HrLZZe99u5egAU2DhmbjKSyyOAn7ejXIojU46EyMTnVgy73DGtchBRYYfz1aQ2UgSYkbRsUbuU/nCKjRjVOnX9xbTxFI7Yjj0JGFqXhYFLqt+OnFoaU=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=n8bIeOc9UNcI98hqgn1oLxwEXU4YAEhTStiFsj3YYI/9h+kAi+8/4V4TsJNsOHXUQnGtlVo26Mu8+RJ+syOfZ6VKfLykDKhtmFUtniHqBD9lmW9CLhpJ455ZP5JJYTyekUrckL66l0OcfhbB/KWOE3nTDurASBimTYfnCxrD5xA=;
Message-ID: <888894.94802.qm@web110103.mail.gq1.yahoo.com>
X-YMail-OSG: Lwu_lDgVM1npAkMyqeQdglfVKzV8bAt_A3Rs5aTSX67GivPsR2bQUJg3
Received: from [216.243.71.77] by web110103.mail.gq1.yahoo.com via HTTP; Thu, 20 Aug 2009 16:01:02 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <69035570908131902o32deaa8cv147f753a7e741f55@mail.gmail.com> <51284.88272.qm@web110107.mail.gq1.yahoo.com>
Date: Thu, 20 Aug 2009 16:01:02 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: Re: Cluster Disk Usage
To: common-user@hadoop.apache.org
In-Reply-To: <51284.88272.qm@web110107.mail.gq1.yahoo.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-1211347358-1250809262=:94802"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-1211347358-1250809262=:94802
Content-Type: text/plain; charset=us-ascii

Using hadoop-0.19.2




________________________________
From: Arvind Sharma <arvind321@yahoo.com>
To: common-user@hadoop.apache.org
Sent: Thursday, August 20, 2009 3:56:53 PM
Subject: Cluster Disk Usage

Is there a way to find out how much disk space - overall or per Datanode basis - is available before creating a file ?

I am trying to address an issue where the disk got full (config error) and the client was not able to create a file on the HDFS.

I want to be able to check if  there space left on the grid before trying to create the file.

Arvind


      
--0-1211347358-1250809262=:94802--


From common-user-return-16953-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 23:44:56 2009
Return-Path: <common-user-return-16953-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 74368 invoked from network); 20 Aug 2009 23:44:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 23:44:56 -0000
Received: (qmail 5819 invoked by uid 500); 20 Aug 2009 23:45:12 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 5746 invoked by uid 500); 20 Aug 2009 23:45:12 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 5736 invoked by uid 99); 20 Aug 2009 23:45:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 23:45:12 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [98.136.44.42] (HELO n78.bullet.mail.sp1.yahoo.com) (98.136.44.42)
    by apache.org (qpsmtpd/0.29) with SMTP; Thu, 20 Aug 2009 23:45:00 +0000
Received: from [216.252.122.219] by n78.bullet.mail.sp1.yahoo.com with NNFMP; 20 Aug 2009 23:44:36 -0000
Received: from [67.195.9.81] by t4.bullet.sp1.yahoo.com with NNFMP; 20 Aug 2009 23:44:36 -0000
Received: from [67.195.9.99] by t1.bullet.mail.gq1.yahoo.com with NNFMP; 20 Aug 2009 23:44:36 -0000
Received: from [127.0.0.1] by omp103.mail.gq1.yahoo.com with NNFMP; 20 Aug 2009 23:44:36 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 546236.76715.bm@omp103.mail.gq1.yahoo.com
Received: (qmail 54814 invoked by uid 60001); 20 Aug 2009 23:44:36 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1250811876; bh=8Md2ezkeXL861jFtjtaNPoE0/MLsohmoImErrHinyns=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=YBLROO4GRpi0VTCnwNdqiAOiaOsOwBf7Q6hnvwvXonbH9br4h6yP9uqFxin2jkqE24g1xaHbSjZ2/CM2/9ubXX4SsSm2wckr4C17tZrLrrVlSaYhO9dTAZ/byDOQx8vb/CLWM+z9q3XJehkZIDi+MtWGaSM46VyYfbX3WT50L1M=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=R7sFxpZd4/1oki5kyQOCZnpq+Dv7otJ72J1hX4HfD0J+zB91/4ZC4/yECU93XxteJHdJz2AEMbyo+Vdb0gzk7OTZiz6Bt9VhlC3G+SPP0GAmVbRz4CcyrfskxndB4lIXqy/zC7x8yGvTkr6pyqtX0GN8P5a84RAO7X/yWBT0FwU=;
Message-ID: <403425.54775.qm@web110111.mail.gq1.yahoo.com>
X-YMail-OSG: WfyYeZkVM1ms0XhLL7UAT0PFWc5bpCvkcljB9pi5D1HyjBZcsByKy3LpoeSFQRVEkuBPRO0w8xLzcwQJnPNYOc_MtB2iqUvxDJKxB4vsKBPHB7ld8nfAGOmtozpGpW9vIDPzmFiArvs25Igte2XTeIwBdwUMHUpFdIGTXwwM92TXdXbYlChO1TY7Px1dv7rMLJ1T1o8uxX9.Yh6nswDLRciOvcbgeNGjnS4Nrx0kO9_Z.onSC4zlSmeNJpeVYanyhqmNRu.MPxrxwVD7JFX1j5qxNC4EZodPIKkodEtO8RfzmPyfm1ghoRLWjiLc8m1TTaB7HQSus05Z5sA0k3uEJrIlVBpob0VMJCRS
Received: from [216.243.71.77] by web110111.mail.gq1.yahoo.com via HTTP; Thu, 20 Aug 2009 16:44:35 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <69035570908131902o32deaa8cv147f753a7e741f55@mail.gmail.com> <51284.88272.qm@web110107.mail.gq1.yahoo.com> <888894.94802.qm@web110103.mail.gq1.yahoo.com>
Date: Thu, 20 Aug 2009 16:44:35 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: Re: Cluster Disk Usage
To: common-user@hadoop.apache.org
In-Reply-To: <888894.94802.qm@web110103.mail.gq1.yahoo.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-1877311827-1250811875=:54775"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-1877311827-1250811875=:54775
Content-Type: text/plain; charset=us-ascii

Sorry, I also sent a direct e-mail to one response.... 

there I asked one question - what is the cost of these APIs ???  Are they too expensive calls ?  Is the API only going to the NN which stores this data ?

Thanks!
Arvind




________________________________
From: Arvind Sharma <arvind321@yahoo.com>
To: common-user@hadoop.apache.org
Sent: Thursday, August 20, 2009 4:01:02 PM
Subject: Re: Cluster Disk Usage

Using hadoop-0.19.2




________________________________
From: Arvind Sharma <arvind321@yahoo.com>
To: common-user@hadoop.apache.org
Sent: Thursday, August 20, 2009 3:56:53 PM
Subject: Cluster Disk Usage

Is there a way to find out how much disk space - overall or per Datanode basis - is available before creating a file ?

I am trying to address an issue where the disk got full (config error) and the client was not able to create a file on the HDFS.

I want to be able to check if  there space left on the grid before trying to create the file.

Arvind


      
--0-1877311827-1250811875=:54775--


From common-user-return-16954-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 20 23:52:31 2009
Return-Path: <common-user-return-16954-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 76609 invoked from network); 20 Aug 2009 23:52:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 20 Aug 2009 23:52:31 -0000
Received: (qmail 12822 invoked by uid 500); 20 Aug 2009 23:52:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 12738 invoked by uid 500); 20 Aug 2009 23:52:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 12728 invoked by uid 99); 20 Aug 2009 23:52:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 23:52:47 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rvmishwar@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 20 Aug 2009 23:52:39 +0000
Received: by fxm25 with SMTP id 25so211892fxm.29
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 16:52:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=3VwpWs4DDrJz7P66+wIvlclLMt4Tv3k0UEqd+Vpz7Gc=;
        b=dByMuN1nq00hXou7qdhZT7hkhl2frIs7/kHW21U8dZPoprMb30+rA7nxOgp7IJQpx9
         SXvovS9EGbTxTMTshwtlVbz754eQtmbidB4EXOUpsn4ZPovik9tyqj1YU2wiql3wQGeW
         F+4tFpK0spv9ykZ/+JBLWjRdPXy6fl8CEcvhQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=GZbn375ogPnFn+7Mj9hPolNgLYJK7J3OVUaBjJ/TMqGOHmW9ZQTtWfu8c1pumHF2jN
         mN7cZRbX59F2J04rxHHpt0t9TENzaWcTeptTu3Hira0dZp5Sy5gk3jcfqD6jENEthskt
         630KNvihYOQ1Zn2ZMQnVykpXWWjvFPD+SwM9k=
MIME-Version: 1.0
Received: by 10.103.37.38 with SMTP id p38mr147578muj.134.1250812338889; Thu, 
	20 Aug 2009 16:52:18 -0700 (PDT)
Date: Thu, 20 Aug 2009 16:52:18 -0700
Message-ID: <fe35e3c40908201652m543cc48crc2e12820dd463388@mail.gmail.com>
Subject: Writing to a db with DBOutputFormat spits out IOException Error
From: ishwar ramani <rvmishwar@gmail.com>
To: common-user <common-user@hadoop.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

I am trying to run a simple map reduce that writes the result from the
reducer to a mysql db.

I Keep getting

09/08/20 15:44:59 INFO mapred.JobClient: Task Id :
attempt_200908201210_0013_r_000000_0, Status : FAILED
java.io.IOException: com.mysql.jdbc.Driver
        at org.apache.hadoop.mapred.lib.db.DBOutputFormat.getRecordWriter(DBOutputFormat.java:162)
        at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:435)
        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:413)
        at org.apache.hadoop.mapred.Child.main(Child.java:170)

when the reducer is run.

Here is my code. The user name and password are valid and works fine.
Is there any way get more info on this exception?



static class MyWritable implements Writable, DBWritable {
  long id;
  String description;

  MyWritable(long mid, String mdescription) {
    id = mid;
    description = mdescription;
  }

  public void readFields(DataInput in) throws IOException {
    this.id = in.readLong();
    this.description = Text.readString(in);
  }

  public void readFields(ResultSet resultSet)
      throws SQLException {
    this.id = resultSet.getLong(1);
    this.description = resultSet.getString(2);
  }

  public void write(DataOutput out) throws IOException {
    out.writeLong(this.id);
    Text.writeString(out, this.description);
  }

  public void write(PreparedStatement stmt) throws SQLException {
    stmt.setLong(1, this.id);
    stmt.setString(2, this.description);
  }
}






public static class Reduce extends MapReduceBase implements
Reducer<Text, IntWritable, MyWritable, IntWritable> {
  public void reduce(Text key, Iterator<IntWritable> values,
OutputCollector<MyWritable, IntWritable> output, Reporter reporter)
throws IOException {
    int sum = 0;
    while (values.hasNext()) {
      sum += values.next().get();
    }

    output.collect(new MyWritable(sum, key.toString()), new IntWritable(sum));
  }
}





public static void main(String[] args) throws Exception {
  JobConf conf = new JobConf(WordCount.class);
  conf.setJobName("wordcount");

  conf.setMapperClass(Map.class);

  conf.setReducerClass(Reduce.class);

  DBConfiguration.configureDB(conf, "com.mysql.jdbc.Driver",
"jdbc:mysql://localhost:8100/testvmysqlsb", "dummy", "pass");


  String fields[] = {"id", "description"};
  DBOutputFormat.setOutput(conf, "funtable", fields);



  conf.setNumMapTasks(1);
  conf.setNumReduceTasks(1);

  conf.setMapOutputKeyClass(Text.class);
  conf.setMapOutputValueClass(IntWritable.class);


  conf.setOutputKeyClass(MyWritable.class);
  conf.setOutputValueClass(IntWritable.class);

  conf.setInputFormat(TextInputFormat.class);




  FileInputFormat.setInputPaths(conf, new Path(args[0]));


  JobClient.runJob(conf);
}

From common-user-return-16955-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 00:08:53 2009
Return-Path: <common-user-return-16955-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 82687 invoked from network); 21 Aug 2009 00:08:53 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 00:08:53 -0000
Received: (qmail 30456 invoked by uid 500); 21 Aug 2009 00:09:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 30396 invoked by uid 500); 21 Aug 2009 00:09:09 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 30386 invoked by uid 99); 21 Aug 2009 00:09:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 00:09:09 +0000
X-ASF-Spam-Status: No, hits=3.3 required=10.0
	tests=DATE_IN_FUTURE_12_24,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zjffdu@gmail.com designates 209.85.216.190 as permitted sender)
Received: from [209.85.216.190] (HELO mail-px0-f190.google.com) (209.85.216.190)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 00:08:59 +0000
Received: by pxi28 with SMTP id 28so3571561pxi.2
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 17:08:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:from:to:references
         :in-reply-to:subject:date:message-id:mime-version:content-type
         :content-transfer-encoding:x-mailer:thread-index:content-language;
        bh=4005WPiVO5RjhgDWmbcUFYelp0nENf1xbVMYIh0KBxI=;
        b=YmzYbvIlt6zs07tjN6MmWLR7rsvJ93SLRnGzyQeFOkiV0K23GosiI3B+Jh44TLcVSF
         ahJL/r+7V1/HOWUtsZnUO+55Pp6+IC5Hx/vsSUX0WhJH+PG9YTMFTufs7A+EbYDz1K2V
         cmYZ371ICoC8scB2uOOuCpea56sIkZwcUSdq4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=from:to:references:in-reply-to:subject:date:message-id:mime-version
         :content-type:content-transfer-encoding:x-mailer:thread-index
         :content-language;
        b=MXzDAHtZRQPKd5+RWnAIKzlvfralrYNWAXkl9bAvdPaA8eHmKdfsc/EPQkcT5LG5/Q
         0SQigs+YUvqe4XS5feoZemK2mf+gaRphqUz9vR95N1gJpRtNSd9SGlQJ2hlI5TUHyyjL
         ssSPDh9SZ+va4OPFdou5RIzhOK3fYz/00Tfvc=
Received: by 10.114.250.11 with SMTP id x11mr601457wah.70.1250813319370;
        Thu, 20 Aug 2009 17:08:39 -0700 (PDT)
Received: from zjf ([58.247.233.141])
        by mx.google.com with ESMTPS id n9sm167001wag.23.2009.08.20.17.08.37
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Thu, 20 Aug 2009 17:08:38 -0700 (PDT)
From: "zjffdu" <zjffdu@gmail.com>
To: <common-user@hadoop.apache.org>
References: <69035570908131902o32deaa8cv147f753a7e741f55@mail.gmail.com> <51284.88272.qm@web110107.mail.gq1.yahoo.com>
In-Reply-To: <51284.88272.qm@web110107.mail.gq1.yahoo.com>
Subject: RE: Cluster Disk Usage
Date: Fri, 21 Aug 2009 08:10:06 -0700
Message-ID: <017501ca2271$7a73aad0$6f5b0070$@com>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="gb2312"
Content-Transfer-Encoding: quoted-printable
X-Mailer: Microsoft Office Outlook 12.0
Thread-Index: Acoh6Ze4uMdpclTjQhmD1Ufr/2YhigAh82Ug
Content-Language: zh-cn
X-Virus-Checked: Checked by ClamAV on apache.org

You can use the jobtracker Web UI to use the disk usage.



-----Original Message-----
From: Arvind Sharma [mailto:arvind321@yahoo.com]=20
Sent: 2009=C4=EA8=D4=C220=C8=D5 15:57
To: common-user@hadoop.apache.org
Subject: Cluster Disk Usage

Is there a way to find out how much disk space - overall or per Datanode
basis - is available before creating a file ?

I am trying to address an issue where the disk got full (config error) =
and
the client was not able to create a file on the HDFS.

I want to be able to check if  there space left on the grid before =
trying to
create the file.

Arvind



     =20


From common-user-return-16956-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 00:21:48 2009
Return-Path: <common-user-return-16956-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 85819 invoked from network); 21 Aug 2009 00:21:47 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 00:21:47 -0000
Received: (qmail 41142 invoked by uid 500); 21 Aug 2009 00:22:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 41067 invoked by uid 500); 21 Aug 2009 00:22:03 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 41056 invoked by uid 99); 21 Aug 2009 00:22:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 00:22:03 +0000
X-ASF-Spam-Status: No, hits=3.3 required=10.0
	tests=DATE_IN_FUTURE_12_24,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zjffdu@gmail.com designates 209.85.216.190 as permitted sender)
Received: from [209.85.216.190] (HELO mail-px0-f190.google.com) (209.85.216.190)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 00:21:52 +0000
Received: by pxi28 with SMTP id 28so3576692pxi.2
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 17:21:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:from:to:references
         :in-reply-to:subject:date:message-id:mime-version:content-type
         :content-transfer-encoding:x-mailer:thread-index:content-language;
        bh=81kmvglRgHVnL2nY6IamQ1957htj6gFa64Bl9oQzQG0=;
        b=xCD7YO1jpZYgfVC9PL0uZn3Y7qC9xY4xcK+JggY0Zhe18Oi5HNPRmcB0ITvUCjPu4i
         nv/os2vzkA2ficz6xa6JvI9H7P5ssRVhVRfLyzMmC8HedVn9wIqxym26ToeAWv+LFXHq
         eaXdjpH9NUl+X5i35BAsV6ogVUHHbC2MeSCyE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=from:to:references:in-reply-to:subject:date:message-id:mime-version
         :content-type:content-transfer-encoding:x-mailer:thread-index
         :content-language;
        b=FQyRisXJz0MCOiWH2/fHcR6svyKaWE/s71AwBppm7paMf+K32JhJiWjzzpEcA73/l9
         XMysNjs4Bf51N9IlXRhwTpaN1/AImGknQYLR5qi0SL+3EB5Zx2Iw0OzoFDPrdKrALGFA
         BK8y6vjh1+nZroxFkuWl9u5Vtyu2ms+CQjcrk=
Received: by 10.115.65.39 with SMTP id s39mr585345wak.194.1250814091305;
        Thu, 20 Aug 2009 17:21:31 -0700 (PDT)
Received: from zjf ([58.247.233.141])
        by mx.google.com with ESMTPS id n9sm165282wag.58.2009.08.20.17.21.29
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Thu, 20 Aug 2009 17:21:30 -0700 (PDT)
From: "zjffdu" <zjffdu@gmail.com>
To: <common-user@hadoop.apache.org>
References: <69035570908131902o32deaa8cv147f753a7e741f55@mail.gmail.com> <51284.88272.qm@web110107.mail.gq1.yahoo.com> <888894.94802.qm@web110103.mail.gq1.yahoo.com> <403425.54775.qm@web110111.mail.gq1.yahoo.com>
In-Reply-To: <403425.54775.qm@web110111.mail.gq1.yahoo.com>
Subject: RE: Cluster Disk Usage
Date: Fri, 21 Aug 2009 08:22:58 -0700
Message-ID: <017601ca2273$468d9df0$d3a8d9d0$@com>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="gb2312"
Content-Transfer-Encoding: quoted-printable
X-Mailer: Microsoft Office Outlook 12.0
Thread-Index: Acoh8ELL1OncQXhHQ8K9xX1TaRBNxAAgoUgQ
Content-Language: zh-cn
X-Virus-Checked: Checked by ClamAV on apache.org

Arvind,

You can use this API to get the size of file system used

FileSystem.getUsed();


But, I do not find the API for calculate the remaining space. You can =
write
some code to create a API, =20

The remaining disk space =3D Total of disk space - operate system space =
-
FileSystem.getUsed()=20



-----Original Message-----
From: Arvind Sharma [mailto:arvind321@yahoo.com]=20
Sent: 2009=C4=EA8=D4=C220=C8=D5 16:45
To: common-user@hadoop.apache.org
Subject: Re: Cluster Disk Usage

Sorry, I also sent a direct e-mail to one response....=20

there I asked one question - what is the cost of these APIs ???  Are =
they
too expensive calls ?  Is the API only going to the NN which stores this
data ?

Thanks!
Arvind




________________________________
From: Arvind Sharma <arvind321@yahoo.com>
To: common-user@hadoop.apache.org
Sent: Thursday, August 20, 2009 4:01:02 PM
Subject: Re: Cluster Disk Usage

Using hadoop-0.19.2




________________________________
From: Arvind Sharma <arvind321@yahoo.com>
To: common-user@hadoop.apache.org
Sent: Thursday, August 20, 2009 3:56:53 PM
Subject: Cluster Disk Usage

Is there a way to find out how much disk space - overall or per Datanode
basis - is available before creating a file ?

I am trying to address an issue where the disk got full (config error) =
and
the client was not able to create a file on the HDFS.

I want to be able to check if  there space left on the grid before =
trying to
create the file.

Arvind


     =20


From common-user-return-16957-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 00:30:22 2009
Return-Path: <common-user-return-16957-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 87954 invoked from network); 21 Aug 2009 00:30:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 00:30:21 -0000
Received: (qmail 50358 invoked by uid 500); 21 Aug 2009 00:30:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 50310 invoked by uid 500); 21 Aug 2009 00:30:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 50300 invoked by uid 99); 21 Aug 2009 00:30:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 00:30:37 +0000
X-ASF-Spam-Status: No, hits=3.3 required=10.0
	tests=DATE_IN_FUTURE_12_24,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zjffdu@gmail.com designates 209.85.222.200 as permitted sender)
Received: from [209.85.222.200] (HELO mail-pz0-f200.google.com) (209.85.222.200)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 00:30:27 +0000
Received: by pzk38 with SMTP id 38so29223pzk.5
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 17:30:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:from:to:references
         :in-reply-to:subject:date:message-id:mime-version:content-type
         :content-transfer-encoding:x-mailer:thread-index:content-language;
        bh=Qt2zFa4w/pIp4JDEAlawUhuQGz89UrBUJ+8cHvGVdgY=;
        b=juCBk4iV3qk5AnKLRJscRo3guCXTOLbcn2zI7MjH3S4yhdvzy+Tyu8xUd5grYAYcyz
         Larlc2lKcaIpQlGE9bmxYDxoSHEwFJS6antJlQJemv/rrxbc++4k01jTWVrB363Pv1gs
         83G3FOcQH8zL4qbXyQh4oxmXLzIDRhaSPClEo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=from:to:references:in-reply-to:subject:date:message-id:mime-version
         :content-type:content-transfer-encoding:x-mailer:thread-index
         :content-language;
        b=bE/8JB4+NC22oqNa/Uvmbw1sI/RhervF2HlkWv1tNToXwqYrGWBzpYNj7JX4n4Sz7+
         F/SdenKbo6rfUKSXfrPn1CbRhLnx0OLys98FoM4KPbr7R8NixsJXQWGPjSggs2ZR5sPs
         WubWNaJ7M0cp45Fy15BlbvLURqI2HxzxoSrFs=
Received: by 10.114.7.14 with SMTP id 14mr603633wag.171.1250814606322;
        Thu, 20 Aug 2009 17:30:06 -0700 (PDT)
Received: from zjf ([58.247.233.141])
        by mx.google.com with ESMTPS id j31sm178942waf.49.2009.08.20.17.30.04
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Thu, 20 Aug 2009 17:30:05 -0700 (PDT)
From: "zjffdu" <zjffdu@gmail.com>
To: <common-user@hadoop.apache.org>
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com> <65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com>
In-Reply-To: <65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com>
Subject: RE: MR job scheduler
Date: Fri, 21 Aug 2009 08:31:33 -0700
Message-ID: <017701ca2274$79929240$6cb7b6c0$@com>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="gb2312"
Content-Transfer-Encoding: quoted-printable
X-Mailer: Microsoft Office Outlook 12.0
Thread-Index: AcohxiC9KN87lbWsRn6JNFVo6hTrBgArWaLQ
Content-Language: zh-cn
X-Virus-Checked: Checked by ClamAV on apache.org

Add some detials:

1. #map is determined by the block size and InputFormat (whether you can
want to split or not split)

2. The default scheduler for Hadoop is FIFO, and the Fair Scheduler and
Capacity Scheduler are other two options as I know.  JobTracker has the
scheduler.

3. Once the map task is done, it will tell its own tasktracker, and the
tasktracker will tell jobtracker, so jobtracker manage all the tasks, =
and it
will decide how to and when to start the reduce task



-----Original Message-----
From: Arun C Murthy [mailto:acm@yahoo-inc.com]=20
Sent: 2009=C4=EA8=D4=C220=C8=D5 11:41
To: common-user@hadoop.apache.org
Subject: Re: MR job scheduler


On Aug 20, 2009, at 9:00 AM, bharath vissapragada wrote:

> Hi all,
>
> Can anyone tell me how the MR scheduler schedule the MR jobs?
> How does it decide where t create MAP tasks and how many to create.
> Once the MAP tasks are over how does it decide to move the keys to the
> reducer efficiently(minimizing the data movement across the network).
> Is there any doc available which describes this scheduling process =20
> quite
> efficiently
>

The #maps is decided by the application. The scheduler decides where =20
to execute them.

Once the map is done, the reduce tasks connect to the tasktracker (on =20
the node where the map-task executed) and copies the entire output =20
over http.

Arun


From common-user-return-16958-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 04:20:47 2009
Return-Path: <common-user-return-16958-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 27693 invoked from network); 21 Aug 2009 04:20:47 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 04:20:47 -0000
Received: (qmail 35669 invoked by uid 500); 21 Aug 2009 04:21:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 35461 invoked by uid 500); 21 Aug 2009 04:21:03 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35451 invoked by uid 99); 21 Aug 2009 04:21:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 04:21:02 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bharathvissapragada1990@gmail.com designates 74.125.92.24 as permitted sender)
Received: from [74.125.92.24] (HELO qw-out-2122.google.com) (74.125.92.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 04:20:54 +0000
Received: by qw-out-2122.google.com with SMTP id 8so286405qwh.35
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 21:20:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=hx43pzotB66ThoBqNHvvWA3UCdcm2VwADSYoC1DXEYE=;
        b=PBDHob6SwDoZIBOHf310jJ34KOsL8B6J003XzJRRnmN45ES67HqcDWUM8I956dI2V3
         L0c0PlZgAUAnPlJec5Tg4ykp418Kb3cD05P2U6vSoDMRASOHvVyRK7oT/ltKnTckyJBb
         VS1JDt64gR8V6JCMIZFzQmr2drMtKjxMsn+kg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=Dkl26jXYXAEjzZnpFP3xTSqvvUYayz1Gkiw7b0UevuE3j950kaR1WRzosaM2jLiq0q
         dDgTUto/WiTvaVA2oBvJ8IL1GB0NvWNSDuirqsQJkwGpo74bun1czzgIECVxpOVqKfxX
         oFaq2IgGvd3WpCTxOv2+v+V2e4fZqZcxts/mo=
MIME-Version: 1.0
Received: by 10.229.19.72 with SMTP id z8mr120518qca.35.1250828433270; Thu, 20 
	Aug 2009 21:20:33 -0700 (PDT)
In-Reply-To: <017701ca2274$79929240$6cb7b6c0$@com>
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com> 
	<65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com> <017701ca2274$79929240$6cb7b6c0$@com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Fri, 21 Aug 2009 09:50:13 +0530
Message-ID: <73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com>
Subject: Re: MR job scheduler
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163683265c70a88704719f3030
X-Virus-Checked: Checked by ClamAV on apache.org

--00163683265c70a88704719f3030
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

OK i'll be a bit more specific ,

Suppose map outputs 100 different keys .

Consider a key "K" whose correspoding values may be on N diff datanodes.
Consider a datanode "D" which have maximum number of values . So instead of
moving the values on "D"
to other systems , it is useful to bring in the values from other datanodes
to "D" to minimize the data movement and
also the delay. Similar is the case with All the other keys . How does the
scheduler take care of this ?
2009/8/21 zjffdu <zjffdu@gmail.com>

> Add some detials:
>
> 1. #map is determined by the block size and InputFormat (whether you can
> want to split or not split)
>
> 2. The default scheduler for Hadoop is FIFO, and the Fair Scheduler and
> Capacity Scheduler are other two options as I know.  JobTracker has the
> scheduler.
>
> 3. Once the map task is done, it will tell its own tasktracker, and the
> tasktracker will tell jobtracker, so jobtracker manage all the tasks, and
> it
> will decide how to and when to start the reduce task
>
>
>
> -----Original Message-----
> From: Arun C Murthy [mailto:acm@yahoo-inc.com]
> Sent: 2009=E5=B9=B48=E6=9C=8820=E6=97=A5 11:41
> To: common-user@hadoop.apache.org
> Subject: Re: MR job scheduler
>
>
> On Aug 20, 2009, at 9:00 AM, bharath vissapragada wrote:
>
> > Hi all,
> >
> > Can anyone tell me how the MR scheduler schedule the MR jobs?
> > How does it decide where t create MAP tasks and how many to create.
> > Once the MAP tasks are over how does it decide to move the keys to the
> > reducer efficiently(minimizing the data movement across the network).
> > Is there any doc available which describes this scheduling process
> > quite
> > efficiently
> >
>
> The #maps is decided by the application. The scheduler decides where
> to execute them.
>
> Once the map is done, the reduce tasks connect to the tasktracker (on
> the node where the map-task executed) and copies the entire output
> over http.
>
> Arun
>
>

--00163683265c70a88704719f3030--

From common-user-return-16959-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 04:22:55 2009
Return-Path: <common-user-return-16959-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 28703 invoked from network); 21 Aug 2009 04:22:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 04:22:54 -0000
Received: (qmail 38962 invoked by uid 500); 21 Aug 2009 04:23:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 38644 invoked by uid 500); 21 Aug 2009 04:23:07 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 38559 invoked by uid 500); 21 Aug 2009 04:23:07 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 38551 invoked by uid 99); 21 Aug 2009 04:23:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 04:23:07 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jnekanayake@gmail.com designates 209.85.146.176 as permitted sender)
Received: from [209.85.146.176] (HELO wa-out-1112.google.com) (209.85.146.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 04:22:57 +0000
Received: by wa-out-1112.google.com with SMTP id j32so85976waf.29
        for <multiple recipients>; Thu, 20 Aug 2009 21:22:37 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:from:to:cc:references
         :in-reply-to:subject:date:message-id:mime-version:content-type
         :content-transfer-encoding:x-mailer:thread-index:content-language;
        bh=zUuOwLJ3nXy9tDHCYsdNyd8JOjEhdtQ6rOi7X27w/M4=;
        b=ObY9xko1icqW6EwgUfiKipAn+E+7rg+++F87pfD3PWBhPzvj/IM0HyC3o6q8fTodyW
         UYel26kJckU5B2WSPO1XM6Aq9MnTkOF8/T4KcSqLSaE/8TIoIBu14T+cHEGnjvTyBBnJ
         x0zFoujOHhYmlUi5DdOsAAVaAouV2oMZ+7fgY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=from:to:cc:references:in-reply-to:subject:date:message-id
         :mime-version:content-type:content-transfer-encoding:x-mailer
         :thread-index:content-language;
        b=qKiRasVzEH4oxQRbz+VsBPnR7GtrgV6VfwXsIy9yl0Svinii2M3MX5IsKqO3y4xrW6
         skkIIm9gmJUZwhpLoa08yytkBJ9085oTlB0Bt0HpD2XT6/RkqeA3LXIfieMpdmhhKa02
         MbzaFufht1xrh6LLm2LVM+DuH7VkbAh06hJzU=
Received: by 10.115.114.9 with SMTP id r9mr897663wam.206.1250828557085;
        Thu, 20 Aug 2009 21:22:37 -0700 (PDT)
Received: from jaliyaLAP (c-24-18-205-133.hsd1.wa.comcast.net [24.18.205.133])
        by mx.google.com with ESMTPS id m25sm452558waf.20.2009.08.20.21.22.35
        (version=SSLv3 cipher=RC4-MD5);
        Thu, 20 Aug 2009 21:22:36 -0700 (PDT)
From: "Jaliya Ekanayake" <jnekanayake@gmail.com>
To: <common-dev@hadoop.apache.org>
Cc: <core-dev@hadoop.apache.org>,
	<core-user@hadoop.apache.org>,
	<spodxx@gmail.com>
References: <002c01ca21bb$d897d2f0$89c778d0$@com> <d6d7c4410908201500n20844f3ao5c29fc1ec496d9d8@mail.gmail.com>
In-Reply-To: <d6d7c4410908201500n20844f3ao5c29fc1ec496d9d8@mail.gmail.com>
Subject: RE: Using Hadoop with executables and binary data
Date: Thu, 20 Aug 2009 21:22:34 -0700
Message-ID: <00cf01ca2217$0263af40$072b0dc0$@com>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: 7bit
X-Mailer: Microsoft Office Outlook 12.0
Thread-Index: Acoh4b8Ke5YSzre0T/S42HUE8mOCQwANNf9Q
Content-Language: en-us
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks for the quick reply.
I looked at it, but still could not figure out how to use HDFS to store
input data (binary) and call an executable.
Please note that I cannot modify the executable.

May be I am asking some dumb question, but could you please explain a bit of
how to handle the scenario I have described.

Thanks,
Jaliya

-----Original Message-----
From: Aaron Kimball [mailto:aaron@cloudera.com] 
Sent: Thursday, August 20, 2009 3:00 PM
To: common-dev@hadoop.apache.org
Cc: core-dev@hadoop.apache.org; core-user@hadoop.apache.org;
spodxx@gmail.com
Subject: Re: Using Hadoop with executables and binary data

Look into "typed bytes":
http://dumbotics.com/2009/02/24/hadoop-1722-and-typed-bytes/

On Thu, Aug 20, 2009 at 10:29 AM, Jaliya Ekanayake
<jnekanayake@gmail.com>wrote:

> Hi Stefan,
>
>
>
> I am sorry, for the late reply. Somehow the response email has slipped my
> eyes.
>
> Could you explain a bit on how to use Hadoop streaming with binary data
> formats.
>
> I can see, explanations on using it with text data formats, but not for
> binary files.
>
>
> Thank you,
>
> Jaliya
>
> Stefan Podkowinski
> Mon, 10 Aug 2009 01:40:05 -0700
>
> Jaliya,
>
> did you consider Hadoop Streaming for your case?
> http://wiki.apache.org/hadoop/HadoopStreaming
>
>
> On Wed, Jul 29, 2009 at 8:35 AM, Jaliya
> Ekanayake<jekan...@cs.indiana.edu> wrote:
> > Dear Hadoop devs,
> >
> >
> >
> > Please help me to figure out a way to program the following problem
using
> > Hadoop.
> >
> > I have a program which I need to invoke in parallel using Hadoop. The
> > program takes an input file(binary) and produce an output file (binary)
> >
> >
> >
> > Input.bin ->prog.exe-> output.bin
> >
> >
> >
> > The input data set is about 1TB in size. Each input data file is about
> 33MB
> > in size. (So I have about 31000 files)
> >
> > The output binary file is about 9KBs in size.
> >
> >
> >
> > I have implemented this program using Hadoop in the following way.
> >
> >
> >
> > I keep the input data in a shared parallel file system (Lustre File
> System).
> >
> > Then, I collect the input file names and write them to a collection of
> files
> > in HDFS (let's say hdfs_input_0.txt ..).
> >
> > Each hdfs_input file contains roughly the equal number of files URIs to
> the
> > original input file.
> >
> > The map task, simply take a string Value which is a URI to an original
> input
> > data file and execute the program as an external program.
> >
> > The output of the program is also written to the shared file system
> (Lustre
> > File System).
> >
> >
> >
> > The problem in this approach is I am not utilizing the true benefit of
> > MapReduce. The use of local disks.
> >
> > Could  you please suggest me a way to use local disks for the above
> > problem.?
> >
> >
> >
> > I thought, of the following way, but would like to verify from you if
> there
> > is a better way.
> >
> >
> >
> > 1.       Upload the original data files in HDFS
> >
> > 2.       In the map task, read the data file as an binary object.
> >
> > 3.       Save it in the local file system.
> >
> > 4.       Call the executable
> >
> > 5.       Push the output from the local file system to HDFS.
> >
> >
> >
> > Any suggestion is greatly appreciated.
> >
> >
> > Thank you,
> >
> > Jaliya
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
>
>
>
>


From common-user-return-16960-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 05:22:23 2009
Return-Path: <common-user-return-16960-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 43612 invoked from network); 21 Aug 2009 05:22:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 05:22:23 -0000
Received: (qmail 92846 invoked by uid 500); 21 Aug 2009 05:22:39 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 92737 invoked by uid 500); 21 Aug 2009 05:22:39 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 78278 invoked by uid 99); 21 Aug 2009 05:08:42 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lvzheng19800619@gmail.com designates 209.85.223.176 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=tRsQt8IKUEfY1bj88roIl59ylmguCFE2aQOcm1OoDOs=;
        b=k1bFacqrt/EdiRChc4XKZ/MlOV6cHSUMex0S1Oc7r8tQjdCWxiUGgXEpQnB0ka4YMq
         w9TWhQkQ2Te8s5Y6Fal+ZlSpEpUxrZrSQRlXRhOfi9EeYS4s1ZpakdypBiyNEkt0DtYq
         V9Uktz9gVRxrbbN1kQ/aZGJwm9dCju0lgiIBg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=D7Gvq35yIRv1680lSDD0Od6yF8hbFuF0BBLX0XljYqpStdKG80YGPvLuhUSSs69FDp
         cHEyZmyPNQSPdcc+oA6D1QSzNrwfA4D2VFHsnqiYtlEvMiHvTtTvMibU11Z/PZBsjCGb
         24ikOS6dqoZS3tN2xfYvpxAqEectfZlyXm1w0=
MIME-Version: 1.0
Date: Fri, 21 Aug 2009 13:08:14 +0800
Message-ID: <f7a6f8650908202208w5d595629x8a3baac10580a5d7@mail.gmail.com>
Subject: Exception when starting namenode
From: Zheng Lv <lvzheng19800619@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221532c7a4f9867b04719fda6f
X-Virus-Checked: Checked by ClamAV on apache.org

--00221532c7a4f9867b04719fda6f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello,

    I got these exceptions when I started the cluster, any suggestions?
    I used hadoop 0.15.2.
    2009-08-21 12:12:53,463 ERROR org.apache.hadoop.dfs.NameNode:
java.io.EOFException
        at java.io.DataInputStream.readInt(DataInputStream.java:375)
        at org.apache.hadoop.dfs.FSImage.loadFSImage(FSImage.java:650)
        at org.apache.hadoop.dfs.FSImage.loadFSImage(FSImage.java:614)
        at
org.apache.hadoop.dfs.FSImage.recoverTransitionRead(FSImage.java:222)
        at
org.apache.hadoop.dfs.FSDirectory.loadFSImage(FSDirectory.java:76)
        at org.apache.hadoop.dfs.FSNamesystem.<init>(FSNamesystem.java:221)
        at org.apache.hadoop.dfs.NameNode.init(NameNode.java:130)
        at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:168)
        at org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:804)
        at org.apache.hadoop.dfs.NameNode.main(NameNode.java:813)
    Thank you,
    LvZheng

--00221532c7a4f9867b04719fda6f--

From common-user-return-16961-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 05:56:52 2009
Return-Path: <common-user-return-16961-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 50883 invoked from network); 21 Aug 2009 05:56:52 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 05:56:52 -0000
Received: (qmail 25174 invoked by uid 500); 21 Aug 2009 05:57:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25109 invoked by uid 500); 21 Aug 2009 05:57:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25099 invoked by uid 99); 21 Aug 2009 05:57:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 05:57:07 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 05:56:57 +0000
Received: from EGL-EX07CAS02.ds.corp.yahoo.com (egl-ex07cas02.eglbp.corp.yahoo.com [203.83.248.209])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7L5t3k7089701
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 22:55:04 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=p9JB1x+IeFXEGF8Q/DuMcBrHVwCrfJGELFnJE5saSdk4+fwIuL1y6EStretXdlOm
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.206]) by
 EGL-EX07CAS02.ds.corp.yahoo.com ([203.83.248.216]) with mapi; Fri, 21 Aug
 2009 11:25:02 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Fri, 21 Aug 2009 11:23:53 +0530
Subject: RE: passing job arguments as an xml file
Thread-Topic: passing job arguments as an xml file
Thread-Index: Acoh85GUnNYA7R6hSPCQmb4VKqKTrgAL29vA
Message-ID: <616DA47B2EF5B944B91846785B512FF4CFADEA7077@EGL-EX07VS01.ds.corp.yahoo.com>
References: <fe35e3c40908201307n2b0c4066o95ae09d90b9cc086@mail.gmail.com>
In-Reply-To: <fe35e3c40908201307n2b0c4066o95ae09d90b9cc086@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,
GenericOptionsParser is customized only for Hadoop specific params :=20

* <code>GenericOptionsParser</code> recognizes several standarad command=20
 * line arguments, enabling applications to easily specify a namenode, a=20
 * jobtracker, additional configuration resources etc.

Ideally, all params must be passed via Tool interface. In my application, I=
 have a custom serialiizer/deseralizer classes to parse any xml file I migh=
t be supplying, which I use to generate some metadata. This can be a part o=
f the above interface as well. Hope this helps.

Thanks,
Amogh
-----Original Message-----
From: ishwar ramani [mailto:rvmishwar@gmail.com]=20
Sent: Friday, August 21, 2009 1:38 AM
To: common-user
Subject: passing job arguments as an xml file

Hi,

I am looking at an easy way to passing the job arguments trough a config fi=
le.
The genericoptionsparser seems to parse only the hadoop options.

Normally i use jsap but that would not co-exist with  genericoptionsparser =
....

thanks
ishwar

From common-user-return-16962-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 06:11:43 2009
Return-Path: <common-user-return-16962-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 55754 invoked from network); 21 Aug 2009 06:11:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 06:11:43 -0000
Received: (qmail 34963 invoked by uid 500); 21 Aug 2009 06:11:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 34876 invoked by uid 500); 21 Aug 2009 06:11:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 34866 invoked by uid 99); 21 Aug 2009 06:11:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:11:59 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.20] (HELO mrout1-b.corp.re1.yahoo.com) (69.147.107.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:11:48 +0000
Received: from EGL-EX07CAS02.ds.corp.yahoo.com (egl-ex07cas02.eglbp.corp.yahoo.com [203.83.248.209])
	by mrout1-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7L6AtgW040563
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 23:10:56 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=iaXqqUKfFeQdmtLdlrBhX8fUCFHChNWl4GcMlwGVbbCGzRBKoOwx+Wi6wX6a23sr
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.206]) by
 EGL-EX07CAS02.ds.corp.yahoo.com ([203.83.248.216]) with mapi; Fri, 21 Aug
 2009 11:40:54 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Fri, 21 Aug 2009 11:39:45 +0530
Subject: RE: MR job scheduler
Thread-Topic: MR job scheduler
Thread-Index: AcoiFwV+TBSVKEz7TsOcyYSR2nLmHwADOxeQ
Message-ID: <616DA47B2EF5B944B91846785B512FF4CFADEA707D@EGL-EX07VS01.ds.corp.yahoo.com>
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com>
 	<65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com>
 <017701ca2274$79929240$6cb7b6c0$@com>
 <73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com>
In-Reply-To: <73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-2022-jp"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

I'm not sure that is the case with Hadoop. I think its assigning reduce tas=
k to an available tasktracker at any instant; Since a reducer polls JT for =
completed maps. And if it were the case as you said, a reducer wont be init=
ialized until all maps have completed , after which copy phase would start.=
=20

Thanks,
Amogh

-----Original Message-----
From: bharath vissapragada [mailto:bharathvissapragada1990@gmail.com]=20
Sent: Friday, August 21, 2009 9:50 AM
To: common-user@hadoop.apache.org
Subject: Re: MR job scheduler

OK i'll be a bit more specific ,

Suppose map outputs 100 different keys .

Consider a key "K" whose correspoding values may be on N diff datanodes.
Consider a datanode "D" which have maximum number of values . So instead of
moving the values on "D"
to other systems , it is useful to bring in the values from other datanodes
to "D" to minimize the data movement and
also the delay. Similar is the case with All the other keys . How does the
scheduler take care of this ?
2009/8/21 zjffdu <zjffdu@gmail.com>

> Add some detials:
>
> 1. #map is determined by the block size and InputFormat (whether you can
> want to split or not split)
>
> 2. The default scheduler for Hadoop is FIFO, and the Fair Scheduler and
> Capacity Scheduler are other two options as I know.  JobTracker has the
> scheduler.
>
> 3. Once the map task is done, it will tell its own tasktracker, and the
> tasktracker will tell jobtracker, so jobtracker manage all the tasks, and
> it
> will decide how to and when to start the reduce task
>
>
>
> -----Original Message-----
> From: Arun C Murthy [mailto:acm@yahoo-inc.com]
> Sent: 2009=1B$BG/=1B(B8=1B$B7n=1B(B20=1B$BF|=1B(B 11:41
> To: common-user@hadoop.apache.org
> Subject: Re: MR job scheduler
>
>
> On Aug 20, 2009, at 9:00 AM, bharath vissapragada wrote:
>
> > Hi all,
> >
> > Can anyone tell me how the MR scheduler schedule the MR jobs?
> > How does it decide where t create MAP tasks and how many to create.
> > Once the MAP tasks are over how does it decide to move the keys to the
> > reducer efficiently(minimizing the data movement across the network).
> > Is there any doc available which describes this scheduling process
> > quite
> > efficiently
> >
>
> The #maps is decided by the application. The scheduler decides where
> to execute them.
>
> Once the map is done, the reduce tasks connect to the tasktracker (on
> the node where the map-task executed) and copies the entire output
> over http.
>
> Arun
>
>

From common-user-return-16963-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 06:25:11 2009
Return-Path: <common-user-return-16963-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 57440 invoked from network); 21 Aug 2009 06:25:09 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 06:25:09 -0000
Received: (qmail 43159 invoked by uid 500); 21 Aug 2009 06:25:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 43071 invoked by uid 500); 21 Aug 2009 06:25:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 43061 invoked by uid 99); 21 Aug 2009 06:25:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:25:25 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:25:13 +0000
Received: from [192.168.1.64] (snvvpn1-10-73-152-c174.hq.corp.yahoo.com [10.73.152.174])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7L6NY5i099872
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 23:23:34 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:from:to:in-reply-to:content-type:
	content-transfer-encoding:mime-version:subject:date:references:x-mailer;
	b=oFIOin5JxVfmFKuFhd6iLsylmTCdY+UyWuE28TsiNj93B4WHbefd+5wLYOEW/pV8
Message-Id: <F0763B19-871A-44E1-86D1-3BBF63C376A3@yahoo-inc.com>
From: Arun C Murthy <acm@yahoo-inc.com>
To: common-user@hadoop.apache.org
In-Reply-To: <73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: MR job scheduler
Date: Thu, 20 Aug 2009 23:23:33 -0700
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com>  <65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com> <017701ca2274$79929240$6cb7b6c0$@com> <73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org


On Aug 20, 2009, at 9:20 PM, bharath vissapragada wrote:

> OK i'll be a bit more specific ,
>
> Suppose map outputs 100 different keys .
>
> Consider a key "K" whose correspoding values may be on N diff  
> datanodes.
> Consider a datanode "D" which have maximum number of values . So  
> instead of
> moving the values on "D"
> to other systems , it is useful to bring in the values from other  
> datanodes
> to "D" to minimize the data movement and
> also the delay. Similar is the case with All the other keys . How  
> does the
> scheduler take care of this ?

Map-Reduce doesn't 'bring' values from N datanodes to the map. A map  
gets a single block of data to work with, N-1 other maps get the other  
N-1 blocks; thus multiple maps might get the key K and different  
values. Eventually the output of the maps i.e. K and values <V> land  
up at one of the reduces (based on the Partitioner). Please read some  
of the widely available map-reduce literature for more details.

Arun


From common-user-return-16964-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 06:30:08 2009
Return-Path: <common-user-return-16964-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 58058 invoked from network); 21 Aug 2009 06:30:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 06:30:07 -0000
Received: (qmail 46746 invoked by uid 500); 21 Aug 2009 06:30:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 46678 invoked by uid 500); 21 Aug 2009 06:30:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 46668 invoked by uid 99); 21 Aug 2009 06:30:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:30:24 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bharathvissapragada1990@gmail.com designates 74.125.92.24 as permitted sender)
Received: from [74.125.92.24] (HELO qw-out-2122.google.com) (74.125.92.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:30:16 +0000
Received: by qw-out-2122.google.com with SMTP id 8so312016qwh.35
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 23:29:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=gvYPbl9Eq8DKwvYsIHEAHLLWKubRhujL0oSsi5okW08=;
        b=jAkghXZ8lviEt65q6CXETY0Y4VviW3Re8ezqxN9vL5VoDBSb1f4I/O7wMK+o7LoJDK
         BXJM2kYLbbzv5LRKdDsY5GiYWAaDXJUVq19qfI/GM0vAC8HHIcGYd5Hwo/mG9ld0gA/2
         nwGOMZof+zrv8Z3va9f7Yd/tIHHeDXL0Nak60=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=EnxKju94AzQB4LK3KYTBIhYg7wSL13hz60SGwDqAKaJb5W2BmVCfROS9EgDbhKRwT2
         nLXoyK9zj8YSkb4z9QBqW65hZOlSpN3fO6KUFRy3yfbR72xomtYCNGkqV/Z5hnzFDZn3
         6BBMpAhq9a4dgr1kLC0D+mgVm568yUClWUUSA=
MIME-Version: 1.0
Received: by 10.229.19.21 with SMTP id y21mr127685qca.27.1250836195188; Thu, 
	20 Aug 2009 23:29:55 -0700 (PDT)
In-Reply-To: <616DA47B2EF5B944B91846785B512FF4CFADEA707D@EGL-EX07VS01.ds.corp.yahoo.com>
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com> 
	<65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com> <017701ca2274$79929240$6cb7b6c0$@com> 
	<73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com> 
	<616DA47B2EF5B944B91846785B512FF4CFADEA707D@EGL-EX07VS01.ds.corp.yahoo.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Fri, 21 Aug 2009 11:59:35 +0530
Message-ID: <73d592f60908202329k7579c1o68e612e5041f6235@mail.gmail.com>
Subject: Re: MR job scheduler
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64f688c1622e40471a0ff6a
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64f688c1622e40471a0ff6a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Amogh

i think Reduce phase starts only when all the map phases are completed .
Because it needs all the values corresponding to a particular key!

2009/8/21 Amogh Vasekar <amogh@yahoo-inc.com>

> I'm not sure that is the case with Hadoop. I think its assigning reduce
> task to an available tasktracker at any instant; Since a reducer polls JT
> for completed maps. And if it were the case as you said, a reducer wont b=
e
> initialized until all maps have completed , after which copy phase would
> start.
>
> Thanks,
> Amogh
>
> -----Original Message-----
> From: bharath vissapragada [mailto:bharathvissapragada1990@gmail.com]
> Sent: Friday, August 21, 2009 9:50 AM
> To: common-user@hadoop.apache.org
> Subject: Re: MR job scheduler
>
> OK i'll be a bit more specific ,
>
> Suppose map outputs 100 different keys .
>
> Consider a key "K" whose correspoding values may be on N diff datanodes.
> Consider a datanode "D" which have maximum number of values . So instead =
of
> moving the values on "D"
> to other systems , it is useful to bring in the values from other datanod=
es
> to "D" to minimize the data movement and
> also the delay. Similar is the case with All the other keys . How does th=
e
> scheduler take care of this ?
> 2009/8/21 zjffdu <zjffdu@gmail.com>
>
> > Add some detials:
> >
> > 1. #map is determined by the block size and InputFormat (whether you ca=
n
> > want to split or not split)
> >
> > 2. The default scheduler for Hadoop is FIFO, and the Fair Scheduler and
> > Capacity Scheduler are other two options as I know.  JobTracker has the
> > scheduler.
> >
> > 3. Once the map task is done, it will tell its own tasktracker, and the
> > tasktracker will tell jobtracker, so jobtracker manage all the tasks, a=
nd
> > it
> > will decide how to and when to start the reduce task
> >
> >
> >
> > -----Original Message-----
> > From: Arun C Murthy [mailto:acm@yahoo-inc.com]
> > Sent: 2009=E5=B9=B48=E6=9C=8820=E6=97=A5 11:41
> > To: common-user@hadoop.apache.org
> > Subject: Re: MR job scheduler
> >
> >
> > On Aug 20, 2009, at 9:00 AM, bharath vissapragada wrote:
> >
> > > Hi all,
> > >
> > > Can anyone tell me how the MR scheduler schedule the MR jobs?
> > > How does it decide where t create MAP tasks and how many to create.
> > > Once the MAP tasks are over how does it decide to move the keys to th=
e
> > > reducer efficiently(minimizing the data movement across the network).
> > > Is there any doc available which describes this scheduling process
> > > quite
> > > efficiently
> > >
> >
> > The #maps is decided by the application. The scheduler decides where
> > to execute them.
> >
> > Once the map is done, the reduce tasks connect to the tasktracker (on
> > the node where the map-task executed) and copies the entire output
> > over http.
> >
> > Arun
> >
> >
>

--0016e64f688c1622e40471a0ff6a--

From common-user-return-16965-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 06:33:43 2009
Return-Path: <common-user-return-16965-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 59587 invoked from network); 21 Aug 2009 06:33:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 06:33:42 -0000
Received: (qmail 51408 invoked by uid 500); 21 Aug 2009 06:33:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 51310 invoked by uid 500); 21 Aug 2009 06:33:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 51295 invoked by uid 99); 21 Aug 2009 06:33:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:33:59 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bharathvissapragada1990@gmail.com designates 74.125.92.25 as permitted sender)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:33:51 +0000
Received: by qw-out-2122.google.com with SMTP id 8so312633qwh.35
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 23:33:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=zpv4nmAQjKhGyRYEMlx4OhnkCZD1DP0R7hEw6558vmo=;
        b=QbgiYWjgc7XeMNb6QqJbU0+WiEHnPePw0oeJLYfoiI+x2qFXRc+m8cJUrn+07MNUNk
         fmqmY+SB+vgBbB/COKc7xAy2A1m6rHN8LRKUJExlEmTf4Yz2AzCWaKe44SofNBrYEqms
         aFXzV4B05GDIf9cKCdmDFnxmk8z1tXkW9Khlw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=iWwNcZdE6WIKFzUOxNwlpZo+nSgoWOnV4kFy98UQ6qdP0y/Qo3W07Y5Th1rq30jjx6
         IMH+ekEiHYQyYOASSjqoP3imwWiEnxFRSHPelB/ipVnY5QARFkYlLQd2fFr4J0iP5Bzo
         pJDDgkTRI2QdeFMv7c6+KbWCR//P6jpMUWGt4=
MIME-Version: 1.0
Received: by 10.229.19.21 with SMTP id y21mr128109qca.27.1250836410206; Thu, 
	20 Aug 2009 23:33:30 -0700 (PDT)
In-Reply-To: <F0763B19-871A-44E1-86D1-3BBF63C376A3@yahoo-inc.com>
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com> 
	<65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com> <017701ca2274$79929240$6cb7b6c0$@com> 
	<73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com> 
	<F0763B19-871A-44E1-86D1-3BBF63C376A3@yahoo-inc.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Fri, 21 Aug 2009 12:03:10 +0530
Message-ID: <73d592f60908202333r497b1a66t35bc6a896f754b9c@mail.gmail.com>
Subject: Re: MR job scheduler
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64f688ce70bf00471a10b3b
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64f688ce70bf00471a10b3b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Arun

iam not talkin about the map phase . Iam talking abt the reduce phase which
starts after the map gets finished

The Key "K" iam referring to in my example is  one of the distinct keys wch
map outputs. and its corresponding values may be on any system depending on
where the map phase gets executed. In order to start the reduce phase on a
machine it has to copy all the values corresponding to a particular key over
http. Iam talking abt the way it done .
In that sense am i right?

On Fri, Aug 21, 2009 at 11:53 AM, Arun C Murthy <acm@yahoo-inc.com> wrote:

>
> On Aug 20, 2009, at 9:20 PM, bharath vissapragada wrote:
>
>  OK i'll be a bit more specific ,
>>
>> Suppose map outputs 100 different keys .
>>
>> Consider a key "K" whose correspoding values may be on N diff datanodes.
>> Consider a datanode "D" which have maximum number of values . So instead
>> of
>> moving the values on "D"
>> to other systems , it is useful to bring in the values from other
>> datanodes
>> to "D" to minimize the data movement and
>> also the delay. Similar is the case with All the other keys . How does the
>> scheduler take care of this ?
>>
>
> Map-Reduce doesn't 'bring' values from N datanodes to the map. A map gets a
> single block of data to work with, N-1 other maps get the other N-1 blocks;
> thus multiple maps might get the key K and different values. Eventually the
> output of the maps i.e. K and values <V> land up at one of the reduces
> (based on the Partitioner). Please read some of the widely available
> map-reduce literature for more details.
>
> Arun
>
>

--0016e64f688ce70bf00471a10b3b--

From common-user-return-16966-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 06:37:06 2009
Return-Path: <common-user-return-16966-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 60136 invoked from network); 21 Aug 2009 06:37:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 06:37:05 -0000
Received: (qmail 55087 invoked by uid 500); 21 Aug 2009 06:37:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 55013 invoked by uid 500); 21 Aug 2009 06:37:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 55003 invoked by uid 99); 21 Aug 2009 06:37:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:37:21 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:37:10 +0000
Received: from EGL-EX07CAS01.ds.corp.yahoo.com (egl-ex07cas01.eglbp.corp.yahoo.com [203.83.248.208])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7L6ZuEG076073
	for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 23:36:15 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=Bh/5sfKpVRSIlyl0nddxZtGmtZLDq6syz4vohno+biuISYDfcS012Kv/HFWRicVk
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.206]) by
 EGL-EX07CAS01.ds.corp.yahoo.com ([203.83.248.215]) with mapi; Fri, 21 Aug
 2009 12:06:11 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Fri, 21 Aug 2009 12:05:01 +0530
Subject: RE: MR job scheduler
Thread-Topic: MR job scheduler
Thread-Index: AcoiKOoSjxAUqR4URK62YTnmAMQ0WwAAF8kQ
Message-ID: <616DA47B2EF5B944B91846785B512FF4CFADEA707E@EGL-EX07VS01.ds.corp.yahoo.com>
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com>
 	<65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com>
 <017701ca2274$79929240$6cb7b6c0$@com>
 	<73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com>
 	<616DA47B2EF5B944B91846785B512FF4CFADEA707D@EGL-EX07VS01.ds.corp.yahoo.com>
 <73d592f60908202329k7579c1o68e612e5041f6235@mail.gmail.com>
In-Reply-To: <73d592f60908202329k7579c1o68e612e5041f6235@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-2022-jp"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Yes, but the copy phase starts with the initialization for a reducer, after=
 which it would keep polling for completed map tasks to fetch the respectiv=
e outputs.

-----Original Message-----
From: bharath vissapragada [mailto:bharathvissapragada1990@gmail.com]=20
Sent: Friday, August 21, 2009 12:00 PM
To: common-user@hadoop.apache.org
Subject: Re: MR job scheduler

Amogh

i think Reduce phase starts only when all the map phases are completed .
Because it needs all the values corresponding to a particular key!

2009/8/21 Amogh Vasekar <amogh@yahoo-inc.com>

> I'm not sure that is the case with Hadoop. I think its assigning reduce
> task to an available tasktracker at any instant; Since a reducer polls JT
> for completed maps. And if it were the case as you said, a reducer wont b=
e
> initialized until all maps have completed , after which copy phase would
> start.
>
> Thanks,
> Amogh
>
> -----Original Message-----
> From: bharath vissapragada [mailto:bharathvissapragada1990@gmail.com]
> Sent: Friday, August 21, 2009 9:50 AM
> To: common-user@hadoop.apache.org
> Subject: Re: MR job scheduler
>
> OK i'll be a bit more specific ,
>
> Suppose map outputs 100 different keys .
>
> Consider a key "K" whose correspoding values may be on N diff datanodes.
> Consider a datanode "D" which have maximum number of values . So instead =
of
> moving the values on "D"
> to other systems , it is useful to bring in the values from other datanod=
es
> to "D" to minimize the data movement and
> also the delay. Similar is the case with All the other keys . How does th=
e
> scheduler take care of this ?
> 2009/8/21 zjffdu <zjffdu@gmail.com>
>
> > Add some detials:
> >
> > 1. #map is determined by the block size and InputFormat (whether you ca=
n
> > want to split or not split)
> >
> > 2. The default scheduler for Hadoop is FIFO, and the Fair Scheduler and
> > Capacity Scheduler are other two options as I know.  JobTracker has the
> > scheduler.
> >
> > 3. Once the map task is done, it will tell its own tasktracker, and the
> > tasktracker will tell jobtracker, so jobtracker manage all the tasks, a=
nd
> > it
> > will decide how to and when to start the reduce task
> >
> >
> >
> > -----Original Message-----
> > From: Arun C Murthy [mailto:acm@yahoo-inc.com]
> > Sent: 2009=1B$BG/=1B(B8=1B$B7n=1B(B20=1B$BF|=1B(B 11:41
> > To: common-user@hadoop.apache.org
> > Subject: Re: MR job scheduler
> >
> >
> > On Aug 20, 2009, at 9:00 AM, bharath vissapragada wrote:
> >
> > > Hi all,
> > >
> > > Can anyone tell me how the MR scheduler schedule the MR jobs?
> > > How does it decide where t create MAP tasks and how many to create.
> > > Once the MAP tasks are over how does it decide to move the keys to th=
e
> > > reducer efficiently(minimizing the data movement across the network).
> > > Is there any doc available which describes this scheduling process
> > > quite
> > > efficiently
> > >
> >
> > The #maps is decided by the application. The scheduler decides where
> > to execute them.
> >
> > Once the map is done, the reduce tasks connect to the tasktracker (on
> > the node where the map-task executed) and copies the entire output
> > over http.
> >
> > Arun
> >
> >
>

From common-user-return-16968-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 08:14:28 2009
Return-Path: <common-user-return-16968-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11914 invoked from network); 21 Aug 2009 08:14:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 08:14:26 -0000
Received: (qmail 72139 invoked by uid 500); 21 Aug 2009 08:14:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 72070 invoked by uid 500); 21 Aug 2009 08:14:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 72060 invoked by uid 99); 21 Aug 2009 08:14:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 08:14:46 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.216.190 as permitted sender)
Received: from [209.85.216.190] (HELO mail-px0-f190.google.com) (209.85.216.190)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 08:14:37 +0000
Received: by pxi28 with SMTP id 28so3811059pxi.2
        for <common-user@hadoop.apache.org>; Fri, 21 Aug 2009 01:14:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=0PAOdhs3V7MsXz6sNztdgbATeeliR5iLlsTxjUd/nbg=;
        b=oGdpd/F/nEAL9dcyvBZVDvaVe9kkm29A+DIJS6WOOEqSY+8gWpr1U6WQTF0huLuGgg
         as30ZoebDd9zERB0GhrAJV70ZSdzUbAxXQPCHpfQcMpDg2nDGh4eumG+RePEZQz9oM6g
         U2ddbxlKjBqAhI2j+oOWRBNHhDVNv5qTIm0YM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=sC8zUONdtWMyljP7IIhYCRNauw76iKmlbTR27uChU2R++xWIlfmVWJtcn7pifrMsxs
         /9GtrdCA0Lf58q+Xm0FJGk0ZkI8tujYC+2HokQlLKYjVE4YilY9Av/al1Knyg3G/lycd
         RGbplFVimwAw7d5wIm+Cmfrny+VgWez0ZpIVY=
MIME-Version: 1.0
Received: by 10.142.60.19 with SMTP id i19mr84956wfa.315.1250842456079; Fri, 
	21 Aug 2009 01:14:16 -0700 (PDT)
In-Reply-To: <73d592f60908202341v6434df19w2921c748983760d6@mail.gmail.com>
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com> 
	<65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com> <017701ca2274$79929240$6cb7b6c0$@com> 
	<73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com> 
	<616DA47B2EF5B944B91846785B512FF4CFADEA707D@EGL-EX07VS01.ds.corp.yahoo.com> 
	<73d592f60908202329k7579c1o68e612e5041f6235@mail.gmail.com> 
	<616DA47B2EF5B944B91846785B512FF4CFADEA707E@EGL-EX07VS01.ds.corp.yahoo.com> 
	<73d592f60908202341v6434df19w2921c748983760d6@mail.gmail.com>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Fri, 21 Aug 2009 13:43:56 +0530
Message-ID: <e01b80590908210113m7bbac13bu66a266eb780ba0cf@mail.gmail.com>
Subject: Re: MR job scheduler
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00504502ad1043bd5b0471a2742d
X-Virus-Checked: Checked by ClamAV on apache.org

--00504502ad1043bd5b0471a2742d
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Fri, Aug 21, 2009 at 12:11 PM, bharath vissapragada <
bharathvissapragada1990@gmail.com> wrote:

> Yes , My doubt is that how is the location of the reducer selected . Is it
> selected arbitrarily or is selected on a particular machine which has
> already the more values (corresponding to the key of that reducer) which
> reduces the cost of transferring data across the network(because already
> many values to that key are on that machine where the map phase
> completed)..
>

I think what you're asking for is whether a ReduceTask is scheduled on a
node which has the largest partition among all the mapoutput partitions
(p1-pN) that the ReduceTask has to fetch in order to do its job. The answer
is "no" - the ReduceTasks are assigned arbitrarily (no such optimization is
done and I think this can really be an optimization only if 1 of your
partitions is heavily skewed for some reason). Also as Amogh pointed out,
the ReduceTasks start fetching their mapoutput-partitions (shuffle phase) as
and when they hear about completed ones. So it would not be possible to
schedule ReduceTasks only on nodes with the largest partitions.

-- 
Harish Mallipeddi
http://blog.poundbang.in

--00504502ad1043bd5b0471a2742d--

From common-user-return-16967-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 08:31:22 2009
Return-Path: <common-user-return-16967-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 22046 invoked from network); 21 Aug 2009 08:31:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 08:31:21 -0000
Received: (qmail 59995 invoked by uid 500); 21 Aug 2009 06:42:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 59919 invoked by uid 500); 21 Aug 2009 06:42:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 59909 invoked by uid 99); 21 Aug 2009 06:42:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:42:22 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bharathvissapragada1990@gmail.com designates 74.125.92.27 as permitted sender)
Received: from [74.125.92.27] (HELO qw-out-2122.google.com) (74.125.92.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 06:42:13 +0000
Received: by qw-out-2122.google.com with SMTP id 8so314078qwh.35
        for <common-user@hadoop.apache.org>; Thu, 20 Aug 2009 23:41:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=7KOyP2LztKiQvmeknKyhmhO7VHq23LyOapR0tLok4Vg=;
        b=qGOSE+NEV/VqjeBMh7uSgT4pJK0saT/uTKC2xEgFxWIVgn7LhgzkTtlNhrLUT12iZu
         qTm2G9H7FPYkDxvfsLBAWsxijjJX6QXOysuqWZBsjOZLIS4stffLIxOcJpN4SzI8g6Vj
         U1aqTRdSPoAZaQrM3rV6NDIeu2/HM7V6fxCaY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=fAMGNC8A/5u3PjN6OPEkv43I8zBXGwW1fnI2YwXv9VMo5TD8ZWPnWrrtHK+TjQ4Qfv
         di+9eoKuFDDXYcEPPmfp4tQ1OCHy0iNaWN+Oeq8SChgrPS4BVzxOBmvSkF0Az8nIX+bO
         txGMKgZoVFjKiHBm4ylcCOrvKldfhbn0myPrU=
MIME-Version: 1.0
Received: by 10.229.116.140 with SMTP id m12mr133051qcq.54.1250836912118; Thu, 
	20 Aug 2009 23:41:52 -0700 (PDT)
In-Reply-To: <616DA47B2EF5B944B91846785B512FF4CFADEA707E@EGL-EX07VS01.ds.corp.yahoo.com>
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com> 
	<65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com> <017701ca2274$79929240$6cb7b6c0$@com> 
	<73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com> 
	<616DA47B2EF5B944B91846785B512FF4CFADEA707D@EGL-EX07VS01.ds.corp.yahoo.com> 
	<73d592f60908202329k7579c1o68e612e5041f6235@mail.gmail.com> 
	<616DA47B2EF5B944B91846785B512FF4CFADEA707E@EGL-EX07VS01.ds.corp.yahoo.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Fri, 21 Aug 2009 12:11:32 +0530
Message-ID: <73d592f60908202341v6434df19w2921c748983760d6@mail.gmail.com>
Subject: Re: MR job scheduler
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00c09fa216fed19db80471a129e9
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09fa216fed19db80471a129e9
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Yes , My doubt is that how is the location of the reducer selected . Is it
selected arbitrarily or is selected on a particular machine which has
already the more values (corresponding to the key of that reducer) which
reduces the cost of transferring data across the network(because already
many values to that key are on that machine where the map phase completed).=
.

2009/8/21 Amogh Vasekar <amogh@yahoo-inc.com>

> Yes, but the copy phase starts with the initialization for a reducer, aft=
er
> which it would keep polling for completed map tasks to fetch the respecti=
ve
> outputs.
>
> -----Original Message-----
> From: bharath vissapragada [mailto:bharathvissapragada1990@gmail.com]
> Sent: Friday, August 21, 2009 12:00 PM
> To: common-user@hadoop.apache.org
> Subject: Re: MR job scheduler
>
> Amogh
>
> i think Reduce phase starts only when all the map phases are completed .
> Because it needs all the values corresponding to a particular key!
>
> 2009/8/21 Amogh Vasekar <amogh@yahoo-inc.com>
>
> > I'm not sure that is the case with Hadoop. I think its assigning reduce
> > task to an available tasktracker at any instant; Since a reducer polls =
JT
> > for completed maps. And if it were the case as you said, a reducer wont
> be
> > initialized until all maps have completed , after which copy phase woul=
d
> > start.
> >
> > Thanks,
> > Amogh
> >
> > -----Original Message-----
> > From: bharath vissapragada [mailto:bharathvissapragada1990@gmail.com]
> > Sent: Friday, August 21, 2009 9:50 AM
> > To: common-user@hadoop.apache.org
> > Subject: Re: MR job scheduler
> >
> > OK i'll be a bit more specific ,
> >
> > Suppose map outputs 100 different keys .
> >
> > Consider a key "K" whose correspoding values may be on N diff datanodes=
.
> > Consider a datanode "D" which have maximum number of values . So instea=
d
> of
> > moving the values on "D"
> > to other systems , it is useful to bring in the values from other
> datanodes
> > to "D" to minimize the data movement and
> > also the delay. Similar is the case with All the other keys . How does
> the
> > scheduler take care of this ?
> > 2009/8/21 zjffdu <zjffdu@gmail.com>
> >
> > > Add some detials:
> > >
> > > 1. #map is determined by the block size and InputFormat (whether you
> can
> > > want to split or not split)
> > >
> > > 2. The default scheduler for Hadoop is FIFO, and the Fair Scheduler a=
nd
> > > Capacity Scheduler are other two options as I know.  JobTracker has t=
he
> > > scheduler.
> > >
> > > 3. Once the map task is done, it will tell its own tasktracker, and t=
he
> > > tasktracker will tell jobtracker, so jobtracker manage all the tasks,
> and
> > > it
> > > will decide how to and when to start the reduce task
> > >
> > >
> > >
> > > -----Original Message-----
> > > From: Arun C Murthy [mailto:acm@yahoo-inc.com]
> > > Sent: 2009=E5=B9=B48=E6=9C=8820=E6=97=A5 11:41
> > > To: common-user@hadoop.apache.org
> > > Subject: Re: MR job scheduler
> > >
> > >
> > > On Aug 20, 2009, at 9:00 AM, bharath vissapragada wrote:
> > >
> > > > Hi all,
> > > >
> > > > Can anyone tell me how the MR scheduler schedule the MR jobs?
> > > > How does it decide where t create MAP tasks and how many to create.
> > > > Once the MAP tasks are over how does it decide to move the keys to
> the
> > > > reducer efficiently(minimizing the data movement across the network=
).
> > > > Is there any doc available which describes this scheduling process
> > > > quite
> > > > efficiently
> > > >
> > >
> > > The #maps is decided by the application. The scheduler decides where
> > > to execute them.
> > >
> > > Once the map is done, the reduce tasks connect to the tasktracker (on
> > > the node where the map-task executed) and copies the entire output
> > > over http.
> > >
> > > Arun
> > >
> > >
> >
>

--00c09fa216fed19db80471a129e9--

From common-user-return-16969-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 09:21:49 2009
Return-Path: <common-user-return-16969-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 49524 invoked from network); 21 Aug 2009 09:21:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 09:21:48 -0000
Received: (qmail 79547 invoked by uid 500); 21 Aug 2009 09:22:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 79452 invoked by uid 500); 21 Aug 2009 09:22:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 79442 invoked by uid 99); 21 Aug 2009 09:22:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 09:22:08 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 09:21:55 +0000
Received: from EGL-EX07CAS02.ds.corp.yahoo.com (egl-ex07cas02.eglbp.corp.yahoo.com [203.83.248.209])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7L9LAKX019309
	for <common-user@hadoop.apache.org>; Fri, 21 Aug 2009 02:21:10 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=06zibv15mSRkIEL4ynqtrdBGjxt+GsEqnHNd7wVyDqzE9B2zhUje1eR+cHTVkPF3
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.206]) by
 EGL-EX07CAS02.ds.corp.yahoo.com ([203.83.248.216]) with mapi; Fri, 21 Aug
 2009 14:51:09 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Fri, 21 Aug 2009 14:50:00 +0530
Subject: RE: MR job scheduler
Thread-Topic: MR job scheduler
Thread-Index: AcoiKr6O5NUh13l2SeOnQScr7TQUQQACMNoA
Message-ID: <616DA47B2EF5B944B91846785B512FF4CFADEA708D@EGL-EX07VS01.ds.corp.yahoo.com>
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com>
 	<65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com>
 <017701ca2274$79929240$6cb7b6c0$@com>
 	<73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com>
 	<616DA47B2EF5B944B91846785B512FF4CFADEA707D@EGL-EX07VS01.ds.corp.yahoo.com>
 	<73d592f60908202329k7579c1o68e612e5041f6235@mail.gmail.com>
 	<616DA47B2EF5B944B91846785B512FF4CFADEA707E@EGL-EX07VS01.ds.corp.yahoo.com>
 <73d592f60908202341v6434df19w2921c748983760d6@mail.gmail.com>
In-Reply-To: <73d592f60908202341v6434df19w2921c748983760d6@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-2022-jp"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Let me rephrase,

1. Copy phase starts after reducer initialization, which happens before all=
 maps have completed.
2. Which mapper has maximum values for a particular key wont be known until=
 all mappers have completed ( to be more precise, until a particular percen=
tage of running mappers is completed as we have the "current" maximum value=
 mapper).
Also, there is no rule which says one record can go to only one reducer.

Thanks,
Amogh

-----Original Message-----
From: bharath vissapragada [mailto:bharathvissapragada1990@gmail.com]=20
Sent: Friday, August 21, 2009 12:12 PM
To: common-user@hadoop.apache.org
Subject: Re: MR job scheduler

Yes , My doubt is that how is the location of the reducer selected . Is it
selected arbitrarily or is selected on a particular machine which has
already the more values (corresponding to the key of that reducer) which
reduces the cost of transferring data across the network(because already
many values to that key are on that machine where the map phase completed).=
.

2009/8/21 Amogh Vasekar <amogh@yahoo-inc.com>

> Yes, but the copy phase starts with the initialization for a reducer, aft=
er
> which it would keep polling for completed map tasks to fetch the respecti=
ve
> outputs.
>
> -----Original Message-----
> From: bharath vissapragada [mailto:bharathvissapragada1990@gmail.com]
> Sent: Friday, August 21, 2009 12:00 PM
> To: common-user@hadoop.apache.org
> Subject: Re: MR job scheduler
>
> Amogh
>
> i think Reduce phase starts only when all the map phases are completed .
> Because it needs all the values corresponding to a particular key!
>
> 2009/8/21 Amogh Vasekar <amogh@yahoo-inc.com>
>
> > I'm not sure that is the case with Hadoop. I think its assigning reduce
> > task to an available tasktracker at any instant; Since a reducer polls =
JT
> > for completed maps. And if it were the case as you said, a reducer wont
> be
> > initialized until all maps have completed , after which copy phase woul=
d
> > start.
> >
> > Thanks,
> > Amogh
> >
> > -----Original Message-----
> > From: bharath vissapragada [mailto:bharathvissapragada1990@gmail.com]
> > Sent: Friday, August 21, 2009 9:50 AM
> > To: common-user@hadoop.apache.org
> > Subject: Re: MR job scheduler
> >
> > OK i'll be a bit more specific ,
> >
> > Suppose map outputs 100 different keys .
> >
> > Consider a key "K" whose correspoding values may be on N diff datanodes=
.
> > Consider a datanode "D" which have maximum number of values . So instea=
d
> of
> > moving the values on "D"
> > to other systems , it is useful to bring in the values from other
> datanodes
> > to "D" to minimize the data movement and
> > also the delay. Similar is the case with All the other keys . How does
> the
> > scheduler take care of this ?
> > 2009/8/21 zjffdu <zjffdu@gmail.com>
> >
> > > Add some detials:
> > >
> > > 1. #map is determined by the block size and InputFormat (whether you
> can
> > > want to split or not split)
> > >
> > > 2. The default scheduler for Hadoop is FIFO, and the Fair Scheduler a=
nd
> > > Capacity Scheduler are other two options as I know.  JobTracker has t=
he
> > > scheduler.
> > >
> > > 3. Once the map task is done, it will tell its own tasktracker, and t=
he
> > > tasktracker will tell jobtracker, so jobtracker manage all the tasks,
> and
> > > it
> > > will decide how to and when to start the reduce task
> > >
> > >
> > >
> > > -----Original Message-----
> > > From: Arun C Murthy [mailto:acm@yahoo-inc.com]
> > > Sent: 2009=1B$BG/=1B(B8=1B$B7n=1B(B20=1B$BF|=1B(B 11:41
> > > To: common-user@hadoop.apache.org
> > > Subject: Re: MR job scheduler
> > >
> > >
> > > On Aug 20, 2009, at 9:00 AM, bharath vissapragada wrote:
> > >
> > > > Hi all,
> > > >
> > > > Can anyone tell me how the MR scheduler schedule the MR jobs?
> > > > How does it decide where t create MAP tasks and how many to create.
> > > > Once the MAP tasks are over how does it decide to move the keys to
> the
> > > > reducer efficiently(minimizing the data movement across the network=
).
> > > > Is there any doc available which describes this scheduling process
> > > > quite
> > > > efficiently
> > > >
> > >
> > > The #maps is decided by the application. The scheduler decides where
> > > to execute them.
> > >
> > > Once the map is done, the reduce tasks connect to the tasktracker (on
> > > the node where the map-task executed) and copies the entire output
> > > over http.
> > >
> > > Arun
> > >
> > >
> >
>

From common-user-return-16970-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 09:40:31 2009
Return-Path: <common-user-return-16970-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63438 invoked from network); 21 Aug 2009 09:40:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 09:40:31 -0000
Received: (qmail 7352 invoked by uid 500); 21 Aug 2009 09:40:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 7275 invoked by uid 500); 21 Aug 2009 09:40:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 7265 invoked by uid 500); 21 Aug 2009 09:40:50 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 7262 invoked by uid 99); 21 Aug 2009 09:40:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 09:40:50 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 09:40:42 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MeQbd-0001D5-DT
	for core-user@hadoop.apache.org; Fri, 21 Aug 2009 02:40:21 -0700
Message-ID: <25076132.post@talk.nabble.com>
Date: Fri, 21 Aug 2009 02:40:21 -0700 (PDT)
From: udiw <udi.weinsberg@gmail.com>
To: core-user@hadoop.apache.org
Subject: Job design question
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: udi.weinsberg@gmail.com
X-Virus-Checked: Checked by ClamAV on apache.org


Hi all,
I'm trying to design an MR job for processing "walks-on-graph" data from
database. The idea is that I have a list of random walks on a graph (which
is unknown).

I have two tables ("walk ids" and "hops"): 
- the first holds the list of random-walk ids, one row per walk, each is
unique id (increasing).
- the second holds, for each walk (identified by the uid) the list of hops
(vertices) traversed in the walk (one hop per row) 
-- these two tables are in a "one-to-many" structure, with the walk uid used
as a foreign key in the hops table.

Meaning, walks should be split between nodes but hops per walk must not.
How would you suggest handling this structure? is it even possible with
DBInputFormat?

Second, assuming it is possible to have this split in an MR job, I would
like to have different reducers that operate on the data during reading (I
want to avoid multiple reading since it can take a long time).
For example, one Reducer should create the actual graph: (Source Node,Dest
Node)-->(num_walks).
Another one should create a length analysis: (Origin Node, Final
Node)-->distance
etc.

Any comments and thoughts will help!
Thanks.
-- 
View this message in context: http://www.nabble.com/Job-design-question-tp25076132p25076132.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-16971-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 10:11:17 2009
Return-Path: <common-user-return-16971-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 77973 invoked from network); 21 Aug 2009 10:11:17 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 10:11:16 -0000
Received: (qmail 44554 invoked by uid 500); 21 Aug 2009 10:11:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 44473 invoked by uid 500); 21 Aug 2009 10:11:36 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 44461 invoked by uid 99); 21 Aug 2009 10:11:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 10:11:36 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [140.203.201.101] (HELO mx2.nuigalway.ie) (140.203.201.101)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 10:11:26 +0000
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: ApoEAM8PjkoKhJ0L/2dsb2JhbADGBgiQUoJFCIFLBQ
X-IronPort-AV: E=Sophos;i="4.44,249,1249254000"; 
   d="scan'208";a="6096033"
Received: from unknown (HELO EVS1.ac.nuigalway.ie) ([10.132.157.11])
  by mx2.nuigalway.ie with ESMTP; 21 Aug 2009 11:10:32 +0100
Received: from EVS1.ac.nuigalway.ie ([10.132.157.14]) by EVS1.ac.nuigalway.ie with Microsoft SMTPSVC(6.0.3790.3959);
	 Fri, 21 Aug 2009 11:10:31 +0100
Received: from [10.2.18.121] ([140.203.154.11]) by EVS1.ac.nuigalway.ie over TLS secured channel with Microsoft SMTPSVC(6.0.3790.3959);
	 Fri, 21 Aug 2009 11:10:31 +0100
Message-ID: <4A8E7296.9070405@deri.org>
Date: Fri, 21 Aug 2009 11:10:30 +0100
From: stephen mulcahy <stephen.mulcahy@deri.org>
User-Agent: Mozilla-Thunderbird 2.0.0.22 (X11/20090706)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Running hadoop jobs from a client and tuning  (was Re: How does
 hadoop deal with hadoop-site.xml?)
References: <3b1311780908190721g3814f4dft9e00e9edce1eb86b@mail.gmail.com> 	<d6d7c4410908191638g6c9452f7h104cad20ba604f7e@mail.gmail.com> 	<3b1311780908192039p441bb4eciaf877e67dca6786f@mail.gmail.com> <d6d7c4410908200006k762e70aapc428c0ddf71778d@mail.gmail.com> <4A8D1CD2.9000703@deri.org> <616DA47B2EF5B944B91846785B512FF4CFADEA7046@EGL-EX07VS01.ds.corp.yahoo.com>
In-Reply-To: <616DA47B2EF5B944B91846785B512FF4CFADEA7046@EGL-EX07VS01.ds.corp.yahoo.com>
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit
X-OriginalArrivalTime: 21 Aug 2009 10:10:31.0702 (UTC) FILETIME=[9DAF6360:01CA2247]
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Amogh,

Thanks for your reply. Some comments below.

Amogh Vasekar wrote:
> AFAIK,
> hadoop.tmp.dir : Used by NN and DN for directory listings and metadata ( don't have much info on this )

I've been running some test jobs against a local hadoop cluster from 
eclipse using the eclipse plugin. The eclipse plugin manages the client 
equivalent of hadoop-site.xml in it's settings. One of the settings 
there is hadoop.tmp.dir. When running a hadoop job through eclipse, 
there are sometimes items created on the client machine in the 
designated hadoop.tmp.dir so there is a client notion of a 
hadoop.tmp.dir aswell.

Some of my confusion is arising from trying to get client jobs working 
on our cluster while running as someone other than the superuser - what 
I thought were permissions errors may have been caused by blindly 
copying the hadoop.tmp.dir setting from a cluster node for client use - 
instead of setting this to something client specific like 
/tmp/hadoop-${user}

> java.opts & ulimit : ulimit defines the maximum limit of virtual mem for task launched. java.opts is the amount of memory reserved for a task. 
> When setting you need to account for memory set aside for hadoop daemons like tasktracker etc.

Right. This is the one tunable I mostly understand :)

> mapred.map.tasks and mapred.reduce.tasks : these are job wide configurations and not per-task configurations for a node. Acts as a hint to the hadoop framework and explicitly setting them might not be always recommended, unless you want to run a no-reducer job.

I notice in the Hadoop samples like WordCount, the mappers and reducers 
are being explicitly set in the code. Is there any standard approach to 
this? Is it better to set this in the client's hadoop-site.xml after 
understanding the capacity of the cluster or do developers normally make 
their own call on this? As a hadoop cluster admin, should I let 
developers worry about this themselves and concentrate on the 
per-machine limits below?

> mapred.tasktracker.(map | reduce )tasks.maximum : Limit on concurrent tasks running on a machine, typically set according to cores & memory each map/reduce task will be using.

Right, so as an admin, these are probably the more interesting ones to 
worry.

> Also, typically client and datanodes will be the same.

Given my comments above, is this correct?

Thanks,

-stephen

-- 
Stephen Mulcahy, DI2, Digital Enterprise Research Institute,
NUI Galway, IDA Business Park, Lower Dangan, Galway, Ireland
http://di2.deri.ie    http://webstar.deri.ie    http://sindice.com

From common-user-return-16972-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 10:20:03 2009
Return-Path: <common-user-return-16972-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81117 invoked from network); 21 Aug 2009 10:20:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 10:20:02 -0000
Received: (qmail 52264 invoked by uid 500); 21 Aug 2009 10:20:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52214 invoked by uid 500); 21 Aug 2009 10:20:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52204 invoked by uid 500); 21 Aug 2009 10:20:22 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 52201 invoked by uid 99); 21 Aug 2009 10:20:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 10:20:22 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zjffdu@gmail.com designates 209.85.222.200 as permitted sender)
Received: from [209.85.222.200] (HELO mail-pz0-f200.google.com) (209.85.222.200)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 10:20:13 +0000
Received: by pzk38 with SMTP id 38so63073pzk.5
        for <core-user@hadoop.apache.org>; Fri, 21 Aug 2009 03:19:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=EVZtxajKUlXnvGWfKam9BudQD2vi/oHekeZEQ1wENRA=;
        b=r50Tjy8Eej+2XKo4V3qP1cNhnplnR0FX3a/tO+PLtLihu2zEfiVqZO+e61qv9COIOl
         6CUrm3q8slpJ2DFLXu4BOsmc6x0/E0b25IKZYelj/w3PHalrliu7Lx4/JYX+7EG4MaN1
         /jvTyY0+Ugs/6fl9LDCQpts2UjWnvgBd/sN5M=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=Nu58S4iCvfvv6MfwbLo5H/GnDyBJScSGaZ0zMBVioGgq1+/Pym193PHyihH27zqDkq
         4z8u0VU4HBLyPfpOgzu0HJ1Gxgg7yBVHhje1RjFh+oLpLGc5vV4VIVqae2PMIyJWi636
         6HexPQ4On1IXYD2ES3nh5/u8bT63eljVT3IAI=
MIME-Version: 1.0
Received: by 10.143.131.1 with SMTP id i1mr47652wfn.339.1250849992088; Fri, 21 
	Aug 2009 03:19:52 -0700 (PDT)
Date: Fri, 21 Aug 2009 18:19:52 +0800
Message-ID: <8211a1320908210319y656eb9ddw71200f65bd45fe9a@mail.gmail.com>
Subject: How can I copy files from S3 to my local hadoop cluster
From: zhang jianfeng <zjffdu@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd72d34721d9e0471a4357f
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd72d34721d9e0471a4357f
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hi all,


I found hadoop has a filesystem implementation for S3, So how can I copy
files from S3 to my local hadoop cluster ?
Is there any Java API examples?


Thank you.

Jeff Zhang

--000e0cd72d34721d9e0471a4357f--

From common-user-return-16973-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 11:31:40 2009
Return-Path: <common-user-return-16973-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 8536 invoked from network); 21 Aug 2009 11:31:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 11:31:40 -0000
Received: (qmail 47894 invoked by uid 500); 21 Aug 2009 11:32:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 47823 invoked by uid 500); 21 Aug 2009 11:32:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 34213 invoked by uid 500); 21 Aug 2009 07:44:01 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com.cn; s=s1024; t=1250571943; bh=k5XVd52f4RYqdstbBr8hvd28I+fbqq0yZkw5CPsextU=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:MIME-Version:Content-Type; b=YD3hH6MPqd+2sEJllZVUxcJyznQiTKROKUbxW7aq0npoXSObjFe/ZblLCWg1cByvp2IVfRbEGbgVA7ARPet0LwLwzG7VxthVhtsXtRBM3h60D0PJbLNKbQKL+i6YhIGRtt0vY79m2JmhFLKg5rZGpGrEt89NjN9GVCM9bdJMkVU=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com.cn;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:MIME-Version:Content-Type;
  b=1YxjlEBjroC6qBjcrReTvhnIhLKCehAXt29tgP4N8MJCQw8ZwAN40+fNEpZG8k6VuOx8G6R4TMZTUPTHKGOFi4VwF4cOOziqK9B/wWeJgo8v7FjmdGTAS+HCso5zssCC+K4o2ZTJjcKbhChmqno9PJDyakSyycqYEQlOY3BMDJg=;
Message-ID: <74655.90702.qm@web15206.mail.cnb.yahoo.com>
X-YMail-OSG: zN_jT0sVM1kWZgGqe09i4rP6Ynh65T4CQXi9XSi2HghOjICl8vww.JyGVVi9eu_rZ7xTnA_Xyi7eNAVOPWmrGmklhA_iecrpA7ob9z0Q31jT1dxFV7ZOqICooUe.Rb1Ko61ISJ7AlRCVuEXlllTwdhiL1d6o5snrpO0cdb_TF9Aq.zKMws6Op8C_Aap7wIJXHvLM_OIvjFfnXv8W3COSr6DL0a6SjQD9Fjjli9YDNNmoehpB
X-Mailer: YahooMailClassic/6.1.2 YahooMailWebService/0.7.338.2
Date: Tue, 18 Aug 2009 13:05:42 +0800 (CST)
From: qiu tian <tianqiu_527@yahoo.com.cn>
Subject: Help.
To: core-user@hadoop.apache.org
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-7321796-1250571942=:90702"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-7321796-1250571942=:90702
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Hi everyone.
I installed hadoop among three pcs. When I ran the command 'start-all.sh', =
I only could start the jobtracker and tasktrackers. I use 192.*.*.x as mast=
er and use 192.*.*.y and 192.*.*.z as slaves.

The namenode log from the master 192.*.*.x is following like this:

2009-08-18 10:48:44,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* Nam=
eSystem.registerDatanode: node 192.*.*.y:50010 is replaced by 192.*.*.x:500=
10 with the same storageID DS-1120429845-127.0.0.1-50010-1246697164684
2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology: Removin=
g a node: /default-rack/192.*.*.y:50010
2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology: Adding =
a new node: /default-rack/192.*.*.x:50010
2009-08-18 10:48:45,932 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* Na=
meSystem.getDatanode: Data node 192.*.*.z:50010 is attempting to report sto=
rage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 i=
s expected to serve this storage.
2009-08-18 10:48:45,932 INFO org.apache.hadoop.ipc.Server: IPC Server handl=
er 8 on 9000, call blockReport(DatanodeRegistration(192.*.*.z:50010, storag=
eID=3DDS-1120429845-127.0.0.1-50010-1246697164684, infoPort=3D50075, ipcPor=
t=3D50020), [J@1b8ebe3) from 192.*.*.z:33177: error: org.apache.hadoop.hdfs=
.protocol.UnregisteredDatanodeException: Data node 192.*.*.z:50010 is attem=
pting to report storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Nod=
e 192.*.*.x:50010 is expected to serve this storage.
org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data node 19=
2.*.*.z:50010 is attempting to report storage ID DS-1120429845-127.0.0.1-50=
010-1246697164684. Node 192.*.*.x:50010 is expected to serve this storage.
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.FSNamesystem.getDatanode(FSNamesystem.java:3800)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.FSNamesystem.processReport(FSNamesystem.java:2771)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.NameNode.blockReport(NameNode.java:636)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at sun.reflect.GeneratedMethodAc=
cessor14.invoke(Unknown Source)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at sun.reflect.DelegatingMethodA=
ccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at java.lang.reflect.Method.invo=
ke(Method.java:597)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.ipc.RPC$Ser=
ver.call(RPC.java:452)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.ipc.Server$=
Handler.run(Server.java:892)
2009-08-18 10:48:46,398 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* Na=
meSystem.getDatanode: Data node 192.*.*.y:50010 is attempting to report sto=
rage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 i=
s expected to serve this storage.
2009-08-18 10:48:46,398 INFO org.apache.hadoop.ipc.Server: IPC Server handl=
er 0 on 9000, call blockReport(DatanodeRegistration(192.9.200.y:50010, stor=
ageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, infoPort=3D50075, ipcP=
ort=3D50020), [J@186b634) from 192.*.*.y:47367: error: org.apache.hadoop.hd=
fs.protocol.UnregisteredDatanodeException: Data node 192.*.*.y:50010 is att=
empting to report storage ID DS-1120429845-127.0.0.1-50010-1246697164684. N=
ode 192.*.*.x:50010 is expected to serve this storage.
org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data node 19=
2.*.*.y:50010 is attempting to report storage ID DS-1120429845-127.0.0.1-50=
010-1246697164684. Node 192.*.*.x:50010 is expected to serve this storage.
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.FSNamesystem.getDatanode(FSNamesystem.java:3800)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.FSNamesystem.processReport(FSNamesystem.java:2771)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.NameNode.blockReport(NameNode.java:636)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at sun.reflect.GeneratedMethodAc=
cessor14.invoke(Unknown Source)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at sun.reflect.DelegatingMethodA=
ccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at java.lang.reflect.Method.invo=
ke(Method.java:597)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.ipc.RPC$Ser=
ver.call(RPC.java:452)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.ipc.Server$=
Handler.run(Server.java:892)
2009-08-18 10:48:47,000 INFO org.apache.hadoop.hdfs.server.namenode.FSNames=
ystem: Roll Edit Log from 192.*.*.x
~=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=20

The message on the shell looks like this:
192.*.*.x: Exception in thread "main" java.io.IOException: Cannot lock stor=
age /home/gaojun/HadoopInstall/tmp/dfs/namesecondary. The directory is alre=
ady locked.
192.*.*.x: =C2=A0=C2=A0 =C2=A0at org.apache.hadoop.hdfs.server.common.Stora=
ge$StorageDirectory.lock(Storage.java:510)
192.*.*.x: =C2=A0=C2=A0 =C2=A0at org.apache.hadoop.hdfs.server.common.Stora=
ge$StorageDirectory.analyzeStorage(Storage.java:363)
192.*.*.x: =C2=A0=C2=A0 =C2=A0at org.apache.hadoop.hdfs.server.namenode.Sec=
ondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:517)
192.*.*.x: =C2=A0=C2=A0 =C2=A0at org.apache.hadoop.hdfs.server.namenode.Sec=
ondaryNameNode.initialize(SecondaryNameNode.java:145)
192.*.*.x: =C2=A0=C2=A0 =C2=A0at org.apache.hadoop.hdfs.server.namenode.Sec=
ondaryNameNode.<init>(SecondaryNameNode.java:115)
192.*.*.x: =C2=A0=C2=A0 =C2=A0at org.apache.hadoop.hdfs.server.namenode.Sec=
ondaryNameNode.main(SecondaryNameNode.java:469)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=20
I could not find the reason. Can someone help me?
Thanks!

yan =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=20
=0A=0A=0A      ___________________________________________________________ =
=0A  =E5=A5=BD=E7=8E=A9=E8=B4=BA=E5=8D=A1=E7=AD=89=E4=BD=A0=E5=8F=91=EF=BC=
=8C=E9=82=AE=E7=AE=B1=E8=B4=BA=E5=8D=A1=E5=85=A8=E6=96=B0=E4=B8=8A=E7=BA=BF=
=EF=BC=81 =0Ahttp://card.mail.cn.yahoo.com/
--0-7321796-1250571942=:90702--

From common-user-return-16974-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 13:18:46 2009
Return-Path: <common-user-return-16974-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 59669 invoked from network); 21 Aug 2009 13:18:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 13:18:45 -0000
Received: (qmail 10773 invoked by uid 500); 21 Aug 2009 13:19:05 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10688 invoked by uid 500); 21 Aug 2009 13:19:05 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10678 invoked by uid 99); 21 Aug 2009 13:19:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 13:19:05 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 13:18:55 +0000
Received: by vws40 with SMTP id 40so564887vws.2
        for <common-user@hadoop.apache.org>; Fri, 21 Aug 2009 06:18:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=0OqeZV0PsETQA1GGaB9CiMY/RIONrYWhqjObEAiy5lU=;
        b=NQT2FkEHcFyWy9aA6fqOmbZuwt0sjn2CsL7qeR3bkOu5A+BoupT/Bzz1cwzGEgNFjF
         6X5VuBpj3sVRyyiTFl2HP/o2qK1aPRd5grJC552w/npTgO+Fy+Si8/5k13lMDxcjh8JV
         aprISrqWJIk1oc4B1ijzz0L0PkBp2V05nbYA8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=fXC+tVEGIQiaKvNQc9Nn+jsWw4If5z7w1qCoRt8so08RUiedekpjsx6avPbfQ31HTU
         ii13MU2pM/Hjc2P4uOFKQIUbUoZnQqMF1HnF7499DmxVrbzZqxDR6m2lCOr3TPRlaHTr
         OHUpHE+o1gZoRIKmNfPhe6D54743NSW6fQfw4=
MIME-Version: 1.0
Received: by 10.220.42.142 with SMTP id s14mr720751vce.69.1250860713883; Fri, 
	21 Aug 2009 06:18:33 -0700 (PDT)
In-Reply-To: <4A8D8B55.8080400@yahoo-inc.com>
References: <ad681e7f0908180900s2eee6cd0y43c9f2d27a71934f@mail.gmail.com>
	 <4A8B8D11.8020008@yahoo-inc.com>
	 <cbbf4b570908190811m6ef7eaa2pd0fbb1f222071ca9@mail.gmail.com>
	 <ad681e7f0908190845j59dc22aet95e9af971efa8798@mail.gmail.com>
	 <cbbf4b570908190914j206797ecrc862d06b6eccbd37@mail.gmail.com>
	 <4A8C3D32.3010905@yahoo-inc.com>
	 <ad681e7f0908191324n1e04a72fo9ebbd436e89aef20@mail.gmail.com>
	 <4A8C6205.6000306@yahoo-inc.com>
	 <ad681e7f0908200801r52a0baa4mfd71af42263d8174@mail.gmail.com>
	 <4A8D8B55.8080400@yahoo-inc.com>
Date: Fri, 21 Aug 2009 06:18:33 -0700
Message-ID: <314098690908210618m5ee2efc2r37fea0ccd9564f60@mail.gmail.com>
Subject: Re: Faster alternative to FSDataInputStream
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163649911b83b9720471a6b4ef
X-Virus-Checked: Checked by ClamAV on apache.org

--00163649911b83b9720471a6b4ef
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

It may be some kind of hostname name or reverse lookup delay, either on the
origination or destination side.

On Thu, Aug 20, 2009 at 10:43 AM, Raghu Angadi <rangadi@yahoo-inc.com>wrote:

> Ananth T. Sarathy wrote:
>
>> it's on s3. and it always happens.
>>
>
> I have no experience with S3. You might want to check out S3 forums. It
> can't be normal for S3 either.. there must be something missing
> (configuration, ACLs... ).
>
> Raghu.
>
>
>  Ananth T Sarathy
>>
>>
>> On Wed, Aug 19, 2009 at 4:35 PM, Raghu Angadi <rangadi@yahoo-inc.com>
>> wrote:
>>
>>  Ananth T. Sarathy wrote:
>>>
>>>  Also, I just want to clear... the delay seems to at the intial
>>>>
>>>> (read = in.read(buf))
>>>>
>>>>  It the file on HDFS (over S3) or S3?
>>>
>>> Does it always happen?
>>>
>>> Raghu.
>>>
>>>
>>>  after the first time into the loop it flies...
>>>
>>>> Ananth T Sarathy
>>>>
>>>>
>>>> On Wed, Aug 19, 2009 at 1:58 PM, Raghu Angadi <rangadi@yahoo-inc.com>
>>>> wrote:
>>>>
>>>>  Edward Capriolo wrote:
>>>>
>>>>>  On Wed, Aug 19, 2009 at 11:11 AM, Edward Capriolo <
>>>>>
>>>>>> edlinuxguru@gmail.com
>>>>>>
>>>>>>  wrote:
>>>>>>>  It would be as fast as underlying filesystem goes.
>>>>>>>
>>>>>>>  I would not agree with that statement. There is overhead.
>>>>>>>> You might be misinterpreting my comment. There is of course some
>>>>>>>> over
>>>>>>>>
>>>>>>> head
>>>>> (at the least the procedure calls).. depending on you underlying
>>>>> filesystem,
>>>>> there could be extra buffer copies and CRC overhead. But none of that
>>>>> explains transfer as slow as 1 MBps (if my interpretation of of results
>>>>> is
>>>>> correct).
>>>>>
>>>>> Raghu.
>>>>>
>>>>>
>>>>>
>>>>>
>>
>


-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--00163649911b83b9720471a6b4ef--

From common-user-return-16975-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 13:25:41 2009
Return-Path: <common-user-return-16975-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63961 invoked from network); 21 Aug 2009 13:25:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 13:25:41 -0000
Received: (qmail 31512 invoked by uid 500); 21 Aug 2009 13:26:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 31435 invoked by uid 500); 21 Aug 2009 13:26:01 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 31420 invoked by uid 99); 21 Aug 2009 13:26:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 13:26:01 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 13:25:49 +0000
Received: by vws40 with SMTP id 40so568495vws.2
        for <common-user@hadoop.apache.org>; Fri, 21 Aug 2009 06:25:27 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=/IEJtHHT4S92yZj+o0dzt1/iUryLVBTyvfHmkji6mso=;
        b=G03Jnx49ZBchWknWjSAo9MvBXF4/26vb3frL9OKP6pMQAiE7+U7Ik7rdN4kvPgrBM9
         wddEZRE7aK/BYSmg+6XXID2bzWCbxip0Xlmem36/mtVqQPYFckrNgYwsYbsgVheCM9s3
         grfXYyju+yxJ9zykTc6kf/qTvLOcoeRANdCYw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=TYvByLuqEIk3/SyzxjQ4sykWWlZGfo4TUPg2spYB0I4jKa6TXiMkfs0ipl4icahoXt
         6fCoC02J9P6YPIfvN33AG3fmnKA5KMCUReDjZpihDKoSQqOh76f4vVVTOBPFGRnQVbju
         srw48LbyksR8QTe7JZXvqLzw4UAa66yIKDd/c=
MIME-Version: 1.0
Received: by 10.220.41.73 with SMTP id n9mr692293vce.3.1250861126819; Fri, 21 
	Aug 2009 06:25:26 -0700 (PDT)
In-Reply-To: <74655.90702.qm@web15206.mail.cnb.yahoo.com>
References: <74655.90702.qm@web15206.mail.cnb.yahoo.com>
Date: Fri, 21 Aug 2009 06:25:26 -0700
Message-ID: <314098690908210625q44e1eb15xf584358dce8071d@mail.gmail.com>
Subject: Re: Help.
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163646d70820a2370471a6cddb
X-Virus-Checked: Checked by ClamAV on apache.org

--00163646d70820a2370471a6cddb
Content-Type: text/plain; charset=GB2312
Content-Transfer-Encoding: quoted-printable

It may be that the individual datanodes get different names for their ip
addresses than the namenode does.
It may also be that some subset of your namenode/datanodes do not have writ=
e
access to the hdfs storage directories.


On Mon, Aug 17, 2009 at 10:05 PM, qiu tian <tianqiu_527@yahoo.com.cn> wrote=
:

> Hi everyone.
> I installed hadoop among three pcs. When I ran the command 'start-all.sh'=
,
> I only could start the jobtracker and tasktrackers. I use 192.*.*.x as
> master and use 192.*.*.y and 192.*.*.z as slaves.
>
> The namenode log from the master 192.*.*.x is following like this:
>
> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK*
> NameSystem.registerDatanode: node 192.*.*.y:50010 is replaced by
> 192.*.*.x:50010 with the same storageID
> DS-1120429845-127.0.0.1-50010-1246697164684
> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology:
> Removing a node: /default-rack/192.*.*.y:50010
> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology: Addin=
g
> a new node: /default-rack/192.*.*.x:50010
> 2009-08-18 10:48:45,932 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK*
> NameSystem.getDatanode: Data node 192.*.*.z:50010 is attempting to report
> storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50=
010
> is expected to serve this storage.
> 2009-08-18 10:48:45,932 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 8 on 9000, call blockReport(DatanodeRegistration(192.*.*.z:50010,
> storageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, infoPort=3D50075=
,
> ipcPort=3D50020), [J@1b8ebe3) from 192.*.*.z:33177: error:
> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data node
> 192.*.*.z:50010 is attempting to report storage ID
> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
> expected to serve this storage.
> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data node
> 192.*.*.z:50010 is attempting to report storage ID
> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
> expected to serve this storage.
>         at
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDatanode(FSNamesys=
tem.java:3800)
>         at
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport(FSNames=
ystem.java:2771)
>         at
> org.apache.hadoop.hdfs.server.namenode.NameNode.blockReport(NameNode.java=
:636)
>         at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
>         at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
>         at java.lang.reflect.Method.invoke(Method.java:597)
>         at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
>         at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)
> 2009-08-18 10:48:46,398 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK*
> NameSystem.getDatanode: Data node 192.*.*.y:50010 is attempting to report
> storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50=
010
> is expected to serve this storage.
> 2009-08-18 10:48:46,398 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 0 on 9000, call blockReport(DatanodeRegistration(192.9.200.y:5001=
0,
> storageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, infoPort=3D50075=
,
> ipcPort=3D50020), [J@186b634) from 192.*.*.y:47367: error:
> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data node
> 192.*.*.y:50010 is attempting to report storage ID
> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
> expected to serve this storage.
> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data node
> 192.*.*.y:50010 is attempting to report storage ID
> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
> expected to serve this storage.
>         at
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDatanode(FSNamesys=
tem.java:3800)
>         at
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport(FSNames=
ystem.java:2771)
>         at
> org.apache.hadoop.hdfs.server.namenode.NameNode.blockReport(NameNode.java=
:636)
>         at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
>         at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:25)
>         at java.lang.reflect.Method.invoke(Method.java:597)
>         at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
>         at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)
> 2009-08-18 10:48:47,000 INFO
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from
> 192.*.*.x
> ~
>
> The message on the shell looks like this:
> 192.*.*.x: Exception in thread "main" java.io.IOException: Cannot lock
> storage /home/gaojun/HadoopInstall/tmp/dfs/namesecondary. The directory i=
s
> already locked.
> 192.*.*.x:     at
> org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storag=
e.java:510)
> 192.*.*.x:     at
> org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStor=
age(Storage.java:363)
> 192.*.*.x:     at
> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorag=
e.recoverCreate(SecondaryNameNode.java:517)
> 192.*.*.x:     at
> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(Secon=
daryNameNode.java:145)
> 192.*.*.x:     at
> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(Secondary=
NameNode.java:115)
> 192.*.*.x:     at
> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNa=
meNode.java:469)
>
> I could not find the reason. Can someone help me?
> Thanks!
>
> yan
>
>
>
>      ___________________________________________________________
>  =BA=C3=CD=E6=BA=D8=BF=A8=B5=C8=C4=E3=B7=A2=A3=AC=D3=CA=CF=E4=BA=D8=BF=A8=
=C8=AB=D0=C2=C9=CF=CF=DF=A3=A1
> http://card.mail.cn.yahoo.com/
>



--=20
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--00163646d70820a2370471a6cddb--

From common-user-return-16976-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 14:20:33 2009
Return-Path: <common-user-return-16976-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 96593 invoked from network); 21 Aug 2009 14:20:33 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 14:20:33 -0000
Received: (qmail 66133 invoked by uid 500); 21 Aug 2009 14:20:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 66046 invoked by uid 500); 21 Aug 2009 14:20:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 66036 invoked by uid 99); 21 Aug 2009 14:20:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 14:20:53 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vtsujith@gmail.com designates 74.125.92.25 as permitted sender)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 14:20:41 +0000
Received: by qw-out-2122.google.com with SMTP id 8so431152qwh.35
        for <common-user@hadoop.apache.org>; Fri, 21 Aug 2009 07:20:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:from:to
         :in-reply-to:content-type:content-transfer-encoding:x-mailer
         :mime-version:subject:date:references;
        bh=dfvXfymZxQtws9WxL8vgA6S914EU0Lh0I1IqbXF786U=;
        b=rDBL5kzcY8zV+9eUYZ2M7UEGldOZBcfTEq/pB1p8Gh0Im5l6cF2zRpniR9+2CGvVzZ
         Mp44vM0FJFVo1mykKCpfVAbMHYzbSH4KpMZOr18u2Sb++CcfXZ0jinytR97QyyYys9Tr
         7YO8I/CHbbYv4xB0q2id1sLYei1+cP/9ThzUA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:from:to:in-reply-to:content-type
         :content-transfer-encoding:x-mailer:mime-version:subject:date
         :references;
        b=dUGkngMqRtjL1VGnfw+IMSshIN9RYlzC1Oj9w6EZ8S8BsoT8cA1vQaUt7Aig2cgEJj
         IYjcYckj/JdW7bPf49v2SbqMRX5J094qE5tpdlk2W8SbrT7uNEVPD0kSzzOHUOdEPyFQ
         dgGUaHFoMa82fZPur9oBeX1IpCVXVgxNzA61Q=
Received: by 10.224.24.84 with SMTP id u20mr715853qab.160.1250864413950;
        Fri, 21 Aug 2009 07:20:13 -0700 (PDT)
Received: from ?10.189.224.89? (mobile-166-137-134-061.mycingular.net [166.137.134.61])
        by mx.google.com with ESMTPS id 4sm1949981qwe.5.2009.08.21.07.20.10
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Fri, 21 Aug 2009 07:20:12 -0700 (PDT)
Message-Id: <C175257A-B2D8-4388-AF5B-B43B62CF80BD@gmail.com>
From: Sujith Vellat <vtsujith@gmail.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
In-Reply-To: <314098690908210625q44e1eb15xf584358dce8071d@mail.gmail.com>
Content-Type: text/plain;
	charset=utf-8;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: quoted-printable
X-Mailer: iPhone Mail (7A341)
Mime-Version: 1.0 (iPhone Mail 7A341)
Subject: Re: Help.
Date: Fri, 21 Aug 2009 10:19:55 -0400
References: <74655.90702.qm@web15206.mail.cnb.yahoo.com> <314098690908210625q44e1eb15xf584358dce8071d@mail.gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org



Sent from my iPhone

On Aug 21, 2009, at 9:25 AM, Jason Venner <jason.hadoop@gmail.com> =20
wrote:

> It may be that the individual datanodes get different names for =20
> their ip
> addresses than the namenode does.
> It may also be that some subset of your namenode/datanodes do not =20
> have write
> access to the hdfs storage directories.
>
>
> On Mon, Aug 17, 2009 at 10:05 PM, qiu tian =20
> <tianqiu_527@yahoo.com.cn> wrote:
>
>> Hi everyone.
>> I installed hadoop among three pcs. When I ran the command 'start-=20
>> all.sh',
>> I only could start the jobtracker and tasktrackers. I use 192.*.*.x =20=

>> as
>> master and use 192.*.*.y and 192.*.*.z as slaves.
>>
>> The namenode log from the master 192.*.*.x is following like this:
>>
>> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.hdfs.StateChange: =20
>> BLOCK*
>> NameSystem.registerDatanode: node 192.*.*.y:50010 is replaced by
>> 192.*.*.x:50010 with the same storageID
>> DS-1120429845-127.0.0.1-50010-1246697164684
>> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology:
>> Removing a node: /default-rack/192.*.*.y:50010
>> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology: =20=

>> Adding
>> a new node: /default-rack/192.*.*.x:50010
>> 2009-08-18 10:48:45,932 FATAL org.apache.hadoop.hdfs.StateChange: =20
>> BLOCK*
>> NameSystem.getDatanode: Data node 192.*.*.z:50010 is attempting to =20=

>> report
>> storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node =20
>> 192.*.*.x:50010
>> is expected to serve this storage.
>> 2009-08-18 10:48:45,932 INFO org.apache.hadoop.ipc.Server: IPC Server
>> handler 8 on 9000, call blockReport(DatanodeRegistration(192.*.*.z:=20=

>> 50010,
>> storageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, =20
>> infoPort=3D50075,
>> ipcPort=3D50020), [J@1b8ebe3) from 192.*.*.z:33177: error:
>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data =20=

>> node
>> 192.*.*.z:50010 is attempting to report storage ID
>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>> expected to serve this storage.
>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data =20=

>> node
>> 192.*.*.z:50010 is attempting to report storage ID
>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>> expected to serve this storage.
>>        at
>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDatanode=20
>> (FSNamesystem.java:3800)
>>        at
>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport=20
>> (FSNamesystem.java:2771)
>>        at
>> org.apache.hadoop.hdfs.server.namenode.NameNode.blockReport=20
>> (NameNode.java:636)
>>        at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown =20
>> Source)
>>        at
>> sun.reflect.DelegatingMethodAccessorImpl.invoke=20
>> (DelegatingMethodAccessorImpl.java:25)
>>        at java.lang.reflect.Method.invoke(Method.java:597)
>>        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
>>        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)
>> 2009-08-18 10:48:46,398 FATAL org.apache.hadoop.hdfs.StateChange: =20
>> BLOCK*
>> NameSystem.getDatanode: Data node 192.*.*.y:50010 is attempting to =20=

>> report
>> storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node =20
>> 192.*.*.x:50010
>> is expected to serve this storage.
>> 2009-08-18 10:48:46,398 INFO org.apache.hadoop.ipc.Server: IPC Server
>> handler 0 on 9000, call blockReport(DatanodeRegistration=20
>> (192.9.200.y:50010,
>> storageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, =20
>> infoPort=3D50075,
>> ipcPort=3D50020), [J@186b634) from 192.*.*.y:47367: error:
>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data =20=

>> node
>> 192.*.*.y:50010 is attempting to report storage ID
>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>> expected to serve this storage.
>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data =20=

>> node
>> 192.*.*.y:50010 is attempting to report storage ID
>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>> expected to serve this storage.
>>        at
>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDatanode=20
>> (FSNamesystem.java:3800)
>>        at
>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport=20
>> (FSNamesystem.java:2771)
>>        at
>> org.apache.hadoop.hdfs.server.namenode.NameNode.blockReport=20
>> (NameNode.java:636)
>>        at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown =20
>> Source)
>>        at
>> sun.reflect.DelegatingMethodAccessorImpl.invoke=20
>> (DelegatingMethodAccessorImpl.java:25)
>>        at java.lang.reflect.Method.invoke(Method.java:597)
>>        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
>>        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)
>> 2009-08-18 10:48:47,000 INFO
>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log =20=

>> from
>> 192.*.*.x
>> ~
>>
>> The message on the shell looks like this:
>> 192.*.*.x: Exception in thread "main" java.io.IOException: Cannot =20
>> lock
>> storage /home/gaojun/HadoopInstall/tmp/dfs/namesecondary. The =20
>> directory is
>> already locked.
>> 192.*.*.x:     at
>> org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock=20
>> (Storage.java:510)
>> 192.*.*.x:     at
>> org.apache.hadoop.hdfs.server.common.Storage=20
>> $StorageDirectory.analyzeStorage(Storage.java:363)
>> 192.*.*.x:     at
>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode=20
>> $CheckpointStorage.recoverCreate(SecondaryNameNode.java:517)
>> 192.*.*.x:     at
>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize=20=

>> (SecondaryNameNode.java:145)
>> 192.*.*.x:     at
>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>=20
>> (SecondaryNameNode.java:115)
>> 192.*.*.x:     at
>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main=20
>> (SecondaryNameNode.java:469)
>>
>> I could not find the reason. Can someone help me?
>> Thanks!
>>
>> yan
>>
>>
>>
>>     ___________________________________________________________
>> =E5=A5=BD=E7=8E=A9=E8=B4=BA=E5=8D=A1=E7=AD=89=E4=BD=A0=E5=8F=91=EF=BC=8C=
=E9=82=AE=E7=AE=B1=E8=B4=BA=E5=8D=A1=E5=85=A8=E6=96=B0=E4=B8=8A=E7=BA=BF=EF=
=BC=81
>> http://card.mail.cn.yahoo.com/
>>
>
>
>
> --=20
> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
> www.prohadoopbook.com a community for Hadoop Professionals

From common-user-return-16977-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 15:27:36 2009
Return-Path: <common-user-return-16977-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 36441 invoked from network); 21 Aug 2009 15:27:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 15:27:35 -0000
Received: (qmail 1615 invoked by uid 500); 21 Aug 2009 15:27:55 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 1561 invoked by uid 500); 21 Aug 2009 15:27:55 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 1551 invoked by uid 99); 21 Aug 2009 15:27:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 15:27:55 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [128.8.132.61] (HELO mrouter3.umiacs.umd.edu) (128.8.132.61)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 15:27:45 +0000
Received: from [192.168.93.36] (unknown [128.8.118.5])
	by mrouter3.umiacs.umd.edu (Postfix) with ESMTP id 51D9B13D283
	for <common-user@hadoop.apache.org>; Fri, 21 Aug 2009 11:27:23 -0400 (EDT)
Message-ID: <4A8EBCD8.5010508@umd.edu>
Date: Fri, 21 Aug 2009 11:27:20 -0400
From: Jimmy Lin <jimmylin@umd.edu>
User-Agent: Thunderbird 2.0.0.22 (Windows/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: NSF/Google/IBM CLuE PI Meeting: October 5, 2009 in Mountain View,
 California
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 8bit
X-Virus-Checked: Checked by ClamAV on apache.org

==CLuE PI Meeting 2009==

Monday, October 5, 2009
Mountain View, California (Exact Location TBA)

Sponsored by the National Science Foundation, Google, IBM
Organized by the University of Maryland Cloud Computing Center

Website: https://wiki.umiacs.umd.edu/ccc/index.php/CLuE_PI_Meeting_2009
Registration: http://clue2009.eventbrite.com/
               (Early-bird registration ends 8/31)

= What's this event about?

In October 2007, Google and IBM announced the first pilot phase of the 
Academic Cloud Computing Initiative (ACCI), which granted several 
prominent U.S. universities access to a large computer cluster running 
Hadoop, an open source distributed computing platform inspired by 
Googles file system and MapReduce programming model. In February 2008, 
the ACCI partnered with the National Science Foundation to provide grant 
funding to academic researchers interested in exploring large-data 
applications that could take advantage of this infrastructure. This 
resulted in the creation of the Cluster Exploratory (CLuE) program led 
by Dr. Jim French, which currently funds 14 projects from 17 universities.

Nearing the two year anniversary of this collaboration, the National 
Science Foundation, Google, and IBM will be jointly sponsoring a meeting 
for the CLuE project principal investigators (PIs). This will event will 
be open to the publicin fact, the explicit goal of this event is to 
showcase the exciting research currently underway in academia and 
promote closer ties with the broader "cloud computing" community in the 
bay area.  Register now!

= Who's speaking?

Most of the meeting will consist of plenary talks by the following people:

* Daniel Abadi (Yale University): "HadoopDB An Architectural Hybrid of 
MapReduce and DBMS Technologies for Analytical Workloads"

* Jamie Callan (Carnegie Mellon University): "Topic-Partitioned Search 
Engine Indexes"

* Andrew Connolly (University of Washington): "Scaling the Universe 
through MapReduce"

* Bill Howe (University of Washington) and Claudio Silva (University of 
Utah)

* Chen Li (University of California, Irvine): "Large-Scale Data Cleaning 
Using Hadoop"

* Jimmy Lin (University of Maryland): "Data-Intensive Text Processing 
with MapReduce"

* Sam Madden (MIT): "A Performance and Usability Comparison of Hadoop 
and Relational Database Systems"

* Mihai Pop (University of Maryland): "Commodity Computing in Genomics 
Research"

* Naphtali Rishe (Florida International University): "Experience with 
Geospatial Data in MapReduce"

* Suresh Jagannathan and Ananth Grama (Purdue University): "Relaxed 
Synchronization and Eager Scheduling in MapReduce"

* Stephan Vogel (Carnegie Mellon University)

* Ben Zhao and Xifeng Yan (University of California, Santa Barbara): 
"Scalable Graph Processing in Data Center Environments"

We are also anticipating keynotes from both Google and IBM.

The meeting will be capped off with a poster reception in the early 
evening, where representatives of all CLuE projects will present their 
work in a more informal setting. The speakers above will be joined by 
the follow presenters in the poster session:

* James Allan (University of Massachusetts, Amherst)

* Jason Lawrence (University of Virginia)

* Chaitanya Baru and Sriram Krishnan (San Diego Supercomputer 
Center/University of California, San Diego)


From common-user-return-16978-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 16:22:22 2009
Return-Path: <common-user-return-16978-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61533 invoked from network); 21 Aug 2009 16:22:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 16:22:20 -0000
Received: (qmail 10499 invoked by uid 500); 21 Aug 2009 16:22:41 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10398 invoked by uid 500); 21 Aug 2009 16:22:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10388 invoked by uid 99); 21 Aug 2009 16:22:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 16:22:40 +0000
X-ASF-Spam-Status: No, hits=4.0 required=10.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [159.226.40.9] (HELO mail.software.ict.ac.cn) (159.226.40.9)
    by apache.org (qpsmtpd/0.29) with SMTP; Fri, 21 Aug 2009 16:22:31 +0000
Received: (qmail 23244 invoked from network); 21 Aug 2009 15:33:29 -0000
Received: from unknown (HELO ?192.168.1.101?) (heyongqiang@10.61.0.222)
  by 10.60.0.9 with SMTP; 21 Aug 2009 15:33:29 -0000
User-Agent: Microsoft-Entourage/12.0.0.071130
Date: Sat, 22 Aug 2009 00:21:58 +0800
Subject: CFP of 3rd Hadoop in China event (Hadoop World:Beijing)
From: He Yongqiang <heyongqiang@software.ict.ac.cn>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>,
	"pig-user@hadoop.apache.org" <pig-user@hadoop.apache.org>,
	"hive-user@hadoop.apache.org" <hive-user@hadoop.apache.org>,
	"hdfs-user@hadoop.apache.org" <hdfs-user@hadoop.apache.org>,
	"mapreduce-user@hadoop.apache.org" <mapreduce-user@hadoop.apache.org>,
	"hbase-user@hadoop.apache.org" <hbase-user@hadoop.apache.org>,
	"avro-user@hadoop.apache.org" <avro-user@hadoop.apache.org>,
	<zookeeper-user@hadoop.apache.org>
Message-ID: <C6B4EAA6.6DA3%heyongqiang@software.ict.ac.cn>
Thread-Topic: CFP of 3rd Hadoop in China event (Hadoop World:Beijing)
Thread-Index: Acoie4Fa0FqA0AUTUUaPT63LaqIHrw==
Mime-version: 1.0
Content-type: multipart/alternative;
	boundary="B_3333745319_15560743"
X-Virus-Checked: Checked by ClamAV on apache.org

--B_3333745319_15560743
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit


http://www.hadooper.cn/hadoop/cgi-bin/moin.cgi/thirdcfp

Time : Sunday, November 15, 2009
City: Beijing, China

Sponsored by Yahoo!, Cloudera
Organized by hadooper.cn

Website: http://www.hadooper.cn/hadoop/cgi-bin/moin.cgi/thirdcfp

====  Sorry for the cross posting. Have a good day!  =====

Thanks,
Yongqiang

--B_3333745319_15560743--



From common-user-return-16979-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 16:34:20 2009
Return-Path: <common-user-return-16979-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 67477 invoked from network); 21 Aug 2009 16:34:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 16:34:19 -0000
Received: (qmail 37244 invoked by uid 500); 21 Aug 2009 16:34:39 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 37158 invoked by uid 500); 21 Aug 2009 16:34:39 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 37035 invoked by uid 99); 21 Aug 2009 16:34:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 16:34:39 +0000
X-ASF-Spam-Status: No, hits=4.0 required=10.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [159.226.40.9] (HELO mail.software.ict.ac.cn) (159.226.40.9)
    by apache.org (qpsmtpd/0.29) with SMTP; Fri, 21 Aug 2009 16:34:30 +0000
Received: (qmail 23772 invoked from network); 21 Aug 2009 15:45:17 -0000
Received: from unknown (HELO ?192.168.1.101?) (heyongqiang@10.61.0.222)
  by 10.60.0.9 with SMTP; 21 Aug 2009 15:45:17 -0000
User-Agent: Microsoft-Entourage/12.0.0.071130
Date: Sat, 22 Aug 2009 00:33:40 +0800
Subject: Re: CFP of 3rd Hadoop in China event (Hadoop World:Beijing)
From: He Yongqiang <heyongqiang@software.ict.ac.cn>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>,
	"pig-user@hadoop.apache.org" <pig-user@hadoop.apache.org>,
	"hive-user@hadoop.apache.org" <hive-user@hadoop.apache.org>,
	"hdfs-user@hadoop.apache.org" <hdfs-user@hadoop.apache.org>,
	"mapreduce-user@hadoop.apache.org" <mapreduce-user@hadoop.apache.org>,
	"hbase-user@hadoop.apache.org" <hbase-user@hadoop.apache.org>,
	"avro-user@hadoop.apache.org" <avro-user@hadoop.apache.org>,
	<zookeeper-user@hadoop.apache.org>
Message-ID: <C6B4ED64.6DB0%heyongqiang@software.ict.ac.cn>
Thread-Topic: CFP of 3rd Hadoop in China event (Hadoop World:Beijing)
Thread-Index: Acoie4Fa0FqA0AUTUUaPT63LaqIHrwAAaJvV
In-Reply-To: <C6B4EAA6.6DA3%heyongqiang@software.ict.ac.cn>
Mime-version: 1.0
Content-type: multipart/alternative;
	boundary="B_3333746026_15646462"
X-Virus-Checked: Checked by ClamAV on apache.org

--B_3333746026_15646462
Content-type: text/plain;
	charset="ISO-2022-JP"
Content-transfer-encoding: 7bit

Hi all,
   
Please do not directly reply this announce email. Please send all your
messages to the secretary email in the CFP.

====  Sorry for the cross posting. Have a good day!  =====

Thanks,
Yongqiang

On 09-8-22 $B>e8a(B12:21, "He Yongqiang" <heyongqiang@software.ict.ac.cn> wrote:

> 
> http://www.hadooper.cn/hadoop/cgi-bin/moin.cgi/thirdcfp
> 
> Time : Sunday, November 15, 2009
> City: Beijing, China
> 
> Sponsored by Yahoo!, Cloudera
> Organized by hadooper.cn
> 
> Website: http://www.hadooper.cn/hadoop/cgi-bin/moin.cgi/thirdcfp
> 
> ====  Sorry for the cross posting. Have a good day!  =====
> 
> Thanks,
> Yongqiang


--B_3333746026_15646462--



From common-user-return-16980-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 21 16:58:14 2009
Return-Path: <common-user-return-16980-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 76358 invoked from network); 21 Aug 2009 16:58:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 21 Aug 2009 16:58:14 -0000
Received: (qmail 68783 invoked by uid 500); 21 Aug 2009 16:58:34 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 68697 invoked by uid 500); 21 Aug 2009 16:58:33 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 68687 invoked by uid 99); 21 Aug 2009 16:58:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 16:58:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bharathvissapragada1990@gmail.com designates 74.125.92.27 as permitted sender)
Received: from [74.125.92.27] (HELO qw-out-2122.google.com) (74.125.92.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 21 Aug 2009 16:58:26 +0000
Received: by qw-out-2122.google.com with SMTP id 8so507848qwh.35
        for <common-user@hadoop.apache.org>; Fri, 21 Aug 2009 09:58:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=rjt9j9vZNcKd3ooDTOiFBfpuvK/QTxaGWWSfRQIpjdk=;
        b=WiGh2aSqPiVLKB8Ro8lhXegfmBW0bAqBCmvQC+qRdoX3182vTjpzRKJ5z7bXTqTy2O
         tUZ2BiAPNX+sBv5hsGsE6otl5jZZYUr3wKDL9zeyDU/MJct0jWWBBWaw2xCC0HBJn52h
         TuXykK3jmxwRgARJYaeWg/ZCWGtstnRnGj9p4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=oAwgiWFzu61o3ud32xPMB9AdC0CqEiTVjfxsOGaFuX5YpRk9xgCJnWqmDL/oeddmhJ
         z+7qKtiU6vOhOYNvpYXExa05rhwFAC79S9SMSjEcl2d/2xYdTzGKPqb1YklbP0uNlaVJ
         K37FFfo5NxjiWztS/mSAqYFZ2KPkQ5mtBDDfM=
MIME-Version: 1.0
Received: by 10.229.28.8 with SMTP id k8mr255795qcc.78.1250873885127; Fri, 21 
	Aug 2009 09:58:05 -0700 (PDT)
In-Reply-To: <e01b80590908210113m7bbac13bu66a266eb780ba0cf@mail.gmail.com>
References: <73d592f60908200900h121f42bbp8777991e45afaf22@mail.gmail.com> 
	<65EB723B-ABAF-4E14-BBFC-581B2C2DBC61@yahoo-inc.com> <017701ca2274$79929240$6cb7b6c0$@com> 
	<73d592f60908202120l7264f494q3ee465d4d5c2775@mail.gmail.com> 
	<616DA47B2EF5B944B91846785B512FF4CFADEA707D@EGL-EX07VS01.ds.corp.yahoo.com> 
	<73d592f60908202329k7579c1o68e612e5041f6235@mail.gmail.com> 
	<616DA47B2EF5B944B91846785B512FF4CFADEA707E@EGL-EX07VS01.ds.corp.yahoo.com> 
	<73d592f60908202341v6434df19w2921c748983760d6@mail.gmail.com> 
	<e01b80590908210113m7bbac13bu66a266eb780ba0cf@mail.gmail.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Fri, 21 Aug 2009 22:27:45 +0530
Message-ID: <73d592f60908210957v30c0f96doc01fd6f0888bbdfc@mail.gmail.com>
Subject: Re: MR job scheduler
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636426d3b94f3c10471a9c53b
X-Virus-Checked: Checked by ClamAV on apache.org

--001636426d3b94f3c10471a9c53b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I discussed the same doubt in Hbase forums .. Iam pasting the reply i got
(for those who aren't subscribed to that list)

Regarding optimizing the reduce phase(similar to what harish was pointing
out)

I got the following reply .. frm Ryan

"I think people are confused about how optimal map reduces have to be.
Keeping all the data super-local on each machine is not always helping
you, since you have to read via a socket anyways. Going remote doesn't
actually make things that much slower, since on a modern lan ping
times are < 0.1ms.  If your entire cluster is hanging off a single
switch, there is nearly unlimited bandwidth between all nodes
(certainly much higher than any single system could push).  Only once
you go multi-switch then switch-locality (aka rack locality) becomes
important.

Remember, hadoop isn't about the instantaneous speed of any job, but
about running jobs in a highly scalable manner that works on tens or
tens of thousands of nodes. You end up blocking on single machine
limits anyways, and the r=3 of HDFS helps you transcend a single
machine read speed for large files. Keeping the data transfer local in
this case results in lower performance."

Just FYI!
Thanks

On Fri, Aug 21, 2009 at 1:43 PM, Harish Mallipeddi <
harish.mallipeddi@gmail.com> wrote:

> On Fri, Aug 21, 2009 at 12:11 PM, bharath vissapragada <
> bharathvissapragada1990@gmail.com> wrote:
>
> > Yes , My doubt is that how is the location of the reducer selected . Is
> it
> > selected arbitrarily or is selected on a particular machine which has
> > already the more values (corresponding to the key of that reducer) which
> > reduces the cost of transferring data across the network(because already
> > many values to that key are on that machine where the map phase
> > completed)..
> >
>

I discussed the same issue on hbase forums and one of its developers
answered my questi

>
> I think what you're asking for is whether a ReduceTask is scheduled on a
> node which has the largest partition among all the mapoutput partitions
> (p1-pN) that the ReduceTask has to fetch in order to do its job. The answer
> is "no" - the ReduceTasks are assigned arbitrarily (no such optimization is
> done and I think this can really be an optimization only if 1 of your
> partitions is heavily skewed for some reason). Also as Amogh pointed out,
> the ReduceTasks start fetching their mapoutput-partitions (shuffle phase)
> as
> and when they hear about completed ones. So it would not be possible to
> schedule ReduceTasks only on nodes with the largest partitions.
>
> --
> Harish Mallipeddi
> http://blog.poundbang.in
>

--001636426d3b94f3c10471a9c53b--

From common-user-return-16990-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 11:22:37 2009
Return-Path: <common-user-return-16990-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 75053 invoked from network); 23 Aug 2009 11:22:37 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 11:22:37 -0000
Received: (qmail 5200 invoked by uid 500); 23 Aug 2009 11:22:56 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 5108 invoked by uid 500); 23 Aug 2009 11:22:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 5098 invoked by uid 500); 23 Aug 2009 11:22:56 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 5095 invoked by uid 99); 23 Aug 2009 11:22:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 11:22:56 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of stas.oskin@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 11:22:47 +0000
Received: by bwz10 with SMTP id 10so1099690bwz.29
        for <core-user@hadoop.apache.org>; Sun, 23 Aug 2009 04:22:26 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=BuxS9Sg8nmaBeFf2eCjOQHl0qxaOp7hUJatu1I2jvS0=;
        b=NKvhS+YFFUEK/OFS2EmsUY0jx6DHkTa5uLApy0AXVwrULYOe/K3wFgz24u2kwSCLwT
         MfKQZ1Ne7UFDvCPkMboIYmS8gBjbSUfbi3mNqbSJ9LAdbxPITvzZQtcpiWxUq23igp2m
         Luy1ADqjHUe6ETwW5Z3pHdmGx3WnIszDaNsK4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=rFBMpq0frv7hCmJERmljaHju2wOfpGdl7eXWH2KUqDvxcWuETgmcVfA8JfSZfrHwGa
         j0kYz9zxkdtpU9tIIpbFKIyDntoyLxUEHuXiPgNTqEI/PHwKhUEH4W/K+uoOlUKVGKgX
         SPO+n4qBjhQdcGRCeS/mM0bJnN7ancnvLcmDQ=
MIME-Version: 1.0
Received: by 10.223.144.201 with SMTP id a9mr2900841fav.17.1251026546738; Sun, 
	23 Aug 2009 04:22:26 -0700 (PDT)
Date: Sun, 23 Aug 2009 14:22:26 +0300
Message-ID: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
Subject: Getting free space percentage on DFS
From: Stas Oskin <stas.oskin@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0023545bd814ec46060471cd50cf
X-Virus-Checked: Checked by ClamAV on apache.org

--0023545bd814ec46060471cd50cf
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

How can I get the free / used space on DFS, via Java?

What are the functions that can be used for that?

Note, I'm using a regular (non-super) user, so I need to do it in a similar
way to dfshealth.jsp, which AFAIK doesn't require any permissions.

Thanks in advance.

--0023545bd814ec46060471cd50cf--

From common-user-return-16991-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 12:10:05 2009
Return-Path: <common-user-return-16991-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 80416 invoked from network); 23 Aug 2009 12:10:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 12:10:04 -0000
Received: (qmail 54644 invoked by uid 500); 23 Aug 2009 12:10:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 54567 invoked by uid 500); 23 Aug 2009 12:10:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 54548 invoked by uid 99); 23 Aug 2009 12:10:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 12:10:23 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nipun.saggar@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 12:10:14 +0000
Received: by vws40 with SMTP id 40so1420800vws.2
        for <common-user@hadoop.apache.org>; Sun, 23 Aug 2009 05:09:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=5qmxfwEoAjRHREhxxdahDdsmNjHk83QNL1D4v0Eb6a4=;
        b=D6eVNfJW7sCvP7RaGidvIEV/labgslDVku/Iu6atJ0DYaZ2mUijp6DKmYYpS5SofC1
         kEtGGgLRasuM00zEElwXwhm1qbKDs3nK91Y4PpOAu3+aAno/iYc+8lGrM8qlRQEoaO9E
         M3nni4/7tE58XIdKV+2sC1oW2IdPWJh522kZU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=cWyR0TN4j88wKnYaYqB7MQ/D06vrtWDkSkBTnn1qGuiWL+OG85y2xq3CLzGBFJWx+a
         3HRI5T0rm7SGQ3mYNXwDGLkOBnSbVZ5TAuTlQpXemiLPfoEuLFvCJEoF0syc94uHEwX0
         Oyk2ItBr4QFZMiMLUGbOpgkFRKtOvLrRtW4OY=
MIME-Version: 1.0
Received: by 10.220.89.33 with SMTP id c33mr4034336vcm.81.1251029393551; Sun, 
	23 Aug 2009 05:09:53 -0700 (PDT)
Date: Sun, 23 Aug 2009 17:39:53 +0530
Message-ID: <6c1002100908230509t138131eas39749ef14aadfa50@mail.gmail.com>
Subject: Hadoop streaming: How is data distributed from mappers to reducers?
From: Nipun Saggar <nipun.saggar@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016363108dd9b30d90471cdfac2
X-Virus-Checked: Checked by ClamAV on apache.org

--0016363108dd9b30d90471cdfac2
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi all,

I have recently started using Hadoop streaming. From the documentation, I
understand that by default, each line output from a mapper up to the first
tab becomes the key and rest of the line is the value. I wanted to know that
between the mapper and reducer, is there a shuffling(sorting) phase? More
specifically, Would it be correct to assume that output from all mappers
with the same key will go to the same reducer?

Thanks,
Nipun

--0016363108dd9b30d90471cdfac2--

From common-user-return-16992-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 15:00:23 2009
Return-Path: <common-user-return-16992-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7448 invoked from network); 23 Aug 2009 15:00:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 15:00:23 -0000
Received: (qmail 40846 invoked by uid 500); 23 Aug 2009 15:00:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 40755 invoked by uid 500); 23 Aug 2009 15:00:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 40745 invoked by uid 99); 23 Aug 2009 15:00:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 15:00:42 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of edlinuxguru@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 15:00:33 +0000
Received: by bwz10 with SMTP id 10so1146429bwz.29
        for <common-user@hadoop.apache.org>; Sun, 23 Aug 2009 08:00:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=nWmqM5jgwvHvfD81g8aXikC+3prxGI2UzengZ4nc/EE=;
        b=mPU0OcdbCf9S4om5P2t9TKMIlV0zGAHY9DZ05UwtbmfQAUGfGzgqAoaM5AS/xGC5xn
         Kw8GssQgD7Oo+hjkut75H4Riyw8O71oP4q1OQ4CSMGSoI5Q29xx6NNdR4FHqVS9x1jij
         QSRYJO5K7DDx5e9Z+hOr7OUCGbsYDHhUV57Fw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=vFNS6QwmXMsUbYyRo1VjPo8hOWe5ZKNv442KF1kbm11gsC4NvqhvvWKfgcrxbP+7EQ
         /rror4C8q1vGTvEzig8gHHm9oiKA2T8fqO0ZikYURooJCbkA93Pc1SGkMIEuvmSRAk+V
         Kgk0O/Z1ez0KboA+jzpKtMdlFcag6AjGVYx/g=
MIME-Version: 1.0
Received: by 10.239.139.201 with SMTP id u9mr335789hbu.112.1251039609854; Sun, 
	23 Aug 2009 08:00:09 -0700 (PDT)
In-Reply-To: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
References: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
Date: Sun, 23 Aug 2009 11:00:09 -0400
Message-ID: <cbbf4b570908230800i573b2012pe0d91bcf6076f024@mail.gmail.com>
Subject: Re: Getting free space percentage on DFS
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

On Sun, Aug 23, 2009 at 7:22 AM, Stas Oskin<stas.oskin@gmail.com> wrote:
> Hi.
>
> How can I get the free / used space on DFS, via Java?
>
> What are the functions that can be used for that?
>
> Note, I'm using a regular (non-super) user, so I need to do it in a similar
> way to dfshealth.jsp, which AFAIK doesn't require any permissions.
>
> Thanks in advance.
>

One way you can do this is thought JMX.

http://www.jointhegrid.com/svn/hadoop-cacti-jtg/trunk/src/com/jointhegrid/hadoopjmx/NameNodeStatistics.java

That is part of a cacti graphing application for hadoop I wrote
(http://www.jointhegrid.com/hadoop/)

Enjoy,

From common-user-return-16993-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 15:09:14 2009
Return-Path: <common-user-return-16993-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 9811 invoked from network); 23 Aug 2009 15:09:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 15:09:14 -0000
Received: (qmail 48876 invoked by uid 500); 23 Aug 2009 15:09:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 48800 invoked by uid 500); 23 Aug 2009 15:09:33 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 48790 invoked by uid 500); 23 Aug 2009 15:09:33 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 48787 invoked by uid 99); 23 Aug 2009 15:09:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 15:09:33 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 15:09:23 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MfEgn-0000Qx-Rk
	for core-user@hadoop.apache.org; Sun, 23 Aug 2009 08:09:01 -0700
Message-ID: <25104139.post@talk.nabble.com>
Date: Sun, 23 Aug 2009 08:09:01 -0700 (PDT)
From: "Xie, Tao" <xietao1981@gmail.com>
To: core-user@hadoop.apache.org
Subject: hdfs.DFSClient: DataStreamer Exception:
 java.net.SocketTimeoutException
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: xietao1981@gmail.com
X-Virus-Checked: Checked by ClamAV on apache.org


I found this exception below in my datanode log. Anybody know why this
happens? 

09/08/23 22:13:50 WARN hdfs.DFSClient: DataStreamer Exception:
java.net.SocketTimeoutException: 15000 millis timeout while waiting for
channel to be ready for write. ch :
java.nio.channels.SocketChannel[connected local=/10.0.0.8:37135
remote=/10.0.0.8:50010]
       at
org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
       at
org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
       at
org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
       at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)
       at java.io.DataOutputStream.write(DataOutputStream.java:90)
       at
org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2247)
-- 
View this message in context: http://www.nabble.com/hdfs.DFSClient%3A-DataStreamer-Exception%3A-java.net.SocketTimeoutException-tp25104139p25104139.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-16994-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 18:56:43 2009
Return-Path: <common-user-return-16994-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 33648 invoked from network); 23 Aug 2009 18:56:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 18:56:43 -0000
Received: (qmail 74791 invoked by uid 500); 23 Aug 2009 18:57:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 74705 invoked by uid 500); 23 Aug 2009 18:57:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 74693 invoked by uid 99); 23 Aug 2009 18:57:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 18:57:01 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [98.136.44.189] (HELO n64.bullet.mail.sp1.yahoo.com) (98.136.44.189)
    by apache.org (qpsmtpd/0.29) with SMTP; Sun, 23 Aug 2009 18:56:51 +0000
Received: from [216.252.122.216] by n64.bullet.mail.sp1.yahoo.com with NNFMP; 23 Aug 2009 18:56:30 -0000
Received: from [67.195.9.82] by t1.bullet.sp1.yahoo.com with NNFMP; 23 Aug 2009 18:56:30 -0000
Received: from [67.195.9.107] by t2.bullet.mail.gq1.yahoo.com with NNFMP; 23 Aug 2009 18:56:30 -0000
Received: from [127.0.0.1] by omp111.mail.gq1.yahoo.com with NNFMP; 23 Aug 2009 18:56:30 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 192989.37713.bm@omp111.mail.gq1.yahoo.com
Received: (qmail 46688 invoked by uid 60001); 23 Aug 2009 18:56:30 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1251053790; bh=zAkApt5ztA09simcSI6HllISj9ijUVuAHYXPc5ylsF8=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=Mf0qUBECViaUHoyhx9EeSBysoTZ56UorXQZLjHvBiMOaacVBx0KlctGExi1RVJ5w4zn7gSFtrlLgj/9eu4jXF6plP2nGWGBFnXfbde9CbEBwlacNDnNm092/YStfOf1JJ2RMPVF9f1MEhU99wWcy5z/FQzGKqkCYASA2ZpyOS0E=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=xgWP2DHO2WV1vvjX6Dhq/ausok+E2ZbZIU3c9jO4RSwVqvGOPv8M1LE4PYpMR2t23af9embUlwG5nXr1gZ07TGUJT+HSlrxOTUvxS6lZIUTJxpExG9MQGUj6zfAK4+xgR0GvzoDS3zpfIW/kMSAOyBO4cyw9x4ASjC655GLLud0=;
Message-ID: <30557.28736.qm@web110109.mail.gq1.yahoo.com>
X-YMail-OSG: BU2Ri.4VM1kS2N_fT9DeH077UyuzHp1S7aPo78aJxSWhPp5UT7hqgXvQ08cVbuK7eG7_PYg.wLHxqFsJdvR4xURzvK870Zp.loGiWwQ4r2GEA.BFael3X3p4tq.sFFq4Z1GVFat5DfWvToRhj05kRtjqY5ptCvMoyn8u9ed1dtpJw2C8eBOdNck0dW9Pfp6kwpcO3_VeTykGXZNvNzaTY.CDODrirToU0kZYv9.38la8oJTLmNiQS5jPhUT3obZjzxhidmyj49.iUoS3rY12C_NiBxha0INvIP4l3tPljkIrrSdE40TpVN2jpOi3zPsnyVfXXxwU1WDlnuyEGixgntCmadgpJjCboVZrq8aO
Received: from [71.134.224.123] by web110109.mail.gq1.yahoo.com via HTTP; Sun, 23 Aug 2009 11:56:29 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
Date: Sun, 23 Aug 2009 11:56:29 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: Re: Getting free space percentage on DFS
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org
In-Reply-To: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-788348595-1251053789=:28736"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-788348595-1251053789=:28736
Content-Type: text/plain; charset=us-ascii

You can try something like this:


if (_FileSystem instanceof DistributedFileSystem)
        {
            DistributedFileSystem dfs = (DistributedFileSystem) _FileSystems;
            DiskStatus ds = dfs.getDiskStatus();
            long capacity = ds.getCapacity();
            long used = ds.getDfsUsed();
            long remaining = ds.getRemaining();
            long presentCapacity = used + remaining;

            hdfsPercentDiskUsed = Math.round((((1.0 * used) / presentCapacity) * 100));
        }



Arvind



________________________________
From: Stas Oskin <stas.oskin@gmail.com>
To: core-user@hadoop.apache.org
Sent: Sunday, August 23, 2009 4:22:26 AM
Subject: Getting free space percentage on DFS

Hi.

How can I get the free / used space on DFS, via Java?

What are the functions that can be used for that?

Note, I'm using a regular (non-super) user, so I need to do it in a similar
way to dfshealth.jsp, which AFAIK doesn't require any permissions.

Thanks in advance.



      
--0-788348595-1251053789=:28736--


From common-user-return-16995-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 18:57:46 2009
Return-Path: <common-user-return-16995-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 33739 invoked from network); 23 Aug 2009 18:57:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 18:57:46 -0000
Received: (qmail 76667 invoked by uid 500); 23 Aug 2009 18:58:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 76567 invoked by uid 500); 23 Aug 2009 18:58:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 76557 invoked by uid 500); 23 Aug 2009 18:58:04 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 76553 invoked by uid 99); 23 Aug 2009 18:58:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 18:58:04 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [98.136.44.38] (HELO n70.bullet.mail.sp1.yahoo.com) (98.136.44.38)
    by apache.org (qpsmtpd/0.29) with SMTP; Sun, 23 Aug 2009 18:57:53 +0000
Received: from [69.147.84.144] by n70.bullet.mail.sp1.yahoo.com with NNFMP; 23 Aug 2009 18:56:30 -0000
Received: from [67.195.9.81] by t6.bullet.mail.sp1.yahoo.com with NNFMP; 23 Aug 2009 18:56:30 -0000
Received: from [67.195.9.106] by t1.bullet.mail.gq1.yahoo.com with NNFMP; 23 Aug 2009 18:56:30 -0000
Received: from [127.0.0.1] by omp110.mail.gq1.yahoo.com with NNFMP; 23 Aug 2009 18:56:30 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 194295.52608.bm@omp110.mail.gq1.yahoo.com
Received: (qmail 46688 invoked by uid 60001); 23 Aug 2009 18:56:30 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1251053790; bh=zAkApt5ztA09simcSI6HllISj9ijUVuAHYXPc5ylsF8=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=Mf0qUBECViaUHoyhx9EeSBysoTZ56UorXQZLjHvBiMOaacVBx0KlctGExi1RVJ5w4zn7gSFtrlLgj/9eu4jXF6plP2nGWGBFnXfbde9CbEBwlacNDnNm092/YStfOf1JJ2RMPVF9f1MEhU99wWcy5z/FQzGKqkCYASA2ZpyOS0E=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=xgWP2DHO2WV1vvjX6Dhq/ausok+E2ZbZIU3c9jO4RSwVqvGOPv8M1LE4PYpMR2t23af9embUlwG5nXr1gZ07TGUJT+HSlrxOTUvxS6lZIUTJxpExG9MQGUj6zfAK4+xgR0GvzoDS3zpfIW/kMSAOyBO4cyw9x4ASjC655GLLud0=;
Message-ID: <30557.28736.qm@web110109.mail.gq1.yahoo.com>
X-YMail-OSG: BU2Ri.4VM1kS2N_fT9DeH077UyuzHp1S7aPo78aJxSWhPp5UT7hqgXvQ08cVbuK7eG7_PYg.wLHxqFsJdvR4xURzvK870Zp.loGiWwQ4r2GEA.BFael3X3p4tq.sFFq4Z1GVFat5DfWvToRhj05kRtjqY5ptCvMoyn8u9ed1dtpJw2C8eBOdNck0dW9Pfp6kwpcO3_VeTykGXZNvNzaTY.CDODrirToU0kZYv9.38la8oJTLmNiQS5jPhUT3obZjzxhidmyj49.iUoS3rY12C_NiBxha0INvIP4l3tPljkIrrSdE40TpVN2jpOi3zPsnyVfXXxwU1WDlnuyEGixgntCmadgpJjCboVZrq8aO
Received: from [71.134.224.123] by web110109.mail.gq1.yahoo.com via HTTP; Sun, 23 Aug 2009 11:56:29 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
Date: Sun, 23 Aug 2009 11:56:29 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: Re: Getting free space percentage on DFS
To: common-user@hadoop.apache.org, core-user@hadoop.apache.org
In-Reply-To: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-788348595-1251053789=:28736"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-788348595-1251053789=:28736
Content-Type: text/plain; charset=us-ascii

You can try something like this:


if (_FileSystem instanceof DistributedFileSystem)
        {
            DistributedFileSystem dfs = (DistributedFileSystem) _FileSystems;
            DiskStatus ds = dfs.getDiskStatus();
            long capacity = ds.getCapacity();
            long used = ds.getDfsUsed();
            long remaining = ds.getRemaining();
            long presentCapacity = used + remaining;

            hdfsPercentDiskUsed = Math.round((((1.0 * used) / presentCapacity) * 100));
        }



Arvind



________________________________
From: Stas Oskin <stas.oskin@gmail.com>
To: core-user@hadoop.apache.org
Sent: Sunday, August 23, 2009 4:22:26 AM
Subject: Getting free space percentage on DFS

Hi.

How can I get the free / used space on DFS, via Java?

What are the functions that can be used for that?

Note, I'm using a regular (non-super) user, so I need to do it in a similar
way to dfshealth.jsp, which AFAIK doesn't require any permissions.

Thanks in advance.



      
--0-788348595-1251053789=:28736--


From common-user-return-16996-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 20:33:50 2009
Return-Path: <common-user-return-16996-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 43113 invoked from network); 23 Aug 2009 20:33:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 20:33:50 -0000
Received: (qmail 20117 invoked by uid 500); 23 Aug 2009 20:34:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20020 invoked by uid 500); 23 Aug 2009 20:34:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20010 invoked by uid 99); 23 Aug 2009 20:34:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 20:34:08 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 20:33:59 +0000
Received: by bwz10 with SMTP id 10so1225687bwz.29
        for <common-user@hadoop.apache.org>; Sun, 23 Aug 2009 13:33:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=xfPbEgktPxEXAjUkXO8EDqK+LczPSH51JrW58153ZX0=;
        b=XKrBoi2N+Z2DtXWXq8RUScYQAeVFf6MkXHVxmX7iHyo3mXGv3q9OyFdhlrxySpOo+m
         uSvvUPiVLKH434d/7xvDaNojGRanB615nCchbj5MQc0eAYpM5Tw56g87OxiFbulVdd39
         2VIra9WAwZmI/sXgFU22ANsJOlnxM2I0rzLYI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=P0DC5kPiB4QXl6D0lsCDzh6qjdhCLKHfeu3UCUOA6q/h2Tn5sNexbGfCkJ1F4h2igA
         CXZRSsRvpdiLmRK4Wfv8shx60rXQW+szLNtGCf3kecUnhM66zjh+NcANlk3OBfVDtUB0
         yZ90ANpmjbPoriRmJAVQAk53NUyOEWl/SEMjE=
MIME-Version: 1.0
Received: by 10.223.1.6 with SMTP id 6mr3663280fad.103.1251059618285; Sun, 23 
	Aug 2009 13:33:38 -0700 (PDT)
In-Reply-To: <cbbf4b570908230800i573b2012pe0d91bcf6076f024@mail.gmail.com>
References: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
	 <cbbf4b570908230800i573b2012pe0d91bcf6076f024@mail.gmail.com>
Date: Sun, 23 Aug 2009 23:33:38 +0300
Message-ID: <77938bc20908231333i6128b643o9bfa9675253c5d4f@mail.gmail.com>
Subject: Re: Getting free space percentage on DFS
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0ce0edb8240ad20471d504b2
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0ce0edb8240ad20471d504b2
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

Thank you both for the advices - any idea if these approaches works for
non-super user?

Regards.

--000e0ce0edb8240ad20471d504b2--

From common-user-return-16997-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 20:39:53 2009
Return-Path: <common-user-return-16997-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 44548 invoked from network); 23 Aug 2009 20:39:53 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 20:39:53 -0000
Received: (qmail 25007 invoked by uid 500); 23 Aug 2009 20:40:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 24914 invoked by uid 500); 23 Aug 2009 20:40:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 24904 invoked by uid 99); 23 Aug 2009 20:40:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 20:40:11 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nguyenminhanh@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 20:40:02 +0000
Received: by gxk27 with SMTP id 27so2244196gxk.12
        for <common-user@hadoop.apache.org>; Sun, 23 Aug 2009 13:39:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=DbjoXQ6OcigMxm/vvw2qBVo/VaeJ0HiNyPcLotkebCg=;
        b=oNfBjiaOYCbgs8aoHgFl9Gt7/Svf2YIZItAuLIlc8bieerqS8iUBGAeK4/EXvH84Ua
         ADEwjGgJECUmHFzR1dmwDqdI4FJDFibedodFMZxs2HN2wjEXv4v11kojE+6/wb1MV3GE
         LzY2X3+v9x7D5NXiQN/fo61624bjBn0wTbeKQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=pzond6HzPjTGSPPZytILaTKwLv1898HQsRApvHX4IEMiWMgHMHih1MSBmr4ZajZBUR
         3wrTZcfjH5uNCOuNtQwXuPb18AEeSgm6jubUwh5Oty9KG4fw54mDx/NKLdekOYVmnghR
         3fk8TiNf9KNwdJT/kCRVWx1njaySsveHAW7s8=
MIME-Version: 1.0
Received: by 10.91.89.17 with SMTP id r17mr3315712agl.58.1251059981397; Sun, 
	23 Aug 2009 13:39:41 -0700 (PDT)
Date: Sun, 23 Aug 2009 15:39:41 -0500
Message-ID: <f90f1ab00908231339u317cc595s89b9324ee00bdeeb@mail.gmail.com>
Subject: NLineInputFormat - Map always left out one split
From: Anh Nguyen <nguyenminhanh@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e6470e22c8b0b10471d5198f
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e6470e22c8b0b10471d5198f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I am using Hadoop for one of my research. I use NLineInputFormat for Map,
which take a few lines as one split. Each line specify a filename. So if I
have 10 input files 1..10 in my hdfs home, I would have an input file list
this:

*~/1*
*~/2*
*.*
*.*
*.*
*~/10*

It used to works fine but recently I ran into this problem: the Map phase
could not finish because it always left out 1 split. For example if I have 2
splits:

*09/08/23 15:32:02 INFO mapred.FileInputFormat: Total input paths to process
: 1
09/08/23 15:32:03 INFO mapred.JobClient: Running job: job_200908101504_0075
09/08/23 15:32:04 INFO mapred.JobClient:  map 0% reduce 0%
09/08/23 15:32:10 INFO mapred.JobClient:  map 50% reduce 0%
09/08/23 15:32:20 INFO mapred.JobClient:  map 50% reduce 8%*

And then everything is stuck there. I don't know why reduce get to 8% even
when Map is not finished. I am using Hadoop 0.19.1

I think this is Hadoop problem because at the very begining of each map task
I print out the input value, which is the name of the file that will get
processed. And when I look into the log of all mappers, many such output are
missing, meaning some files's location they are not sent to Mapper.

Any comment, suggestion on how to fix this is welcome.

Another related question: Is there a better way to split Map inputs so that
each raw binary file is one split, and the key = path of the file?
SequenceInputFile seems to require that both <K,V> is stored within the
file.

Thanks,

-- 
----------------------------
Anh Nguyen
http://www.im-nguyen.com

--0016e6470e22c8b0b10471d5198f--

From common-user-return-16998-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 20:54:18 2009
Return-Path: <common-user-return-16998-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 47403 invoked from network); 23 Aug 2009 20:54:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 20:54:18 -0000
Received: (qmail 36220 invoked by uid 500); 23 Aug 2009 20:54:36 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 36140 invoked by uid 500); 23 Aug 2009 20:54:36 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 36130 invoked by uid 99); 23 Aug 2009 20:54:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 20:54:36 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [98.136.44.33] (HELO n63.bullet.mail.sp1.yahoo.com) (98.136.44.33)
    by apache.org (qpsmtpd/0.29) with SMTP; Sun, 23 Aug 2009 20:54:25 +0000
Received: from [216.252.122.218] by n63.bullet.mail.sp1.yahoo.com with NNFMP; 23 Aug 2009 20:52:51 -0000
Received: from [67.195.9.82] by t3.bullet.sp1.yahoo.com with NNFMP; 23 Aug 2009 20:52:50 -0000
Received: from [67.195.9.98] by t2.bullet.mail.gq1.yahoo.com with NNFMP; 23 Aug 2009 20:52:50 -0000
Received: from [127.0.0.1] by omp102.mail.gq1.yahoo.com with NNFMP; 23 Aug 2009 20:52:50 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 805888.85997.bm@omp102.mail.gq1.yahoo.com
Received: (qmail 45973 invoked by uid 60001); 23 Aug 2009 20:52:50 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1251060770; bh=Gavv8euqd2mZym91e+/v8tOYMbQuP0w9GnymJVQ300s=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=1OUwG/U+kk7X0L/aH+ACCm/fCxb6XP6uSfo5hlUNpfG8bYsjojLu3bFLyp4tAyS0Ehdkq3SGAaYsQYjvb9UK7q86/1gwxISbApXnd2azYpU59n+m5oIvknkx5sVwXJNLaCOOxkG0C4d4lT3HEXEsfr3fTKFtwhUDyoyEPXp/zqs=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=hoWc4F7vJY6Fhw+PrQ4NmIPz1ebQChAyUAVQHZKGfT88Vx5SPmZyUd/jSGz3W3eDQ1+AJRAAoOdzY5mGeYRGUr653QssueszT76rHsZ05iiQZRjWyvn+tVt1RZZgtXMTney0iW5N6fag9WUJJq9jjtuMvPsUdvxXviBE1/fco4E=;
Message-ID: <683229.45456.qm@web110116.mail.gq1.yahoo.com>
X-YMail-OSG: y7iD36kVM1lChqYMm_NacBcDcb53jSWtvZxzBlMgi09slBSx1owUeu0MaOrj0Et5rZefSUSF4ooYEHtZBfsRydJQWtdKUxQ4yHXWfN3_18hVlGXnxF10KAzi7KLnFplRP3M2Guc7gYXglyqb54iW2QA_CJ_EFQzBrTzEIVsnciIQFEvGba7Yk0d_.YPAd4ghuS.tkcxXGRix0XVIPs9e8XIAtG_nRO1puAu.IuoAw2SmjQVMWUWT8t5xwEzBIQ4kBX0yVwEvDDOPgz4obAhkLwDq8a1NIKqDfUHJ4n5cupcdQM2Ig7pnH_1mralWU7BunI7iJdERxmo5pgHmU6KFOE1OrOpEWhBZ6H6cKRk-
Received: from [71.134.224.123] by web110116.mail.gq1.yahoo.com via HTTP; Sun, 23 Aug 2009 13:52:50 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>  <cbbf4b570908230800i573b2012pe0d91bcf6076f024@mail.gmail.com> <77938bc20908231333i6128b643o9bfa9675253c5d4f@mail.gmail.com>
Date: Sun, 23 Aug 2009 13:52:50 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: Re: Getting free space percentage on DFS
To: common-user@hadoop.apache.org
In-Reply-To: <77938bc20908231333i6128b643o9bfa9675253c5d4f@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-1360927293-1251060770=:45456"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-1360927293-1251060770=:45456
Content-Type: text/plain; charset=us-ascii

The APIs work for the user with which Hadoop was started. And moreover I don't think the User level authentication is there yet in Hadoop (not sure here though) for APIs...




________________________________
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Sent: Sunday, August 23, 2009 1:33:38 PM
Subject: Re: Getting free space percentage on DFS

Hi.

Thank you both for the advices - any idea if these approaches works for
non-super user?

Regards.



      
--0-1360927293-1251060770=:45456--


From common-user-return-16999-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 21:26:18 2009
Return-Path: <common-user-return-16999-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 51757 invoked from network); 23 Aug 2009 21:26:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 21:26:18 -0000
Received: (qmail 50967 invoked by uid 500); 23 Aug 2009 21:26:36 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 50863 invoked by uid 500); 23 Aug 2009 21:26:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 50853 invoked by uid 99); 23 Aug 2009 21:26:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 21:26:35 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bill.w.au@gmail.com designates 74.125.92.26 as permitted sender)
Received: from [74.125.92.26] (HELO qw-out-2122.google.com) (74.125.92.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 21:26:27 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1102070qwh.35
        for <common-user@hadoop.apache.org>; Sun, 23 Aug 2009 14:26:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=u2Mik48qN5yAYeS4rtd2yLdakJ3zgCg4YsRCQGsf+Kk=;
        b=UVNhMkPW8r8xIln/aGrG6ab/HOTrc2ySRqifT9fR0vWxWrSLGRr6O6iM6y59IdMOQh
         oiS+MTRhLvxlWSSf1JOv2WciEe9iXrOWS7gx/4FCcCRxNZRubJF4THKuXe54Pu6kdhDN
         NHcVjZKC/HzAiRECj6rTDL7K3HrbcpipxXN8g=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=OIMR6NtHLzA+iaCls4MUayBF9/JkvpSg3GPh/7Lcw54CUEishK01nkmWAykfY8SIPL
         TtWiB25Jr0emObskkRrwkMu77HPdJK9tz6fyAHCUIATYl8sYf/SYkm2j5LoyE1fRFxy5
         YxiZENULplHIkJ8ZJ80dB9XgJlFRt5cya/Qjk=
MIME-Version: 1.0
Received: by 10.229.1.200 with SMTP id 8mr759467qcg.64.1251062766929; Sun, 23 
	Aug 2009 14:26:06 -0700 (PDT)
Date: Sun, 23 Aug 2009 17:26:06 -0400
Message-ID: <3b5f72030908231426g6287eb66oacee8efada55b115@mail.gmail.com>
Subject: problem using Hadoop 0.18.3 with lzo 2.03
From: Bill Au <bill.w.au@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485394218d087920471d5bf47
X-Virus-Checked: Checked by ClamAV on apache.org

--001485394218d087920471d5bf47
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I am using Hadoop 0.18.3 with lzo 2.03.  I am able to compile Hadoop's
native code and load lzo's native library.  I am trying to run the grep
example in examples.jar on a lzo-compressed file.  I am getting an
OutOfMemoryError on the Java heap space.  My input file is 1628727 bytes
which compressed into 157879 bytes.  My map/reduce child java process is
running with a 2000m heap.  So I think that ought to be enough.  What am I
doing wrong?
Bill

<property>
  <name>mapred.child.java.opts</name>
  <value>-Xmx2000m</value>
  <description>Java opts for the task tracker child processes.
  The following symbol, if present, will be interpolated: @taskid@ is
replaced
  by current TaskID. Any other occurrences of '@' will go unchanged.
  For example, to enable verbose gc logging to a file named for the taskid
in
  /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:
        -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc

  The configuration variable mapred.child.ulimit can be used to control the
  maximum virtual memory of the child processes.
  </description>
</property>


2009-08-21 14:48:44,043 INFO org.apache.hadoop.metrics.jvm.JvmMetrics:
Initializing JVM Metrics with processName=MAP, sessionId=
2009-08-21 14:48:44,158 INFO org.apache.hadoop.mapred.MapTask:
numReduceTasks: 1
2009-08-21 14:48:44,175 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb =
100
2009-08-21 14:48:44,286 INFO org.apache.hadoop.mapred.MapTask: data buffer =
79691776/99614720
2009-08-21 14:48:44,286 INFO org.apache.hadoop.mapred.MapTask: record buffer
= 262144/327680
2009-08-21 14:48:44,379 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded
the native-hadoop library
2009-08-21 14:48:44,382 INFO org.apache.hadoop.io.compress.LzoCodec:
Successfully loaded & initialized native-lzo library
2009-08-21 14:48:44,591 WARN org.apache.hadoop.mapred.TaskTracker: Error
running child
java.lang.OutOfMemoryError: Java heap space
at
org.apache.hadoop.io.compress.BlockDecompressorStream.getCompressedData(BlockDecompressorStream.java:100)
at
org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(BlockDecompressorStream.java:82)
at
org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:74)
at java.io.InputStream.read(InputStream.java:85)
at
org.apache.hadoop.mapred.LineRecordReader$LineReader.backfill(LineRecordReader.java:94)
at
org.apache.hadoop.mapred.LineRecordReader$LineReader.readLine(LineRecordReader.java:124)
at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:266)
at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:39)
at
org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:165)
at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:45)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:227)
at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2210)

--001485394218d087920471d5bf47--

From common-user-return-17000-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 23 23:57:05 2009
Return-Path: <common-user-return-17000-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63844 invoked from network); 23 Aug 2009 23:57:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 23 Aug 2009 23:57:05 -0000
Received: (qmail 92307 invoked by uid 500); 23 Aug 2009 23:57:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 92218 invoked by uid 500); 23 Aug 2009 23:57:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 92208 invoked by uid 99); 23 Aug 2009 23:57:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 23:57:22 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vliaskov@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 23 Aug 2009 23:57:10 +0000
Received: by vws40 with SMTP id 40so1582854vws.2
        for <common-user@hadoop.apache.org>; Sun, 23 Aug 2009 16:56:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=DHpi4SCfcht575S0nagc33kq/IsQJ9J8QCGrqB1FSq8=;
        b=e6U/r/5SaSrtZlXtClS18kcAhHp2uJH9r/OS/SgZvHRNYhR4R0ujKaq3ONeXMAn5eb
         7mBFBhuCzeNHfCpQfmqlCvjPyTlqbpdxQp4lz3PnwXlX6UdNQyABQ2gpB6mn2nx6Dq+f
         pjpgT8VFZYyJytltyu/ajfLdOeFObRBD76v1o=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=h+BGGp2cx/1ASncY4okh+1Jz+uJ0iUd93EsrsfFs1lxnxqHjtjyLYT1S9qFaA0nD9C
         SZoRFA+RJwjS3szY8SfXxU6gYlWZr88lKym1vjNr5PD20OHdjMoZGB4ISxbgpNBfDmbS
         bY/ugl+S6csnYzhw3J3H21SWKJYFKoNyDaZvg=
MIME-Version: 1.0
Received: by 10.220.69.227 with SMTP id a35mr4678871vcj.98.1251071809267; Sun, 
	23 Aug 2009 16:56:49 -0700 (PDT)
In-Reply-To: <314098690908190709y14d4d271n589676693100b7a7@mail.gmail.com>
References: <bec373e0908171717r66a736efkbd384530718b4c86@mail.gmail.com>
	 <e01b80590908172206g1fc04218p7df876f5b7b08cab@mail.gmail.com>
	 <616DA47B2EF5B944B91846785B512FF4CFADEA6F56@EGL-EX07VS01.ds.corp.yahoo.com>
	 <314098690908190709y14d4d271n589676693100b7a7@mail.gmail.com>
Date: Sun, 23 Aug 2009 18:56:49 -0500
Message-ID: <bec373e0908231656h7dac4c61ue09807cf0e8589db@mail.gmail.com>
Subject: Re: utilizing all cores on single-node hadoop
From: Vasilis Liaskovitis <vliaskov@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

thanks to everyone for the valuable suggestions.

what would be the default number of map and reduce tasks for the
sort-rand example described at:
http://wiki.apache.org/hadoop/Sort
This is one of the simplest possible examples and uses identity mapper/reducers

I am seeing 160 map tasks and 27 reduce tasks on my jobtracker web ui
for a single-node test. The number of map tasks seems particularly
odd, because my tasktracker.reduce.tasks.maximum=30 and
mapred.map.tasks=24 settings were was well below 160.

In general, is the number of map/reduce tasks for a specific job set
by the Mapper/Reducer job-specific java classes or is it inferred
somehow by the framework?

Also, cores may be idle because the job is I/O-bound - what are the
config parameters related to memory/disk buffering of map outputs and
reduce merges?  WIth the default io.sort.mb and io.sort.factor, would
you expect the sort example to be i/o-bound? Some profiling runs
should help investigate this soon, but at this point I am just asking
for any untuition from more  experienced users.

I have switched to using hadoop-0.20.0 (I believe this version has
changed the site-specfic overrides file from conf/hadoop-site.xml to
conf/mapred-site.xml and several other conf/ files. Let me know if the
site overrides don't work or should be changed somewhere else for this
version)
Does 0.20.0 have a different job scheduler or different default
settings than 0.19.2 - I am getting higher core utlizations with
0.20.0 for some jobs e.g. wordcount examples.

thanks,

- Vasilis

On Wed, Aug 19, 2009 at 9:09 AM, Jason Venner<jason.hadoop@gmail.com> wrote:
> Another reason you may not see full utilization of your map tasks per
> tracker is if the mean run time of a task is very short, All the slots are
> being used but the setup and teardown for each task is large enough in time
> compared to the run time of the task that it appears that not all the task
> slots are being used.
>
>
> On Mon, Aug 17, 2009 at 10:35 PM, Amogh Vasekar <amogh@yahoo-inc.com> wrote:
>
>> While setting mapred.tasktracker.map.tasks.maximum and
>> mapred.tasktracker.reduce.tasks.maximum, please consider the memory usage
>> your application might have since all tasks will be competing for the same
>> and might reduce overall performance.
>>
>> Thanks,
>> Amogh
>> -----Original Message-----
>> From: Harish Mallipeddi [mailto:harish.mallipeddi@gmail.com]
>> Sent: Tuesday, August 18, 2009 10:37 AM
>> To: common-user@hadoop.apache.org
>> Subject: Re: utilizing all cores on single-node hadoop
>>
>> Hi Vasilis,
>>
>> Here's some info that I know:
>>
>> mapred.map.tasks - this is a job-specific setting. This is just a hint to
>> InputFormat as to how many InputSplits (and hence MapTasks) you want for
>> your job. The default InputFormat classes usually keep each split size to
>> the HDFS block size (64MB default). So if your input data is less than 64
>> MB, it will just result in only 1 split and hence 1 MapTask only.
>>
>> mapred.reduce.tasks - this is also a job-specific setting.
>>
>> mapred.tasktracker.map.tasks.maximum
>> mapred.tasktracker.reduce.tasks.maximum
>>
>> The above 2 are tasktracker-specific config options and determine how many
>> "simultaneous" MapTasks and ReduceTasks run on each TT. Ideally on a 8-core
>> box, you would want to set map.tasks.maximum to something like 6 and
>> reduce.tasks.maximum to 4 to utilize all the 8 cores to the maximum
>> (there's
>> a little bit of over-subscription to account for tasks idling while doing
>> I/O).
>>
>> In the web admin console, how many map-tasks and reduce-tasks are reported
>> to have been launched for your job?
>>
>> Cheers,
>> Harish
>>
>> On Tue, Aug 18, 2009 at 5:47 AM, Vasilis Liaskovitis <vliaskov@gmail.com
>> >wrote:
>>
>> > Hi,
>> >
>> > I am a beginner trying to setup a few simple hadoop tests on a single
>> > node before moving on to a cluster. I am just using the simple
>> > wordcount example for now. My question is what's the best way to
>> > guarantee utilization of all cores on a single-node? So assuming a
>> > single node with 16-cores what are the suggested values for:
>> >
>> > mapred.map.tasks
>> > mapred.reduce.tasks
>> >
>> mapred.tasktracker.map.tasks.maximum
>> > mapred.tasktracker.map.tasks.maxium
>> >
>>
>> > I found an old similar thread
>> > http://www.mail-archive.com/hadoop-user@lucene.apache.org/msg00152.html
>> > and I have followed similar settings for my 16-core system (e.g.
>> > map.tasks=reduce.tasks=90 and map.tasks.maximum=100), however I always
>> > see only 3-4 cores utilized using top.
>> >
>> > - The description for mapred.map.tasks says "Ignored when
>> > mapred.job.tracker is "local" ", and in my case
>> > mapred.job.tracker=hdfs://localhost:54311
>> > is it possible that the map.tasks and reduce.tasks I am setting are
>> > being ignored? How can I verify this? Is there a way to enforce my
>> > values even on a localhost scenario like this?
>> >
>> > - Are there other config options/values that I need to set besides the
>> > 4 I mentioned above?
>> >
>> > - Also is it possible that for short tasks, I won't see full
>> > utilization of all cores anyway? Something along those lines is
>> > mentioned in an issue a year ago:
>> > http://issues.apache.org/jira/browse/HADOOP-3136
>> > "If the individual tasks are very short i.e. run for less than the
>> > heartbeat interval the TaskTracker serially runs one task at a time"
>> >
>> > I am using hadoop-0.19.2
>> >
>> > thanks for any guidance,
>> >
>> > - Vasilis
>> >
>>
>>
>>
>> --
>> Harish Mallipeddi
>> http://blog.poundbang.in
>>
>
>
>
> --
> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
> http://www.amazon.com/dp/1430219424?tag=jewlerymall
> www.prohadoopbook.com a community for Hadoop Professionals
>

From common-user-return-17001-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 03:19:04 2009
Return-Path: <common-user-return-17001-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81078 invoked from network); 24 Aug 2009 03:19:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 03:19:04 -0000
Received: (qmail 53198 invoked by uid 500); 24 Aug 2009 03:19:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52849 invoked by uid 500); 24 Aug 2009 03:19:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52839 invoked by uid 99); 24 Aug 2009 03:19:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 03:19:21 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nguyenminhanh@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 03:19:11 +0000
Received: by gxk27 with SMTP id 27so2407991gxk.12
        for <common-user@hadoop.apache.org>; Sun, 23 Aug 2009 20:18:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=/IxFUmGEqL7RckMqy5qd/ttGBVUZ7ZcAvm2Zn4x77fE=;
        b=s8rjoC0vMzoNJMYnsGN2vsuIxsgckt5ksc9/+Z7j86Xo6/lhlIKRBGkvAdjxddFDlu
         igHzrolcFHU1ml+YXz9hEzUuUtFGKg4Mkta0yg4Hz0/TnD7ZyV+Gw52ruyVZ7LloLDb/
         eI4E6LDTqrFG1eu58/qhzux8Mw3xHj1nH9L+Q=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=RgGE1wzGKVngZny8AZ8lyNbvm3DM6eU0/tIGLl1DGcv/DrMOAFqLymLRNG0IZOMJvk
         gMEJXs4NGyIjCL9Qj+93vJlgfcYrp+SwyGDc3mLWVrTK8v2OWHFovX1lRBvlSMVZiNhm
         NEQfODeHNGB52dGj9waekB40nlBcaHuNs6oe0=
MIME-Version: 1.0
Received: by 10.90.128.9 with SMTP id a9mr3577370agd.117.1251083930429; Sun, 
	23 Aug 2009 20:18:50 -0700 (PDT)
In-Reply-To: <f90f1ab00908231339u317cc595s89b9324ee00bdeeb@mail.gmail.com>
References: <f90f1ab00908231339u317cc595s89b9324ee00bdeeb@mail.gmail.com>
Date: Sun, 23 Aug 2009 22:18:50 -0500
Message-ID: <f90f1ab00908232018l86b401dgd7913d8d7ee7da2e@mail.gmail.com>
Subject: Re: NLineInputFormat - Map always left out one split
From: Anh Nguyen <nguyenminhanh@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163630f88541eaa50471daad38
X-Virus-Checked: Checked by ClamAV on apache.org

--00163630f88541eaa50471daad38
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Fixed. I restart hadoop and everything works again. It could be that there
are some hidden bugs in the Hadoop code that get triggered.

Anh

On Sun, Aug 23, 2009 at 3:39 PM, Anh Nguyen <nguyenminhanh@gmail.com> wrote:

> I am using Hadoop for one of my research. I use NLineInputFormat for Map,
> which take a few lines as one split. Each line specify a filename. So if I
> have 10 input files 1..10 in my hdfs home, I would have an input file list
> this:
>
> *~/1*
> *~/2*
> *.*
> *.*
> *.*
> *~/10*
>
> It used to works fine but recently I ran into this problem: the Map phase
> could not finish because it always left out 1 split. For example if I have 2
> splits:
>
> *09/08/23 15:32:02 INFO mapred.FileInputFormat: Total input paths to
> process : 1
> 09/08/23 15:32:03 INFO mapred.JobClient: Running job: job_200908101504_0075
> 09/08/23 15:32:04 INFO mapred.JobClient:  map 0% reduce 0%
> 09/08/23 15:32:10 INFO mapred.JobClient:  map 50% reduce 0%
> 09/08/23 15:32:20 INFO mapred.JobClient:  map 50% reduce 8%*
>
> And then everything is stuck there. I don't know why reduce get to 8% even
> when Map is not finished. I am using Hadoop 0.19.1
>
> I think this is Hadoop problem because at the very begining of each map
> task I print out the input value, which is the name of the file that will
> get processed. And when I look into the log of all mappers, many such output
> are missing, meaning some files's location they are not sent to Mapper.
>
> Any comment, suggestion on how to fix this is welcome.
>
> Another related question: Is there a better way to split Map inputs so that
> each raw binary file is one split, and the key = path of the file?
> SequenceInputFile seems to require that both <K,V> is stored within the
> file.
>
> Thanks,
>
> --
> ----------------------------
> Anh Nguyen
> http://www.im-nguyen.com
>
>


-- 
----------------------------
Anh Nguyen
http://www.im-nguyen.com

--00163630f88541eaa50471daad38--

From common-user-return-17002-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 04:15:10 2009
Return-Path: <common-user-return-17002-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 85267 invoked from network); 24 Aug 2009 04:15:10 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 04:15:10 -0000
Received: (qmail 71313 invoked by uid 500); 24 Aug 2009 04:15:27 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 71146 invoked by uid 500); 24 Aug 2009 04:15:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 71136 invoked by uid 500); 24 Aug 2009 04:15:26 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 71133 invoked by uid 99); 24 Aug 2009 04:15:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 04:15:26 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sugandha.n87@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 04:15:17 +0000
Received: by iwn6 with SMTP id 6so873188iwn.5
        for <core-user@hadoop.apache.org>; Sun, 23 Aug 2009 21:14:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=2DFhrghPtrDHg0T5jyYrSa2fqZr5CD0SHwjBLLpZf+0=;
        b=A0HQL3kI4ZRluXgxUY3NX+qTlTBRljrES9tox10gJUG/qSKTO1EXF05tqMi1mWO8IX
         pQm0nHpj/L4WxgoT4lh4TfiJIcG9ZpDU5yvLnfhHbctvZg1r5M7vxaPvVK2wXK+DXXmA
         fJPlg4VuztAILHMv5c8E/gzuGE8/x2CP4dIk0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=bCNw9JWpY99or9mE0Q61CwBP7BzzLB1BCyZiwkOmdkCxxkaJh9VKg4NhzfaPj7vtc8
         VY+hZpKvoco2nl1D7wfmUrzSUDI1hUSkDjnfiMoW3flNQ5unDJxii8pQjN6OczIFKi9k
         4H6bT0COi2LeCRnUXcRURsh0WE2fxWQD/Ycfw=
MIME-Version: 1.0
Received: by 10.231.18.69 with SMTP id v5mr1976832iba.26.1251087297064; Sun, 
	23 Aug 2009 21:14:57 -0700 (PDT)
In-Reply-To: <6f72e2db0908180156w574a23a9nf7d041b5977432fb@mail.gmail.com>
References: <6f72e2db0908180156w574a23a9nf7d041b5977432fb@mail.gmail.com>
Date: Mon, 24 Aug 2009 09:44:57 +0530
Message-ID: <6f72e2db0908232114o4b9ffd1fg427a7a4bdc49decf@mail.gmail.com>
Subject: Re: Datanode-Failure..!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221504666fecb1a60471db7563
X-Virus-Checked: Checked by ClamAV on apache.org

--00221504666fecb1a60471db7563
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

hello!

Still the same status I am getting::

09/08/24 09:46:37 WARN datanode.DataNode: Invalid directory in dfs.data.dir:
can not create directory: /home/hadoop/Softwares/hadoop-0.19.0/temp/dfs/data
09/08/24 09:46:37 ERROR datanode.DataNode: All directories in dfs.data.dir
are invalid.
09/08/24 09:46:37 INFO datanode.DataNode: SHUTDOWN_MSG:
/************************************************************



It's niether getting formatted nor getting invoked...!Please help me out

On Tue, Aug 18, 2009 at 2:26 PM, Sugandha Naolekar
<sugandha.n87@gmail.com>wrote:

> Hello!  I am trying to invoke datanode named as repository1.  But, it's
> giving me below errors. Also, I tried formatting namenode and cleaning up
> the temporary directories. But, no help. And, I am not getting the relevant
> error details or status in log file as well...
> Do help me out on this..!
>
>
> hadoop@repository1:~/Softwares/hadoop/hadoop-0.19.0$ bin/hadoop datanode
> 09/08/18 14:28:43 INFO datanode.DataNode: STARTUP_MSG:
> /************************************************************
> STARTUP_MSG: Starting DataNode
> STARTUP_MSG:   host = repository1/10.20.220.35
> STARTUP_MSG:   args = []
> STARTUP_MSG:   version = 0.19.0
> STARTUP_MSG:   build =
> https://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.19 -r
> 713890; compiled by 'ndaley' on Fri Nov 14 03:12:29 UTC 2008
> ************************************************************/
> 09/08/18 14:28:43 WARN datanode.DataNode: Invalid directory in
> dfs.data.dir: can not create directory:
> /home/hadoop/Softwares/hadoop-0.19.0/temp/dfs/data
> 09/08/18 14:28:43 ERROR datanode.DataNode: All directories in dfs.data.dir
> are invalid.
> 09/08/18 14:28:43 INFO datanode.DataNode: SHUTDOWN_MSG:
> /************************************************************
> SHUTDOWN_MSG: Shutting down DataNode at repository1/10.20.220.35
> ************************************************************/
>
>
> --
> Regards!
> Sugandha
>



-- 
Regards!
Sugandha

--00221504666fecb1a60471db7563--

From common-user-return-17003-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 05:53:35 2009
Return-Path: <common-user-return-17003-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 91160 invoked from network); 24 Aug 2009 05:53:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 05:53:35 -0000
Received: (qmail 8259 invoked by uid 500); 24 Aug 2009 05:53:52 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 8157 invoked by uid 500); 24 Aug 2009 05:53:52 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 8147 invoked by uid 500); 24 Aug 2009 05:53:52 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 8143 invoked by uid 99); 24 Aug 2009 05:53:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 05:53:52 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sugandha.n87@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 05:53:42 +0000
Received: by iwn6 with SMTP id 6so887831iwn.5
        for <core-user@hadoop.apache.org>; Sun, 23 Aug 2009 22:53:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=R2cwiUJulZY9+7TptpVk9Vn7zdYUC8L07gZ4rau7l2s=;
        b=N9PuXYprGJn7n+NrwlxjAXN6WGkHHVm95C4USqnYj8Nw9edTT72esmgYBkhRuJCrbA
         J52hSX6BjJ42VoD7J2KVjv8wS+SsCCnUWjik3Jrv6i4TCFw8HQWTDUISJHfS9YzYBREM
         irOOjOoA7uXFzH3xC38rpMpEJY36K0ON1qdDM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=MOiWQOHWSAkDdCnEG/111kW0fNatLnkMk/vEGOrs6KbAtMlu5nOn2GkNHOHKQYaTMV
         lpwUxIy6IBQFrHnw4mVknDsuL7ZVU00qxZqFfONG6SGDM7Jc6Yg88jW5pTfL17PKfNAb
         tnOeucHeM2NpsHvrXfAWd009dnpO7YNpvOZwI=
MIME-Version: 1.0
Received: by 10.231.18.69 with SMTP id v5mr2010708iba.26.1251093201877; Sun, 
	23 Aug 2009 22:53:21 -0700 (PDT)
Date: Mon, 24 Aug 2009 11:23:21 +0530
Message-ID: <6f72e2db0908232253p63f59657q655dca21c451b117@mail.gmail.com>
Subject: Some issues related to cluster invokation!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221504666fe0fce90471dcd56a
X-Virus-Checked: Checked by ClamAV on apache.org

--00221504666fe0fce90471dcd56a
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello!

It takes a lot of time to invoke all the nodes in a cluster and run the
corresponding daemons. Why is it so???It seems to be a very tedious job!

-- 
Regards!
Sugandha

--00221504666fe0fce90471dcd56a--

From common-user-return-17004-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 06:49:56 2009
Return-Path: <common-user-return-17004-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 97029 invoked from network); 24 Aug 2009 06:49:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 06:49:56 -0000
Received: (qmail 44596 invoked by uid 500); 24 Aug 2009 06:50:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 44505 invoked by uid 500); 24 Aug 2009 06:50:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 44495 invoked by uid 99); 24 Aug 2009 06:50:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 06:50:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.132.244 as permitted sender)
Received: from [209.85.132.244] (HELO an-out-0708.google.com) (209.85.132.244)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 06:50:04 +0000
Received: by an-out-0708.google.com with SMTP id c38so777756ana.29
        for <common-user@hadoop.apache.org>; Sun, 23 Aug 2009 23:49:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=kQNO90SYMTfWbALI77ATHjwkck1yuuQTw+60aVg4UqY=;
        b=xbkQ/ytW2WYY4x7C2ZNKwtBFXcbo5B5hQqhnIWMDNx0oNv/R/Kh25QDgEWKvZDeHRi
         G//w6/2pjoyyyGCuWkNmEAF6Gy55qrOJlkHnaTbWNAVHxJh7QmygH/HNxWGJ2n7hF4CS
         EpswfwczLWbqC0h7sGuoW0/G4zqEDlzA3IgpY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=OTltkbVURrCXMIuii5RKeDAcXzUnQaUpluwhfWjuNBqKTBd7JHAKhn8/MrazShWI3A
         7O0Qrzoj0A+JVfC74hsAC3BK7aqfWmXHMUoqQJyHvKKTOe543sNHEW3/Ak25i9yAfJvj
         /qyCbDWhJyFF6wRWHO/B/UYHP4RIzDciUdNm0=
MIME-Version: 1.0
Received: by 10.101.131.20 with SMTP id i20mr4110575ann.114.1251096583016; 
	Sun, 23 Aug 2009 23:49:43 -0700 (PDT)
Date: Mon, 24 Aug 2009 14:49:42 +0800
Message-ID: <3b1311780908232349s56df94b9k321a48255adcdd85@mail.gmail.com>
Subject: How to speed up the copy phrase?
From: yang song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c928706910ef0471dd9fcd
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c928706910ef0471dd9fcd
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello, everyone

When I submit a big job(e.g. maptasks:10000, reducetasks:500), I find that
the copy phrase will last for a long long time. From WebUI, the message
"reduce > copy (xxxx of 10000 at 0.01 MB/s) >" tells me the transfer speed
is just 0.01 MB/s. Does it a regular value? How can I solve it?

Thank you!

P.S. The hadoop version is 0.19.1. The cluster has 20 nodes. Heap size of JT
is 6G while the     others are default settings.

--001636c928706910ef0471dd9fcd--

From common-user-return-17005-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 07:25:49 2009
Return-Path: <common-user-return-17005-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 969 invoked from network); 24 Aug 2009 07:25:49 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 07:25:49 -0000
Received: (qmail 77463 invoked by uid 500); 24 Aug 2009 07:26:06 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 77376 invoked by uid 500); 24 Aug 2009 07:26:06 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 77366 invoked by uid 99); 24 Aug 2009 07:26:06 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 07:26:05 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 07:25:55 +0000
Received: from SNV-EXPF01.ds.corp.yahoo.com (snv-expf01.ds.corp.yahoo.com [207.126.227.250])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7O7Omwt076516
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 00:24:48 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=cSeCy87lWUL1WiG/gk9HRs66ZdKUe4eclv6LdQKCfU1Zf9dZxOE3owBV4517PXlZ
Received: from SNV-EXVS08.ds.corp.yahoo.com ([207.126.227.8]) by SNV-EXPF01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Mon, 24 Aug 2009 00:24:48 -0700
Received: from 10.66.92.213 ([10.66.92.213]) by SNV-EXVS08.ds.corp.yahoo.com ([207.126.227.58]) with Microsoft Exchange Server HTTP-DAV ;
 Mon, 24 Aug 2009 07:24:46 +0000
User-Agent: Microsoft-Entourage/12.20.0.090605
Date: Mon, 24 Aug 2009 12:54:45 +0530
Subject: Re: How to speed up the copy phrase?
From: Jothi Padmanabhan <jothipn@yahoo-inc.com>
To: <common-user@hadoop.apache.org>
Message-ID: <C6B83E15.1CB94%jothipn@yahoo-inc.com>
Thread-Topic: How to speed up the copy phrase?
Thread-Index: Acoki/Q6LlDEKiedmE+kQNDSmNo9Fw==
In-Reply-To: <3b1311780908232349s56df94b9k321a48255adcdd85@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-OriginalArrivalTime: 24 Aug 2009 07:24:48.0418 (UTC) FILETIME=[F643E820:01CA248B]
X-Virus-Checked: Checked by ClamAV on apache.org

The transfer rate is a little misleading. The timer for this calculation
starts when the reducer itself starts and so includes the time spent by the
reducer waiting for maps to complete. So, the speed shown when shuffling the
first few maps might be totally misleading, it does not necessarily reflect
the network speed. You should be able to see more reasonable numbers towards
the end of shuffle.

Jothi


On 8/24/09 12:19 PM, "yang song" <hadoop.inifok@gmail.com> wrote:

> Hello, everyone
> 
> When I submit a big job(e.g. maptasks:10000, reducetasks:500), I find that
> the copy phrase will last for a long long time. From WebUI, the message
> "reduce > copy (xxxx of 10000 at 0.01 MB/s) >" tells me the transfer speed
> is just 0.01 MB/s. Does it a regular value? How can I solve it?
> 
> Thank you!
> 
> P.S. The hadoop version is 0.19.1. The cluster has 20 nodes. Heap size of JT
> is 6G while the     others are default settings.


From common-user-return-17006-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 07:34:43 2009
Return-Path: <common-user-return-17006-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 2156 invoked from network); 24 Aug 2009 07:34:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 07:34:42 -0000
Received: (qmail 87683 invoked by uid 500); 24 Aug 2009 07:34:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87588 invoked by uid 500); 24 Aug 2009 07:34:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87578 invoked by uid 99); 24 Aug 2009 07:34:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 07:34:58 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 07:34:48 +0000
Received: from EGL-EX07CAS02.ds.corp.yahoo.com (egl-ex07cas02.eglbp.corp.yahoo.com [203.83.248.209])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7O7X5RT034393
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 00:33:06 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=h07AB9yDQHnFXqR1iXApCy+8YnHnK0Is/nZj0LpzxHnuHMyXbs3OtT8g3nK9U3zl
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.206]) by
 EGL-EX07CAS02.ds.corp.yahoo.com ([203.83.248.216]) with mapi; Mon, 24 Aug
 2009 13:03:04 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Mon, 24 Aug 2009 13:01:53 +0530
Subject: RE: How to speed up the copy phrase?
Thread-Topic: How to speed up the copy phrase?
Thread-Index: AcokiC2zEr2XYhnuR6u0bTgWS84bwAABDmDA
Message-ID: <616DA47B2EF5B944B91846785B512FF4CFADEA70F9@EGL-EX07VS01.ds.corp.yahoo.com>
References: <3b1311780908232349s56df94b9k321a48255adcdd85@mail.gmail.com>
In-Reply-To: <3b1311780908232349s56df94b9k321a48255adcdd85@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Maybe look at mapred.reduce.parallel.copies property to speed it up...I don=
't see as to why transfer speed be configured via params, and I'm think had=
oop wont be messing with that.

Thanks,
Amogh

-----Original Message-----
From: yang song [mailto:hadoop.inifok@gmail.com]=20
Sent: Monday, August 24, 2009 12:20 PM
To: common-user@hadoop.apache.org
Subject: How to speed up the copy phrase?

Hello, everyone

When I submit a big job(e.g. maptasks:10000, reducetasks:500), I find that
the copy phrase will last for a long long time. From WebUI, the message
"reduce > copy (xxxx of 10000 at 0.01 MB/s) >" tells me the transfer speed
is just 0.01 MB/s. Does it a regular value? How can I solve it?

Thank you!

P.S. The hadoop version is 0.19.1. The cluster has 20 nodes. Heap size of J=
T
is 6G while the     others are default settings.

From common-user-return-17007-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 07:41:11 2009
Return-Path: <common-user-return-17007-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 3017 invoked from network); 24 Aug 2009 07:41:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 07:41:11 -0000
Received: (qmail 99798 invoked by uid 500); 24 Aug 2009 07:41:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 99716 invoked by uid 500); 24 Aug 2009 07:41:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 99706 invoked by uid 500); 24 Aug 2009 07:41:27 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 99703 invoked by uid 99); 24 Aug 2009 07:41:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 07:41:27 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sugandha.n87@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 07:41:19 +0000
Received: by iwn6 with SMTP id 6so902647iwn.5
        for <core-user@hadoop.apache.org>; Mon, 24 Aug 2009 00:40:58 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=nFjLZwc0WUKapjfC629Lhrm2chNQmQhBPPBzEsMrNpw=;
        b=B9mggLvGWBLBuK1MoxZTLq1V0QLWemUezFZv6NDAlIw3inlWOyjTab3cLHqq07o1fh
         zQ4wfRFEEQ7MHn7C8plxgjGHhOAWD3gOXlQnRI9k6rkBis4E0RkMwvtNbNy8I1pka1Ym
         +8zohdaTX+Fww0V2Yk0f+SC80+jUt2XbZzBvY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=h2ikbCeCmXB30/uA2RgsumOLdSvl6VaRoSBIx3Cl/6TRouyWZ+1pdTdY3MrdhS17fv
         ZMrrSXq8SDh76wQcapJlP2xj1pHpBb7NSexdrkQah2vbmhewe88MJ6wqnnna/2sxIQlo
         X6kA8lhWcDCKTARXYmnDRwBGu+70TQZKt5Y9I=
MIME-Version: 1.0
Received: by 10.231.18.69 with SMTP id v5mr2048177iba.26.1251099658099; Mon, 
	24 Aug 2009 00:40:58 -0700 (PDT)
Date: Mon, 24 Aug 2009 13:10:58 +0530
Message-ID: <6f72e2db0908240040v7b2dbefje673b7788ee76369@mail.gmail.com>
Subject: Rack Awareness!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221504666fb31e6e0471de5616
X-Virus-Checked: Checked by ClamAV on apache.org

--00221504666fb31e6e0471de5616
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello!

**************************************************************************************
Below is the python script I have written::

#!/usr/bin/env python

'''
This script used by hadoop to determine network/rack topology.  It
should be specified in hadoop-site.xml via topology.script.file.name
Property.

<property>
  name>topology.script.file.name</name>
 <value>/home/hadoop/topology.py</value>
</property>
'''

import sys
from string import join

DEFAULT_RACK = '/default/rack0';

RACK_MAP =
{
    '10.20.220.35' : '/jobsec/rack1',
    '10.20.220.78' : '/jobsec/rack1',
    '10.20.220.71' : '/jobsec/rack1',

    '10.20.220.74' : '/jobsec/rack2',
}

if len(sys.argv)==1:
     print DEFAULT_RACK
else:
     print join([RACK_MAP.get(i, DEFAULT_RACK) for i in sys.argv[1:]]," ")

***************************************************************************************
I have to configure my 6 node cluster in which 4 r d datanodes and the other
2 are playing NN,JT and sec.NN roles. The m/c playing JT is also Sec. NN.
Now, i want to configure 3 DN's in rack 1 of JT and the 4th DN in rack2 of
JT.
**************************************************************************************

Also, the values of corresponding tags is also set in site-sml file as::

<property>
  <name>topology.node.switch.mapping.impl</name>
  <value>org.apache.hadoop.net.ScriptBasedMapping</value>
  <description> The default implementation of the DNSToSwitchMapping. It
    invokes a script specified in topology.script.file.name to resolve
    node names. If the value for topology.script.file.name is not set, the
    default value of DEFAULT_RACK is returned for all node names.
  </description>
</property>

<property>
  <name>topology.script.file.name</name>
  <value>/home/hadoop/Softwares/hadoop-0.19.0/conf/test.py</value>
  <description> The script name that should be invoked to resolve DNS names
to
    NetworkTopology names. Example: the script would take host.foo.bar as an
    argument, and return /rack1 as the output.
  </description>
</property>

<property>
  <name>topology.script.number.args</name>
  <value>10</value>
  <description> The max number of args that the script configured with
    topology.script.file.name should be run with. Each arg is an
    IP address.
  </description>
</property>

Here, test.py is the python script file name.

*****************************************************

Now, the moment I start or invoke namenode daemon, this file gets invoked
automatically? What do I do to acheive my purpose...The aove things are
correct(files and scripsts and tags?) how to chk the rack status of
machines..and special command? PLease do help me out!

-- 
Regards!
Sugandha

--00221504666fb31e6e0471de5616--

From common-user-return-17008-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 08:19:35 2009
Return-Path: <common-user-return-17008-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 6695 invoked from network); 24 Aug 2009 08:19:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 08:19:34 -0000
Received: (qmail 27474 invoked by uid 500); 24 Aug 2009 08:19:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 27384 invoked by uid 500); 24 Aug 2009 08:19:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 27374 invoked by uid 500); 24 Aug 2009 08:19:51 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 27370 invoked by uid 99); 24 Aug 2009 08:19:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 08:19:51 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sugandha.n87@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 08:19:41 +0000
Received: by iwn6 with SMTP id 6so907481iwn.5
        for <core-user@hadoop.apache.org>; Mon, 24 Aug 2009 01:19:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=gaMvK8sz3aZI/x1rX0213isMapvKKHyx9zwyIUFHz24=;
        b=n4AoB5RqrtLY2C0O2NADFFmrS/eTOjdQbhrlG0QfmbLGMx780fM9rBVd4os8AVMgzg
         m+U9d279IDGafpuClU56lY0p7+Wp9Ptoqrp8fBd5Ti4fAiKfUTRah9JVffOkiMAa/NFf
         QZ4UKP62j2GDT7YRsm8lCUz4EEInh8nE0TtcQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=ZWesuAQ6+Z6ZMIJ73OhdnfESJfak8CnjjvL4yVHIcsH21kMdY4KZ152kac2uJ8sM2x
         6HNHdhr8v8F/D4gAzDsqAtsmaMpwKGkBq2YW+7EWcqxknp/uHrPXImMguUeYsjXsx8qO
         t8YLPCJjz1oJ4AJ1l5RoNVWYf/F3vnQhgWfB8=
MIME-Version: 1.0
Received: by 10.231.19.10 with SMTP id y10mr2045060iba.32.1251101960564; Mon, 
	24 Aug 2009 01:19:20 -0700 (PDT)
Date: Mon, 24 Aug 2009 13:49:20 +0530
Message-ID: <6f72e2db0908240119l59b77515t4dfcf5cb764d36c@mail.gmail.com>
Subject: Error!
From: Sugandha Naolekar <sugandha.n87@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00221532c75ceff1510471dedfd0
X-Virus-Checked: Checked by ClamAV on apache.org

--00221532c75ceff1510471dedfd0
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello!

below is the error I am getting in invoking DN. PLease help me out::


2009-08-24 13:04:19,622 ERROR
org.apache.hadoop.hdfs.server.datanode.DataNode:
org.apache.hadoop.ipc.RemoteException: java.io.IOException:
java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
    at java.util.ArrayList.RangeCheck(ArrayList.java:547)
    at java.util.ArrayList.get(ArrayList.java:322)
    at
org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:64)
    at
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.resolveNetworkLocation(FSNamesystem.java:2138)
    at
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerDatanode(FSNamesystem.java:2109)
    at
org.apache.hadoop.hdfs.server.namenode.NameNode.register(NameNode.java:608)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)

    at org.apache.hadoop.ipc.Client.call(Client.java:696)
    at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
    at $Proxy4.register(Unknown Source)
    at
org.apache.hadoop.hdfs.server.datanode.DataNode.register(DataNode.java:510)
    at
org.apache.hadoop.hdfs.server.datanode.DataNode.runDatanodeDaemon(DataNode.java:1128)
    at
org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1163)
    at
org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1284)


-- 
Regards!
Sugandha

--00221532c75ceff1510471dedfd0--

From common-user-return-17010-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 08:20:37 2009
Return-Path: <common-user-return-17010-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 6949 invoked from network); 24 Aug 2009 08:20:37 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 08:20:37 -0000
Received: (qmail 33020 invoked by uid 500); 24 Aug 2009 08:20:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 32880 invoked by uid 500); 24 Aug 2009 08:20:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 32862 invoked by uid 500); 24 Aug 2009 08:20:50 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 32856 invoked by uid 99); 24 Aug 2009 08:20:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 08:20:50 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 08:20:41 +0000
Received: by fxm25 with SMTP id 25so1369695fxm.29
        for <multiple recipients>; Mon, 24 Aug 2009 01:20:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=JEDwxrTN7f7W6kdBQ/SYO3GIaNV81jeBJtcnb5J9Ahw=;
        b=rfNxVywxjPnmi44q9SHy45pGOn6f7QY3Ouq0VH1uXv+GFGHc5xIGIXmMCXAmFHYzTZ
         sOORPNlWKm9Ls1nTfEg7Duo7TNVKNQ0XoEKeHGFeO2j+RdcVeFvMGASNCBbssjTHrV1C
         4Wa1IB6AoF75lF+//JO9x9LmzcdbzDI5/Jj14=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        b=p3fUi/z8icjmINcanKKiClpZ8iyHn794vomlCi5kFxv98c0N/Rh7TDo/YRHzMSHh3w
         qHP023iuAi1VpbFq7FDqLoY2dQeKxNN15FA9w4rZn18XeyBtSj+X3Y3cHKJKWhkt82BI
         KvP4OhSIAeynQoQd9Y9TvFMvhxE83rtbgCZFk=
MIME-Version: 1.0
Received: by 10.223.14.22 with SMTP id e22mr4494849faa.42.1251102021313; Mon, 
	24 Aug 2009 01:20:21 -0700 (PDT)
In-Reply-To: <30557.28736.qm@web110109.mail.gq1.yahoo.com>
References: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
	 <30557.28736.qm@web110109.mail.gq1.yahoo.com>
Date: Mon, 24 Aug 2009 11:20:21 +0300
Message-ID: <77938bc20908240120o28c64008pcd6d53f26e6a43e9@mail.gmail.com>
Subject: Re: Getting free space percentage on DFS
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015173fe52a8ee59f0471dee370
X-Virus-Checked: Checked by ClamAV on apache.org

--0015173fe52a8ee59f0471dee370
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

2009/8/23 Arvind Sharma <arvind321@yahoo.com>

> You can try something like this:
>
>
> if (_FileSystem instanceof DistributedFileSystem)
>        {
>            DistributedFileSystem dfs = (DistributedFileSystem)
> _FileSystems;
>            DiskStatus ds = dfs.getDiskStatus();
>            long capacity = ds.getCapacity();
>            long used = ds.getDfsUsed();
>            long remaining = ds.getRemaining();
>            long presentCapacity = used + remaining;
>
>            hdfsPercentDiskUsed = Math.round((((1.0 * used) /
> presentCapacity) * 100));
>        }
>

 I just tested it, and I'm getting the exception that I'm not the superuser
- "Superuser privilege is required".

Any idea how to bypass this?

Thanks in advance!

--0015173fe52a8ee59f0471dee370--

From common-user-return-17009-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 08:20:37 2009
Return-Path: <common-user-return-17009-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 6939 invoked from network); 24 Aug 2009 08:20:37 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 08:20:37 -0000
Received: (qmail 32986 invoked by uid 500); 24 Aug 2009 08:20:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 32875 invoked by uid 500); 24 Aug 2009 08:20:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 32856 invoked by uid 99); 24 Aug 2009 08:20:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 08:20:50 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 08:20:41 +0000
Received: by fxm25 with SMTP id 25so1369695fxm.29
        for <multiple recipients>; Mon, 24 Aug 2009 01:20:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=JEDwxrTN7f7W6kdBQ/SYO3GIaNV81jeBJtcnb5J9Ahw=;
        b=rfNxVywxjPnmi44q9SHy45pGOn6f7QY3Ouq0VH1uXv+GFGHc5xIGIXmMCXAmFHYzTZ
         sOORPNlWKm9Ls1nTfEg7Duo7TNVKNQ0XoEKeHGFeO2j+RdcVeFvMGASNCBbssjTHrV1C
         4Wa1IB6AoF75lF+//JO9x9LmzcdbzDI5/Jj14=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        b=p3fUi/z8icjmINcanKKiClpZ8iyHn794vomlCi5kFxv98c0N/Rh7TDo/YRHzMSHh3w
         qHP023iuAi1VpbFq7FDqLoY2dQeKxNN15FA9w4rZn18XeyBtSj+X3Y3cHKJKWhkt82BI
         KvP4OhSIAeynQoQd9Y9TvFMvhxE83rtbgCZFk=
MIME-Version: 1.0
Received: by 10.223.14.22 with SMTP id e22mr4494849faa.42.1251102021313; Mon, 
	24 Aug 2009 01:20:21 -0700 (PDT)
In-Reply-To: <30557.28736.qm@web110109.mail.gq1.yahoo.com>
References: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
	 <30557.28736.qm@web110109.mail.gq1.yahoo.com>
Date: Mon, 24 Aug 2009 11:20:21 +0300
Message-ID: <77938bc20908240120o28c64008pcd6d53f26e6a43e9@mail.gmail.com>
Subject: Re: Getting free space percentage on DFS
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015173fe52a8ee59f0471dee370
X-Virus-Checked: Checked by ClamAV on apache.org

--0015173fe52a8ee59f0471dee370
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

2009/8/23 Arvind Sharma <arvind321@yahoo.com>

> You can try something like this:
>
>
> if (_FileSystem instanceof DistributedFileSystem)
>        {
>            DistributedFileSystem dfs = (DistributedFileSystem)
> _FileSystems;
>            DiskStatus ds = dfs.getDiskStatus();
>            long capacity = ds.getCapacity();
>            long used = ds.getDfsUsed();
>            long remaining = ds.getRemaining();
>            long presentCapacity = used + remaining;
>
>            hdfsPercentDiskUsed = Math.round((((1.0 * used) /
> presentCapacity) * 100));
>        }
>

 I just tested it, and I'm getting the exception that I'm not the superuser
- "Superuser privilege is required".

Any idea how to bypass this?

Thanks in advance!

--0015173fe52a8ee59f0471dee370--

From common-user-return-17011-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 08:27:18 2009
Return-Path: <common-user-return-17011-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 8152 invoked from network); 24 Aug 2009 08:27:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 08:27:18 -0000
Received: (qmail 46290 invoked by uid 500); 24 Aug 2009 08:27:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 46235 invoked by uid 500); 24 Aug 2009 08:27:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 46225 invoked by uid 99); 24 Aug 2009 08:27:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 08:27:35 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 08:27:24 +0000
Received: by fxm25 with SMTP id 25so1372061fxm.29
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 01:27:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=+JQfQF+eSq44FhumLbBAvva4sGIiQ6VkKYNBSNT8MuI=;
        b=sJWEPy1Tu7A4d11TxgEUj88MoHJGGjnS7ABdu7EaAVS8u3v3WQsAnNW4bB4UxTPQ+b
         sz1ear9uyBgzEK+1nv/gLxTYY1aDv0QiZR2vL88K4tW78CbejmdCQc8gCbLX0hfMdWqZ
         fNxR7cg9v6+6RSGULb1p8kEyV7bXvg1BpeupY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=JaIijErJhSxpeYw9FDXs2O+AzGXPQK/wWX9PiQkoXC7/1HLDx+J7kn7RopbSCPbyyV
         Lcowz9cXwYmbo/+Tnvw7wr+k93fRR5PFaEReLToxfO4pO1UIo9j51HKT3Z4Bj5ROuv4t
         tZR0fAOlwSjUTTvGP8j8SzPNkkL138hGe6iL8=
MIME-Version: 1.0
Received: by 10.223.98.19 with SMTP id o19mr4485168fan.82.1251102423799; Mon, 
	24 Aug 2009 01:27:03 -0700 (PDT)
In-Reply-To: <cbbf4b570908230800i573b2012pe0d91bcf6076f024@mail.gmail.com>
References: <77938bc20908230422h4e634c78s2fc40e433145f391@mail.gmail.com>
	 <cbbf4b570908230800i573b2012pe0d91bcf6076f024@mail.gmail.com>
Date: Mon, 24 Aug 2009 11:27:03 +0300
Message-ID: <77938bc20908240127g63639b19mc2db15a037106cd5@mail.gmail.com>
Subject: Re: Getting free space percentage on DFS
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015174ff0948c57bf0471defbe0
X-Virus-Checked: Checked by ClamAV on apache.org

--0015174ff0948c57bf0471defbe0
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi.

One way you can do this is thought JMX.
>
>
> http://www.jointhegrid.com/svn/hadoop-cacti-jtg/trunk/src/com/jointhegrid/hadoopjmx/NameNodeStatistics.java
>
> That is part of a cacti graphing application for hadoop I wrote
> (http://www.jointhegrid.com/hadoop/)
>
> Enjoy,
>

I'm going to try this next - you probably meant these links?

http://www.jointhegrid.com/svn/hadoop-cacti-jtg/trunk/src/com/jointhegrid/hadoopjmx/FSNamesystemStatus.java

http://www.jointhegrid.com/svn/hadoop-cacti-jtg/trunk/src/com/jointhegrid/hadoopjmx/FSDatasetStatus.java
(inherits
http://www.jointhegrid.com/svn/hadoop-cacti-jtg/trunk/src/com/jointhegrid/hadoopjmx/JMXBase.java
)

--0015174ff0948c57bf0471defbe0--

From common-user-return-17021-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 16:33:12 2009
Return-Path: <common-user-return-17021-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 5854 invoked from network); 24 Aug 2009 16:33:12 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 16:33:12 -0000
Received: (qmail 8430 invoked by uid 500); 24 Aug 2009 16:26:16 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 8363 invoked by uid 500); 24 Aug 2009 16:26:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 8343 invoked by uid 99); 24 Aug 2009 16:26:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 16:26:15 +0000
X-ASF-Spam-Status: No, hits=4.9 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [128.163.184.75] (HELO ironporta.uky.edu) (128.163.184.75)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 16:26:04 +0000
Received: from ex7hb03.ad.uky.edu ([128.163.187.55])
  by ironporta.uky.edu with ESMTP; 24 Aug 2009 12:25:43 -0400
Received: from EX7FM02.ad.uky.edu ([128.163.187.11]) by EX7HB03.ad.uky.edu
 ([128.163.187.55]) with mapi; Mon, 24 Aug 2009 12:25:43 -0400
From: "Nelson, William" <wnels2@email.uky.edu>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Mon, 24 Aug 2009 12:25:46 -0400
Subject: IP address or host name 
Thread-Topic: IP address or host name 
Thread-Index: Acok14if2seeixypT1mFQ5gVPEWaLA==
Message-ID: <36C0284259386544B2E9F11BE30CBDF5015963979B@EX7FM02.ad.uky.edu>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: multipart/alternative;
	boundary="_000_36C0284259386544B2E9F11BE30CBDF5015963979BEX7FM02adukye_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_36C0284259386544B2E9F11BE30CBDF5015963979BEX7FM02adukye_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

I'm new to hadoop.
I'm running 0.19.2 on a Centos 5.2  cluster.
I have been having problems with the nodes connecting to the master (even w=
hen the firewall is off) using the hostname  in the hadoop-site.xml but it =
will connect using the IP address.
 This is also true trying to connect to port 9000 with telnet. If I start h=
adoop with hostnames in the hadoop-site.xml, I get  Connection refused. Whe=
n I use IP addresses in the hadoop-site.xml I can connect with telnet using=
 either the IP address or hostname.
The datanode running on the master node can connect with either IP address =
or hostname in the hadoop-site.xml.
I have found this problem posted a couple of time but have not found the an=
swer yet.


Datanodes on slaves can't connect but the datanode on master can connect.
<property>
    <name>fs.default.name</name>
    <value>hdfs://master.com:9000</value>
 </property>

Everybody can connect.
<property>
    <name>fs.default.name</name>
    <value>hdfs://192.68.42.221:9000</value>
 </property>

Unfortunately  using IP addresses creates another problem when I try to run=
 the job: Wrong FS exception


Previous posts refer to https://issues.apache.org/jira/browse/HADOOP-5191 b=
ut it appears the work around is to switch back to host names, which I can'=
t get to work.



Thanks in advance for any help.



Bill





--_000_36C0284259386544B2E9F11BE30CBDF5015963979BEX7FM02adukye_--

From common-user-return-17022-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 16:33:56 2009
Return-Path: <common-user-return-17022-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 6884 invoked from network); 24 Aug 2009 16:33:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 16:33:56 -0000
Received: (qmail 8770 invoked by uid 500); 24 Aug 2009 16:26:17 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 8681 invoked by uid 500); 24 Aug 2009 16:26:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 8572 invoked by uid 99); 24 Aug 2009 16:26:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 16:26:16 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of markkerzner@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 16:26:05 +0000
Received: by bwz10 with SMTP id 10so1596217bwz.29
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 09:25:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=/LILeNS4fStoVCyxlBSp+FX4JnesGYXQYE0XIqcyJdY=;
        b=vDRGPiHcnpa/y3HR1CMkFHKKPUYOQXdwWhQ7cnEuIW/224f2TJ3V9lPmU4EOCMW7Zx
         yrZfhv19IImreJHefaAMe0WwECLfEzpVXdDFk6D4a5Kdl1huLomRbiwyQ8bJ+gDcw4fw
         nNGrmuVK+Dca6JihvwwCNrI4Q1fMVHYHflcAc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=rtpT0YABDRgxlQUs2e95PMibDVJioG9Q1bkIRnz3l4COPVZ9J8bt++lUCqq+wEWmSe
         HVel5F7sOazMOwY8oJbPA0sX1SgqO/Vli9Oh4JpeXdApFKXonV0Ztz/YWghXGY1u55uT
         YGBNvppfpuAiiOcWQAnHej9+sK3skbtfx6qEs=
MIME-Version: 1.0
Received: by 10.204.155.73 with SMTP id r9mr1534428bkw.101.1251131143786; Mon, 
	24 Aug 2009 09:25:43 -0700 (PDT)
In-Reply-To: <25118783.post@talk.nabble.com>
References: <25118783.post@talk.nabble.com>
Date: Mon, 24 Aug 2009 11:25:43 -0500
Message-ID: <c9b0d8bd0908240925u67a4e3f1jd8d9ac07551049bf@mail.gmail.com>
Subject: Re: Developer Needed
From: Mark Kerzner <markkerzner@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175cfa8e6492cf0471e5abee
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175cfa8e6492cf0471e5abee
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Alex,
I am interested, here is my resume http://markkerzner.googlepages.com

Sincerely,
Mark

On Mon, Aug 24, 2009 at 11:07 AM, alevin <alevin@brilig.com> wrote:

>
> SQL Data Migration Specialist
>
> Overview
>
> The SQL Data Migration Specialist plays a crucial role in converting new
> Client's data onto Brilig's service platforms. We are looking for a
> talented
> and energetic full-time freelance programmer to work both remotely and
> onsite at our midtown Manhattan location. The Specialist will work with our
> clients' technical teams to determine the optimal formats and requirements
> to create files for subsequent import into a Brilig remote database during
> the implementation process. This process involves extracting, scrubbing,
> combining, transforming, validating and importing large data tables into
> final data sets suitable for loading into Brilig's defined databases. The
> Specialist will be responsible for creating/editing the database structure
> and writing of all import scripts and programs. The ability to work on
> multiple projects simultaneously while meeting tight deadlines is critical.
> This project will last for 3 months but may be extended or may eventually
> lead to a full time position in our fun and exciting startup. Must be able
> to travel to client meetings and work independently.
>
> Responsibilities:
>
> - Subject Matter Expert on software tools used in the entire data migration
> process from extraction to validation and load
> - Design, develop and execute quality data movement processes that are
> consistent, repeatable and scalable
> - Streamline testing, audit and validation processes through data scrubbing
> routines and presentation of audit reports prior to load
> - Roll out newly developed processes via documentation and training
> - Maintain and manage a template library of executed solutions to leverage
> against future opportunities
> - Identify, clarify, and resolve issues and risks, escalating them as
> needed
> - Build and nourish strong business relationships with external clients
>
> Please include:
>
> - Salary Requirements
> - Availability
>
> Experience
>
> - At least 3-5 years experience in the development of java applications
> - Use of XML and other protocols for data exchange between systems
> - SQL database design and implementation
> - Experience with Eclipse, Maven, and SVN a plus
> - Experience with Htable and Hadoop a big plus
> - Excellent communication skills with both technical and non-technical
> colleagues
> - Upper management and client facing skills
> - Interest in keeping up with technology advances
>
> PLEASE NOTE:
> US citizens and Green Card Holders and those authorized to work in the US
> only. We are unable to sponsor or transfer H-1B candidates.
>
> Contact:
>
> Alex Levin, COO
> Brilig
> alevin@brilig.com
>
> --
> View this message in context:
> http://www.nabble.com/Developer-Needed-tp25118783p25118783.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>
>

--0015175cfa8e6492cf0471e5abee--

From common-user-return-17020-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 16:36:00 2009
Return-Path: <common-user-return-17020-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 10196 invoked from network); 24 Aug 2009 16:35:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 16:35:59 -0000
Received: (qmail 76610 invoked by uid 500); 24 Aug 2009 16:08:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 76559 invoked by uid 500); 24 Aug 2009 16:08:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 76549 invoked by uid 500); 24 Aug 2009 16:08:23 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 76546 invoked by uid 99); 24 Aug 2009 16:08:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 16:08:23 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 16:08:13 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1Mfc5I-0007Bz-7i
	for core-user@hadoop.apache.org; Mon, 24 Aug 2009 09:07:52 -0700
Message-ID: <25118783.post@talk.nabble.com>
Date: Mon, 24 Aug 2009 09:07:52 -0700 (PDT)
From: alevin <alevin@brilig.com>
To: core-user@hadoop.apache.org
Subject: Developer Needed
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: alevin@brilig.com
X-Virus-Checked: Checked by ClamAV on apache.org


SQL Data Migration Specialist 

Overview 

The SQL Data Migration Specialist plays a crucial role in converting new
Client's data onto Brilig's service platforms. We are looking for a talented
and energetic full-time freelance programmer to work both remotely and
onsite at our midtown Manhattan location. The Specialist will work with our
clients' technical teams to determine the optimal formats and requirements
to create files for subsequent import into a Brilig remote database during
the implementation process. This process involves extracting, scrubbing,
combining, transforming, validating and importing large data tables into
final data sets suitable for loading into Brilig's defined databases. The
Specialist will be responsible for creating/editing the database structure
and writing of all import scripts and programs. The ability to work on
multiple projects simultaneously while meeting tight deadlines is critical.
This project will last for 3 months but may be extended or may eventually
lead to a full time position in our fun and exciting startup. Must be able
to travel to client meetings and work independently. 

Responsibilities: 

- Subject Matter Expert on software tools used in the entire data migration
process from extraction to validation and load
- Design, develop and execute quality data movement processes that are
consistent, repeatable and scalable 
- Streamline testing, audit and validation processes through data scrubbing
routines and presentation of audit reports prior to load
- Roll out newly developed processes via documentation and training
- Maintain and manage a template library of executed solutions to leverage
against future opportunities
- Identify, clarify, and resolve issues and risks, escalating them as needed
- Build and nourish strong business relationships with external clients 

Please include: 

- Salary Requirements 
- Availability 

Experience 

- At least 3-5 years experience in the development of java applications 
- Use of XML and other protocols for data exchange between systems 
- SQL database design and implementation 
- Experience with Eclipse, Maven, and SVN a plus 
- Experience with Htable and Hadoop a big plus 
- Excellent communication skills with both technical and non-technical
colleagues 
- Upper management and client facing skills 
- Interest in keeping up with technology advances 

PLEASE NOTE:
US citizens and Green Card Holders and those authorized to work in the US
only. We are unable to sponsor or transfer H-1B candidates.

Contact:

Alex Levin, COO
Brilig
alevin@brilig.com

-- 
View this message in context: http://www.nabble.com/Developer-Needed-tp25118783p25118783.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-17016-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 16:37:42 2009
Return-Path: <common-user-return-17016-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 12675 invoked from network); 24 Aug 2009 16:37:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 16:37:41 -0000
Received: (qmail 49064 invoked by uid 500); 24 Aug 2009 11:06:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 48992 invoked by uid 500); 24 Aug 2009 11:06:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 48976 invoked by uid 99); 24 Aug 2009 11:06:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 11:06:45 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jingkei.ly@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 11:06:37 +0000
Received: by bwz10 with SMTP id 10so1433489bwz.29
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 04:06:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:sender:received:in-reply-to
         :references:from:date:x-google-sender-auth:message-id:subject:to
         :content-type;
        bh=l1+fxttPU44ydzLno1snO135g+kZP/s3iZPIkSQX82Q=;
        b=Mq/DMJSYFGYWBFydA1P+9bBuEdlyXPbUfilLJhaV2YNiErgwkBnLgu5rvQzO+tH89z
         /NnXYqj0+8uE39v8vhFSR0IPzBS/U8EaaFlqUF+kyUpBrNo+X1+vpLIb6tT2sd+p04zj
         GtT7pSSeeLNlAGq2WexqzYhn6/ZvwPYGah/LQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:sender:in-reply-to:references:from:date
         :x-google-sender-auth:message-id:subject:to:content-type;
        b=q7lkMWKvzrdj5EotAHPBdoiqe0xz4hUZbTPto8jIWItTyXcqrBauv8Ud4Ak6tIuLBJ
         hzVN5TRH8FevnUj89pssR0TX3+ml9VH0QrzLNvs/pa3oTemZK8REuBq16O/WUfPQNTj8
         QsGQewLgalACIxXOYBcx6B0ZOFVMuY+5KC544=
MIME-Version: 1.0
Sender: jingkei.ly@gmail.com
Received: by 10.86.228.16 with SMTP id a16mr3055478fgh.49.1251111976079; Mon, 
	24 Aug 2009 04:06:16 -0700 (PDT)
In-Reply-To: <2aa3aff80908240252h6fcaebeaoc52efe63c13da0ad@mail.gmail.com>
References: <2aa3aff80908240252h6fcaebeaoc52efe63c13da0ad@mail.gmail.com>
From: Jingkei Ly <jly.list@googlemail.com>
Date: Mon, 24 Aug 2009 12:05:56 +0100
X-Google-Sender-Auth: 1612dc4b3f3a2835
Message-ID: <c238cbb50908240405x4fa11a70od11a97f03f4dbc25@mail.gmail.com>
Subject: Re: Problems using custom output format
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00148531b92ce894370471e1344e
X-Virus-Checked: Checked by ClamAV on apache.org

--00148531b92ce894370471e1344e
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

It looks like your readFields() and write() methods in PObjectWritable don't
match up with each other - assuming none of your fields are null in
PObjectWritable your write method will write:

UTF, UTF, UTF, UTF

yet your readFields method will try to read:

boolean, UTF, boolean, UTF, boolean, UTF, boolean, UTF

which is why you get a EOFException.

2009/8/24 Rakhi Khatwani <rkhatwani@gmail.com>

> Hi,
>      I was tryin to run a map reduce program which reads a txt file filled
> wid some keywords,
> my map task takes each of these keywords, does some processing and returns
> a
> complex object url which contains media, status, link and title (each being
> a string).
> my reduce class simply has one line
> while(value.hasnext()){
> output.collect(key, value.next())
> }
> i tried the following configuration:
>  conf.setInputFormat(TextInputFormat.class);
>  conf.setOutputFormat(TextOutputFormat.class);
>  conf.setMapOutputKeyClass(Text.class);
>  conf.setMapOutputValueClass(PObjectWritable.class);
>  conf.setOutputKeyClass(Text.class);
>  conf.setOutputValueClass(PObjectWritable.class);
>
> Following is my PObjectWritable object:
>
> ************************************************************************************************************************************************************************
>
> import java.io.DataInput;
> import java.io.DataOutput;
> import java.io.IOException;
>
> import org.apache.hadoop.io.Writable;
>
> public class PObjectWritable implements Writable{
>
>  private String url;
>  private String media;
>  private String title;
>  private String status;
>
>
>  public String getUrl() {
>  return url;
>  }
>
>  public void setUrl(String url) {
>  this.url = url;
>  }
>
>  public String getMedia() {
>  return media;
>  }
>
>  public void setMedia(String media) {
>  this.media = media;
>  }
>
>  public String getTitle() {
>  return title;
>  }
>
>  public void setTitle(String title) {
>  this.title = title;
>  }
>
>  public String getStatus() {
>  return status;
>  }
>
>  public void setStatus(String status) {
>  this.status = status;
>  }
>
>  @Override
>  public void readFields(DataInput in) throws IOException {
>  // TODO Auto-generated method stub
>  if(in.readBoolean()){
>  url = in.readUTF();
>  }else{
>  url = null;
>  }
>
>  if(in.readBoolean()){
>  media = in.readUTF();
>  }else{
>  media = null;
>  }
>
>  if(in.readBoolean()){
>  title = in.readUTF();
>  }else{
>  title = null;
>  }
>
>  if(in.readBoolean()){
>  status = in.readUTF();
>  }else{
>  status = null;
>  }
>  }
>
>  @Override
>  public void write(DataOutput out) throws IOException {
>  // TODO Auto-generated method stub
>  if(url!=null){
>  out.writeUTF(url);
>  }
>
>  if(media!=null){
>  out.writeUTF(media);
>  }
>
>  if(title!=null){
>  out.writeUTF(title);
>  }
>
>  if(status!=null){
>  out.writeUTF(status);
>  }
>  }
>
>  @Override
>  public String toString() {
>  // TODO Auto-generated method stub
>  return url + ", " + media + ", " + title + ", " + status;
>  }
>
> }
>
>
> **************************************************************************************************************************************************************************
> Following is the exception at reduce:
> java.lang.RuntimeException: problem advancing post rec#0
>  at org.apache.hadoop.mapred.Task$ValuesIterator.next(Task.java:831)
>  at
>
> org.apache.hadoop.mapred.ReduceTask$ReduceValuesIterator.moveToNext(ReduceTask.java:237)
>  at
>
> org.apache.hadoop.mapred.ReduceTask$ReduceValuesIterator.next(ReduceTask.java:233)
>  at
>
> org.apache.hadoop.mapred.lib.IdentityReducer.reduce(IdentityReducer.java:39)
>  at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:430)
>  at org.apache.hadoop.mapred.Child.main(Child.java:155)
> Caused by: java.io.EOFException
>  at java.io.DataInputStream.readFully(DataInputStream.java:180)
>  at java.io.DataInputStream.readUTF(DataInputStream.java:592)
>  at java.io.DataInputStream.readUTF(DataInputStream.java:547)
>  at com.mapreduce.PObjectWritable.readFields(PObjectWritable.java:59)
>  at
>
> org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)
>  at
>
> org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:40)
>  at
> org.apache.hadoop.mapred.Task$ValuesIterator.readNextValue(Task.java:888)
>  at org.apache.hadoop.mapred.Task$ValuesIterator.next(Task.java:828)
>  ... 5 more
> wht could cause the exception??
> Regards
> Raakhi
>

--00148531b92ce894370471e1344e--

From common-user-return-17023-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 16:46:26 2009
Return-Path: <common-user-return-17023-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 25425 invoked from network); 24 Aug 2009 16:46:25 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 16:46:25 -0000
Received: (qmail 41510 invoked by uid 500); 24 Aug 2009 16:46:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 41429 invoked by uid 500); 24 Aug 2009 16:46:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 41419 invoked by uid 99); 24 Aug 2009 16:46:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 16:46:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of simon.willnauer@googlemail.com designates 72.14.220.155 as permitted sender)
Received: from [72.14.220.155] (HELO fg-out-1718.google.com) (72.14.220.155)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 16:46:35 +0000
Received: by fg-out-1718.google.com with SMTP id l26so540845fgb.12
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 09:46:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=googlemail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=2KAlmGtLXjmDK9/3siQR176C+Sqx5ZZzNqYMYpmWAiw=;
        b=e43h7zsOQ1PDGz5Sv+5cJcUpgKTx991hjUaotxCyCfrJ45vsjC4UftaOVdaUmsmK5J
         wQ/JLoPA8tH4mDhbJO43QJdeu9WC5hZ2/9r6sEMA/WxN37KeHatU3/5yRhVREijuL2zN
         XkzpQQgTDuJrm4nekMt9ebGwfCWdynaqK3LgM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=googlemail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:date:message-id
         :subject:from:to:content-type:content-transfer-encoding;
        b=G6zxceJpvfKF9HdTFxP+RteLWx7szixEcBWXprjjXfmX+Ua6yYyCc0Ghvl79BrAjCN
         lyjOAMayKDR46Zhp4YHWgWxW/ZpFB5I/SzL9Xmcdv3a1lBiIvIJthKVjr0dMIOJu7kAU
         uPVD2reoyN4OYXP0cXfcTNfU+P3SFDQXEgPY0=
MIME-Version: 1.0
Received: by 10.239.145.33 with SMTP id q33mr517082hba.126.1251132375181; Mon, 
	24 Aug 2009 09:46:15 -0700 (PDT)
Reply-To: simon.willnauer@gmail.com
In-Reply-To: <36C0284259386544B2E9F11BE30CBDF5015963979B@EX7FM02.ad.uky.edu>
References: <36C0284259386544B2E9F11BE30CBDF5015963979B@EX7FM02.ad.uky.edu>
Date: Mon, 24 Aug 2009 18:46:15 +0200
Message-ID: <f18c9dde0908240946q1745ff0dx427fa99f1a441507@mail.gmail.com>
Subject: Re: IP address or host name
From: Simon Willnauer <simon.willnauer@googlemail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

You can either try to set the "master.com" name in your /etc/hosts
file or if that does not work for some reason you can try to set the
name in your configured DNS server.
You should make sure that you hostname is not mapped to 127.0.0.1
otherwise hadoop will bind its sockets to loopback. That would explain
why your local datanode can connect but others can't.
Make sure you format you dfs again otherwise you will get the same FS
exception again.

simon

On Mon, Aug 24, 2009 at 6:25 PM, Nelson, William<wnels2@email.uky.edu> wrot=
e:
> I'm new to hadoop.
> I'm running 0.19.2 on a Centos 5.2 =C2=A0cluster.
> I have been having problems with the nodes connecting to the master (even=
 when the firewall is off) using the hostname =C2=A0in the hadoop-site.xml =
but it will connect using the IP address.
> =C2=A0This is also true trying to connect to port 9000 with telnet. If I =
start hadoop with hostnames in the hadoop-site.xml, I get =C2=A0Connection =
refused. When I use IP addresses in the hadoop-site.xml I can connect with =
telnet using either the IP address or hostname.
> The datanode running on the master node can connect with either IP addres=
s or hostname in the hadoop-site.xml.
> I have found this problem posted a couple of time but have not found the =
answer yet.
>
>
> Datanodes on slaves can't connect but the datanode on master can connect.
> <property>
> =C2=A0 =C2=A0<name>fs.default.name</name>
> =C2=A0 =C2=A0<value>hdfs://master.com:9000</value>
> =C2=A0</property>
>
> Everybody can connect.
> <property>
> =C2=A0 =C2=A0<name>fs.default.name</name>
> =C2=A0 =C2=A0<value>hdfs://192.68.42.221:9000</value>
> =C2=A0</property>
>
> Unfortunately =C2=A0using IP addresses creates another problem when I try=
 to run the job: Wrong FS exception
>
>
> Previous posts refer to https://issues.apache.org/jira/browse/HADOOP-5191=
 but it appears the work around is to switch back to host names, which I ca=
n't get to work.
>
>
>
> Thanks in advance for any help.
>
>
>
> Bill
>
>
>
>
>

From common-user-return-17018-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 16:49:42 2009
Return-Path: <common-user-return-17018-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 30105 invoked from network); 24 Aug 2009 16:49:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 16:49:41 -0000
Received: (qmail 10038 invoked by uid 500); 24 Aug 2009 14:00:06 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 9950 invoked by uid 500); 24 Aug 2009 14:00:06 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 9939 invoked by uid 99); 24 Aug 2009 14:00:06 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 14:00:06 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of edlinuxguru@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 13:59:58 +0000
Received: by bwz10 with SMTP id 10so1514901bwz.29
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 06:59:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=NZ4BSEVyXV1oMcW4/lWE727XzeBhxWYb4H33IrZtKKI=;
        b=fIMU3me3y9bESntd0hvlllImEcp9bd3Xp+zijuEsTjVOQrgyM2SQYr2FvijA0qvgth
         qnw0+H2aU2eKtXUp1y2ffn4c3flEijX+B/8DyaEO35c+8ISiN70uzMhJ5jm5AbdnfRnT
         8d8U7VGqf1ozmDPYv9uLJORUA9heUWYDtlYqk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=YkOMNL8fu+ImSzF/1ujTua/VGI5WAHnPz21k1ROmWf2daCc6Ul3rOliu+NKbsCQO6U
         fKKyeCNsRU6Ft7rauceNWGd60OGc08RD4Y8k29wP01fVvYAq5MhBJrVPr6kEQ7RSgtPJ
         xEUk19OKAZFGJN9GtwgGhG4eZl+rS8qpYr3pk=
MIME-Version: 1.0
Received: by 10.239.145.5 with SMTP id q5mr499394hba.89.1251122376333; Mon, 24 
	Aug 2009 06:59:36 -0700 (PDT)
In-Reply-To: <6f72e2db0908240040v7b2dbefje673b7788ee76369@mail.gmail.com>
References: <6f72e2db0908240040v7b2dbefje673b7788ee76369@mail.gmail.com>
Date: Mon, 24 Aug 2009 09:59:20 -0400
Message-ID: <cbbf4b570908240659v7e3bcc79w17d97c1dbf625f1c@mail.gmail.com>
Subject: Re: Rack Awareness!
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Mon, Aug 24, 2009 at 3:40 AM, Sugandha
Naolekar<sugandha.n87@gmail.com> wrote:
> Hello!
>
> *************************************************************************=
*************
> Below is the python script I have written::
>
> #!/usr/bin/env python
>
> '''
> This script used by hadoop to determine network/rack topology. =A0It
> should be specified in hadoop-site.xml via topology.script.file.name
> Property.
>
> <property>
> =A0name>topology.script.file.name</name>
> =A0<value>/home/hadoop/topology.py</value>
> </property>
> '''
>
> import sys
> from string import join
>
> DEFAULT_RACK =3D '/default/rack0';
>
> RACK_MAP =3D
> {
> =A0 =A0'10.20.220.35' : '/jobsec/rack1',
> =A0 =A0'10.20.220.78' : '/jobsec/rack1',
> =A0 =A0'10.20.220.71' : '/jobsec/rack1',
>
> =A0 =A0'10.20.220.74' : '/jobsec/rack2',
> }
>
> if len(sys.argv)=3D=3D1:
> =A0 =A0 print DEFAULT_RACK
> else:
> =A0 =A0 print join([RACK_MAP.get(i, DEFAULT_RACK) for i in sys.argv[1:]],=
" ")
>
> *************************************************************************=
**************
> I have to configure my 6 node cluster in which 4 r d datanodes and the ot=
her
> 2 are playing NN,JT and sec.NN roles. The m/c playing JT is also Sec. NN.
> Now, i want to configure 3 DN's in rack 1 of JT and the 4th DN in rack2 o=
f
> JT.
> *************************************************************************=
*************
>
> Also, the values of corresponding tags is also set in site-sml file as::
>
> <property>
> =A0<name>topology.node.switch.mapping.impl</name>
> =A0<value>org.apache.hadoop.net.ScriptBasedMapping</value>
> =A0<description> The default implementation of the DNSToSwitchMapping. It
> =A0 =A0invokes a script specified in topology.script.file.name to resolve
> =A0 =A0node names. If the value for topology.script.file.name is not set,=
 the
> =A0 =A0default value of DEFAULT_RACK is returned for all node names.
> =A0</description>
> </property>
>
> <property>
> =A0<name>topology.script.file.name</name>
> =A0<value>/home/hadoop/Softwares/hadoop-0.19.0/conf/test.py</value>
> =A0<description> The script name that should be invoked to resolve DNS na=
mes
> to
> =A0 =A0NetworkTopology names. Example: the script would take host.foo.bar=
 as an
> =A0 =A0argument, and return /rack1 as the output.
> =A0</description>
> </property>
>
> <property>
> =A0<name>topology.script.number.args</name>
> =A0<value>10</value>
> =A0<description> The max number of args that the script configured with
> =A0 =A0topology.script.file.name should be run with. Each arg is an
> =A0 =A0IP address.
> =A0</description>
> </property>
>
> Here, test.py is the python script file name.
>
> *****************************************************
>
> Now, the moment I start or invoke namenode daemon, this file gets invoked
> automatically? What do I do to acheive my purpose...The aove things are
> correct(files and scripsts and tags?) how to chk the rack status of
> machines..and special command? PLease do help me out!
>
> --
> Regards!
> Sugandha
>

You know you have done this correctly if you look at the logs of the
namenode and jobtracker. They log messages like adding node 'X' rack
'Y'. Also running 'hadoop fsck /' shows you the number of racks and
nodes. Is there anything that produces a pretty layout? I do not think
so.

From common-user-return-17024-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 16:52:23 2009
Return-Path: <common-user-return-17024-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 34256 invoked from network); 24 Aug 2009 16:52:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 16:52:23 -0000
Received: (qmail 52122 invoked by uid 500); 24 Aug 2009 16:52:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52061 invoked by uid 500); 24 Aug 2009 16:52:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52051 invoked by uid 99); 24 Aug 2009 16:52:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 16:52:46 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=SPF_HELO_PASS,SPF_NEUTRAL,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [74.208.4.194] (HELO mout.perfora.net) (74.208.4.194)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 16:52:35 +0000
Received: from Habermaas ([209.212.94.31])
	by mrelay.perfora.net (node=mrus1) with ESMTP (Nemesis)
	id 0MKpCa-1MfcmA3R8y-000Clh; Mon, 24 Aug 2009 12:52:13 -0400
From: "Bill Habermaas" <bill@habermaas.us>
To: <common-user@hadoop.apache.org>
References: <36C0284259386544B2E9F11BE30CBDF5015963979B@EX7FM02.ad.uky.edu>
In-Reply-To: <36C0284259386544B2E9F11BE30CBDF5015963979B@EX7FM02.ad.uky.edu>
Subject: RE: IP address or host name 
Date: Mon, 24 Aug 2009 12:52:05 -0400
Message-ID: <002401ca24db$36cd6a70$a4683f50$@us>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="US-ASCII"
Content-Transfer-Encoding: 7bit
X-Mailer: Microsoft Office Outlook 12.0
Thread-Index: Acok14if2seeixypT1mFQ5gVPEWaLAAAnDtQ
Content-Language: en-us
X-Provags-ID: V01U2FsdGVkX18H8j5Ts1zQAkIx651+Ij3h32SmbCoyemGppQs
 HNCHVlL9D/8zpEIIzKtT+zGIft/L6OjBNVTVRhgHxYtQjG8UCQ
 swTV6m66OZIOwcRlg3NHA==
X-Virus-Checked: Checked by ClamAV on apache.org

The problem resolved by HADOOP-5191 involves client connection to the name
node and has nothing to do with connections between the master and slave. 

In my configuration I use IP addresses exclusively.  Mixing hostnames and IP
addresses leads to all kinds of problems. 

Bill 

-----Original Message-----
From: Nelson, William [mailto:wnels2@email.uky.edu] 
Sent: Monday, August 24, 2009 12:26 PM
To: common-user@hadoop.apache.org
Subject: IP address or host name 

I'm new to hadoop.
I'm running 0.19.2 on a Centos 5.2  cluster.
I have been having problems with the nodes connecting to the master (even
when the firewall is off) using the hostname  in the hadoop-site.xml but it
will connect using the IP address.
 This is also true trying to connect to port 9000 with telnet. If I start
hadoop with hostnames in the hadoop-site.xml, I get  Connection refused.
When I use IP addresses in the hadoop-site.xml I can connect with telnet
using either the IP address or hostname.
The datanode running on the master node can connect with either IP address
or hostname in the hadoop-site.xml.
I have found this problem posted a couple of time but have not found the
answer yet.


Datanodes on slaves can't connect but the datanode on master can connect.
<property>
    <name>fs.default.name</name>
    <value>hdfs://master.com:9000</value>
 </property>

Everybody can connect.
<property>
    <name>fs.default.name</name>
    <value>hdfs://192.68.42.221:9000</value>
 </property>

Unfortunately  using IP addresses creates another problem when I try to run
the job: Wrong FS exception


Previous posts refer to https://issues.apache.org/jira/browse/HADOOP-5191
but it appears the work around is to switch back to host names, which I
can't get to work.



Thanks in advance for any help.



Bill







From common-user-return-17012-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 16:52:36 2009
Return-Path: <common-user-return-17012-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 34415 invoked from network); 24 Aug 2009 16:52:36 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 16:52:36 -0000
Received: (qmail 29027 invoked by uid 500); 24 Aug 2009 09:41:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 28938 invoked by uid 500); 24 Aug 2009 09:41:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 28928 invoked by uid 99); 24 Aug 2009 09:41:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 09:41:00 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cubicdesign@gmail.com designates 74.125.78.25 as permitted sender)
Received: from [74.125.78.25] (HELO ey-out-2122.google.com) (74.125.78.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 09:40:51 +0000
Received: by ey-out-2122.google.com with SMTP id 22so525546eye.35
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 02:40:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:date:from
         :user-agent:mime-version:to:subject:content-type;
        bh=f1P903dvFOBsxso2tb36xk+w+XWI7yB+oUBiL8mlcWM=;
        b=qG7XnyDoH+ym4gotcqijdfHda1wSI5X8lWCL3mpg+OsM/AFTuiVCLwGG+SOgSfEP71
         vhJ3F5I+drUSDN9nZobyMif2mrPoKS9i/LZVypxiQLJjLCfOHKLTwyFznep6Y2SRAvnS
         UKQez2AdovNcVlYmuHqVcl3i2+w4v71EsOpso=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:date:from:user-agent:mime-version:to:subject
         :content-type;
        b=XQS+YHzrODJ9W93ofQiWIZrb1x7mwCvVE+/NSVTfmRtNAjp0quewaATORAS5TcfRAI
         WgXtugGTMNgGIUnNCO6UKrjNv5EEzEHwvPjIhehfByNxMtP2lBiCA741i3XQCjsakUC3
         VhB+LlqnF+p7BuJRWrF96Q3j0bN6O+O15xLS0=
Received: by 10.210.87.16 with SMTP id k16mr1664145ebb.2.1251106829862;
        Mon, 24 Aug 2009 02:40:29 -0700 (PDT)
Received: from ?192.168.220.104? (host-091-097-241-036.ewe-ip-backbone.de [91.97.241.36])
        by mx.google.com with ESMTPS id 10sm11186837eyz.11.2009.08.24.02.40.28
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Mon, 24 Aug 2009 02:40:29 -0700 (PDT)
Message-ID: <4A92600A.9030403@Gmail.com>
Date: Mon, 24 Aug 2009 11:40:26 +0200
From: CubicDesign <cubicdesign@gmail.com>
User-Agent: Thunderbird 2.0.0.23 (Windows/20090812)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Writing a graphic interface for Hadoop
Content-Type: multipart/alternative;
 boundary="------------020305050005020600000406"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------020305050005020600000406
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Hi.

I want to write a GUI for Hadoop using Lazarus (a Pascal strain). 
Anybody can give some hints about how I can interact with the daemons?
Any ideas that will point me to the right direction are appreciated.

10x

--------------020305050005020600000406--

From common-user-return-17025-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:00:13 2009
Return-Path: <common-user-return-17025-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 47259 invoked from network); 24 Aug 2009 17:00:13 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:00:13 -0000
Received: (qmail 63859 invoked by uid 500); 24 Aug 2009 17:00:36 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 63782 invoked by uid 500); 24 Aug 2009 17:00:36 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 63754 invoked by uid 99); 24 Aug 2009 17:00:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 17:00:36 +0000
X-ASF-Spam-Status: No, hits=-4.0 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [129.128.22.22] (HELO fleet.cs.ualberta.ca) (129.128.22.22)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 17:00:26 +0000
Received: from fleet.cs.ualberta.ca (localhost.localdomain [127.0.0.1])
	by fleet-spampd (Postfix) with ESMTP id 1F92B28019
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 10:59:58 -0600 (MDT)
X-Spam-Checker-Version: SpamAssassin 3.2.4 (2008-01-01) on fleet.cs.ualberta.ca
X-Spam-Level: 
Received: from localhost (localhost.localdomain [127.0.0.1])
	by fleet-amavis (Postfix) with ESMTP id 1CE4D28014
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 10:59:58 -0600 (MDT)
X-Virus-Scanned: amavisd-new at cs.ualberta.ca
Received: from fleet.cs.ualberta.ca ([127.0.0.1])
	by localhost (cs.ualberta.ca [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id lzMkXLSeKIZh for <common-user@hadoop.apache.org>;
	Mon, 24 Aug 2009 10:59:58 -0600 (MDT)
Received: from [129.128.23.21] (st-brides.cs.ualberta.ca [129.128.23.21])
	by fleet.cs.ualberta.ca (Postfix) with ESMTP id F3D5928004
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 10:59:57 -0600 (MDT)
Message-ID: <4A92C70D.2000904@cs.ualberta.ca>
Date: Mon, 24 Aug 2009 10:59:57 -0600
From: Cam Macdonell <cam@cs.ualberta.ca>
User-Agent: Thunderbird 2.0.0.23 (X11/20090812)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Can't find TestDFSIO
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org
X-Old-Spam-Status: No, score=-102.6 required=10.0 tests=AWL,BAYES_00,
	USER_IN_WHITELIST autolearn=disabled version=3.2.4


Hi,

I'm trying to run the TestDFSIO benchmark that is mentioned in the 
hadoop o'reilly book.  However, I can't find it in any of the jars 
(common, mapred or hdfs).

For example, I presume it would be under hdfs, but the only mentioned 
test is 'dfsthroughput'.

$ ./bin/hadoop jar 
/home/cam/research/SVN/hadoop/lib/hadoop-hdfs-test-0.21.0-dev.jar
An example program must be given as the first argument.
Valid program names are:
   dfsthroughput: measure hdfs throughput

Has the name of TestDFSIO changed or am I looking in the wrong place?

Any tips or pointers are appreciated,
Cam

From common-user-return-17013-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:04:24 2009
Return-Path: <common-user-return-17013-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 52817 invoked from network); 24 Aug 2009 17:04:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:04:23 -0000
Received: (qmail 58187 invoked by uid 500); 24 Aug 2009 09:52:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 58084 invoked by uid 500); 24 Aug 2009 09:52:48 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 58063 invoked by uid 99); 24 Aug 2009 09:52:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 09:52:48 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rkhatwani@gmail.com designates 209.85.216.190 as permitted sender)
Received: from [209.85.216.190] (HELO mail-px0-f190.google.com) (209.85.216.190)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 09:52:40 +0000
Received: by pxi28 with SMTP id 28so5066373pxi.2
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 02:52:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=UY2HSBzkANagaacUPm82fJM5SKd1tRtk3ToChoXMEGA=;
        b=VYtX1xXZNluqmFXq0sn8nyE2LaVhcGHgDS6hcCYhF4wdZJKLTRHZvOcg1FGwGgaqQO
         E6Zb6snAFQ0jFnzgg9CSU9qnFK29OIt/AGHn7TWSAG4UGhsR7b/WQmbtTwx/XT4/D1e4
         IdDcvVSyhk01yW2qQxkd07JuER42wU47o4Z7g=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=aiSw6sRfwiGLj+I56+M0hKAN3AhH/C45WhiUPs9H8/gKA79KZZRzJUzUfJYzT6TWQp
         WuBKVVpwt1eLeNECa2+NSRYMtuy4ZgtMFUJFdWT0qInA2xJrBJWaGxj7cDKmx8t1bXE9
         yn/eu6gU6yMv7n7OXap44atTr5/TzYklQSYus=
MIME-Version: 1.0
Received: by 10.115.66.10 with SMTP id t10mr5694099wak.20.1251107539811; Mon, 
	24 Aug 2009 02:52:19 -0700 (PDT)
Date: Mon, 24 Aug 2009 15:22:19 +0530
Message-ID: <2aa3aff80908240252h6fcaebeaoc52efe63c13da0ad@mail.gmail.com>
Subject: Problems using custom output format
From: Rakhi Khatwani <rkhatwani@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e649b7027c7f8c0471e02cab
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e649b7027c7f8c0471e02cab
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,
      I was tryin to run a map reduce program which reads a txt file filled
wid some keywords,
my map task takes each of these keywords, does some processing and returns a
complex object url which contains media, status, link and title (each being
a string).
my reduce class simply has one line
while(value.hasnext()){
output.collect(key, value.next())
}
i tried the following configuration:
 conf.setInputFormat(TextInputFormat.class);
  conf.setOutputFormat(TextOutputFormat.class);
  conf.setMapOutputKeyClass(Text.class);
  conf.setMapOutputValueClass(PObjectWritable.class);
  conf.setOutputKeyClass(Text.class);
  conf.setOutputValueClass(PObjectWritable.class);

Following is my PObjectWritable object:
************************************************************************************************************************************************************************

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;

import org.apache.hadoop.io.Writable;

public class PObjectWritable implements Writable{

 private String url;
 private String media;
 private String title;
 private String status;


 public String getUrl() {
  return url;
 }

 public void setUrl(String url) {
  this.url = url;
 }

 public String getMedia() {
  return media;
 }

 public void setMedia(String media) {
  this.media = media;
 }

 public String getTitle() {
  return title;
 }

 public void setTitle(String title) {
  this.title = title;
 }

 public String getStatus() {
  return status;
 }

 public void setStatus(String status) {
  this.status = status;
 }

 @Override
 public void readFields(DataInput in) throws IOException {
  // TODO Auto-generated method stub
  if(in.readBoolean()){
  url = in.readUTF();
  }else{
  url = null;
  }

  if(in.readBoolean()){
  media = in.readUTF();
  }else{
  media = null;
  }

  if(in.readBoolean()){
  title = in.readUTF();
  }else{
  title = null;
  }

  if(in.readBoolean()){
  status = in.readUTF();
  }else{
  status = null;
  }
 }

 @Override
 public void write(DataOutput out) throws IOException {
  // TODO Auto-generated method stub
  if(url!=null){
  out.writeUTF(url);
  }

  if(media!=null){
  out.writeUTF(media);
  }

  if(title!=null){
  out.writeUTF(title);
  }

  if(status!=null){
  out.writeUTF(status);
  }
 }

 @Override
 public String toString() {
  // TODO Auto-generated method stub
  return url + ", " + media + ", " + title + ", " + status;
 }

}

**************************************************************************************************************************************************************************
Following is the exception at reduce:
java.lang.RuntimeException: problem advancing post rec#0
 at org.apache.hadoop.mapred.Task$ValuesIterator.next(Task.java:831)
 at
org.apache.hadoop.mapred.ReduceTask$ReduceValuesIterator.moveToNext(ReduceTask.java:237)
 at
org.apache.hadoop.mapred.ReduceTask$ReduceValuesIterator.next(ReduceTask.java:233)
 at
org.apache.hadoop.mapred.lib.IdentityReducer.reduce(IdentityReducer.java:39)
 at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:430)
 at org.apache.hadoop.mapred.Child.main(Child.java:155)
Caused by: java.io.EOFException
 at java.io.DataInputStream.readFully(DataInputStream.java:180)
 at java.io.DataInputStream.readUTF(DataInputStream.java:592)
 at java.io.DataInputStream.readUTF(DataInputStream.java:547)
 at com.mapreduce.PObjectWritable.readFields(PObjectWritable.java:59)
 at
org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)
 at
org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:40)
 at
org.apache.hadoop.mapred.Task$ValuesIterator.readNextValue(Task.java:888)
 at org.apache.hadoop.mapred.Task$ValuesIterator.next(Task.java:828)
 ... 5 more
wht could cause the exception??
Regards
Raakhi

--0016e649b7027c7f8c0471e02cab--

From common-user-return-17019-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:05:03 2009
Return-Path: <common-user-return-17019-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 54964 invoked from network); 24 Aug 2009 17:05:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:05:03 -0000
Received: (qmail 80529 invoked by uid 500); 24 Aug 2009 15:16:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80457 invoked by uid 500); 24 Aug 2009 15:16:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 80447 invoked by uid 99); 24 Aug 2009 15:16:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 15:16:07 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 15:15:57 +0000
Received: from pcp088964pcs.unl.edu (pcp088964pcs.unl.edu [129.93.158.79])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7OFFVGC009936
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 10:15:33 -0500
Message-Id: <D15A2AC3-67B1-43E7-B4AD-DEC706A5B699@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <4A926E92.8080303@apache.org>
Content-Type: multipart/signed; boundary=Apple-Mail-210-89308226; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: NN memory consumption on 0.20/0.21 with compressed pointers/
Date: Mon, 24 Aug 2009 10:15:31 -0500
References: <4A8D281B.9070006@apache.org> <4A8D8D3D.5070404@yahoo-inc.com> <4A926E92.8080303@apache.org>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-210-89308226
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit


On Aug 24, 2009, at 5:42 AM, Steve Loughran wrote:

> Raghu Angadi wrote:
>> Suresh had made an spreadsheet for memory consumption.. will check.
>> A large portion of NN memory is taken by references. I would expect  
>> memory savings to be very substantial (same as going from 64bit to  
>> 32bit), could be on the order of 40%.
>> The last I heard from Sun was that compressed pointers will be in  
>> very near future JVM (certainly JDK 1.6_x). It can use compressed  
>> pointers upto 32GB of heap.
>
> It's in JDK 1.6u14. Looking at the source and reading the specs  
> implies there is savings, but we need to experiment to see. I now  
> know how to do sizeof() in java, (in the instrumentation API), so  
> these experiments are possible
>

Hey Steve,

I'm a bit dumb with Java (so this might be something you already  
know), but last week I discovered the "jhat" tool.  You can dump the  
Java stack with JMX to a file, then use jhat to build a little  
webserver that allows you to explore your heap.

One page it provides is a table histogram of the instance counts and #  
of bytes per class.

This helped me a lot when I was trying to track memory leaks in libhdfs.

>> I would expect runtime over head on NN would be minimal in practice.
>
>
> I think there's a small extra deref cost, but its very minimal; one  
> 8 bit logical shift left, possibly also an addition. Both of which  
> run at CPU-speeds, not main memory bus rates

One interesting tidbit (from my memory of a presentation 2 months  
ago... I might have the numbers wrong, but the general message is the  
same):

On petascale-level computers, the application codes' CPU instructions  
are about 10% floating point (that is, in scientific applications,  
there are less floating point instructions than in most floating point  
benchmarks).  Of the remaining instructions, about 1/3 are memory- 
related and 2/3 are integer.  Of the integer instructions, 40% are  
computing memory locations.

So, on the biggest DOE computers, about 50% of the CPU time is spent  
on memory-related computations.  I found this pretty mind-boggling  
when I learned this.  It seems to me that the "central" part of the  
computer is becoming the bus, not the CPU.

Brian



--Apple-Mail-210-89308226
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-210-89308226--

From common-user-return-17026-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:21:14 2009
Return-Path: <common-user-return-17026-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 73711 invoked from network); 24 Aug 2009 17:21:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:21:14 -0000
Received: (qmail 98770 invoked by uid 500); 24 Aug 2009 17:21:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 98673 invoked by uid 500); 24 Aug 2009 17:21:36 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 98661 invoked by uid 99); 24 Aug 2009 17:21:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 17:21:36 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=SPF_NEUTRAL,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [128.163.184.76] (HELO ironportb.uky.edu) (128.163.184.76)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 17:21:25 +0000
Received: from ex7hb03.ad.uky.edu ([128.163.187.55])
  by ironportb.uky.edu with ESMTP; 24 Aug 2009 13:21:04 -0400
Received: from EX7FM02.ad.uky.edu ([128.163.187.11]) by EX7HB03.ad.uky.edu
 ([128.163.187.55]) with mapi; Mon, 24 Aug 2009 13:21:04 -0400
From: "Nelson, William" <wnels2@email.uky.edu>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Mon, 24 Aug 2009 13:21:07 -0400
Subject: RE: IP address or host name
Thread-Topic: IP address or host name
Thread-Index: Acok2oE/FgkGwpVlRKi1Ya2nrcIFewAAB2Ig
Message-ID: <36C0284259386544B2E9F11BE30CBDF5015963987F@EX7FM02.ad.uky.edu>
References: <36C0284259386544B2E9F11BE30CBDF5015963979B@EX7FM02.ad.uky.edu>
 <f18c9dde0908240946q1745ff0dx427fa99f1a441507@mail.gmail.com>
In-Reply-To: <f18c9dde0908240946q1745ff0dx427fa99f1a441507@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org
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From common-user-return-17027-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:36:25 2009
Return-Path: <common-user-return-17027-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 89639 invoked from network); 24 Aug 2009 17:36:25 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:36:25 -0000
Received: (qmail 17362 invoked by uid 500); 24 Aug 2009 17:36:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 17297 invoked by uid 500); 24 Aug 2009 17:36:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 17287 invoked by uid 99); 24 Aug 2009 17:36:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 17:36:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of simon.willnauer@googlemail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 17:36:35 +0000
Received: by bwz10 with SMTP id 10so1635017bwz.29
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 10:36:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=googlemail.com; s=gamma;
        h=domainkey-signature:mime-version:received:reply-to:in-reply-to
         :references:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=uMjf97WR3C38vvOvgcw6EM6deI+9FuUCQ874cHBOSHU=;
        b=Qs5WjtT0LJ1p3Tz2rpjgu0QwWIp34tK4dnWTTHK7JNyr5h9KLLLfQNgJ4wxJ4m71yH
         zbUeKOiWJ+E2YkKfIKamjb3W0qcdFDdGUS69LZCiQ4XiMkAQ0+xnciIKj/CApc7UZdTI
         ZO5v2iKIEElFaqs1o4KudFLryUulaqya6ahqI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=googlemail.com; s=gamma;
        h=mime-version:reply-to:in-reply-to:references:date:message-id
         :subject:from:to:content-type:content-transfer-encoding;
        b=MIWWiolSwHz1M1tStUAVlReVFm9a1u8JpGlHyBZWLcFh5HqXhj+TjV5PqkTxdExHVd
         KZ83xyHfw0yh6TNNMgmIOS1HWwLYlS8BVybPHCLh7rqH12oj6bsr/NBK6/c8zKHX1sWe
         DPvHzKspQyUQM2bfS5vxDGDI+OGEc6yP+8z5E=
MIME-Version: 1.0
Received: by 10.239.130.35 with SMTP id 35mr481563hbh.31.1251135374574; Mon, 
	24 Aug 2009 10:36:14 -0700 (PDT)
Reply-To: simon.willnauer@gmail.com
In-Reply-To: <36C0284259386544B2E9F11BE30CBDF5015963987F@EX7FM02.ad.uky.edu>
References: <36C0284259386544B2E9F11BE30CBDF5015963979B@EX7FM02.ad.uky.edu>
	 <f18c9dde0908240946q1745ff0dx427fa99f1a441507@mail.gmail.com>
	 <36C0284259386544B2E9F11BE30CBDF5015963987F@EX7FM02.ad.uky.edu>
Date: Mon, 24 Aug 2009 19:36:14 +0200
Message-ID: <f18c9dde0908241036n4c2d2f6brbf40d2ca7a27b465@mail.gmail.com>
Subject: Re: IP address or host name
From: Simon Willnauer <simon.willnauer@googlemail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

happy to help :)

simon

On Mon, Aug 24, 2009 at 7:21 PM, Nelson, William<wnels2@email.uky.edu> wrot=
e:
> Thanks for the quick reply. The host name on the master was bound to the =
loopback connecter.
> All is well.
> Bill
>
> -----Original Message-----
> From: Simon Willnauer [mailto:simon.willnauer@googlemail.com]
> Sent: Monday, August 24, 2009 12:46 PM
> To: common-user@hadoop.apache.org
> Subject: Re: IP address or host name
>
> You can either try to set the "master.com" name in your /etc/hosts
> file or if that does not work for some reason you can try to set the
> name in your configured DNS server.
> You should make sure that you hostname is not mapped to 127.0.0.1
> otherwise hadoop will bind its sockets to loopback. That would explain
> why your local datanode can connect but others can't.
> Make sure you format you dfs again otherwise you will get the same FS
> exception again.
>
> simon
>
> On Mon, Aug 24, 2009 at 6:25 PM, Nelson, William<wnels2@email.uky.edu> wr=
ote:
>> I'm new to hadoop.
>> I'm running 0.19.2 on a Centos 5.2 =C2=A0cluster.
>> I have been having problems with the nodes connecting to the master (eve=
n when the firewall is off) using the hostname =C2=A0in the hadoop-site.xml=
 but it will connect using the IP address.
>> =C2=A0This is also true trying to connect to port 9000 with telnet. If I=
 start hadoop with hostnames in the hadoop-site.xml, I get =C2=A0Connection=
 refused. When I use IP addresses in the hadoop-site.xml I can connect with=
 telnet using either the IP address or hostname.
>> The datanode running on the master node can connect with either IP addre=
ss or hostname in the hadoop-site.xml.
>> I have found this problem posted a couple of time but have not found the=
 answer yet.
>>
>>
>> Datanodes on slaves can't connect but the datanode on master can connect=
.
>> <property>
>> =C2=A0 =C2=A0<name>fs.default.name</name>
>> =C2=A0 =C2=A0<value>hdfs://master.com:9000</value>
>> =C2=A0</property>
>>
>> Everybody can connect.
>> <property>
>> =C2=A0 =C2=A0<name>fs.default.name</name>
>> =C2=A0 =C2=A0<value>hdfs://192.68.42.221:9000</value>
>> =C2=A0</property>
>>
>> Unfortunately =C2=A0using IP addresses creates another problem when I tr=
y to run the job: Wrong FS exception
>>
>>
>> Previous posts refer to https://issues.apache.org/jira/browse/HADOOP-519=
1 but it appears the work around is to switch back to host names, which I c=
an't get to work.
>>
>>
>>
>> Thanks in advance for any help.
>>
>>
>>
>> Bill
>>
>>
>>
>>
>>
>

From common-user-return-17028-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:38:28 2009
Return-Path: <common-user-return-17028-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 91327 invoked from network); 24 Aug 2009 17:38:27 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:38:27 -0000
Received: (qmail 24354 invoked by uid 500); 24 Aug 2009 17:38:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 24302 invoked by uid 500); 24 Aug 2009 17:38:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 15693 invoked by uid 99); 22 Aug 2009 12:48:56 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ilay.msp@gmail.com designates 209.85.216.190 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=v1PQpRI0FTmuoLnlIzP1dImdPGXHeu6BR6EXRFbXtwE=;
        b=KusjDn0uUIkdiyVrfJkdMIv1t0Prog7JAr0IYKzwhLYQasSLVCahcnfbLjOJ6fpnyI
         AtaVItLLMHvMxV3EHDbVpMbgR0T+0TQii0BsSZYnmRFUhJxiui+RzLGVRPTF1iCdg0xP
         6Cx9M/fyuUrAIOPLM+NuvZHvOcuQECUu+dKCw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=UjgPx0UdZb0EDmg+XGI8n4HoaWLEqRhxE0YMta61kZzwlAswXBCMirxPfJNpiDJNuV
         gxzElrO748q2W5/Dm3q5oFzvn434S7Sdit9Rrf7yaladvkOPgOlrC2WyEazQ+DS0agEJ
         +EzjSalwOXfd3LXLNg+whDbOOK4779erv3L6Y=
MIME-Version: 1.0
Date: Sat, 22 Aug 2009 18:18:25 +0530
Message-ID: <e2fdce80908220548n316112a9u4a9e1d687576abd3@mail.gmail.com>
Subject: InjectorHbase
From: ilay raja <ilay.msp@gmail.com>
To: hbase-user@hadoop.apache.org, hbase-dev@hadoop.apache.org, 
	nutch-user@lucene.apache.org, nutch-dev@lucene.apache.org, 
	common-user@hadoop.apache.org, common-dev@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636e1fdb19537e70471ba66b2
X-Virus-Checked: Checked by ClamAV on apache.org

--001636e1fdb19537e70471ba66b2
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello,

I am trying to run NutchBase code on Hadoop/Hbase in local mode.
I have setup the environment and everything, its working fine.

I could able to create the table using Hbase shell as well. But, am not
clear how to use the InjectorHbase program for injecting set of seed urls
into my webtable. Please tell me the steps I should be following:
I created an Hbase table : create 'webtable', '__tmp_inject_key__'
Then ran the command: bin/nutch org.apache.nutchbase.crawl.InjectorHbase
webtable urls/
It throws the following exception:
org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException:
org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column
family on metadata:__tmp_inject_key__ does not exist in region
webtable2,,1250941483088 in table {NAME => 'webtable2', FAMILIES => [{NAME
=> '__tmp_inject_key__', COMPRESSION => 'NONE', VERSIONS => '3', LENGTH =>
'2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}]}


Please tell me the way I should create the table, is there something wrong
being done?

-- 
-----------------------------
Product Engineer,
Rediff, Mumbai.

+91 97691 67921
------------------------------

--001636e1fdb19537e70471ba66b2--

From common-user-return-17029-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:38:38 2009
Return-Path: <common-user-return-17029-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 91814 invoked from network); 24 Aug 2009 17:38:38 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:38:38 -0000
Received: (qmail 26907 invoked by uid 500); 24 Aug 2009 17:39:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26855 invoked by uid 500); 24 Aug 2009 17:39:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 88082 invoked by uid 99); 22 Aug 2009 21:37:41 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of digvijaysinghshaktawat@gmail.com designates 209.85.212.202 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=QQVUzSM6KtECUinn3WiazCTB+nUEozdRzD7LsY5nYQo=;
        b=oU3K7LVYkWhxyErA78STTnSULT795CeCADAYZ1oyFs5ImjGJ7W33T/vwrzqIo9pEE6
         F7Bg09q0UsVdcwrontsM5bRsRSIxh0FcM9ue+m2C/k9ec5ZXH3HMxpcJ8jjKc7pe5QwO
         xHTEt1D2hlfB4v4D+uS86Pn5tDh0Sd7VZ/93U=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=SSg1GUD47BOK1/qf0z0m6S5Xp9sN1NqU9QE4XqdKSW2OzcczjV5iLaD62bgTGnRviN
         qyalmM5NsC3ovc22e67XDnv4ofJZ5ougRJ1mQ6VWJEbq4Tyk4/PH9GuZkg0qAeuZRMTK
         oIAJ19YMuYa5PYwp/OK8WickMt9f+hjBOo4uo=
MIME-Version: 1.0
Date: Sun, 23 Aug 2009 03:07:09 +0530
Message-ID: <bf8befe30908221437u38645c35g9727d3af539a1dd8@mail.gmail.com>
Subject: Need Guidance
From: digvijay singh shaktawat <digvijaysinghshaktawat@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016363106eb73028b0471c1c9d2
X-Virus-Checked: Checked by ClamAV on apache.org

--0016363106eb73028b0471c1c9d2
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,
      We are two undergraduate student and have are determined to do a
project in cloud computing as are final Btech project.  We are absolutely
new to hadoop and have arround six months to work on it. We wanted
suggestions regarding some interesting work possible with hadoop.

-Digvijay Singh
-Pushpak Aggarwal

--0016363106eb73028b0471c1c9d2--

From common-user-return-17030-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:38:49 2009
Return-Path: <common-user-return-17030-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 91976 invoked from network); 24 Aug 2009 17:38:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:38:48 -0000
Received: (qmail 28740 invoked by uid 500); 24 Aug 2009 17:39:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 28671 invoked by uid 500); 24 Aug 2009 17:39:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 22676 invoked by uid 99); 23 Aug 2009 07:10:11 -0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Message-ID: <22984.120.61.135.242.1251011360.squirrel@mail.rediff.co.in>
Date: Sun, 23 Aug 2009 12:39:20 +0530 (IST)
Subject: How to use Hbase with Nutch
From: ilayaraja@rediff.co.in
To: hbase-user@hadoop.apache.org,
 hbase-dev@hadoop.apache.org,
 nutch-user@lucene.apache.org,
 nutch-dev@lucene.apache.org,
 common-user@hadoop.apache.org,
 common-dev@hadoop.apache.org
User-Agent: SquirrelMail/1.4.8
MIME-Version: 1.0
Content-Type: text/plain;charset=iso-8859-1
Content-Transfer-Encoding: 8bit
X-Priority: 3 (Normal)
Importance: Normal
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

I am trying to run NutchBase code on Hadoop/Hbase in local mode.
I have setup the environment and everything, its working fine.

I could able to create the table using Hbase shell as well. But, am not
clear how to use the InjectorHbase program for injecting set of seed urls
into my webtable. Please tell me the steps I should be following:
I created an Hbase table : create 'webtable', '__tmp_inject_key__'
Then ran the command: bin/nutch org.apache.nutchbase.crawl.InjectorHbase
webtable urls/
It throws the following exception:
org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException:
org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column
family on metadata:__tmp_inject_key__ does not exist in region
webtable2,,1250941483088 in table {NAME => 'webtable2', FAMILIES => [{NAME
=> '__tmp_inject_key__', COMPRESSION => 'NONE', VERSIONS => '3', LENGTH =>
'2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}]}


Please tell me the way I should create the table, is there something wrong
being done?




From common-user-return-17017-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:42:29 2009
Return-Path: <common-user-return-17017-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 95794 invoked from network); 24 Aug 2009 17:42:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:42:29 -0000
Received: (qmail 26110 invoked by uid 500); 24 Aug 2009 12:11:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26041 invoked by uid 500); 24 Aug 2009 12:11:33 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 26031 invoked by uid 99); 24 Aug 2009 12:11:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 12:11:33 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of alex.mclintock@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 12:11:25 +0000
Received: by fxm25 with SMTP id 25so1455411fxm.29
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 05:11:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=NhVOa8uwV5sQc2M5TRzvVFGEVNxExzSYu1Ieb+FoENg=;
        b=gwS372NmXRv3b6VYCPWvZlfcASXIFPQ1hRcTAuoS4U1/NaFArGpQPfu7pkelSWzRbt
         gzR79TgO3NnkoEXbpuZCA/SNh3zfqDcwafAhzBS6T42flyudz8Yvt9s1aBgDL7wp8G1+
         vlf1pkt/jNX6P3xcc/utHctHilZTxnVr12nX4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=qH5AuLmY+r14VDURoK6bowPooOA8dz+9EB78eWJPA7b6R8t10VjT9MUW7b8V6Wydi0
         ciZplFoyQihIxiOG55/w3qrnkgS5NZ14fSamQGTsRV6oSaU1EPBCFkU1+zk/oqjRn8NH
         CEjeWfzSb9mir4U2/Qa9bfISKaGBRYSqntQnI=
MIME-Version: 1.0
Received: by 10.87.11.8 with SMTP id o8mr3182652fgi.23.1251115863795; Mon, 24 
	Aug 2009 05:11:03 -0700 (PDT)
In-Reply-To: <4A92600A.9030403@Gmail.com>
References: <4A92600A.9030403@Gmail.com>
Date: Mon, 24 Aug 2009 13:11:02 +0100
Message-ID: <d398ec7f0908240511y1cd16a3wcef4b8ecec11ef55@mail.gmail.com>
Subject: Re: Writing a graphic interface for Hadoop
From: Alex McLintock <alex.mclintock@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

2009/8/24 CubicDesign <cubicdesign@gmail.com>:
> I want to write a GUI for Hadoop using Lazarus (a Pascal strain). Anybody
> can give some hints about how I can interact with the daemons?

Presumably your GUI can run shell scripts and capture the response?
Is that what you mean? I dont really understand what more you want.

Are you hoping for something which tells you how far your job/task has
to finish?

From common-user-return-17014-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:54:59 2009
Return-Path: <common-user-return-17014-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 5453 invoked from network); 24 Aug 2009 17:54:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:54:59 -0000
Received: (qmail 20488 invoked by uid 500); 24 Aug 2009 10:43:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20408 invoked by uid 500); 24 Aug 2009 10:43:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20305 invoked by uid 99); 24 Aug 2009 10:43:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 10:43:22 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [192.6.10.60] (HELO tobor.hpl.hp.com) (192.6.10.60)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 10:43:10 +0000
Received: from localhost (localhost [127.0.0.1])
	by tobor.hpl.hp.com (Postfix) with ESMTP id D0758B7CAC
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 11:42:49 +0100 (BST)
X-Virus-Scanned: amavisd-new at hplb.hpl.hp.com
Received: from tobor.hpl.hp.com ([127.0.0.1])
	by localhost (tobor.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id XkKokVEHFtO7 for <common-user@hadoop.apache.org>;
	Mon, 24 Aug 2009 11:42:43 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by tobor.hpl.hp.com (Postfix) with ESMTPS id E32C7B7CA3
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 11:42:42 +0100 (BST)
MailScanner-NULL-Check: 1251715350.1625@xDFfgeG2iHGiUNZKyS0Pcw
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7OAgQPF004338
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 11:42:26 +0100 (BST)
Message-ID: <4A926E92.8080303@apache.org>
Date: Mon, 24 Aug 2009 11:42:26 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: NN memory consumption on 0.20/0.21 with compressed pointers/
References: <4A8D281B.9070006@apache.org> <4A8D8D3D.5070404@yahoo-inc.com>
In-Reply-To: <4A8D8D3D.5070404@yahoo-inc.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7OAgQPF004338
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

Raghu Angadi wrote:
> 
> Suresh had made an spreadsheet for memory consumption.. will check.
> 
> A large portion of NN memory is taken by references. I would expect 
> memory savings to be very substantial (same as going from 64bit to 
> 32bit), could be on the order of 40%.
> 
> The last I heard from Sun was that compressed pointers will be in very 
> near future JVM (certainly JDK 1.6_x). It can use compressed pointers 
> upto 32GB of heap.

It's in JDK 1.6u14. Looking at the source and reading the specs implies 
there is savings, but we need to experiment to see. I now know how to do 
sizeof() in java, (in the instrumentation API), so these experiments are 
possible

> 
> I would expect runtime over head on NN would be minimal in practice.


I think there's a small extra deref cost, but its very minimal; one 8 
bit logical shift left, possibly also an addition. Both of which run at 
CPU-speeds, not main memory bus rates

From common-user-return-17015-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 17:58:33 2009
Return-Path: <common-user-return-17015-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 8423 invoked from network); 24 Aug 2009 17:58:33 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 17:58:33 -0000
Received: (qmail 27014 invoked by uid 500); 24 Aug 2009 10:46:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26945 invoked by uid 500); 24 Aug 2009 10:46:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 26934 invoked by uid 99); 24 Aug 2009 10:46:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 10:46:57 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [192.6.10.2] (HELO colossus.hpl.hp.com) (192.6.10.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 10:46:46 +0000
Received: from localhost (localhost [127.0.0.1])
	by colossus.hpl.hp.com (Postfix) with ESMTP id 5E13A1BA2AC
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 11:46:25 +0100 (BST)
X-Virus-Scanned: Debian amavisd-new at hpl.hp.com
Received: from colossus.hpl.hp.com ([127.0.0.1])
	by localhost (colossus.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id evsmSNs-fbGt for <common-user@hadoop.apache.org>;
	Mon, 24 Aug 2009 11:46:25 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by colossus.hpl.hp.com (Postfix) with ESMTPS id E9DE81BA25F
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 11:46:24 +0100 (BST)
MailScanner-NULL-Check: 1251715572.40701@tElzH+T03KCwD+oEMwmzQA
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7OAkB0A004508
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 11:46:12 +0100 (BST)
Message-ID: <4A926F73.6020605@apache.org>
Date: Mon, 24 Aug 2009 11:46:11 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.22 (X11/20090605)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: NN memory consumption on 0.20/0.21 with compressed pointers/
References: <C6B31AEC.F4A9%scott@richrelevance.com>
In-Reply-To: <C6B31AEC.F4A9%scott@richrelevance.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7OAkB0A004508
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

Scott Carey wrote:

> The implementation in JRE 6u14 uses a shift for all heap sizes, the
> optimization to remove that for heaps less than 4GB is not in the hotspot
> version there (but will be later).

OK. I've been using JRockit 64 bit for a while, and it did a check on 
every pointer to see if it was real or relative, then an add, so I 
suspect its computation was more complex. The sun approach seems better

> The size advantage is there either way.
> 
> I have not tested an app myself that was not faster using
> -XX:+UseCompressedOops on a 64 bit JVM.
> The extra bit shifting is overshadowed by how much faster and less frequent
> GC is with a smaller dataset.

Excellent.

You get better cache efficiency too -less cache misses, and save on 
memory bandwidth

From common-user-return-17031-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 18:04:12 2009
Return-Path: <common-user-return-17031-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11300 invoked from network); 24 Aug 2009 18:04:12 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 18:04:12 -0000
Received: (qmail 69251 invoked by uid 500); 24 Aug 2009 18:04:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 69149 invoked by uid 500); 24 Aug 2009 18:04:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 69137 invoked by uid 99); 24 Aug 2009 18:04:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 18:04:35 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [12.110.209.161] (HELO usausmgw01.spansion.com) (12.110.209.161)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 18:04:27 +0000
X-IronPort-AV: E=McAfee;i="5300,2777,5719"; a="6003746"
Received: from usausexbh2.spansion.com ([10.248.26.116])
  by usausmgw01.spansion.com with ESMTP; 24 Aug 2009 11:04:06 -0700
Received: from USAUSEXMBPF2.spansion.com ([10.248.26.56]) by usausexbh2.spansion.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Mon, 24 Aug 2009 13:04:06 -0500
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
Subject: RE: Can't find TestDFSIO
Date: Mon, 24 Aug 2009 13:04:06 -0500
Message-ID: <AF176AD83CF4724EAAD1AE6F1BAE02043DB3CC@USAUSEXMBPF2.spansion.com>
In-Reply-To: <4A92C70D.2000904@cs.ualberta.ca>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: Can't find TestDFSIO
thread-index: Acok3GjTt01MtldEQQKl7Bq9mkbppQACIv7w
References: <4A92C70D.2000904@cs.ualberta.ca>
From: "Gross, Danny" <Danny.Gross@spansion.com>
To: <common-user@hadoop.apache.org>
X-OriginalArrivalTime: 24 Aug 2009 18:04:06.0856 (UTC) FILETIME=[45AD0C80:01CA24E5]
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Cam,

For what it's worth, in 19.1, I see TestDFSIO in the
hadoop-0.19.1-test.jar.=20

Best regards,

Danny

-----Original Message-----
From: Cam Macdonell [mailto:cam@cs.ualberta.ca]=20
Sent: Monday, August 24, 2009 12:00 PM
To: common-user@hadoop.apache.org
Subject: Can't find TestDFSIO


Hi,

I'm trying to run the TestDFSIO benchmark that is mentioned in the=20
hadoop o'reilly book.  However, I can't find it in any of the jars=20
(common, mapred or hdfs).

For example, I presume it would be under hdfs, but the only mentioned=20
test is 'dfsthroughput'.

$ ./bin/hadoop jar=20
/home/cam/research/SVN/hadoop/lib/hadoop-hdfs-test-0.21.0-dev.jar
An example program must be given as the first argument.
Valid program names are:
   dfsthroughput: measure hdfs throughput

Has the name of TestDFSIO changed or am I looking in the wrong place?

Any tips or pointers are appreciated,
Cam

From common-user-return-17032-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 19:22:26 2009
Return-Path: <common-user-return-17032-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 42128 invoked from network); 24 Aug 2009 19:22:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 19:22:26 -0000
Received: (qmail 84305 invoked by uid 500); 24 Aug 2009 19:22:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 84236 invoked by uid 500); 24 Aug 2009 19:22:49 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 84226 invoked by uid 99); 24 Aug 2009 19:22:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 19:22:48 +0000
X-ASF-Spam-Status: No, hits=-4.0 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [129.128.22.22] (HELO fleet.cs.ualberta.ca) (129.128.22.22)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 19:22:38 +0000
Received: from fleet.cs.ualberta.ca (localhost.localdomain [127.0.0.1])
	by fleet-spampd (Postfix) with ESMTP id 341A728004
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 13:22:09 -0600 (MDT)
X-Spam-Checker-Version: SpamAssassin 3.2.4 (2008-01-01) on fleet.cs.ualberta.ca
X-Spam-Level: 
Received: from localhost (localhost.localdomain [127.0.0.1])
	by fleet-amavis (Postfix) with ESMTP id 2770C28014
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 13:22:09 -0600 (MDT)
X-Virus-Scanned: amavisd-new at cs.ualberta.ca
Received: from fleet.cs.ualberta.ca ([127.0.0.1])
	by localhost (cs.ualberta.ca [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id M8ddQ630CctY for <common-user@hadoop.apache.org>;
	Mon, 24 Aug 2009 13:22:09 -0600 (MDT)
Received: from [129.128.23.21] (st-brides.cs.ualberta.ca [129.128.23.21])
	by fleet.cs.ualberta.ca (Postfix) with ESMTP id 0E2A528004
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 13:22:09 -0600 (MDT)
Message-ID: <4A92E860.90208@cs.ualberta.ca>
Date: Mon, 24 Aug 2009 13:22:08 -0600
From: Cam Macdonell <cam@cs.ualberta.ca>
User-Agent: Thunderbird 2.0.0.23 (X11/20090812)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Can't find TestDFSIO
References: <4A92C70D.2000904@cs.ualberta.ca> <AF176AD83CF4724EAAD1AE6F1BAE02043DB3CC@USAUSEXMBPF2.spansion.com>
In-Reply-To: <AF176AD83CF4724EAAD1AE6F1BAE02043DB3CC@USAUSEXMBPF2.spansion.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org
X-Old-Spam-Status: No, score=-102.6 required=10.0 tests=AWL,BAYES_00,
	USER_IN_WHITELIST autolearn=disabled version=3.2.4


Thanks Danny,

It currently does not show up hadoop-common-test, hadoop-hdfs-test or 
hadoop-mapred-test with 0.21-dev.  So either it has been a victim of the 
project split or I didn't specify the right target for Ant.

Cam

Gross, Danny wrote:
> Hi Cam,
> 
> For what it's worth, in 19.1, I see TestDFSIO in the
> hadoop-0.19.1-test.jar. 
> 
> Best regards,
> 
> Danny
> 
> -----Original Message-----
> From: Cam Macdonell [mailto:cam@cs.ualberta.ca] 
> Sent: Monday, August 24, 2009 12:00 PM
> To: common-user@hadoop.apache.org
> Subject: Can't find TestDFSIO
> 
> 
> Hi,
> 
> I'm trying to run the TestDFSIO benchmark that is mentioned in the 
> hadoop o'reilly book.  However, I can't find it in any of the jars 
> (common, mapred or hdfs).
> 
> For example, I presume it would be under hdfs, but the only mentioned 
> test is 'dfsthroughput'.
> 
> $ ./bin/hadoop jar 
> /home/cam/research/SVN/hadoop/lib/hadoop-hdfs-test-0.21.0-dev.jar
> An example program must be given as the first argument.
> Valid program names are:
>    dfsthroughput: measure hdfs throughput
> 
> Has the name of TestDFSIO changed or am I looking in the wrong place?
> 
> Any tips or pointers are appreciated,
> Cam

From common-user-return-17033-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 19:41:18 2009
Return-Path: <common-user-return-17033-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 48349 invoked from network); 24 Aug 2009 19:41:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 19:41:18 -0000
Received: (qmail 7344 invoked by uid 500); 24 Aug 2009 19:41:41 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 7277 invoked by uid 500); 24 Aug 2009 19:41:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 7267 invoked by uid 99); 24 Aug 2009 19:41:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 19:41:40 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.78.27] (HELO ey-out-2122.google.com) (74.125.78.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 19:41:31 +0000
Received: by ey-out-2122.google.com with SMTP id 22so636921eye.35
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 12:41:10 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.216.72.85 with SMTP id s63mr1102622wed.0.1251142870524; Mon, 
	24 Aug 2009 12:41:10 -0700 (PDT)
In-Reply-To: <4A92E860.90208@cs.ualberta.ca>
References: <4A92C70D.2000904@cs.ualberta.ca>
	 <AF176AD83CF4724EAAD1AE6F1BAE02043DB3CC@USAUSEXMBPF2.spansion.com>
	 <4A92E860.90208@cs.ualberta.ca>
Date: Mon, 24 Aug 2009 20:41:10 +0100
Message-ID: <ac79ea400908241241re74893ctc1d9d4568acbe50f@mail.gmail.com>
Subject: Re: Can't find TestDFSIO
From: Tom White <tom@cloudera.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Cam,

Looks like it's in hadoop-hdfs-hdfswithmr-test-0.21.0-dev.jar, which
should be built with "ant jar-test".

Cheers,
Tom

On Mon, Aug 24, 2009 at 8:22 PM, Cam Macdonell<cam@cs.ualberta.ca> wrote:
>
> Thanks Danny,
>
> It currently does not show up hadoop-common-test, hadoop-hdfs-test or
> hadoop-mapred-test with 0.21-dev. =A0So either it has been a victim of th=
e
> project split or I didn't specify the right target for Ant.
>
> Cam
>
> Gross, Danny wrote:
>>
>> Hi Cam,
>>
>> For what it's worth, in 19.1, I see TestDFSIO in the
>> hadoop-0.19.1-test.jar.
>> Best regards,
>>
>> Danny
>>
>> -----Original Message-----
>> From: Cam Macdonell [mailto:cam@cs.ualberta.ca] Sent: Monday, August 24,
>> 2009 12:00 PM
>> To: common-user@hadoop.apache.org
>> Subject: Can't find TestDFSIO
>>
>>
>> Hi,
>>
>> I'm trying to run the TestDFSIO benchmark that is mentioned in the hadoo=
p
>> o'reilly book. =A0However, I can't find it in any of the jars (common, m=
apred
>> or hdfs).
>>
>> For example, I presume it would be under hdfs, but the only mentioned te=
st
>> is 'dfsthroughput'.
>>
>> $ ./bin/hadoop jar
>> /home/cam/research/SVN/hadoop/lib/hadoop-hdfs-test-0.21.0-dev.jar
>> An example program must be given as the first argument.
>> Valid program names are:
>> =A0 dfsthroughput: measure hdfs throughput
>>
>> Has the name of TestDFSIO changed or am I looking in the wrong place?
>>
>> Any tips or pointers are appreciated,
>> Cam
>

From common-user-return-17034-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 21:10:34 2009
Return-Path: <common-user-return-17034-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 4742 invoked from network); 24 Aug 2009 21:10:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 21:10:34 -0000
Received: (qmail 10863 invoked by uid 500); 24 Aug 2009 21:10:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10786 invoked by uid 500); 24 Aug 2009 21:10:57 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10776 invoked by uid 99); 24 Aug 2009 21:10:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 21:10:57 +0000
X-ASF-Spam-Status: No, hits=-1.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zshao@facebook.com designates 69.63.179.25 as permitted sender)
Received: from [69.63.179.25] (HELO mailout-sf2p.facebook.com) (69.63.179.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 21:10:47 +0000
Received: from mail.thefacebook.com (intlb01.snat.snc1.facebook.com [10.128.203.15] (may be forged))
	by pp02.snc1.tfbnw.net (8.14.1/8.14.1) with ESMTP id n7OLAAgN015049
	(version=TLSv1/SSLv3 cipher=RC4-MD5 bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 14:10:10 -0700
Received: from SC-MBXC1.TheFacebook.com ([192.168.18.100]) by
 sc-hub01.TheFacebook.com ([192.168.18.104]) with mapi; Mon, 24 Aug 2009
 14:10:22 -0700
From: Zheng Shao <zshao@facebook.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
CC: Venky Iyer <venky@facebook.com>
Date: Mon, 24 Aug 2009 14:10:14 -0700
Subject: tmpfiles and tmpjars do not get unarchived
Thread-Topic: tmpfiles and tmpjars do not get unarchived
Thread-Index: Acok/teiYUIWFtg3QaaK9ggZGPQvIgAAGGUw
Message-ID: <CD2E0A273BDAAD409C70BB3F48EE6A126CBE28511C@SC-MBXC1.TheFacebook.com>
References: <13B3902155CF2C46ACE1A187C1D5980401CC91D8@SC-MBXC1.TheFacebook.com>
In-Reply-To: <13B3902155CF2C46ACE1A187C1D5980401CC91D8@SC-MBXC1.TheFacebook.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-cr-puzzleid: {FD019EA3-5DE4-494F-B5F6-39129BF3F44A}
x-cr-hashedpuzzle: gKY= AoNB CRHh CeH3 ChCr C11c DezO Dfyi G0+v HLjy HSE9
 I7Lz I81t JXVs JlCM
 KII9;1;YwBvAG0AbQBvAG4ALQB1AHMAZQByAEAAaABhAGQAbwBvAHAALgBhAHAAYQBjAGgAZQAuAG8AcgBnAA==;Sosha1_v1;7;{FD019EA3-5DE4-494F-B5F6-39129BF3F44A};egBzAGgAYQBvAEAAZgBhAGMAZQBiAG8AbwBrAC4AYwBvAG0A;Mon,
 24 Aug 2009 21:10:14
 GMT;dABtAHAAZgBpAGwAZQBzACAAYQBuAGQAIAB0AG0AcABqAGEAcgBzACAAZABvACAAbgBvAHQAIABnAGUAdAAgAHUAbgBhAHIAYwBoAGkAdgBlAGQA
acceptlanguage: en-US
Content-Type: multipart/alternative;
	boundary="_000_CD2E0A273BDAAD409C70BB3F48EE6A126CBE28511CSCMBXC1TheFac_"
MIME-Version: 1.0
X-Proofpoint-Virus-Version: vendor=fsecure engine=1.12.8161:2.4.5,1.2.40,4.0.166 definitions=2009-08-24_10:2009-08-11,2009-08-24,2009-08-24 signatures=0
X-Proofpoint-Spam-Details: rule=notspam policy=default score=0 spamscore=0 ipscore=0 phishscore=0 bulkscore=0 adultscore=0 classifier=spam adjust=0 reason=mlx engine=5.0.0-0907200000 definitions=main-0908240158
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_CD2E0A273BDAAD409C70BB3F48EE6A126CBE28511CSCMBXC1TheFac_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

We noticed that files uploaded using "tmpfiles" and "tmpjars" are not unarc=
hived somehow.
We are using hadoop 0.17.2.1.

Is there any way to automatically unarchive "tmpfiles" and "tmpjars"?


Zheng


--_000_CD2E0A273BDAAD409C70BB3F48EE6A126CBE28511CSCMBXC1TheFac_--

From common-user-return-17035-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 21:35:01 2009
Return-Path: <common-user-return-17035-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 19088 invoked from network); 24 Aug 2009 21:35:01 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 21:35:01 -0000
Received: (qmail 41466 invoked by uid 500); 24 Aug 2009 21:35:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 41380 invoked by uid 500); 24 Aug 2009 21:35:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 41367 invoked by uid 99); 24 Aug 2009 21:35:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 21:35:24 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 21:35:15 +0000
Received: by gxk27 with SMTP id 27so3207419gxk.12
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 14:34:53 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.91.161.34 with SMTP id n34mr4361268ago.78.1251149692125; Mon, 
	24 Aug 2009 14:34:52 -0700 (PDT)
In-Reply-To: <CD2E0A273BDAAD409C70BB3F48EE6A126CBE28511C@SC-MBXC1.TheFacebook.com>
References: <13B3902155CF2C46ACE1A187C1D5980401CC91D8@SC-MBXC1.TheFacebook.com> 
	<CD2E0A273BDAAD409C70BB3F48EE6A126CBE28511C@SC-MBXC1.TheFacebook.com>
From: Todd Lipcon <todd@cloudera.com>
Date: Mon, 24 Aug 2009 14:34:32 -0700
Message-ID: <45f85f70908241434m300b5730g7737638f50e33a52@mail.gmail.com>
Subject: Re: tmpfiles and tmpjars do not get unarchived
To: common-user@hadoop.apache.org
Cc: Venky Iyer <venky@facebook.com>
Content-Type: multipart/alternative; boundary=001485f54660f5c1280471e9fcad
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f54660f5c1280471e9fcad
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Zheng,
The DistributedCache.addArchiveToClasspath call is the one that makes it get
unarchived into the temp directory. By contrast, addFileToClasspath doesn't.
I don't remember the old-style command line flag to trigger this call...
perhaps -archives or something?

Worth noting that -libjars was recently changed from addArchiveToClasspath
to addFileToClasspath

Thanks
-Todd



On Mon, Aug 24, 2009 at 2:10 PM, Zheng Shao <zshao@facebook.com> wrote:

> We noticed that files uploaded using "tmpfiles" and "tmpjars" are not
> unarchived somehow.
> We are using hadoop 0.17.2.1.
>
> Is there any way to automatically unarchive "tmpfiles" and "tmpjars"?
>
>
> Zheng
>
>

--001485f54660f5c1280471e9fcad--

From common-user-return-17036-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 24 22:18:03 2009
Return-Path: <common-user-return-17036-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 38125 invoked from network); 24 Aug 2009 22:18:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 24 Aug 2009 22:18:03 -0000
Received: (qmail 82543 invoked by uid 500); 24 Aug 2009 22:18:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82340 invoked by uid 500); 24 Aug 2009 22:18:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82256 invoked by uid 99); 24 Aug 2009 22:18:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 22:18:20 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [85.214.115.60] (HELO h1349259.stratoserver.net) (85.214.115.60)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 24 Aug 2009 22:18:10 +0000
Received: from e178061152.adsl.alicedsl.de ([85.178.61.152] helo=motokokusanagi)
	by h1349259.stratoserver.net with esmtpsa (TLS1.0:DHE_RSA_AES_256_CBC_SHA1:32)
	(Exim 4.69)
	(envelope-from <isabel@apache.org>)
	id 1MfhrE-0000vZ-IK; Mon, 24 Aug 2009 22:17:44 +0000
From: Isabel Drost <isabel@apache.org>
Reply-To: isabel@apache.org
To: hadoopberlin@isabel-drost.de
Subject: September Hadoop Get Together
Date: Tue, 25 Aug 2009 00:17:11 +0200
User-Agent: KMail/1.9.9
Cc: mahout-user@lucene.apache.org,
 common-user@hadoop.apache.org,
 hbase-user@hadoop.apache.org,
 katta-developer@lists.sourceforge.net,
 solr-user@lucene.apache.org,
 pig-user@hadoop.apache.org,
 nutch-user@lucene.apache.org
MIME-Version: 1.0
Content-Type: multipart/signed;
  boundary="nextPart2901708.VJtaoK9lat";
  protocol="application/pgp-signature";
  micalg=pgp-sha1
Content-Transfer-Encoding: 7bit
Message-Id: <200908250017.16973.isabel@apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

--nextPart2901708.VJtaoK9lat
Content-Type: text/plain;
  charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

I would like to announce the September-2009 Hadoop Get Together in newthink=
ing=20
store Berlin.



       When: 29. September 2009 at 5:00pm
       Where: newthinking store, Tucholskystr. 48, Berlin, Germany



As always there will be slots of 20min each for talks on your Hadoop topic.=
=20
After each talk there will be a lot time to discuss. You can order drinks=20
directly at the bar in the newthinking store. If you like, you can order=20
pizza. There are quite a few good restaurants nearby, so we can go there=20
after the official part.

Talks scheduled so far:

Thorsten Schuett, Solving Puzzles with MapReduce: MapReduce is most often u=
sed=20
for data mining and filtering large datasets. In this talk we will show tha=
t=20
it also useful for a completely different problem domain: solving puzzles.=
=20
Based on MapReduce, we can implement massively parallel breadth-first and=20
heuristic search. MapReduce will take care of the hard problems, like=20
parallelization, disk and error handling, while we can concentrate on the=20
puzzle. Throughout the talk we will use the sliding puzzle=20
(http://en.wikipedia.org/wiki/Sliding_puzzle) as our example.

Thilo G=F6tz, Text analytics on jaql: Jaql (JSON query language) is a query=
=20
language for Javascript Object Notation that runs on top of Apache Hadoop. =
It=20
was primarily designed for large scale analysis of semi-structured data. I=
=20
will give an introduction to jaql and describe our experiences using it for=
=20
text analytics tasks. Jaql is open source and available from
 http://code.google.com/p/jaql.

Uwe Schindler, Lucene 2.9 Developments: Numeric Search, Per-Segment- and
Near-Real-Time Search, new TokenStream API: Uwe Schindler presents some new=
=20
additions to Lucene 2.9. In the first half he will talk about fast numerica=
l=20
and date range queries (NumericRangeQuery, formerly TrieRangeQuery) and the=
ir=20
usage in geospatial search applications like the Publishing Network for=20
Geoscientific & Environmental Data (PANGAEA). In the second half of his tal=
k,=20
Uwe will highlight various improvements to the internal search implementati=
on=20
for near-real-time search. Finally, he will present the new TokenStream API=
,=20
based on AttributeSource/Attributes that make indexing more pluggable. Futu=
re
developments in the Flexible Indexing Area will make use of it. Uwe will
show a Tokenizer that uses custom attributes to index XML files into various
document fields based on XML element names as a possible use-case.

We would like to invite you, the visitor to also tell your Hadoop story, if=
=20
you like, you can bring slides - there will be a beamer.

A big Thanks goes to the newthinking store for providing a room in the cent=
er=20
of Berlin for us.

=46or further information and updates, please refer to:=20
http://upcoming.yahoo.com/event/4314020/


Hope to see you soon in Berlin,
Isabel

=2D-=20
QOTD: "Gort, klaatu nikto barada."   -- The Day the Earth Stood Still=20
  |\      _,,,---,,_       Web:   <http://www.isabel-drost.de>
  /,`.-'`'    -.  ;-;;,_ =20
 |,4-  ) )-,_..;\ (  `'-'=20
'---''(_/--'  `-'\_) (fL)  IM:  <xmpp://MaineC.@spaceboyz.net>


--nextPart2901708.VJtaoK9lat
Content-Type: application/pgp-signature; name=signature.asc 
Content-Description: This is a digitally signed message part.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (GNU/Linux)

iEYEABECAAYFAkqTEWgACgkQPJpCBAwIhbRpAACfVvWKWyVf8Uuowah2gmcX7LT7
IQ0An2fuvmibwvNlLED8vNodV2DyzMXW
=1DJp
-----END PGP SIGNATURE-----

--nextPart2901708.VJtaoK9lat--

From common-user-return-17037-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 00:42:40 2009
Return-Path: <common-user-return-17037-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 82845 invoked from network); 25 Aug 2009 00:42:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 00:42:40 -0000
Received: (qmail 88383 invoked by uid 500); 25 Aug 2009 00:43:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 88288 invoked by uid 500); 25 Aug 2009 00:43:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 88276 invoked by uid 99); 25 Aug 2009 00:43:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:43:02 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.221.178] (HELO mail-qy0-f178.google.com) (209.85.221.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:42:53 +0000
Received: by qyk8 with SMTP id 8so391685qyk.2
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 17:42:32 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.16.71 with SMTP id n7mr3464722qaa.162.1251160952157; Mon, 
	24 Aug 2009 17:42:32 -0700 (PDT)
In-Reply-To: <fe35e3c40908211047t569046e1q7c3cdb4ef21d6a2a@mail.gmail.com>
References: <fe35e3c40908201652m543cc48crc2e12820dd463388@mail.gmail.com> 
	<fe35e3c40908211047t569046e1q7c3cdb4ef21d6a2a@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Mon, 24 Aug 2009 17:42:12 -0700
Message-ID: <d6d7c4410908241742r44c84aa8wc52afdff7a970ec0@mail.gmail.com>
Subject: Re: Writing to a db with DBOutputFormat spits out IOException Error
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016360f32471c3bc20471ec9cc3
X-Virus-Checked: Checked by ClamAV on apache.org

--0016360f32471c3bc20471ec9cc3
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

As a more general note -- any jars needed by your mappers and reducers
either need to be in your job jar in the lib/ directory of the .jar file, or
in $HADOOP_HOME/lib/ on all tasktracker nodes where mappers and reducers get
run.

- Aaron


On Fri, Aug 21, 2009 at 10:47 AM, ishwar ramani <rvmishwar@gmail.com> wrote:

> For future reference.
>
> This is a class not found exception for the mysql driver.  The
> DBOuputFormat converts
> it into an IO exception grrrrr.
>
> I had the mysql-connector in both $HADOOP/lib and $HADOOP_CLASSPATH.
> That did not help.
>
> I had to pkg the mysql jar into my map reduce jar to fix this problem.
>
> Hope that saves a day for some one!
>
> On Thu, Aug 20, 2009 at 4:52 PM, ishwar ramani<rvmishwar@gmail.com> wrote:
> > Hi,
> >
> > I am trying to run a simple map reduce that writes the result from the
> > reducer to a mysql db.
> >
> > I Keep getting
> >
> > 09/08/20 15:44:59 INFO mapred.JobClient: Task Id :
> > attempt_200908201210_0013_r_000000_0, Status : FAILED
> > java.io.IOException: com.mysql.jdbc.Driver
> >        at
> org.apache.hadoop.mapred.lib.db.DBOutputFormat.getRecordWriter(DBOutputFormat.java:162)
> >        at
> org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:435)
> >        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:413)
> >        at org.apache.hadoop.mapred.Child.main(Child.java:170)
> >
> > when the reducer is run.
> >
> > Here is my code. The user name and password are valid and works fine.
> > Is there any way get more info on this exception?
> >
> >
> >
> > static class MyWritable implements Writable, DBWritable {
> >  long id;
> >  String description;
> >
> >  MyWritable(long mid, String mdescription) {
> >    id = mid;
> >    description = mdescription;
> >  }
> >
> >  public void readFields(DataInput in) throws IOException {
> >    this.id = in.readLong();
> >    this.description = Text.readString(in);
> >  }
> >
> >  public void readFields(ResultSet resultSet)
> >      throws SQLException {
> >    this.id = resultSet.getLong(1);
> >    this.description = resultSet.getString(2);
> >  }
> >
> >  public void write(DataOutput out) throws IOException {
> >    out.writeLong(this.id);
> >    Text.writeString(out, this.description);
> >  }
> >
> >  public void write(PreparedStatement stmt) throws SQLException {
> >    stmt.setLong(1, this.id);
> >    stmt.setString(2, this.description);
> >  }
> > }
> >
> >
> >
> >
> >
> >
> > public static class Reduce extends MapReduceBase implements
> > Reducer<Text, IntWritable, MyWritable, IntWritable> {
> >  public void reduce(Text key, Iterator<IntWritable> values,
> > OutputCollector<MyWritable, IntWritable> output, Reporter reporter)
> > throws IOException {
> >    int sum = 0;
> >    while (values.hasNext()) {
> >      sum += values.next().get();
> >    }
> >
> >    output.collect(new MyWritable(sum, key.toString()), new
> IntWritable(sum));
> >  }
> > }
> >
> >
> >
> >
> >
> > public static void main(String[] args) throws Exception {
> >  JobConf conf = new JobConf(WordCount.class);
> >  conf.setJobName("wordcount");
> >
> >  conf.setMapperClass(Map.class);
> >
> >  conf.setReducerClass(Reduce.class);
> >
> >  DBConfiguration.configureDB(conf, "com.mysql.jdbc.Driver",
> > "jdbc:mysql://localhost:8100/testvmysqlsb", "dummy", "pass");
> >
> >
> >  String fields[] = {"id", "description"};
> >  DBOutputFormat.setOutput(conf, "funtable", fields);
> >
> >
> >
> >  conf.setNumMapTasks(1);
> >  conf.setNumReduceTasks(1);
> >
> >  conf.setMapOutputKeyClass(Text.class);
> >  conf.setMapOutputValueClass(IntWritable.class);
> >
> >
> >  conf.setOutputKeyClass(MyWritable.class);
> >  conf.setOutputValueClass(IntWritable.class);
> >
> >  conf.setInputFormat(TextInputFormat.class);
> >
> >
> >
> >
> >  FileInputFormat.setInputPaths(conf, new Path(args[0]));
> >
> >
> >  JobClient.runJob(conf);
> > }
> >
>

--0016360f32471c3bc20471ec9cc3--

From common-user-return-17038-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 00:44:19 2009
Return-Path: <common-user-return-17038-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 83193 invoked from network); 25 Aug 2009 00:44:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 00:44:19 -0000
Received: (qmail 90531 invoked by uid 500); 25 Aug 2009 00:44:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 90442 invoked by uid 500); 25 Aug 2009 00:44:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 90432 invoked by uid 99); 25 Aug 2009 00:44:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:44:42 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.92.26] (HELO qw-out-2122.google.com) (74.125.92.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:44:33 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1500299qwh.35
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 17:44:12 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.90.73 with SMTP id h9mr3460857qam.93.1251161052077; Mon, 
	24 Aug 2009 17:44:12 -0700 (PDT)
In-Reply-To: <6c1002100908230509t138131eas39749ef14aadfa50@mail.gmail.com>
References: <6c1002100908230509t138131eas39749ef14aadfa50@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Mon, 24 Aug 2009 17:43:52 -0700
Message-ID: <d6d7c4410908241743o78985e9atd9641f39f9e35a4e@mail.gmail.com>
Subject: Re: Hadoop streaming: How is data distributed from mappers to 
	reducers?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00c09f89952210e42f0471eca24b
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09f89952210e42f0471eca24b
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Yes. It works just like Java-based MapReduce in that regard.
- Aaron

On Sun, Aug 23, 2009 at 5:09 AM, Nipun Saggar <nipun.saggar@gmail.com>wrote:

> Hi all,
>
> I have recently started using Hadoop streaming. From the documentation, I
> understand that by default, each line output from a mapper up to the first
> tab becomes the key and rest of the line is the value. I wanted to know
> that
> between the mapper and reducer, is there a shuffling(sorting) phase? More
> specifically, Would it be correct to assume that output from all mappers
> with the same key will go to the same reducer?
>
> Thanks,
> Nipun
>

--00c09f89952210e42f0471eca24b--

From common-user-return-17039-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 00:47:45 2009
Return-Path: <common-user-return-17039-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 83903 invoked from network); 25 Aug 2009 00:47:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 00:47:45 -0000
Received: (qmail 95532 invoked by uid 500); 25 Aug 2009 00:48:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95458 invoked by uid 500); 25 Aug 2009 00:48:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95448 invoked by uid 500); 25 Aug 2009 00:48:08 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 95445 invoked by uid 99); 25 Aug 2009 00:48:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:48:08 +0000
X-ASF-Spam-Status: No, hits=3.7 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zjffdu@gmail.com designates 209.85.222.200 as permitted sender)
Received: from [209.85.222.200] (HELO mail-pz0-f200.google.com) (209.85.222.200)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:47:57 +0000
Received: by pzk38 with SMTP id 38so1204930pzk.5
        for <core-user@hadoop.apache.org>; Mon, 24 Aug 2009 17:47:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=i61cBgckqkBbxeRsxkrw45IAX7Qmfnk5ZzEkMcTmcl4=;
        b=d10cbDJPOzshfzFbkuflL2LwSU21bPehRWVd/Xp84KiV7R0q3XdFeZ6s7MkViSgZ2J
         uWwohmQB9R/1jHaF0VA29dVsbBKI59hzn7fRcnppjtgC4WNsi9TP1JI4vEjxGkTCo8IB
         JetTCXM6BWzgVsbmfu+1UPUYHtFy0A13AOMTQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=P9mfrqHcRr//75RBaXrEIQbBHuPUepFf/eGB9J4s+ge3WPKvBXjrmGZqoUjl5WexhK
         wbWgO1fa+gLeJYzlSa4Ot5Sty+smnevQ2YQbLn85HpGTq5ZYpo06/+65W8MNJx34WoR4
         9v0LegRq28J6zRBjJoWqEkpuTJbdn0mQVCiOE=
MIME-Version: 1.0
Received: by 10.142.7.6 with SMTP id 6mr341871wfg.114.1251161254402; Mon, 24 
	Aug 2009 17:47:34 -0700 (PDT)
Date: Mon, 24 Aug 2009 17:47:34 -0700
Message-ID: <8211a1320908241747u1516e169gddb1641231d8f1b9@mail.gmail.com>
Subject: localhost:9000 and ip:9000 is not the same ?
From: zhang jianfeng <zjffdu@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636b2ac41201ae60471ecaed0
X-Virus-Checked: Checked by ClamAV on apache.org

--001636b2ac41201ae60471ecaed0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi all,



I have two computers, and in the hadoop-site.xml, I define the
fs.default.name as localhost:9000, then I cannot access the cluster with
Java API from another machine

But if I change it to its real IP  192.168.1.103:9000, then I can access th=
e
cluster with Java API from another machine.

It=E2=80=99s so strange, are they any different ?



Thank you.

Jeff zhang

--001636b2ac41201ae60471ecaed0--

From common-user-return-17040-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 00:49:10 2009
Return-Path: <common-user-return-17040-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 84404 invoked from network); 25 Aug 2009 00:49:10 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 00:49:10 -0000
Received: (qmail 98008 invoked by uid 500); 25 Aug 2009 00:49:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 97927 invoked by uid 500); 25 Aug 2009 00:49:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 97917 invoked by uid 500); 25 Aug 2009 00:49:32 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 97914 invoked by uid 99); 25 Aug 2009 00:49:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:49:32 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zjffdu@gmail.com designates 209.85.222.200 as permitted sender)
Received: from [209.85.222.200] (HELO mail-pz0-f200.google.com) (209.85.222.200)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:49:24 +0000
Received: by pzk38 with SMTP id 38so1205376pzk.5
        for <core-user@hadoop.apache.org>; Mon, 24 Aug 2009 17:49:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=O1jEwKj5BuPC+hlGpVE4FgY/VcrpH59M1k6L6poEupk=;
        b=MM7S1oi0xXJylw1Q91ouSVQHZd82XDFoEZ0oee0S5vMZ3Q12/WHi31j4od0Mf1naJG
         X8zo+HHVH7HXE94gxL8eseSeY4iEZcVUCRuiYpIWC5Hafbr3+THq8U4KljATK6N9bdjt
         BSuKk9ZhMc3qOJe4pMX+qeRjqverUvycOG9M4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=CoSHEw2lpSl/JRYRbOg1Fnmp0zi9pqzyNkyPI/tYfYj6DdssXG6ktSaRjSnAcpqNei
         ZneP217DblD3yhUEo7Ri5lfyOdYGxmZPX/CLcjPO/cqva640ISqLeDgvSFj+zyAjug/v
         szzp80wPVctH71mTLoPH8XKF9fI5etIpmMR68=
MIME-Version: 1.0
Received: by 10.143.138.5 with SMTP id q5mr399780wfn.135.1251161344706; Mon, 
	24 Aug 2009 17:49:04 -0700 (PDT)
Date: Mon, 24 Aug 2009 17:49:04 -0700
Message-ID: <8211a1320908241749x71f4d762j3256e6a0be0e22f3@mail.gmail.com>
Subject: Does hadoop delete the intermediate data
From: zhang jianfeng <zjffdu@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd51d62820ac90471ecb3d2
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd51d62820ac90471ecb3d2
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi all,

I found my cluster=E2=80=99s space usage increase over time although I did =
not
upload new data.  And there's a lot of files under folder /tmp .

So I guess hadoop won=E2=80=99t delete the intermediate data(output of mapp=
er).

Am I right ?


Thank you.

Jeff zhang

--000e0cd51d62820ac90471ecb3d2--

From common-user-return-17041-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 00:50:25 2009
Return-Path: <common-user-return-17041-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 84840 invoked from network); 25 Aug 2009 00:50:25 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 00:50:25 -0000
Received: (qmail 2097 invoked by uid 500); 25 Aug 2009 00:50:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 2028 invoked by uid 500); 25 Aug 2009 00:50:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 2018 invoked by uid 99); 25 Aug 2009 00:50:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:50:47 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:50:39 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1501705qwh.35
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 17:50:18 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.65.40 with SMTP id g40mr3402910qai.333.1251161418106; Mon, 
	24 Aug 2009 17:50:18 -0700 (PDT)
In-Reply-To: <616DA47B2EF5B944B91846785B512FF4CFADEA70F9@EGL-EX07VS01.ds.corp.yahoo.com>
References: <3b1311780908232349s56df94b9k321a48255adcdd85@mail.gmail.com> 
	<616DA47B2EF5B944B91846785B512FF4CFADEA70F9@EGL-EX07VS01.ds.corp.yahoo.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Mon, 24 Aug 2009 17:49:58 -0700
Message-ID: <d6d7c4410908241749j6fa32ec1pb46e66eae1d14f28@mail.gmail.com>
Subject: Re: How to speed up the copy phrase?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00c09f92321fe20b260471ecb740
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09f92321fe20b260471ecb740
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

If you've got 20 nodes, then you want to have 20-ish reduce tasks. Maybe 40
if you want it to run in two waves. (Assuming 1 core/node. Multiply by N for
N cores...) As it is, each node has 500-ish map tasks that it has to read
from and for each of these, it needs to generate 500 separate reduce task
output files.  That's going to take Hadoop a long time to do. 10000 map
tasks is also a very large number of map tasks. Are you processing a lot of
little files? If so, try using MultiFileInputFormat or MultipleInputs to
group them together.

As is mentioned, also set mapred.reduce.parallel.copies to 20. (The default
of 5 is appropriate only for 1--5 nodes.)

- Aaron

On Mon, Aug 24, 2009 at 12:31 AM, Amogh Vasekar <amogh@yahoo-inc.com> wrote:

> Maybe look at mapred.reduce.parallel.copies property to speed it up...I
> don't see as to why transfer speed be configured via params, and I'm think
> hadoop wont be messing with that.
>
> Thanks,
> Amogh
>
> -----Original Message-----
> From: yang song [mailto:hadoop.inifok@gmail.com]
> Sent: Monday, August 24, 2009 12:20 PM
> To: common-user@hadoop.apache.org
> Subject: How to speed up the copy phrase?
>
> Hello, everyone
>
> When I submit a big job(e.g. maptasks:10000, reducetasks:500), I find that
> the copy phrase will last for a long long time. From WebUI, the message
> "reduce > copy (xxxx of 10000 at 0.01 MB/s) >" tells me the transfer speed
> is just 0.01 MB/s. Does it a regular value? How can I solve it?
>
> Thank you!
>
> P.S. The hadoop version is 0.19.1. The cluster has 20 nodes. Heap size of
> JT
> is 6G while the     others are default settings.
>

--00c09f92321fe20b260471ecb740--

From common-user-return-17043-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 00:53:20 2009
Return-Path: <common-user-return-17043-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 85356 invoked from network); 25 Aug 2009 00:53:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 00:53:20 -0000
Received: (qmail 4410 invoked by uid 500); 25 Aug 2009 00:53:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 4283 invoked by uid 500); 25 Aug 2009 00:53:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 4259 invoked by uid 99); 25 Aug 2009 00:53:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:53:40 +0000
X-ASF-Spam-Status: No, hits=4.9 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_NEUTRAL,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.92.27] (HELO qw-out-2122.google.com) (74.125.92.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:53:30 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1502336qwh.35
        for <multiple recipients>; Mon, 24 Aug 2009 17:53:09 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.93.130 with SMTP id v2mr3417882qam.119.1251161588141; Mon, 
	24 Aug 2009 17:53:08 -0700 (PDT)
In-Reply-To: <8211a1320908241747u1516e169gddb1641231d8f1b9@mail.gmail.com>
References: <8211a1320908241747u1516e169gddb1641231d8f1b9@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Mon, 24 Aug 2009 17:52:48 -0700
Message-ID: <d6d7c4410908241752m798970c6n852261f8d76d4102@mail.gmail.com>
Subject: Re: localhost:9000 and ip:9000 is not the same ?
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000feaf14861048fd00471ecc2b2
X-Virus-Checked: Checked by ClamAV on apache.org

--000feaf14861048fd00471ecc2b2
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Jeff,

Hadoop (HDFS in particular) is overly strict about machine names. The
filesystem's id is based on the DNS name used to access it. This needs to b=
e
consistent across all nodes and all configurations in your cluster. You
should always use the fully-qualified domain name of the namenode in your
configuration.

- Aaron

On Mon, Aug 24, 2009 at 5:47 PM, zhang jianfeng <zjffdu@gmail.com> wrote:

> Hi all,
>
>
>
> I have two computers, and in the hadoop-site.xml, I define the
> fs.default.name as localhost:9000, then I cannot access the cluster with
> Java API from another machine
>
> But if I change it to its real IP  192.168.1.103:9000, then I can access
> the
> cluster with Java API from another machine.
>
> It=92s so strange, are they any different ?
>
>
>
> Thank you.
>
> Jeff zhang
>

--000feaf14861048fd00471ecc2b2--

From common-user-return-17042-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 00:53:20 2009
Return-Path: <common-user-return-17042-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 85325 invoked from network); 25 Aug 2009 00:53:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 00:53:20 -0000
Received: (qmail 4404 invoked by uid 500); 25 Aug 2009 00:53:40 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 4281 invoked by uid 500); 25 Aug 2009 00:53:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 4264 invoked by uid 500); 25 Aug 2009 00:53:40 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 4259 invoked by uid 99); 25 Aug 2009 00:53:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:53:40 +0000
X-ASF-Spam-Status: No, hits=4.9 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_NEUTRAL,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.92.27] (HELO qw-out-2122.google.com) (74.125.92.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:53:30 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1502336qwh.35
        for <multiple recipients>; Mon, 24 Aug 2009 17:53:09 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.93.130 with SMTP id v2mr3417882qam.119.1251161588141; Mon, 
	24 Aug 2009 17:53:08 -0700 (PDT)
In-Reply-To: <8211a1320908241747u1516e169gddb1641231d8f1b9@mail.gmail.com>
References: <8211a1320908241747u1516e169gddb1641231d8f1b9@mail.gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Mon, 24 Aug 2009 17:52:48 -0700
Message-ID: <d6d7c4410908241752m798970c6n852261f8d76d4102@mail.gmail.com>
Subject: Re: localhost:9000 and ip:9000 is not the same ?
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000feaf14861048fd00471ecc2b2
X-Virus-Checked: Checked by ClamAV on apache.org

--000feaf14861048fd00471ecc2b2
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Jeff,

Hadoop (HDFS in particular) is overly strict about machine names. The
filesystem's id is based on the DNS name used to access it. This needs to b=
e
consistent across all nodes and all configurations in your cluster. You
should always use the fully-qualified domain name of the namenode in your
configuration.

- Aaron

On Mon, Aug 24, 2009 at 5:47 PM, zhang jianfeng <zjffdu@gmail.com> wrote:

> Hi all,
>
>
>
> I have two computers, and in the hadoop-site.xml, I define the
> fs.default.name as localhost:9000, then I cannot access the cluster with
> Java API from another machine
>
> But if I change it to its real IP  192.168.1.103:9000, then I can access
> the
> cluster with Java API from another machine.
>
> It=92s so strange, are they any different ?
>
>
>
> Thank you.
>
> Jeff zhang
>

--000feaf14861048fd00471ecc2b2--

From common-user-return-17044-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 00:56:00 2009
Return-Path: <common-user-return-17044-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 85967 invoked from network); 25 Aug 2009 00:56:00 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 00:56:00 -0000
Received: (qmail 10758 invoked by uid 500); 25 Aug 2009 00:56:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10686 invoked by uid 500); 25 Aug 2009 00:56:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10676 invoked by uid 99); 25 Aug 2009 00:56:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:56:23 +0000
X-ASF-Spam-Status: No, hits=4.9 required=10.0
	tests=HTML_MESSAGE,NORMAL_HTTP_TO_IP,SPF_NEUTRAL,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.198.236] (HELO rv-out-0506.google.com) (209.85.198.236)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 00:56:12 +0000
Received: by rv-out-0506.google.com with SMTP id k40so899884rvb.5
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 17:55:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.143.14 with SMTP id q14mr2400895rvd.15.1251161750234; Mon, 
	24 Aug 2009 17:55:50 -0700 (PDT)
In-Reply-To: <8211a1320908241747u1516e169gddb1641231d8f1b9@mail.gmail.com>
References: <8211a1320908241747u1516e169gddb1641231d8f1b9@mail.gmail.com>
Date: Mon, 24 Aug 2009 17:55:50 -0700
Message-ID: <35538fbe0908241755n47ddf888i7d432629488d9079@mail.gmail.com>
Subject: Re: localhost:9000 and ip:9000 is not the same ?
From: Matt Massie <matt@cloudera.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd22b2aade62f0471eccb2c
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd22b2aade62f0471eccb2c
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Jeff-

If you look in /etc/hosts, you see the "localhost" is 127.0.0.1 (and if you
use IPv6, ::1).  This address is strictly loopback and can only be used for
inter-process communication on a single machine.

See: http://en.wikipedia.org/wiki/Localhost

-Matt


On Mon, Aug 24, 2009 at 5:47 PM, zhang jianfeng <zjffdu@gmail.com> wrote:

> Hi all,
>
>
>
> I have two computers, and in the hadoop-site.xml, I define the
> fs.default.name as localhost:9000, then I cannot access the cluster with
> Java API from another machine
>
> But if I change it to its real IP  192.168.1.103:9000, then I can access
> the
> cluster with Java API from another machine.
>
> It=92s so strange, are they any different ?
>
>
>
> Thank you.
>
> Jeff zhang
>

--000e0cd22b2aade62f0471eccb2c--

From common-user-return-17045-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 01:23:00 2009
Return-Path: <common-user-return-17045-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 47735 invoked from network); 25 Aug 2009 01:23:00 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 01:23:00 -0000
Received: (qmail 26647 invoked by uid 500); 25 Aug 2009 01:23:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26580 invoked by uid 500); 25 Aug 2009 01:23:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 26570 invoked by uid 500); 25 Aug 2009 01:23:19 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 26567 invoked by uid 99); 25 Aug 2009 01:23:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 01:23:19 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of markkerzner@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 01:23:11 +0000
Received: by fxm25 with SMTP id 25so1838242fxm.29
        for <core-user@hadoop.apache.org>; Mon, 24 Aug 2009 18:22:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=ixS9jRVKCGMJbqkLkvBNVHbL7d4Nbw1fFt5unbk9msg=;
        b=ncqlwtUL8bUfxoyPgw3Ta8O6cdq+84Vc/cSkQtjqce9Nxep6xj3Xshiz+IO+ApjuXQ
         COQHHHtKWdwJ4DexyXvzyauPxuR8ufQjQ75OIYwL816hiTbfVGmRNr0LFwkmI1yrHJLM
         wAvmrHFPOuGAtJh+T+8nGfgBw0dqDts7hxXWs=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=aOGkT+1fp3b/7KQ1uCAC+FFjAQruv34okyRES92OxI0UKHk2V2S2firbHeaP19MtP+
         f0OylcULD1B/i02nXywOWMkiE2/8H50D8XLn4trQ/ci03S2Y3ZcjCKzR7zfWcygy7Fha
         NRcWODgLyNcfjB4pQ+54Hi+8IujiIoYCqX7ds=
MIME-Version: 1.0
Received: by 10.204.162.210 with SMTP id w18mr1950980bkx.174.1251163370179; 
	Mon, 24 Aug 2009 18:22:50 -0700 (PDT)
Date: Mon, 24 Aug 2009 20:22:50 -0500
Message-ID: <c9b0d8bd0908241822u1987a610wf87ed64eef22f53b@mail.gmail.com>
Subject: Where does System.out.println() go?
From: Mark Kerzner <markkerzner@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000325559f3e3c4b820471ed2cb9
X-Virus-Checked: Checked by ClamAV on apache.org

--000325559f3e3c4b820471ed2cb9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,

when I run Hadoop in pseudo-distributed mode, I can't find the log which
System.out.println() goes.

When I run in the IDE, I see it. When I run on EC2, it's part of the output
logs. But here - do I need to set something up?

Thank you,
Mark

--000325559f3e3c4b820471ed2cb9--

From common-user-return-17046-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 01:53:46 2009
Return-Path: <common-user-return-17046-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 20665 invoked from network); 25 Aug 2009 01:53:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 01:53:46 -0000
Received: (qmail 49958 invoked by uid 500); 25 Aug 2009 01:54:08 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 49873 invoked by uid 500); 25 Aug 2009 01:54:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 49862 invoked by uid 99); 25 Aug 2009 01:54:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 01:54:08 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of edlinuxguru@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 01:53:58 +0000
Received: by fxm25 with SMTP id 25so1847074fxm.29
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 18:53:37 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=pZiZnQZ/ZcGh3k9u2bD5zxkzbTPjyKtTEbd8atEYczc=;
        b=kI56NAxR+kpOws4LX6BxjkQdFMKssA09CE8SZSes+xqsiT+T3SHaFxgNL4jaBAG14A
         5sQcoaV4Wt3HZm9QrLKqjK2m5fbAuJMBAQi+4XBCLqTXiXSzQTs1ld1r9sSA6Ze7lFCb
         BfdReFA1oaHNk4kPgDtsfzkK//W91vGWJUvrc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=ZmzGDKg27tRJSrSezOeovTj2nbUn6AK0K087ngpz/zzTOjbd2nJHNWKXiJBZz1JURT
         NI90+sNp5PSt0NZz75XAaYAVTltvO1Ea00deat20mty6pUmH/pKapejKwRVnY/zlxWn/
         vx+taYPeOriANtvkf4zNghao2xOznVKEVBX7s=
MIME-Version: 1.0
Received: by 10.239.139.201 with SMTP id u9mr525481hbu.112.1251165216762; Mon, 
	24 Aug 2009 18:53:36 -0700 (PDT)
In-Reply-To: <35538fbe0908241755n47ddf888i7d432629488d9079@mail.gmail.com>
References: <8211a1320908241747u1516e169gddb1641231d8f1b9@mail.gmail.com>
	 <35538fbe0908241755n47ddf888i7d432629488d9079@mail.gmail.com>
Date: Mon, 24 Aug 2009 21:53:36 -0400
Message-ID: <cbbf4b570908241853o25129d39x2ce745c07c678ad3@mail.gmail.com>
Subject: Re: localhost:9000 and ip:9000 is not the same ?
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Mon, Aug 24, 2009 at 8:55 PM, Matt Massie<matt@cloudera.com> wrote:
> Jeff-
>
> If you look in /etc/hosts, you see the "localhost" is 127.0.0.1 (and if y=
ou
> use IPv6, ::1). =A0This address is strictly loopback and can only be used=
 for
> inter-process communication on a single machine.
>
> See: http://en.wikipedia.org/wiki/Localhost
>
> -Matt
>
>
> On Mon, Aug 24, 2009 at 5:47 PM, zhang jianfeng <zjffdu@gmail.com> wrote:
>
>> Hi all,
>>
>>
>>
>> I have two computers, and in the hadoop-site.xml, I define the
>> fs.default.name as localhost:9000, then I cannot access the cluster with
>> Java API from another machine
>>
>> But if I change it to its real IP =A0192.168.1.103:9000, then I can acce=
ss
>> the
>> cluster with Java API from another machine.
>>
>> It=92s so strange, are they any different ?
>>
>>
>>
>> Thank you.
>>
>> Jeff zhang
>>
>

You have to watch out for this fact when configuring multinode hadoop.
For example if your configuration uses
mapred.job.tracker=3Dlocalhost:50030 you can run a job tracker on a
separate node but the other hosts in the cluster will not be able to
find it because they will look for it on localhost instead of where it
really is. Same applies for secondary namenode. It will run happily
repeating the a log like "not able to find namenode on
localhost:50030" hopefully you notice this before you need the
snapshot.

From common-user-return-17047-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 02:53:46 2009
Return-Path: <common-user-return-17047-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 66296 invoked from network); 25 Aug 2009 02:53:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 02:53:46 -0000
Received: (qmail 80928 invoked by uid 500); 25 Aug 2009 02:54:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80828 invoked by uid 500); 25 Aug 2009 02:54:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 80818 invoked by uid 99); 25 Aug 2009 02:54:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 02:54:08 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bharathvissapragada1990@gmail.com designates 209.85.221.178 as permitted sender)
Received: from [209.85.221.178] (HELO mail-qy0-f178.google.com) (209.85.221.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 02:53:59 +0000
Received: by qyk8 with SMTP id 8so417389qyk.2
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 19:53:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=EiThKdADhOSDrpQzmqa4KUYzKy+0p/zjRIqE+ZEZTfk=;
        b=Q6d63Yq47EYm9EmHD5EK1vJ5gFdMJtXWVGWfP6/oHMgxwmMitDgqTDi94ZcXgjWAwI
         xdcBTOV1y53RHY7lRu4MDbOh7ogmIJAw+l1zLJiAL5RaLAYEjZ79UdQLncRE3cIajtyZ
         panhQx1jleuBJTKbTGK9rCiXJo0uajJL0ws1Q=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=jETGycUNsC+/4GrLQLqGRAVimkBpxQlwVbHUA8+5Nf5Hi01vjBGjhYwB2ypoQ6KE1f
         BnDYUUXHIaSrxFAl9k4iVgsDRdruq3BhQc02LbsZ10wHxJLpruO4ndq1jsb3MlJ/SQ6g
         Zaf6Fiq3Tg3ObkckRYOrk2C57tppU7U/6+CIc=
MIME-Version: 1.0
Received: by 10.229.117.130 with SMTP id r2mr954354qcq.12.1251168818063; Mon, 
	24 Aug 2009 19:53:38 -0700 (PDT)
In-Reply-To: <C6B83E15.1CB94%jothipn@yahoo-inc.com>
References: <3b1311780908232349s56df94b9k321a48255adcdd85@mail.gmail.com> 
	<C6B83E15.1CB94%jothipn@yahoo-inc.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Tue, 25 Aug 2009 08:23:18 +0530
Message-ID: <73d592f60908241953i1c7d1ce1s2e80bf770370b3c3@mail.gmail.com>
Subject: Re: How to speed up the copy phrase?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd5cca6f46da20471ee702f
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd5cca6f46da20471ee702f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Jothi ,

Do have any idea , how thease speeds are calculated , I mean some
mathematical expressions or stuff.

On Mon, Aug 24, 2009 at 12:54 PM, Jothi Padmanabhan
<jothipn@yahoo-inc.com>wrote:

> The transfer rate is a little misleading. The timer for this calculation
> starts when the reducer itself starts and so includes the time spent by the
> reducer waiting for maps to complete. So, the speed shown when shuffling
> the
> first few maps might be totally misleading, it does not necessarily reflect
> the network speed. You should be able to see more reasonable numbers
> towards
> the end of shuffle.
>
> Jothi
>
>
> On 8/24/09 12:19 PM, "yang song" <hadoop.inifok@gmail.com> wrote:
>
> > Hello, everyone
> >
> > When I submit a big job(e.g. maptasks:10000, reducetasks:500), I find
> that
> > the copy phrase will last for a long long time. From WebUI, the message
> > "reduce > copy (xxxx of 10000 at 0.01 MB/s) >" tells me the transfer
> speed
> > is just 0.01 MB/s. Does it a regular value? How can I solve it?
> >
> > Thank you!
> >
> > P.S. The hadoop version is 0.19.1. The cluster has 20 nodes. Heap size of
> JT
> > is 6G while the     others are default settings.
>
>

--000e0cd5cca6f46da20471ee702f--

From common-user-return-17048-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 02:59:23 2009
Return-Path: <common-user-return-17048-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 86946 invoked from network); 25 Aug 2009 02:59:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 02:59:23 -0000
Received: (qmail 85143 invoked by uid 500); 25 Aug 2009 02:59:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 85057 invoked by uid 500); 25 Aug 2009 02:59:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 85047 invoked by uid 99); 25 Aug 2009 02:59:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 02:59:46 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [98.136.44.37] (HELO n61.bullet.mail.sp1.yahoo.com) (98.136.44.37)
    by apache.org (qpsmtpd/0.29) with SMTP; Tue, 25 Aug 2009 02:59:34 +0000
Received: from [69.147.84.145] by n61.bullet.mail.sp1.yahoo.com with NNFMP; 25 Aug 2009 02:59:13 -0000
Received: from [67.195.9.82] by t8.bullet.mail.sp1.yahoo.com with NNFMP; 25 Aug 2009 02:59:13 -0000
Received: from [67.195.9.98] by t2.bullet.mail.gq1.yahoo.com with NNFMP; 25 Aug 2009 02:59:13 -0000
Received: from [127.0.0.1] by omp102.mail.gq1.yahoo.com with NNFMP; 25 Aug 2009 02:59:13 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 197457.66084.bm@omp102.mail.gq1.yahoo.com
Received: (qmail 42804 invoked by uid 60001); 25 Aug 2009 02:59:12 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1251169152; bh=/JkWR06v4iUEt4rENJEe8eQLo3KpJ9O6z7okNegw5tk=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=Qe418h43ygi4AajmtPR5zCH+jF3teN2QzNsrZ3Z8VUeiz0rQY+lpcj7A/1usyAuhvy6pBqiOzELWmQyXIMUKQWIGHJNzEU1yoN5cPuX6YXiWPVAgVQORmjvYTYN4VHo1lWHRukFcrWy6QKj1VlgKY35mhivegHOFVD7j5DZIi6s=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:References:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=l0WfMvJkiCINDCK+HiE+giY85LUHsrWAY36kvJBYyPY4sCHmaO6bq1dPoEI1ndo9kNLULxGziNe+6JTSabXuYIduzAsZh38bYv6fTZ5SJ4UwJcbluh3IjLtOiI6c0APBiZ/M+EBaaeXho4KpUSVRmPQKQGGwG4clMhXSN27AjKI=;
Message-ID: <677178.42304.qm@web110101.mail.gq1.yahoo.com>
X-YMail-OSG: 74IzlBMVM1mudvPcxUdFc8AuvuQqbRhNyUQpdX5WVRNoSwV.qfStcB74e4zcBHQyb_g0cnx_MASnhEZ2fvrlSv5FBigrYZO53cWjbmM5EqvZqCn_u49Jjbk7Xi_udb5VuhhMUueOIEE4PKmNEjnlPNL5E579v3s02hO_hY7E3e5cVY4HMXANcJ8n9Q_IzA1_Fs5u6EC.SVMyMG56SBR7kmth_aPqtwCQT0AUecI1ZVBSq2diqdjOMC1qHoGnCAQobzyFlCxp14G1IVImG5coyyMZXkoxYl2kLCwd0W.ZQYUrLok.rdf6kEtnE6rwJXZ1F0taDN54QDzkPEFqn.MF402KK1jH72s7fNZEse0E2J83
Received: from [71.134.224.123] by web110101.mail.gq1.yahoo.com via HTTP; Mon, 24 Aug 2009 19:59:12 PDT
X-Mailer: YahooMailRC/1358.27 YahooMailWebService/0.7.338.1
References: <c9b0d8bd0908241822u1987a610wf87ed64eef22f53b@mail.gmail.com>
Date: Mon, 24 Aug 2009 19:59:12 -0700 (PDT)
From: Arvind Sharma <arvind321@yahoo.com>
Subject: Re: Where does System.out.println() go?
To: common-user@hadoop.apache.org
In-Reply-To: <c9b0d8bd0908241822u1987a610wf87ed64eef22f53b@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-1047826391-1251169152=:42304"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-1047826391-1251169152=:42304
Content-Type: text/plain; charset=us-ascii

most of the user level log files goes under $HADOOP_HOME/logs/userlog...try there....

Arvind




________________________________
From: Mark Kerzner <markkerzner@gmail.com>
To: core-user@hadoop.apache.org
Sent: Monday, August 24, 2009 6:22:50 PM
Subject: Where does System.out.println() go?

Hi,

when I run Hadoop in pseudo-distributed mode, I can't find the log which
System.out.println() goes.

When I run in the IDE, I see it. When I run on EC2, it's part of the output
logs. But here - do I need to set something up?

Thank you,
Mark



      
--0-1047826391-1251169152=:42304--


From common-user-return-17049-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 03:00:32 2009
Return-Path: <common-user-return-17049-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 90095 invoked from network); 25 Aug 2009 03:00:32 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 03:00:32 -0000
Received: (qmail 87777 invoked by uid 500); 25 Aug 2009 03:00:55 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87701 invoked by uid 500); 25 Aug 2009 03:00:55 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87690 invoked by uid 500); 25 Aug 2009 03:00:55 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 87687 invoked by uid 99); 25 Aug 2009 03:00:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 03:00:55 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bharathvissapragada1990@gmail.com designates 74.125.92.25 as permitted sender)
Received: from [74.125.92.25] (HELO qw-out-2122.google.com) (74.125.92.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 03:00:47 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1533642qwh.35
        for <core-user@hadoop.apache.org>; Mon, 24 Aug 2009 20:00:26 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:from:date:message-id
         :subject:to:content-type;
        bh=NKzBgLT7yaVF3pl6KEW3UtaguXHqleSWbcSP6DsKs1c=;
        b=MQRGq99AdAeA6rw6dPjIFD/P8rDkPCjVWBtSaNovI2Cwz8ZKLGaJDh7/KKLfvLenYX
         vQK5tWroEVjAhZ8jHTqb7zGBbrNyP0yCvrl0qPLKhmTK3HPm0HcpJk9CgPbijeZTtRZi
         krFmnkIHybJTfDTc9TQgtsov/8jGR3FBPVyEE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:from:date:message-id:subject:to:content-type;
        b=B+2cmLte6YVhhdA05ds+y80/IdNb95Rpq08Ohwd2tTb9sKRy6khC/29dpPNv1vciyt
         4G3BkBMpBHH9roMdwv++TDx/m4KPNHw+KSdbGMYiqmWfIIx5/WfQVcMHNpfzZrq2AvnN
         nrDEw7U/7qNjflX/T5kj/S2Y/YGnHtdLaEeL0=
MIME-Version: 1.0
Received: by 10.229.10.229 with SMTP id q37mr1131751qcq.106.1251169226168; 
	Mon, 24 Aug 2009 20:00:26 -0700 (PDT)
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Tue, 25 Aug 2009 08:30:06 +0530
Message-ID: <73d592f60908242000x1c2980bbjdd1053560c9d0cae@mail.gmail.com>
Subject: cost model for MR programs
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016364ed7dc479a2e0471ee8919
X-Virus-Checked: Checked by ClamAV on apache.org

--0016364ed7dc479a2e0471ee8919
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi all ,

Is there any general cost model that can be used to guess the run time of a
program (similar to Page IO/s , selectivity factors in RDBMS) in terms of
any config aspects such as number of nodes/page IO/s etc .

--0016364ed7dc479a2e0471ee8919--

From common-user-return-17050-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 03:01:44 2009
Return-Path: <common-user-return-17050-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 94635 invoked from network); 25 Aug 2009 03:01:44 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 03:01:44 -0000
Received: (qmail 89986 invoked by uid 500); 25 Aug 2009 03:02:07 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 89885 invoked by uid 500); 25 Aug 2009 03:02:06 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 89875 invoked by uid 99); 25 Aug 2009 03:02:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 03:02:06 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bharathvissapragada1990@gmail.com designates 74.125.92.27 as permitted sender)
Received: from [74.125.92.27] (HELO qw-out-2122.google.com) (74.125.92.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 03:01:56 +0000
Received: by qw-out-2122.google.com with SMTP id 8so1533869qwh.35
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 20:01:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=9gDnk91Bzs+7qd24pS57Ks8khPQ/uuwvCCAVZYe6uv8=;
        b=GdfVr9N9o5236Zkq09YLmyPf+Phc9ZoG6eTJQarB9A8eEzKdi1n8yxnkP6oNg9mq9z
         70mrxwd1kOzgtEJx2UjhxZHh7UlISqJXRaJZmQiA7GCeXHyboTo5/dmBD7lTCJ5UXlb6
         qfoZpDCsxlZDznwBCERyFz9iQMbt3wzWNLA68=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=LcG9429wMG8a2cFQYJP5Iz7GVkWxPqpKPaQSK+QL6I1Quxc0nXT23tdGP88mnL7IqP
         9HLbPY9WEYYgMO8P5Xxpl3ZZHS1LQK4EAVtl/rH0w5gZ0SNqo06gVlV85Tm6+63Jtas/
         PPaiUOi/3p4qS5JrM1KOHuxLdV/Pj86iG8Rjk=
MIME-Version: 1.0
Received: by 10.229.116.140 with SMTP id m12mr1181087qcq.54.1251169296092; 
	Mon, 24 Aug 2009 20:01:36 -0700 (PDT)
In-Reply-To: <73d592f60908242000x1c2980bbjdd1053560c9d0cae@mail.gmail.com>
References: <73d592f60908242000x1c2980bbjdd1053560c9d0cae@mail.gmail.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Tue, 25 Aug 2009 08:31:16 +0530
Message-ID: <73d592f60908242001t5c7ba526rcbafc6e354a2d097@mail.gmail.com>
Subject: Fwd: cost model for MR programs
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00c09fa216fe7290900471ee8d1f
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09fa216fe7290900471ee8d1f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi all ,

Is there any general cost model that can be used to guess the run time of a
Map reduce program (similar to Page IO/s , selectivity factors in RDBMS) in
terms of any config aspects such as number of nodes/page IO/s etc .

Thanks .

--00c09fa216fe7290900471ee8d1f--

From common-user-return-17051-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 03:05:31 2009
Return-Path: <common-user-return-17051-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 8552 invoked from network); 25 Aug 2009 03:05:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 03:05:31 -0000
Received: (qmail 93820 invoked by uid 500); 25 Aug 2009 03:05:54 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 93625 invoked by uid 500); 25 Aug 2009 03:05:54 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 93615 invoked by uid 99); 25 Aug 2009 03:05:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 03:05:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of markkerzner@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 03:05:44 +0000
Received: by fxm25 with SMTP id 25so1866358fxm.29
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 20:05:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=3mHaW8alGgK8LDL/+dGe1t96b4UUCdSlSfjiSU3TLxo=;
        b=ig4FNBBtOAxNzAluUKgwrkLawZC6zMWmZ40uaNn98vUeJKYm6wo4xMghAGKLYFTdtQ
         BqMBfwUQY8RhRaFfjpOiO//tr4JuHylI3GGHtkdF1Sm1rk2BegcyO2H03Lrmx6WjJKV/
         gRl9uQdDScOcim+JXMJYM9p1VGpiOPEETKSeU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=AKhRTEdihY1uz19EZD53M0DEI3q58ty2m6Gg5JJ2ffuX4iC+7UbtKP9xq4Qc+8dYi0
         DEhm0paYhsVlNqxKl6qkBgmWfk+alB7L1D+x3xN08Ah3FJZcQeQVhK5w2CmTYLqmi2Am
         1etnvS5WQTZyYu+R2DpTJF1zxjPG3CAa9HupM=
MIME-Version: 1.0
Received: by 10.204.143.153 with SMTP id v25mr1992075bku.157.1251169523939; 
	Mon, 24 Aug 2009 20:05:23 -0700 (PDT)
In-Reply-To: <677178.42304.qm@web110101.mail.gq1.yahoo.com>
References: <c9b0d8bd0908241822u1987a610wf87ed64eef22f53b@mail.gmail.com>
	 <677178.42304.qm@web110101.mail.gq1.yahoo.com>
Date: Mon, 24 Aug 2009 22:05:23 -0500
Message-ID: <c9b0d8bd0908242005r1704f2dao7e0bb03780161b56@mail.gmail.com>
Subject: Re: Where does System.out.println() go?
From: Mark Kerzner <markkerzner@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175d031c073a1c0471ee9bb9
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175d031c073a1c0471ee9bb9
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Perfect, that's where it was!
Mark

On Mon, Aug 24, 2009 at 9:59 PM, Arvind Sharma <arvind321@yahoo.com> wrote:

> most of the user level log files goes under $HADOOP_HOME/logs/userlog...try
> there....
>
> Arvind
>
>
>
>
> ________________________________
> From: Mark Kerzner <markkerzner@gmail.com>
> To: core-user@hadoop.apache.org
> Sent: Monday, August 24, 2009 6:22:50 PM
> Subject: Where does System.out.println() go?
>
> Hi,
>
> when I run Hadoop in pseudo-distributed mode, I can't find the log which
> System.out.println() goes.
>
> When I run in the IDE, I see it. When I run on EC2, it's part of the output
> logs. But here - do I need to set something up?
>
> Thank you,
> Mark
>
>
>
>
>

--0015175d031c073a1c0471ee9bb9--

From common-user-return-17052-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 04:08:06 2009
Return-Path: <common-user-return-17052-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 13912 invoked from network); 25 Aug 2009 04:08:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 04:08:06 -0000
Received: (qmail 23234 invoked by uid 500); 25 Aug 2009 04:08:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 23131 invoked by uid 500); 25 Aug 2009 04:08:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 23099 invoked by uid 99); 25 Aug 2009 04:08:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 04:08:28 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [202.165.105.136] (HELO web15206.mail.cnb.yahoo.com) (202.165.105.136)
    by apache.org (qpsmtpd/0.29) with SMTP; Tue, 25 Aug 2009 04:08:15 +0000
Received: (qmail 19010 invoked by uid 60001); 25 Aug 2009 04:07:51 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com.cn; s=s1024; t=1251173271; bh=b8P/V1xbolpnjFkCQM7xCaCIh8QqhG+5JrpoTRH/t1o=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:MIME-Version:Content-Type; b=egmek6mnTGpiQvW5z+cx+f99Ia5TOsLF3Y6WTkCQ1OCvyPeLydtzxbJ+IzZnthGEf/EJNnomRjqKpX9W8tetWPeZIQaK6cvNC7DY2m7XexNSHfC1EOafQXwR+eAJQdltc575iiPK85sXU+DqnNOGTSFb3d6poAf9xpKIw5T8Bss=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com.cn;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:MIME-Version:Content-Type;
  b=wXcX3eXXdTAy4mv8ojkccRwxwkskyrD5mnO7WSBmccvOB1LJcKU8GXEOB1Ok470Ze9DP8PSoVwGXb43wkkncMlo7AuCh21iIe6xsVsJIloTJOGeg66arMTGflk/vpCaMnJUXQ6P75BaYsxYFL5nXNrpmph4i7WJJd/SejDKfcpw=;
Message-ID: <343837.18038.qm@web15206.mail.cnb.yahoo.com>
X-YMail-OSG: WRaEMqoVM1nq2I.YbwEWTvyIJAdN0dNbxm.3oFhWZO551f4FommcpVhIoRPgXbeFndEOBbaTDw6ncglvnF2h9zfV9ywVcxxeRsz2HmL3EBVAscsiVG9V8_IykayM2wyKVW7nXO8pMK0h3eRAzSt8TQfvughaqXUqqkcGbEwI9aszq1682fyigvf4nrzJMfGUPRPNYbnp.DyjqyB4uFOmWlaBEInblK23rL2xCSvrMBk2Gmll
Received: from [125.34.47.203] by web15206.mail.cnb.yahoo.com via HTTP; Mon, 24 Aug 2009 21:07:50 PDT
X-Mailer: YahooMailClassic/6.1.2 YahooMailWebService/0.7.338.1
Date: Mon, 24 Aug 2009 21:07:50 -0700 (PDT)
From: qiu tian <tianqiu_527@yahoo.com.cn>
Subject: some problems about hadoop storage id collision.
To: common-user@hadoop.apache.org
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-1022825376-1251173270=:18038"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-1022825376-1251173270=:18038
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Hi everyone.
I=0Ainstalled hadoop among three pcs. When I ran the command=0A'start-all.s=
h', I only could start the jobtracker and tasktrackers. I=0Ause 192.*.*.x a=
s master and use 192.*.*.y and 192.*.*.z as slaves.

The namenode log from the master 192.*.*.x is following like this:

2009-08-18=0A10:48:44,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK*=
=0ANameSystem.registerDatanode: node 192.*.*.y:50010 is replaced by=0A192.*=
.*.x:50010 with the same storageID=0ADS-1120429845-127.0.0.1-50010-12466971=
64684
2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology: Removin=
g a node: /default-rack/192.*.*.y:50010
2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology: Adding =
a new node: /default-rack/192.*.*.x:50010
2009-08-18=0A10:48:45,932 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK*=
=0ANameSystem.getDatanode: Data node 192.*.*.z:50010 is attempting to=0Arep=
ort storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node=0A192.*.*.=
x:50010 is expected to serve this storage.
2009-08-18=0A10:48:45,932 INFO org.apache.hadoop.ipc.Server: IPC Server han=
dler 8 on=0A9000, call blockReport(DatanodeRegistration(192.*.*.z:50010,=0A=
storageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, infoPort=3D50075,=
=0AipcPort=3D50020), [J@1b8ebe3) from 192.*.*.z:33177: error:=0Aorg.apache.=
hadoop.hdfs.protocol.UnregisteredDatanodeException: Data=0Anode 192.*.*.z:5=
0010 is attempting to report storage ID=0ADS-1120429845-127.0.0.1-50010-124=
6697164684. Node 192.*.*.x:50010 is=0Aexpected to serve this storage.
org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException:=0AData node =
192.*.*.z:50010 is attempting to report storage ID=0ADS-1120429845-127.0.0.=
1-50010-1246697164684. Node 192.*.*.x:50010 is=0Aexpected to serve this sto=
rage.
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at=0A org.apache.hadoop.hdfs.ser=
ver.namenode.FSNamesystem.getDatanode(FSNamesystem.java:3800)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.FSNamesystem.processReport(FSNamesystem.java:2771)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.NameNode.blockReport(NameNode.java:636)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at sun.reflect.GeneratedMethodAc=
cessor14.invoke(Unknown Source)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at sun.reflect.DelegatingMethodA=
ccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at java.lang.reflect.Method.invo=
ke(Method.java:597)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.ipc.RPC$Ser=
ver.call(RPC.java:452)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.ipc.Server$=
Handler.run(Server.java:892)
2009-08-18=0A10:48:46,398 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK*=
=0ANameSystem.getDatanode: Data node 192.*.*.y:50010 is attempting to=0Arep=
ort storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node=0A192.*.*.=
x:50010 is expected to serve this storage.
2009-08-18=0A10:48:46,398 INFO org.apache.hadoop.ipc.Server: IPC Server han=
dler 0 on=0A9000, call blockReport(DatanodeRegistration(192.9.200.y:50010,=
=0AstorageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, infoPort=3D5007=
5,=0AipcPort=3D50020), [J@186b634) from 192.*.*.y:47367: error:=0Aorg.apach=
e.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data=0Anode 192.*.*.y=
:50010 is attempting to report storage ID=0ADS-1120429845-127.0.0.1-50010-1=
246697164684. Node 192.*.*.x:50010 is=0Aexpected to serve this storage.
org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException:=0AData node =
192.*.*.y:50010 is attempting to report storage ID=0ADS-1120429845-127.0.0.=
1-50010-1246697164684. Node 192.*.*.x:50010 is=0Aexpected to serve this sto=
rage.
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.FSNamesystem.getDatanode(FSNamesystem.java:3800)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.FSNamesystem.processReport(FSNamesystem.java:2771)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.hdfs.server=
.namenode.NameNode.blockReport(NameNode.java:636)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at sun.reflect.GeneratedMethodAc=
cessor14.invoke(Unknown Source)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at sun.reflect.DelegatingMethodA=
ccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at java.lang.reflect.Method.invo=
ke(Method.java:597)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at org.apache.hadoop.ipc.RPC$Ser=
ver.call(RPC.java:452)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 at=0A org.apache.hadoop.ipc.Serv=
er$Handler.run(Server.java:892)
2009-08-18 10:48:47,000 INFO org.apache.hadoop.hdfs.server.namenode.FSNames=
ystem: Roll Edit Log from 192.*.*.x
~=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=20

The message on the shell looks like this:
192.*.*.x:=0AException in thread "main" java.io.IOException: Cannot lock st=
orage=0A/home/gaojun/HadoopInstall/tmp/dfs/namesecondary. The directory is=
=0Aalready locked.
192.*.*.x: =C2=A0=C2=A0 =C2=A0at org.apache.hadoop.hdfs.server.common.Stora=
ge$StorageDirectory.lock(Storage.java:510)
192.*.*.x: =C2=A0=C2=A0 =C2=A0at org.apache.hadoop.hdfs.server.common.Stora=
ge$StorageDirectory.analyzeStorage(Storage.java:363)
192.*.*.x:=0A=C2=A0=C2=A0 =C2=A0at=0Aorg.apache.hadoop.hdfs.server.namenode=
.SecondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:5=
17)
192.*.*.x: =C2=A0=C2=A0 =C2=A0at=0A org.apache.hadoop.hdfs.server.namenode.=
SecondaryNameNode.initialize(SecondaryNameNode.java:145)
192.*.*.x: =C2=A0=C2=A0 =C2=A0at org.apache.hadoop.hdfs.server.namenode.Sec=
ondaryNameNode.<init>(SecondaryNameNode.java:115)
192.*.*.x: =C2=A0=C2=A0 =C2=A0at org.apache.hadoop.hdfs.server.namenode.Sec=
ondaryNameNode.main(SecondaryNameNode.java:469)
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=20
I could not find the reason. Can someone help me?
Thanks!

yan=0A =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=20
=0A=0A=0A      ___________________________________________________________ =
=0A  =E5=A5=BD=E7=8E=A9=E8=B4=BA=E5=8D=A1=E7=AD=89=E4=BD=A0=E5=8F=91=EF=BC=
=8C=E9=82=AE=E7=AE=B1=E8=B4=BA=E5=8D=A1=E5=85=A8=E6=96=B0=E4=B8=8A=E7=BA=BF=
=EF=BC=81 =0Ahttp://card.mail.cn.yahoo.com/
--0-1022825376-1251173270=:18038--

From common-user-return-17053-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 04:16:44 2009
Return-Path: <common-user-return-17053-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 43490 invoked from network); 25 Aug 2009 04:16:44 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 04:16:44 -0000
Received: (qmail 33800 invoked by uid 500); 25 Aug 2009 04:17:07 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 33649 invoked by uid 500); 25 Aug 2009 04:17:06 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 33638 invoked by uid 99); 25 Aug 2009 04:17:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 04:17:06 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rvmishwar@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 04:16:57 +0000
Received: by bwz10 with SMTP id 10so1887411bwz.29
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 21:16:37 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=kJiTZGxsVnMTUlPzPmeG4Sz8ER0I2w3foJOlYIzJlo4=;
        b=hij1XsoWB8r2XzCGvXDIqyhlPnSOlzPY6ZlI1FrxpavJrsELIkl363wF724IWBGXsB
         v3Xjp6LxfQ1h8qjE2QLq270DRMGnTiU7ybKH9Yn/fr5JzgusR2Xpjb/csNAzoUCo2ByU
         v9DXz327N1ke3PNmPD/sjxOGu33JKT7VIWGRU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=ppT2gr0DFiMK1dMNkXVSp7hVW2O1mixY9hgtwBEHqJUD1S0xv06JRzsLnvGXbo8ZNH
         22Btghd6p78XOqkuXzOnbz3331XblWYSnC3imtkkVyvEkBBexcEcJJvZs2b7wpq8HIDz
         65/hx1EeLVHxUJnvYvyrxzR6GqmOsDHzYSKC4=
MIME-Version: 1.0
Received: by 10.102.249.10 with SMTP id w10mr2345766muh.49.1251173796332; Mon, 
	24 Aug 2009 21:16:36 -0700 (PDT)
Date: Mon, 24 Aug 2009 21:16:36 -0700
Message-ID: <fe35e3c40908242116m5d60c443o7aa4cb8ce6b5cd@mail.gmail.com>
Subject: Writing to multuple DBs using MultipleOutputs ... howto?
From: ishwar ramani <rvmishwar@gmail.com>
To: common-user <common-user@hadoop.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

I am running into a problem when using MultipleOutputs configuration
for writing to
multiple DBs. Since the DBOutputFormat has a static method setoutput for setting
tables and fields, i cannot use it in addNamedInputClass member.

This seems to be generic problem with multipleOutputs model. If i need to use
OutputFormats with static config params ...

any solutions for this?

From common-user-return-17054-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 05:11:30 2009
Return-Path: <common-user-return-17054-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 36298 invoked from network); 25 Aug 2009 05:11:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 05:11:29 -0000
Received: (qmail 71871 invoked by uid 500); 25 Aug 2009 05:11:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 71626 invoked by uid 500); 25 Aug 2009 05:11:52 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 71616 invoked by uid 99); 25 Aug 2009 05:11:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 05:11:52 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nipun.saggar@gmail.com designates 209.85.216.190 as permitted sender)
Received: from [209.85.216.190] (HELO mail-px0-f190.google.com) (209.85.216.190)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 05:11:44 +0000
Received: by pxi28 with SMTP id 28so5528295pxi.2
        for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 22:11:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=Xhb+Yl4eKdJXzgoYnsa8La+jps1B0mfVuRGoObT2i/o=;
        b=Df+4RG0/lhqHlOpc+AMMxN0q+viiCXqyfxAi9OWY8CqUdX/afEy2shdF8bpRLf+fDD
         z4ecXZey+XshwP1c7Xqu6oB8IqAfN/lOarkZ/xG1H0zeJpTDUGg8kAhvmg28sgZRRK9g
         O7fpyGuo/h0iHB2fJ7LGC7IBwYsKorHAk4SM4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=NLRW8tkm/HaTHGhHn+QnLDkE40SJVy5R6+ydLYRD38GDDfnyiLiMjnocq1pX0N6adU
         YZxlfzxAfjSzc4zcidRYsyeIYOntsAT8UVcHzTf15xY+mV1Pv4W/Qa7IUKqOiLVGaXmO
         +4+LwkPhGphwMQOa5rwDyufT0pwKaTo+D6q1U=
MIME-Version: 1.0
Received: by 10.143.26.29 with SMTP id d29mr442378wfj.281.1251177083819; Mon, 
	24 Aug 2009 22:11:23 -0700 (PDT)
In-Reply-To: <d6d7c4410908241743o78985e9atd9641f39f9e35a4e@mail.gmail.com>
References: <6c1002100908230509t138131eas39749ef14aadfa50@mail.gmail.com>
	 <d6d7c4410908241743o78985e9atd9641f39f9e35a4e@mail.gmail.com>
Date: Tue, 25 Aug 2009 10:41:23 +0530
Message-ID: <6c1002100908242211i340143d9t9cef59dd2d433c8@mail.gmail.com>
Subject: Re: Hadoop streaming: How is data distributed from mappers to 
	reducers?
From: Nipun Saggar <nipun.saggar@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636e0ac8da1d7720471f05d12
X-Virus-Checked: Checked by ClamAV on apache.org

--001636e0ac8da1d7720471f05d12
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Does that mean that, if the same key is emitted more than once from a
mapper, it is not necessary that the key value pairs (for that same key)
will go to the same reducer?

-Nipun

On Tue, Aug 25, 2009 at 6:13 AM, Aaron Kimball <aaron@cloudera.com> wrote:

> Yes. It works just like Java-based MapReduce in that regard.
> - Aaron
>
> On Sun, Aug 23, 2009 at 5:09 AM, Nipun Saggar <nipun.saggar@gmail.com
> >wrote:
>
> > Hi all,
> >
> > I have recently started using Hadoop streaming. From the documentation, I
> > understand that by default, each line output from a mapper up to the
> first
> > tab becomes the key and rest of the line is the value. I wanted to know
> > that
> > between the mapper and reducer, is there a shuffling(sorting) phase? More
> > specifically, Would it be correct to assume that output from all mappers
> > with the same key will go to the same reducer?
> >
> > Thanks,
> > Nipun
> >
>

--001636e0ac8da1d7720471f05d12--

From common-user-return-17055-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 05:21:39 2009
Return-Path: <common-user-return-17055-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 69341 invoked from network); 25 Aug 2009 05:21:39 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 05:21:39 -0000
Received: (qmail 80760 invoked by uid 500); 25 Aug 2009 05:22:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80640 invoked by uid 500); 25 Aug 2009 05:22:01 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 80630 invoked by uid 99); 25 Aug 2009 05:22:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 05:22:01 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.20] (HELO mrout1-b.corp.re1.yahoo.com) (69.147.107.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 05:21:48 +0000
Received: from EGL-EX07CAS02.ds.corp.yahoo.com (egl-ex07cas02.eglbp.corp.yahoo.com [203.83.248.209])
	by mrout1-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7P5Kxa4032888
	for <common-user@hadoop.apache.org>; Mon, 24 Aug 2009 22:21:00 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=jWH7xFZAWoGViCnij52xTbQMaGqfGdmC77QUGXc0csAW8vi1GWunvSZNuHSBl2Mi
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.206]) by
 EGL-EX07CAS02.ds.corp.yahoo.com ([203.83.248.216]) with mapi; Tue, 25 Aug
 2009 10:50:58 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Tue, 25 Aug 2009 10:49:46 +0530
Subject: RE: Hadoop streaming: How is data distributed from mappers to
 	reducers?
Thread-Topic: Hadoop streaming: How is data distributed from mappers to
 	reducers?
Thread-Index: AcolQqRSHu9emzUyQyeBnMB0rDa70gAALdrQ
Message-ID: <616DA47B2EF5B944B91846785B512FF4CFADEA7139@EGL-EX07VS01.ds.corp.yahoo.com>
References: <6c1002100908230509t138131eas39749ef14aadfa50@mail.gmail.com>
	 <d6d7c4410908241743o78985e9atd9641f39f9e35a4e@mail.gmail.com>
 <6c1002100908242211i340143d9t9cef59dd2d433c8@mail.gmail.com>
In-Reply-To: <6c1002100908242211i340143d9t9cef59dd2d433c8@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Hadoop will make sure that every <k,v> pair with same key will land up in s=
ame reducer and consumed in a single reduce instance.

-----Original Message-----
From: Nipun Saggar [mailto:nipun.saggar@gmail.com]=20
Sent: Tuesday, August 25, 2009 10:41 AM
To: common-user@hadoop.apache.org
Subject: Re: Hadoop streaming: How is data distributed from mappers to redu=
cers?

Does that mean that, if the same key is emitted more than once from a
mapper, it is not necessary that the key value pairs (for that same key)
will go to the same reducer?

-Nipun

On Tue, Aug 25, 2009 at 6:13 AM, Aaron Kimball <aaron@cloudera.com> wrote:

> Yes. It works just like Java-based MapReduce in that regard.
> - Aaron
>
> On Sun, Aug 23, 2009 at 5:09 AM, Nipun Saggar <nipun.saggar@gmail.com
> >wrote:
>
> > Hi all,
> >
> > I have recently started using Hadoop streaming. From the documentation,=
 I
> > understand that by default, each line output from a mapper up to the
> first
> > tab becomes the key and rest of the line is the value. I wanted to know
> > that
> > between the mapper and reducer, is there a shuffling(sorting) phase? Mo=
re
> > specifically, Would it be correct to assume that output from all mapper=
s
> > with the same key will go to the same reducer?
> >
> > Thanks,
> > Nipun
> >
>

From common-user-return-17056-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 08:26:40 2009
Return-Path: <common-user-return-17056-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 81051 invoked from network); 25 Aug 2009 08:26:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 08:26:40 -0000
Received: (qmail 83317 invoked by uid 500); 25 Aug 2009 08:27:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 83255 invoked by uid 500); 25 Aug 2009 08:27:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 83242 invoked by uid 99); 25 Aug 2009 08:27:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 08:27:02 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.221.178] (HELO mail-qy0-f178.google.com) (209.85.221.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 08:26:53 +0000
Received: by qyk8 with SMTP id 8so456530qyk.2
        for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 01:26:31 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.34.81 with SMTP id k17mr3623749qad.113.1251188791185; Tue, 
	25 Aug 2009 01:26:31 -0700 (PDT)
In-Reply-To: <C175257A-B2D8-4388-AF5B-B43B62CF80BD@gmail.com>
References: <74655.90702.qm@web15206.mail.cnb.yahoo.com> <314098690908210625q44e1eb15xf584358dce8071d@mail.gmail.com> 
	<C175257A-B2D8-4388-AF5B-B43B62CF80BD@gmail.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Tue, 25 Aug 2009 01:26:11 -0700
Message-ID: <d6d7c4410908250126ic9a8f22wc8abe41d99c7d705@mail.gmail.com>
Subject: Re: Help.
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00c09f8516157214130471f317e6
X-Virus-Checked: Checked by ClamAV on apache.org

--00c09f8516157214130471f317e6
Content-Type: text/plain; charset=GB2312
Content-Transfer-Encoding: quoted-printable

Are you trying to serve blocks from a shared directory e.g. NFS?

The storageID for a node is recorded in a file named "VERSION" in
${dfs.data.dir}/current. If one node claims that the storage directory is
already locked, and another node is reporting the first node's storageID, i=
t
makes me think that you have multiple datanodes attempting to use the same
shared directory for storage.

This can't be done in Hadoop. Each datanode assumes it has sole access to a
storage directory. Besides, it defeats the point of using multiple datanode=
s
to distribute disk and network I/O :) If you're using NFS, reconfigure all
the datanodes to store blocks in local directories only (by moving
dfs.data.dir) and try again.

The mention of the namesecondary directory in there also makes me think tha=
t
you're trying to start redundant copies of the secondarynamenode (e.g., by
listing the same node twice in the 'conf/masters' file) or that the
fs.checkpoint.dir is the same as the dfs.data.dir. This also isn't allowed
-- dfs.data.dir, dfs.name.dir, and fs.checkpoint.dir must all refer to
distinct physical locations.

- Aaron

On Fri, Aug 21, 2009 at 7:19 AM, Sujith Vellat <vtsujith@gmail.com> wrote:

>
>
> Sent from my iPhone
>
>
> On Aug 21, 2009, at 9:25 AM, Jason Venner <jason.hadoop@gmail.com> wrote:
>
>  It may be that the individual datanodes get different names for their ip
>> addresses than the namenode does.
>> It may also be that some subset of your namenode/datanodes do not have
>> write
>> access to the hdfs storage directories.
>>
>>
>> On Mon, Aug 17, 2009 at 10:05 PM, qiu tian <tianqiu_527@yahoo.com.cn>
>> wrote:
>>
>>  Hi everyone.
>>> I installed hadoop among three pcs. When I ran the command
>>> 'start-all.sh',
>>> I only could start the jobtracker and tasktrackers. I use 192.*.*.x as
>>> master and use 192.*.*.y and 192.*.*.z as slaves.
>>>
>>> The namenode log from the master 192.*.*.x is following like this:
>>>
>>> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK*
>>> NameSystem.registerDatanode: node 192.*.*.y:50010 is replaced by
>>> 192.*.*.x:50010 with the same storageID
>>> DS-1120429845-127.0.0.1-50010-1246697164684
>>> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology:
>>> Removing a node: /default-rack/192.*.*.y:50010
>>> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology:
>>> Adding
>>> a new node: /default-rack/192.*.*.x:50010
>>> 2009-08-18 10:48:45,932 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK=
*
>>> NameSystem.getDatanode: Data node 192.*.*.z:50010 is attempting to repo=
rt
>>> storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node
>>> 192.*.*.x:50010
>>> is expected to serve this storage.
>>> 2009-08-18 10:48:45,932 INFO org.apache.hadoop.ipc.Server: IPC Server
>>> handler 8 on 9000, call blockReport(DatanodeRegistration(192.*.*.z:5001=
0,
>>> storageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, infoPort=3D500=
75,
>>> ipcPort=3D50020), [J@1b8ebe3) from 192.*.*.z:33177: error:
>>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data nod=
e
>>> 192.*.*.z:50010 is attempting to report storage ID
>>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>>> expected to serve this storage.
>>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data nod=
e
>>> 192.*.*.z:50010 is attempting to report storage ID
>>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>>> expected to serve this storage.
>>>       at
>>>
>>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDatanode(FSNames=
ystem.java:3800)
>>>       at
>>>
>>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport(FSNam=
esystem.java:2771)
>>>       at
>>>
>>> org.apache.hadoop.hdfs.server.namenode.NameNode.blockReport(NameNode.ja=
va:636)
>>>       at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
>>>       at
>>>
>>> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccesso=
rImpl.java:25)
>>>       at java.lang.reflect.Method.invoke(Method.java:597)
>>>       at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
>>>       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)
>>> 2009-08-18 10:48:46,398 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK=
*
>>> NameSystem.getDatanode: Data node 192.*.*.y:50010 is attempting to repo=
rt
>>> storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node
>>> 192.*.*.x:50010
>>> is expected to serve this storage.
>>> 2009-08-18 10:48:46,398 INFO org.apache.hadoop.ipc.Server: IPC Server
>>> handler 0 on 9000, call
>>> blockReport(DatanodeRegistration(192.9.200.y:50010,
>>> storageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, infoPort=3D500=
75,
>>> ipcPort=3D50020), [J@186b634) from 192.*.*.y:47367: error:
>>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data nod=
e
>>> 192.*.*.y:50010 is attempting to report storage ID
>>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>>> expected to serve this storage.
>>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data nod=
e
>>> 192.*.*.y:50010 is attempting to report storage ID
>>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>>> expected to serve this storage.
>>>       at
>>>
>>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDatanode(FSNames=
ystem.java:3800)
>>>       at
>>>
>>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport(FSNam=
esystem.java:2771)
>>>       at
>>>
>>> org.apache.hadoop.hdfs.server.namenode.NameNode.blockReport(NameNode.ja=
va:636)
>>>       at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
>>>       at
>>>
>>> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccesso=
rImpl.java:25)
>>>       at java.lang.reflect.Method.invoke(Method.java:597)
>>>       at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
>>>       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)
>>> 2009-08-18 10:48:47,000 INFO
>>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from
>>> 192.*.*.x
>>> ~
>>>
>>> The message on the shell looks like this:
>>> 192.*.*.x: Exception in thread "main" java.io.IOException: Cannot lock
>>> storage /home/gaojun/HadoopInstall/tmp/dfs/namesecondary. The directory
>>> is
>>> already locked.
>>> 192.*.*.x:     at
>>>
>>> org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Stor=
age.java:510)
>>> 192.*.*.x:     at
>>>
>>> org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeSt=
orage(Storage.java:363)
>>> 192.*.*.x:     at
>>>
>>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStor=
age.recoverCreate(SecondaryNameNode.java:517)
>>> 192.*.*.x:     at
>>>
>>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(Sec=
ondaryNameNode.java:145)
>>> 192.*.*.x:     at
>>>
>>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(Seconda=
ryNameNode.java:115)
>>> 192.*.*.x:     at
>>>
>>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(Secondary=
NameNode.java:469)
>>>
>>> I could not find the reason. Can someone help me?
>>> Thanks!
>>>
>>> yan
>>>
>>>
>>>
>>>    ___________________________________________________________
>>> =BA=C3=CD=E6=BA=D8=BF=A8=B5=C8=C4=E3=B7=A2=A3=AC=D3=CA=CF=E4=BA=D8=BF=
=A8=C8=AB=D0=C2=C9=CF=CF=DF=A3=A1
>>> http://card.mail.cn.yahoo.com/
>>>
>>>
>>
>>
>> --
>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>> http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
>> www.prohadoopbook.com a community for Hadoop Professionals
>>
>

--00c09f8516157214130471f317e6--

From common-user-return-17057-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 09:58:08 2009
Return-Path: <common-user-return-17057-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 25610 invoked from network); 25 Aug 2009 09:57:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 09:57:40 -0000
Received: (qmail 22045 invoked by uid 500); 25 Aug 2009 09:58:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21966 invoked by uid 500); 25 Aug 2009 09:58:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21952 invoked by uid 99); 25 Aug 2009 09:58:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 09:58:02 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [192.6.10.60] (HELO tobor.hpl.hp.com) (192.6.10.60)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 09:57:52 +0000
Received: from localhost (localhost [127.0.0.1])
	by tobor.hpl.hp.com (Postfix) with ESMTP id 7D3DAB7CB7
	for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 10:57:30 +0100 (BST)
X-Virus-Scanned: amavisd-new at hplb.hpl.hp.com
Received: from tobor.hpl.hp.com ([127.0.0.1])
	by localhost (tobor.hpl.hp.com [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id jnd6qBQBmahw for <common-user@hadoop.apache.org>;
	Tue, 25 Aug 2009 10:57:24 +0100 (BST)
Received: from 0-imap-br1.hpl.hp.com (0-imap-br1.hpl.hp.com [16.25.144.60])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by tobor.hpl.hp.com (Postfix) with ESMTPS id 05C8BB7CB2
	for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 10:57:23 +0100 (BST)
MailScanner-NULL-Check: 1251799031.49263@PHbT9xhZZgigIIavtjAEeg
Received: from [16.25.175.158] (morzine.hpl.hp.com [16.25.175.158])
	by 0-imap-br1.hpl.hp.com (8.14.1/8.13.4) with ESMTP id n7P9vAHZ003754
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 10:57:10 +0100 (BST)
Message-ID: <4A93B576.1050408@apache.org>
Date: Tue, 25 Aug 2009 10:57:10 +0100
From: Steve Loughran <stevel@apache.org>
User-Agent: Thunderbird 2.0.0.23 (X11/20090812)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: NN memory consumption on 0.20/0.21 with compressed pointers/
References: <4A8D281B.9070006@apache.org> <4A8D8D3D.5070404@yahoo-inc.com> <4A926E92.8080303@apache.org> <D15A2AC3-67B1-43E7-B4AD-DEC706A5B699@cse.unl.edu>
In-Reply-To: <D15A2AC3-67B1-43E7-B4AD-DEC706A5B699@cse.unl.edu>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-HPL-MailScanner-Information: Please contact the ISP for more information
X-MailScanner-ID: n7P9vAHZ003754
X-HPL-MailScanner: Found to be clean
X-HPL-MailScanner-From: stevel@apache.org
X-Virus-Checked: Checked by ClamAV on apache.org

Brian Bockelman wrote:
> 
> On Aug 24, 2009, at 5:42 AM, Steve Loughran wrote:
> 
>> Raghu Angadi wrote:
>>> Suresh had made an spreadsheet for memory consumption.. will check.
>>> A large portion of NN memory is taken by references. I would expect 
>>> memory savings to be very substantial (same as going from 64bit to 
>>> 32bit), could be on the order of 40%.
>>> The last I heard from Sun was that compressed pointers will be in 
>>> very near future JVM (certainly JDK 1.6_x). It can use compressed 
>>> pointers upto 32GB of heap.
>>
>> It's in JDK 1.6u14. Looking at the source and reading the specs 
>> implies there is savings, but we need to experiment to see. I now know 
>> how to do sizeof() in java, (in the instrumentation API), so these 
>> experiments are possible
>>
> 
> Hey Steve,
> 
> I'm a bit dumb with Java (so this might be something you already know), 
> but last week I discovered the "jhat" tool.  You can dump the Java stack 
> with JMX to a file, then use jhat to build a little webserver that 
> allows you to explore your heap.
> 
> One page it provides is a table histogram of the instance counts and # 
> of bytes per class.

I've worked out how to do sizeof, got my first results during last 
night's london HUG event,
all the data is going into https://issues.apache.org/jira/browse/HDFS-559


> 
> This helped me a lot when I was trying to track memory leaks in libhdfs.
> 
>>> I would expect runtime over head on NN would be minimal in practice.
>>
>>
>> I think there's a small extra deref cost, but its very minimal; one 8 
>> bit logical shift left, possibly also an addition. Both of which run 
>> at CPU-speeds, not main memory bus rates
> 
> One interesting tidbit (from my memory of a presentation 2 months ago... 
> I might have the numbers wrong, but the general message is the same):
> 
> On petascale-level computers, the application codes' CPU instructions 
> are about 10% floating point (that is, in scientific applications, there 
> are less floating point instructions than in most floating point 
> benchmarks).  Of the remaining instructions, about 1/3 are 
> memory-related and 2/3 are integer.  Of the integer instructions, 40% 
> are computing memory locations.

cool. I wonder what percentage is vtable/function lookup in OO code 
versus data retrieval? After all, every time you read or write an 
instance field in a class instance, there is the this+offset maths 
before the actual retrieval, though there is a fair amount of CPU 
support for such offset operations

> 
> So, on the biggest DOE computers, about 50% of the CPU time is spent on 
> memory-related computations.  I found this pretty mind-boggling when I 
> learned this.  It seems to me that the "central" part of the computer is 
> becoming the bus, not the CPU.

welcome to the new bottlenecks.




From common-user-return-17058-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 11:50:21 2009
Return-Path: <common-user-return-17058-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 68692 invoked from network); 25 Aug 2009 11:50:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 11:50:21 -0000
Received: (qmail 21548 invoked by uid 500); 25 Aug 2009 11:50:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21455 invoked by uid 500); 25 Aug 2009 11:50:44 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21445 invoked by uid 500); 25 Aug 2009 11:50:44 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 21442 invoked by uid 99); 25 Aug 2009 11:50:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 11:50:44 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 11:50:33 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MfuX2-00026Z-Vy
	for core-user@hadoop.apache.org; Tue, 25 Aug 2009 04:49:44 -0700
Message-ID: <25132782.post@talk.nabble.com>
Date: Tue, 25 Aug 2009 04:49:34 -0700 (PDT)
From: HRoger <hanxianyongroger@163.com>
To: core-user@hadoop.apache.org
Subject: Task process exit with nonzero status of 126
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: hanxianyongroger@163.com
X-Virus-Checked: Checked by ClamAV on apache.org


Hi,
Today I have a problem with run job on hadoop with the log message "Task
process exit with nonzero status of 126 Error reading task ouput.....",but I
can put iles in HDFS or get some files from HDFS sucessfully. I  formated
the namenode and start hadoop without any error log messsage, when I run job
it report the same error message again. I also restart my computer but it
doesn't  work.

Thanks 
HRoger
-- 
View this message in context: http://www.nabble.com/Task-process-exit-with-nonzero-status-of-126-tp25132782p25132782.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-17059-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 11:53:40 2009
Return-Path: <common-user-return-17059-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 69126 invoked from network); 25 Aug 2009 11:53:40 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 11:53:40 -0000
Received: (qmail 26275 invoked by uid 500); 25 Aug 2009 11:54:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26189 invoked by uid 500); 25 Aug 2009 11:54:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 26179 invoked by uid 500); 25 Aug 2009 11:54:02 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 26175 invoked by uid 99); 25 Aug 2009 11:54:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 11:54:02 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 11:53:53 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MfuaK-0002Ce-0l
	for core-user@hadoop.apache.org; Tue, 25 Aug 2009 04:53:08 -0700
Message-ID: <25132806.post@talk.nabble.com>
Date: Tue, 25 Aug 2009 04:52:57 -0700 (PDT)
From: HRoger <hanxianyongroger@163.com>
To: core-user@hadoop.apache.org
Subject: Re: localhost:9000 and ip:9000 is not the same ?
In-Reply-To: <8211a1320908241747u1516e169gddb1641231d8f1b9@mail.gmail.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Nabble-From: hanxianyongroger@163.com
References: <8211a1320908241747u1516e169gddb1641231d8f1b9@mail.gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org


fs.default.name is the run the namenode machine,is it 192.168.1.103?


zjffdu wrote:
>=20
> Hi all,
>=20
>=20
>=20
> I have two computers, and in the hadoop-site.xml, I define the
> fs.default.name as localhost:9000, then I cannot access the cluster with
> Java API from another machine
>=20
> But if I change it to its real IP  192.168.1.103:9000, then I can access
> the
> cluster with Java API from another machine.
>=20
> It=E2=80=99s so strange, are they any different ?
>=20
>=20
>=20
> Thank you.
>=20
> Jeff zhang
>=20
>=20

--=20
View this message in context: http://www.nabble.com/localhost%3A9000-and-ip=
%3A9000-is-not-the-same---tp25126420p25132806.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-17060-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 15:59:47 2009
Return-Path: <common-user-return-17060-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 72407 invoked from network); 25 Aug 2009 15:59:47 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 15:59:47 -0000
Received: (qmail 43413 invoked by uid 500); 25 Aug 2009 16:00:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 43319 invoked by uid 500); 25 Aug 2009 16:00:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 43307 invoked by uid 99); 25 Aug 2009 16:00:10 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 16:00:10 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.212.202 as permitted sender)
Received: from [209.85.212.202] (HELO mail-vw0-f202.google.com) (209.85.212.202)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 16:00:00 +0000
Received: by vws40 with SMTP id 40so2718778vws.2
        for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 08:59:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=udfs5RhLQpkfOMVCcwtrCP0N7gddRsi7gn/QcSluLoI=;
        b=UbGXzbevq/sS1bNksQTBi0b3i1vcugYbr0vANxvAuf1KYKhhulbglkuDqqACQhxOkg
         8SBgjyxIb9+gTq8xU57JHsOVtLfdW5yPQ0OhnSq8wAfX22FG+fYjeg7nLrRpvahNZgUm
         iy6FlTVVyUc2c0dRu1DiD5krYyqnhS+VlVdYc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=qSJQWY4MARFylWpqPCwxJT+iwBALw6jtHqtlay/rG4g5UnFHuo7gzz+hAcpbecYx0M
         QT+gBgSF57ovVs94QfB6DI/NPkxzmJ1mRwr8h0GXtCNR9pvR5elM5uJ44zO0IroBp7iy
         B7mRsnS+Nek38uX6xUykpp8+e4uYDvbpyalxg=
MIME-Version: 1.0
Received: by 10.150.22.2 with SMTP id 2mr9609146ybv.293.1251215979069; Tue, 25 
	Aug 2009 08:59:39 -0700 (PDT)
In-Reply-To: <4A93B576.1050408@apache.org>
References: <4A8D281B.9070006@apache.org> <4A8D8D3D.5070404@yahoo-inc.com> 
	<4A926E92.8080303@apache.org> <D15A2AC3-67B1-43E7-B4AD-DEC706A5B699@cse.unl.edu> 
	<4A93B576.1050408@apache.org>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Tue, 25 Aug 2009 08:59:19 -0700
Message-ID: <c7d45fc70908250859u43222c7ej451de231f8dfd2aa@mail.gmail.com>
Subject: Re: NN memory consumption on 0.20/0.21 with compressed pointers/
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd62c90f842ed0471f96bdf
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd62c90f842ed0471f96bdf
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

On Tue, Aug 25, 2009 at 2:57 AM, Steve Loughran <stevel@apache.org> wrote:

> On petascale-level computers, the application codes' CPU instructions are
>> about 10% floating point (that is, in scientific applications, there are
>> less floating point instructions than in most floating point benchmarks).
>>  Of the remaining instructions, about 1/3 are memory-related and 2/3 are
>> integer.  Of the integer instructions, 40% are computing memory locations.
>>
>
> cool. I wonder what percentage is vtable/function lookup in OO code versus
> data retrieval? After all, every time you read or write an instance field in
> a class instance, there is the this+offset maths before the actual
> retrieval, though there is a fair amount of CPU support for such offset
> operations


Since the codes running on these machines tend to be matrix oriented
Fortran, I would expect almost all of this is array index computation.


>
>
>> So, on the biggest DOE computers, about 50% of the CPU time is spent on
>> memory-related computations.  I found this pretty mind-boggling when I
>> learned this.  It seems to me that the "central" part of the computer is
>> becoming the bus, not the CPU.
>>
>
> welcome to the new bottlenecks.
>

Comm ACM had a recent article in which the author measured (informally) the
throughput available for Disk, SSD and main memory with sequential and
random access patterns.  Sequential disk was slightly faster than random
access to main memory.

-- 
Ted Dunning, CTO
DeepDyve

--000e0cd62c90f842ed0471f96bdf--

From common-user-return-17061-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 16:28:31 2009
Return-Path: <common-user-return-17061-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 85390 invoked from network); 25 Aug 2009 16:28:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 16:28:31 -0000
Received: (qmail 88902 invoked by uid 500); 25 Aug 2009 16:28:53 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 88827 invoked by uid 500); 25 Aug 2009 16:28:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 88817 invoked by uid 500); 25 Aug 2009 16:28:53 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 88814 invoked by uid 99); 25 Aug 2009 16:28:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 16:28:53 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=FS_REPLICA,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of thkunkel@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 16:28:44 +0000
Received: by gxk27 with SMTP id 27so4085488gxk.12
        for <core-user@hadoop.apache.org>; Tue, 25 Aug 2009 09:28:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=xeXUEoa0pNaODH7gVnTQ9A1DzwqSF6VndbO0qPAqYHo=;
        b=fezNSNp6gFF3LI549LVZEGGQ8jpzm8zDwd0qo6phKQEAoJIrSnrcgLwBo0TrQZhnmu
         ayoanGsXCUl6zd65CaS3R+7UQl6nOXrOpw1elnsd+enPk0mS5shlF9UDZCLgtcBwvqng
         ldXQHu6AVinfJMfh5vBP1CMMIhJjZ5YFmB1UY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=B4n4yupeY4N6gMyC+MRB0cA9C0AYTYagYwjv0TVSTEZPGkNKCwOc9ehda7rTsxcKDS
         tO5Em7OcNKw1ugAcA2lNE44QNz0DoyqVQLUSMMYK8iXKdBNrDCUoaS7oi9TsK6Qa5G0v
         p/08dASXJByF+ZtrevMY5w/CszWFlSJpv7D1Q=
MIME-Version: 1.0
Received: by 10.90.10.1 with SMTP id 1mr5157706agj.62.1251217702735; Tue, 25 
	Aug 2009 09:28:22 -0700 (PDT)
Date: Tue, 25 Aug 2009 11:28:22 -0500
Message-ID: <8134a2730908250928y797b95b5mda7d894ba1adf907@mail.gmail.com>
Subject: Replication happens too many time when FTP to HDFS
From: Turner Kunkel <thkunkel@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Is there any way to set the replication to a specific number while
FTP-ing to the HDFS?
I have dfs.replication set to 2 on the nodes, but when I transfer
something via FTP to HDFS it replicates 3 times.

Thanks.
-- 

-Turner Kunkel

From common-user-return-17063-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 16:32:23 2009
Return-Path: <common-user-return-17063-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 86669 invoked from network); 25 Aug 2009 16:32:22 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 16:32:22 -0000
Received: (qmail 95958 invoked by uid 500); 25 Aug 2009 16:32:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95831 invoked by uid 500); 25 Aug 2009 16:32:41 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95813 invoked by uid 500); 25 Aug 2009 16:32:41 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 95806 invoked by uid 99); 25 Aug 2009 16:32:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 16:32:41 +0000
X-ASF-Spam-Status: No, hits=1.4 required=10.0
	tests=FS_REPLICA,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 16:32:32 +0000
Received: from pcp089108pcs.unl.edu (pcp089108pcs.unl.edu [129.93.158.223])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7PGVKVo009641
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT);
	Tue, 25 Aug 2009 11:32:08 -0500
Cc: core-user@hadoop.apache.org
Message-Id: <A173EBE1-F375-4B25-8580-046FE26437DC@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <8134a2730908250928y797b95b5mda7d894ba1adf907@mail.gmail.com>
Content-Type: multipart/signed; boundary=Apple-Mail-259-180304670; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: Replication happens too many time when FTP to HDFS
Date: Tue, 25 Aug 2009 11:32:07 -0500
References: <8134a2730908250928y797b95b5mda7d894ba1adf907@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-259-180304670
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Hey Turner,

Replication level is requested by the client.  You need to set the  
replication factor on the hadoop configuration of the client, not the  
nodes.

Brian

On Aug 25, 2009, at 11:28 AM, Turner Kunkel wrote:

> Is there any way to set the replication to a specific number while
> FTP-ing to the HDFS?
> I have dfs.replication set to 2 on the nodes, but when I transfer
> something via FTP to HDFS it replicates 3 times.
>
> Thanks.
> -- 
>
> -Turner Kunkel


--Apple-Mail-259-180304670
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-259-180304670--

From common-user-return-17062-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 16:32:23 2009
Return-Path: <common-user-return-17062-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 86662 invoked from network); 25 Aug 2009 16:32:22 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 16:32:22 -0000
Received: (qmail 95930 invoked by uid 500); 25 Aug 2009 16:32:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95829 invoked by uid 500); 25 Aug 2009 16:32:41 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95806 invoked by uid 99); 25 Aug 2009 16:32:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 16:32:41 +0000
X-ASF-Spam-Status: No, hits=1.4 required=10.0
	tests=FS_REPLICA,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 16:32:32 +0000
Received: from pcp089108pcs.unl.edu (pcp089108pcs.unl.edu [129.93.158.223])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7PGVKVo009641
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT);
	Tue, 25 Aug 2009 11:32:08 -0500
Cc: core-user@hadoop.apache.org
Message-Id: <A173EBE1-F375-4B25-8580-046FE26437DC@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <8134a2730908250928y797b95b5mda7d894ba1adf907@mail.gmail.com>
Content-Type: multipart/signed; boundary=Apple-Mail-259-180304670; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: Replication happens too many time when FTP to HDFS
Date: Tue, 25 Aug 2009 11:32:07 -0500
References: <8134a2730908250928y797b95b5mda7d894ba1adf907@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-259-180304670
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Hey Turner,

Replication level is requested by the client.  You need to set the  
replication factor on the hadoop configuration of the client, not the  
nodes.

Brian

On Aug 25, 2009, at 11:28 AM, Turner Kunkel wrote:

> Is there any way to set the replication to a specific number while
> FTP-ing to the HDFS?
> I have dfs.replication set to 2 on the nodes, but when I transfer
> something via FTP to HDFS it replicates 3 times.
>
> Thanks.
> -- 
>
> -Turner Kunkel


--Apple-Mail-259-180304670
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-259-180304670--

From common-user-return-17064-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 17:00:54 2009
Return-Path: <common-user-return-17064-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 97558 invoked from network); 25 Aug 2009 17:00:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 17:00:54 -0000
Received: (qmail 42997 invoked by uid 500); 25 Aug 2009 17:01:16 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 42915 invoked by uid 500); 25 Aug 2009 17:01:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 42905 invoked by uid 500); 25 Aug 2009 17:01:16 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 42902 invoked by uid 99); 25 Aug 2009 17:01:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 17:01:16 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=FS_REPLICA,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 17:01:06 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MfzO1-0005dq-PQ
	for core-user@hadoop.apache.org; Tue, 25 Aug 2009 10:00:45 -0700
Message-ID: <25138298.post@talk.nabble.com>
Date: Tue, 25 Aug 2009 10:00:45 -0700 (PDT)
From: thkunkel <thkunkel@gmail.com>
To: core-user@hadoop.apache.org
Subject: Re: Replication happens too many time when FTP to HDFS
In-Reply-To: <A173EBE1-F375-4B25-8580-046FE26437DC@cse.unl.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: thkunkel@gmail.com
References: <8134a2730908250928y797b95b5mda7d894ba1adf907@mail.gmail.com> <A173EBE1-F375-4B25-8580-046FE26437DC@cse.unl.edu>
X-Virus-Checked: Checked by ClamAV on apache.org


Gotcha, thanks.

Any idea how to do that on a Windows machine?  My Hadoop cluster is on 3
Ubuntu nodes, but I'm transferring data from a bunch of Windows servers.  Or
can I configure replication in the FTP client itself?

-Turner


Brian Bockelman wrote:
> 
> Hey Turner,
> 
> Replication level is requested by the client.  You need to set the  
> replication factor on the hadoop configuration of the client, not the  
> nodes.
> 
> Brian
> 
> On Aug 25, 2009, at 11:28 AM, Turner Kunkel wrote:
> 
>> Is there any way to set the replication to a specific number while
>> FTP-ing to the HDFS?
>> I have dfs.replication set to 2 on the nodes, but when I transfer
>> something via FTP to HDFS it replicates 3 times.
>>
>> Thanks.
>> -- 
>>
>> -Turner Kunkel
> 
> 
>  
> 

-- 
View this message in context: http://www.nabble.com/Replication-happens-too-many-time-when-FTP-to-HDFS-tp25137745p25138298.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-17065-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 17:33:47 2009
Return-Path: <common-user-return-17065-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 12975 invoked from network); 25 Aug 2009 17:33:47 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 17:33:47 -0000
Received: (qmail 88627 invoked by uid 500); 25 Aug 2009 17:34:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 88554 invoked by uid 500); 25 Aug 2009 17:34:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 88544 invoked by uid 99); 25 Aug 2009 17:34:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 17:34:10 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 17:33:59 +0000
Received: from SNV-EXPF01.ds.corp.yahoo.com (snv-expf01.ds.corp.yahoo.com [207.126.227.250])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7PHUsax099983
	for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 10:30:55 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=oB6tTDQC2b94gFgpI74wF1kF/RC36IrAOJbt+LjkSZ00M5Lz6zAFwA2IPMNa+8PM
Received: from SNV-EXVS08.ds.corp.yahoo.com ([207.126.227.8]) by SNV-EXPF01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Tue, 25 Aug 2009 10:30:53 -0700
Received: from 10.66.100.51 ([10.66.100.51]) by SNV-EXVS08.ds.corp.yahoo.com ([207.126.227.58]) with Microsoft Exchange Server HTTP-DAV ;
 Tue, 25 Aug 2009 17:30:53 +0000
User-Agent: Microsoft-Entourage/12.20.0.090605
Date: Tue, 25 Aug 2009 23:00:53 +0530
Subject: Re: How to speed up the copy phrase?
From: Jothi Padmanabhan <jothipn@yahoo-inc.com>
To: <common-user@hadoop.apache.org>
Message-ID: <C6BA1DA5.1CEF4%jothipn@yahoo-inc.com>
Thread-Topic: How to speed up the copy phrase?
Thread-Index: Acolqcuok/3yHHnOgkKk/5FATrkTeQ==
In-Reply-To: <73d592f60908241953i1c7d1ce1s2e80bf770370b3c3@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-OriginalArrivalTime: 25 Aug 2009 17:30:53.0739 (UTC) FILETIME=[CC1947B0:01CA25A9]
X-Virus-Checked: Checked by ClamAV on apache.org

It is fairly straight forward, on completion of a successful fetch, the
total amount of bytes fetched is divided by the total time taken till then.

Please look at fetchOutputs method in ReduceTask.java, the portion of code
that handles successful copies.

Jothi


On 8/25/09 8:23 AM, "bharath vissapragada"
<bharathvissapragada1990@gmail.com> wrote:

> Jothi ,
> 
> Do have any idea , how thease speeds are calculated , I mean some
> mathematical expressions or stuff.
> 
> On Mon, Aug 24, 2009 at 12:54 PM, Jothi Padmanabhan
> <jothipn@yahoo-inc.com>wrote:
> 
>> The transfer rate is a little misleading. The timer for this calculation
>> starts when the reducer itself starts and so includes the time spent by the
>> reducer waiting for maps to complete. So, the speed shown when shuffling
>> the
>> first few maps might be totally misleading, it does not necessarily reflect
>> the network speed. You should be able to see more reasonable numbers
>> towards
>> the end of shuffle.
>> 
>> Jothi
>> 
>> 
>> On 8/24/09 12:19 PM, "yang song" <hadoop.inifok@gmail.com> wrote:
>> 
>>> Hello, everyone
>>> 
>>> When I submit a big job(e.g. maptasks:10000, reducetasks:500), I find
>> that
>>> the copy phrase will last for a long long time. From WebUI, the message
>>> "reduce > copy (xxxx of 10000 at 0.01 MB/s) >" tells me the transfer
>> speed
>>> is just 0.01 MB/s. Does it a regular value? How can I solve it?
>>> 
>>> Thank you!
>>> 
>>> P.S. The hadoop version is 0.19.1. The cluster has 20 nodes. Heap size of
>> JT
>>> is 6G while the     others are default settings.
>> 
>> 


From common-user-return-17066-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 18:32:46 2009
Return-Path: <common-user-return-17066-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 55296 invoked from network); 25 Aug 2009 18:32:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 18:32:46 -0000
Received: (qmail 89554 invoked by uid 500); 25 Aug 2009 18:33:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 89456 invoked by uid 500); 25 Aug 2009 18:33:08 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 89446 invoked by uid 99); 25 Aug 2009 18:33:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 18:33:08 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of edlinuxguru@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 18:33:00 +0000
Received: by bwz10 with SMTP id 10so2139484bwz.29
        for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 11:32:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=IK8BmLhZoF9q438toOeqLndqenTAEF/bIoCMDJGGC+0=;
        b=cjg7GS7/MNrcODGqhmpzVnp1U8Azl1UiMzBwkEcLMO7wy9fPIZBd7UtKRzlOVRMp/3
         PWimIesCT5HjBbua1wPDAmZHsfP39AuT6Sl/s+98mRkj8PJKW1Hh+wvr+genWpl805bd
         WnSbnW8/htBHYowF7eBBJtSVamKOonWBgC4zk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=hvKUB66SK6UMAcoXXzFT3C6+eZ0TCT/sVBewuvuYvLOfZNn44eTzdujBJtMyl3Je5w
         ohzMO9D+Y1yrzT4t0VPMujyN3S73fqI3MS+j1vTMmjsKnghhxRMsV1S8xGxt0Tu4nfjx
         6sDZsn0BYKg56P+Z5dESay/JWKIVHgp8W7K0w=
MIME-Version: 1.0
Received: by 10.239.143.214 with SMTP id l22mr648726hba.167.1251225158403; 
	Tue, 25 Aug 2009 11:32:38 -0700 (PDT)
In-Reply-To: <c7d45fc70908250859u43222c7ej451de231f8dfd2aa@mail.gmail.com>
References: <4A8D281B.9070006@apache.org> <4A8D8D3D.5070404@yahoo-inc.com>
	 <4A926E92.8080303@apache.org>
	 <D15A2AC3-67B1-43E7-B4AD-DEC706A5B699@cse.unl.edu>
	 <4A93B576.1050408@apache.org>
	 <c7d45fc70908250859u43222c7ej451de231f8dfd2aa@mail.gmail.com>
Date: Tue, 25 Aug 2009 14:32:38 -0400
Message-ID: <cbbf4b570908251132l21cd83a7i2e9ea83160b48943@mail.gmail.com>
Subject: Re: NN memory consumption on 0.20/0.21 with compressed pointers/
From: Edward Capriolo <edlinuxguru@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

On Tue, Aug 25, 2009 at 11:59 AM, Ted Dunning<ted.dunning@gmail.com> wrote:
> On Tue, Aug 25, 2009 at 2:57 AM, Steve Loughran <stevel@apache.org> wrote=
:
>
>> On petascale-level computers, the application codes' CPU instructions ar=
e
>>> about 10% floating point (that is, in scientific applications, there ar=
e
>>> less floating point instructions than in most floating point benchmarks=
).
>>> =A0Of the remaining instructions, about 1/3 are memory-related and 2/3 =
are
>>> integer. =A0Of the integer instructions, 40% are computing memory locat=
ions.
>>>
>>
>> cool. I wonder what percentage is vtable/function lookup in OO code vers=
us
>> data retrieval? After all, every time you read or write an instance fiel=
d in
>> a class instance, there is the this+offset maths before the actual
>> retrieval, though there is a fair amount of CPU support for such offset
>> operations
>
>
> Since the codes running on these machines tend to be matrix oriented
> Fortran, I would expect almost all of this is array index computation.
>
>
>>
>>
>>> So, on the biggest DOE computers, about 50% of the CPU time is spent on
>>> memory-related computations. =A0I found this pretty mind-boggling when =
I
>>> learned this. =A0It seems to me that the "central" part of the computer=
 is
>>> becoming the bus, not the CPU.
>>>
>>
>> welcome to the new bottlenecks.
>>
>
> Comm ACM had a recent article in which the author measured (informally) t=
he
> throughput available for Disk, SSD and main memory with sequential and
> random access patterns. =A0Sequential disk was slightly faster than rando=
m
> access to main memory.
>
> --
> Ted Dunning, CTO
> DeepDyve
>

Warning!

If you decide to switch to 1.6.0u15 with 18.3 you are going to get a
task tracker crash. An odd silent error that appears in logs but does
not manifest itself in a failed status with hadoop. Logs will show:

Exception in thread "main" java.lang.NoClassDefFoundError:
Could_not_reserve_enough_space_for_object_heap
Caused by: java.lang.ClassNotFoundException:
Could_not_reserve_enough_space_for_object_heap
	at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:252)
	at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:320)
Could not find the main class:
Could_not_reserve_enough_space_for_object_heap.  Program will exit.

Issue is :  HADOOP-5564

Fix is here: http://www.koopman.me/2009/04/hadoop-0183-could-not-create-the=
-java-virtual-machine/

From common-user-return-17067-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 19:51:55 2009
Return-Path: <common-user-return-17067-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 82332 invoked from network); 25 Aug 2009 19:51:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 19:51:55 -0000
Received: (qmail 14371 invoked by uid 500); 25 Aug 2009 19:52:18 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 14302 invoked by uid 500); 25 Aug 2009 19:52:18 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 14292 invoked by uid 99); 25 Aug 2009 19:52:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 19:52:18 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.216.191 is neither permitted nor denied by domain of kjirapinyo@biz360.com)
Received: from [209.85.216.191] (HELO mail-px0-f191.google.com) (209.85.216.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 19:52:09 +0000
Received: by pxi29 with SMTP id 29so6077261pxi.30
        for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 12:51:47 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.141.41.5 with SMTP id t5mr2974910rvj.286.1251229907070; Tue, 
	25 Aug 2009 12:51:47 -0700 (PDT)
From: Kris Jirapinyo <kjirapinyo@biz360.com>
Date: Tue, 25 Aug 2009 12:51:27 -0700
Message-ID: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com>
Subject: Intra-datanode balancing?
To: common-user <common-user@hadoop.apache.org>
Content-Type: multipart/alternative; boundary=000e0cd146a424b0e70471fcaaff
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd146a424b0e70471fcaaff
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi all,
    I know this has been filed as a JIRA improvement already
http://issues.apache.org/jira/browse/HDFS-343, but is there any good
workaround at the moment?  What's happening is I have added a few new EBS
volumes to half of the cluster, but Hadoop doesn't want to write to them.
When I try to do cluster rebalancing, since the new disks make the
percentage used lower, it fills up the first two existing local disks, which
is exactly what I don't want to happen.  Currently, I just delete several
subdirs from dfs, since I know that with a replication factor of 3, it'll be
ok, so that fixes the problems in the short term.  But I still cannot get
Hadoop to use those new larger disks efficiently.  Any thoughts?

-- Kris.

--000e0cd146a424b0e70471fcaaff--

From common-user-return-17068-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 20:16:51 2009
Return-Path: <common-user-return-17068-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 88542 invoked from network); 25 Aug 2009 20:16:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 20:16:50 -0000
Received: (qmail 43434 invoked by uid 500); 25 Aug 2009 20:17:13 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 43351 invoked by uid 500); 25 Aug 2009 20:17:13 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 43341 invoked by uid 99); 25 Aug 2009 20:17:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 20:17:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.dunning@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 20:17:04 +0000
Received: by gxk27 with SMTP id 27so4325803gxk.12
        for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 13:16:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=Nd2VU714DlU7d3uoVUe5PmolyQn2EjAZ7zMQNS7GIIc=;
        b=TtivTt00Jb5caYkBZ+EVKd9YqIhw05OY11wf8p2C9W82a/je31caFg5fO7u6UOGf0t
         KLMqcpUTRnL38jDzyV3ba/0Wc0JGFn86B/QDDsvSWM4CKzNFq7MzzKuT1k/uzoymlNtv
         QdSpcUCdDIuTfudPeJ2CzHV7p+GdrxhI2fPs4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=xH/YkWMMZLp/ufIU/ll1InkSe5VpJUI/CGec1BfTztmTcLrZ5/Dl4+Q9T1aADATBBr
         em/v1/DjWown4uU1+f75MpaKNXBeppm6DoypqLoqEtOuPF7LO9YsuD8LA+Isv2kQvcSs
         Sl+1+bZBONzjtvNJkgKnScAH1D9l6x/UDf7ac=
MIME-Version: 1.0
Received: by 10.150.160.10 with SMTP id i10mr11320974ybe.186.1251231403141; 
	Tue, 25 Aug 2009 13:16:43 -0700 (PDT)
In-Reply-To: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com>
References: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Tue, 25 Aug 2009 13:16:23 -0700
Message-ID: <c7d45fc70908251316u1bfc97c7l6677d4d2fb6ebc93@mail.gmail.com>
Subject: Re: Intra-datanode balancing?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cdf1b5650edc00471fd038e
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cdf1b5650edc00471fd038e
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Change the ordering of the volumes in the ocnfig files.

On Tue, Aug 25, 2009 at 12:51 PM, Kris Jirapinyo <kjirapinyo@biz360.com>wrote:

> Hi all,
>    I know this has been filed as a JIRA improvement already
> http://issues.apache.org/jira/browse/HDFS-343, but is there any good
> workaround at the moment?  What's happening is I have added a few new EBS
> volumes to half of the cluster, but Hadoop doesn't want to write to them.
> When I try to do cluster rebalancing, since the new disks make the
> percentage used lower, it fills up the first two existing local disks,
> which
> is exactly what I don't want to happen.  Currently, I just delete several
> subdirs from dfs, since I know that with a replication factor of 3, it'll
> be
> ok, so that fixes the problems in the short term.  But I still cannot get
> Hadoop to use those new larger disks efficiently.  Any thoughts?
>
> -- Kris.
>



-- 
Ted Dunning, CTO
DeepDyve

--000e0cdf1b5650edc00471fd038e--

From common-user-return-17069-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 20:26:26 2009
Return-Path: <common-user-return-17069-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 91160 invoked from network); 25 Aug 2009 20:26:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 20:26:26 -0000
Received: (qmail 55133 invoked by uid 500); 25 Aug 2009 20:26:49 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 55071 invoked by uid 500); 25 Aug 2009 20:26:48 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 55061 invoked by uid 99); 25 Aug 2009 20:26:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 20:26:48 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.216.191 is neither permitted nor denied by domain of kjirapinyo@biz360.com)
Received: from [209.85.216.191] (HELO mail-px0-f191.google.com) (209.85.216.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 20:26:39 +0000
Received: by pxi29 with SMTP id 29so6097130pxi.30
        for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 13:26:18 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.187.21 with SMTP id k21mr3158797rvf.274.1251231978093; 
	Tue, 25 Aug 2009 13:26:18 -0700 (PDT)
In-Reply-To: <c7d45fc70908251316u1bfc97c7l6677d4d2fb6ebc93@mail.gmail.com>
References: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com> 
	<c7d45fc70908251316u1bfc97c7l6677d4d2fb6ebc93@mail.gmail.com>
From: Kris Jirapinyo <kris.jirapinyo@biz360.com>
Date: Tue, 25 Aug 2009 13:25:58 -0700
Message-ID: <42a1925b0908251325w2575567awf75b65826818d7b1@mail.gmail.com>
Subject: Re: Intra-datanode balancing?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd2959a9604a40471fd25ce
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd2959a9604a40471fd25ce
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

The order matters?

On Tue, Aug 25, 2009 at 1:16 PM, Ted Dunning <ted.dunning@gmail.com> wrote:

> Change the ordering of the volumes in the ocnfig files.
>
> On Tue, Aug 25, 2009 at 12:51 PM, Kris Jirapinyo <kjirapinyo@biz360.com
> >wrote:
>
> > Hi all,
> >    I know this has been filed as a JIRA improvement already
> > http://issues.apache.org/jira/browse/HDFS-343, but is there any good
> > workaround at the moment?  What's happening is I have added a few new EBS
> > volumes to half of the cluster, but Hadoop doesn't want to write to them.
> > When I try to do cluster rebalancing, since the new disks make the
> > percentage used lower, it fills up the first two existing local disks,
> > which
> > is exactly what I don't want to happen.  Currently, I just delete several
> > subdirs from dfs, since I know that with a replication factor of 3, it'll
> > be
> > ok, so that fixes the problems in the short term.  But I still cannot get
> > Hadoop to use those new larger disks efficiently.  Any thoughts?
> >
> > -- Kris.
> >
>
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>

--000e0cd2959a9604a40471fd25ce--

From common-user-return-17070-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 20:37:15 2009
Return-Path: <common-user-return-17070-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 94752 invoked from network); 25 Aug 2009 20:37:15 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 20:37:15 -0000
Received: (qmail 70538 invoked by uid 500); 25 Aug 2009 20:37:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 70461 invoked by uid 500); 25 Aug 2009 20:37:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 70436 invoked by uid 99); 25 Aug 2009 20:37:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 20:37:37 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ted.dunning@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 20:37:29 +0000
Received: by gxk27 with SMTP id 27so4347759gxk.12
        for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 13:37:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=JCAX/xmEq14jJqlMcBEKBKHUKXnvZzZXSlr6XPwNkB8=;
        b=xXy/2QOrFk9x5HiWe6+QSHmt73HU+aTLKoBllNL2mnjGQMMb3+ePUZd21hFOl7iTvq
         wr8oY72cy8QmS4jVyZMB7cuzvzp4ArJeCN0ZFuxFUgY4KFO41q7wlpLJWh3dNRcGD0U9
         Z8yz/DW1iD71HRRlXcX4c3aGyCEwb5CN72fnE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=V/NcMDOAhhPBGOjY1HYV2cuY1FXJbcUuxu8VdvjrwnvbO8WrE6E0tOjRbihqvR6lSO
         8yk2v54AIHVpZ95sOV9YKK84IJLhf2xwmvWa5LC5xiHYaOWnYtM+sACwmmzOwldGUszp
         eCpPWndjn8mP0ivIN+bll+vkuwikhminyeYGA=
MIME-Version: 1.0
Received: by 10.150.36.1 with SMTP id j1mr10002933ybj.321.1251232629089; Tue, 
	25 Aug 2009 13:37:09 -0700 (PDT)
In-Reply-To: <42a1925b0908251325w2575567awf75b65826818d7b1@mail.gmail.com>
References: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com> 
	<c7d45fc70908251316u1bfc97c7l6677d4d2fb6ebc93@mail.gmail.com> 
	<42a1925b0908251325w2575567awf75b65826818d7b1@mail.gmail.com>
From: Ted Dunning <ted.dunning@gmail.com>
Date: Tue, 25 Aug 2009 13:36:49 -0700
Message-ID: <c7d45fc70908251336n7aeaa025r2660dd36514cef6f@mail.gmail.com>
Subject: Re: Intra-datanode balancing?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd6b1066365740471fd4c7a
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd6b1066365740471fd4c7a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

It used to matter quite a lot.

On Tue, Aug 25, 2009 at 1:25 PM, Kris Jirapinyo
<kris.jirapinyo@biz360.com>wrote:

> The order matters?
>
>

--000e0cd6b1066365740471fd4c7a--

From common-user-return-17071-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 21:13:58 2009
Return-Path: <common-user-return-17071-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 9545 invoked from network); 25 Aug 2009 21:13:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 21:13:58 -0000
Received: (qmail 13659 invoked by uid 500); 25 Aug 2009 21:14:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 13582 invoked by uid 500); 25 Aug 2009 21:14:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 13572 invoked by uid 99); 25 Aug 2009 21:14:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 21:14:20 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 21:14:12 +0000
Received: by iwn6 with SMTP id 6so1453243iwn.5
        for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 14:13:50 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.231.13.69 with SMTP id b5mr3352458iba.40.1251234830721; Tue, 
	25 Aug 2009 14:13:50 -0700 (PDT)
In-Reply-To: <c7d45fc70908251316u1bfc97c7l6677d4d2fb6ebc93@mail.gmail.com>
References: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com>
	 <c7d45fc70908251316u1bfc97c7l6677d4d2fb6ebc93@mail.gmail.com>
Date: Tue, 25 Aug 2009 14:13:50 -0700
Message-ID: <623d9cf40908251413l1fa002a5oe779acc612026573@mail.gmail.com>
Subject: Re: Intra-datanode balancing?
From: Alex Loddengaard <alex@cloudera.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=002215046cab9da2830471fdcf52
X-Virus-Checked: Checked by ClamAV on apache.org

--002215046cab9da2830471fdcf52
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Changing the ordering of dfs.data.dir won't change anything, because
dfs.data.dir is written to in a round-robin fashion.

Kris, I think you're stuck with the hack you're performing :(.  Sorry I
don't have better news.

Alex

On Tue, Aug 25, 2009 at 1:16 PM, Ted Dunning <ted.dunning@gmail.com> wrote:

> Change the ordering of the volumes in the ocnfig files.
>
> On Tue, Aug 25, 2009 at 12:51 PM, Kris Jirapinyo <kjirapinyo@biz360.com
> >wrote:
>
> > Hi all,
> >    I know this has been filed as a JIRA improvement already
> > http://issues.apache.org/jira/browse/HDFS-343, but is there any good
> > workaround at the moment?  What's happening is I have added a few new EBS
> > volumes to half of the cluster, but Hadoop doesn't want to write to them.
> > When I try to do cluster rebalancing, since the new disks make the
> > percentage used lower, it fills up the first two existing local disks,
> > which
> > is exactly what I don't want to happen.  Currently, I just delete several
> > subdirs from dfs, since I know that with a replication factor of 3, it'll
> > be
> > ok, so that fixes the problems in the short term.  But I still cannot get
> > Hadoop to use those new larger disks efficiently.  Any thoughts?
> >
> > -- Kris.
> >
>
>
>
> --
> Ted Dunning, CTO
> DeepDyve
>

--002215046cab9da2830471fdcf52--

From common-user-return-17072-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 23:21:23 2009
Return-Path: <common-user-return-17072-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 91484 invoked from network); 25 Aug 2009 23:21:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 23:21:23 -0000
Received: (qmail 75832 invoked by uid 500); 25 Aug 2009 23:21:39 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 75715 invoked by uid 500); 25 Aug 2009 23:21:39 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 75420 invoked by uid 500); 25 Aug 2009 23:21:38 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 75293 invoked by uid 99); 25 Aug 2009 23:21:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 23:21:38 +0000
X-ASF-Spam-Status: No, hits=0.0 required=10.0
	tests=HS_INDEX_PARAM,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bradfordstephens@gmail.com designates 209.85.211.177 as permitted sender)
Received: from [209.85.211.177] (HELO mail-yw0-f177.google.com) (209.85.211.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 23:21:28 +0000
Received: by ywh7 with SMTP id 7so4688258ywh.21
        for <multiple recipients>; Tue, 25 Aug 2009 16:21:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=5irSznTvdYtk+2bFn3BYOLjkC1jvi1Q5RHBTobSxp+M=;
        b=PrGFxW+B62fWzEK+sKyYVBEM42FOR0QWx0IwOd44LDuhTh4Yi7i+eVABUQDxMfAHEI
         tCvRBoFRpL25Vu/XI6ihy3diRKbRdBDMcxL7jLbk3VnlLHEg50S5MGoBnTlRJ229nDpo
         WJv07dcUIvqlIidrMeVHVjpXYziA0nxdWpAoI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=dNev73AKfJvyMCdMp9g7cZe7j4PXu1w1DdJfxsbxA5ohrVch2VYH+cxEp6ZvOgelbJ
         5wai+N8LDXo0axYausF2apYSREikdsIIxOrpG76wwUWlXYrawQhPzlFlDY2hQbFfNHoP
         fv4qfAL0VY6nMUQb88oWQh913gm3nqpQZTw1w=
MIME-Version: 1.0
Received: by 10.90.18.33 with SMTP id 33mr5433631agr.113.1251242467885; Tue, 
	25 Aug 2009 16:21:07 -0700 (PDT)
Date: Tue, 25 Aug 2009 16:21:07 -0700
Message-ID: <860544ed0908251621leacbe9andc4daefdabb8d62b@mail.gmail.com>
Subject: Seattle / NW Hadoop, HBase Lucene, etc. Meetup , Wed August 26th, 
	6:45pm
From: Bradford Stephens <bradfordstephens@gmail.com>
To: core-user@hadoop.apache.org, hbase-user@hadoop.apache.org, 
	solr-user@lucene.apache.org, java-user@lucene.apache.org, 
	pig-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hey there,

Apologies for this not going out sooner -- apparently it was sitting
as a draft in my inbox. A few of you have pinged me, so thanks for
your vigilance.

It's time for another Hadoop/Lucene/Apache Stack meetup! We've had
great attendance in the past few months, let's keep it up! I'm always
amazed by the things I learn from everyone.

We're back at the University of Washington, Allen Computer Science
Center (not Computer Engineering)
Map: http://www.washington.edu/home/maps/?CSE

Room: 303 -or- the Entry level. If there are changes, signs will be posted.

More Info:

The meetup is about 2 hours: we'll have two in-depth talks of 15-20
minutes each, and then several "lightning talks" of 5 minutes. If no
one offers, We'll then have discussion and 'social time'.=A0 we'll just
have general discussion. Let net know if you're interested in speaking
or attending. We'd like to focus on education, so every presentation
*needs* to ask some questions at the end. We can talk about these
after the presentations, and I'll record what we've learned in a wiki
and share that with the rest of us.

Contact: Bradford Stephens, 904-415-3009, bradfordstephens@gmail.com

--
http://www.roadtofailure.com -- The Fringes of Scalability, Social
Media, and Computer Science

From common-user-return-17073-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 23:33:42 2009
Return-Path: <common-user-return-17073-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 95747 invoked from network); 25 Aug 2009 23:33:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 23:33:42 -0000
Received: (qmail 89399 invoked by uid 500); 25 Aug 2009 23:34:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 89236 invoked by uid 500); 25 Aug 2009 23:34:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 88942 invoked by uid 99); 25 Aug 2009 23:34:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 23:34:01 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 23:33:35 +0000
Received: from SNV-EXBH01.ds.corp.yahoo.com (snv-exbh01.ds.corp.yahoo.com [207.126.227.249])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7PNXDb2069761
	for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 16:33:13 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=RxvU9pVLLg4sg6/DK+mtEEvBgAAp1nseyPhjoloiIZzy6/zNS30Zrc7MXx8M8iKP
Received: from SNV-EXVS02.ds.corp.yahoo.com ([216.145.51.202]) by SNV-EXBH01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Tue, 25 Aug 2009 16:33:12 -0700
Received: from 172.21.149.23 ([172.21.149.23]) by SNV-EXVS02.ds.corp.yahoo.com ([216.145.51.163]) via Exchange Front-End Server snv-webmail.corp.yahoo.com ([207.126.227.247]) with Microsoft Exchange Server HTTP-DAV ;
 Tue, 25 Aug 2009 23:33:12 +0000
User-Agent: Microsoft-Entourage/12.19.0.090515
Date: Tue, 25 Aug 2009 16:33:12 -0700
Subject: Re: Getting free space percentage on DFS
From: Boris Shkolnik <borya@yahoo-inc.com>
To: <common-user@hadoop.apache.org>
Message-ID: <C6B9C2C8.1FE6C%borya@yahoo-inc.com>
Thread-Topic: Getting free space percentage on DFS
Thread-Index: Acol3GkccGdQaQIELUqQqQn2DOjRXg==
In-Reply-To: <77938bc20908240127g63639b19mc2db15a037106cd5@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-OriginalArrivalTime: 25 Aug 2009 23:33:12.0719 (UTC) FILETIME=[698A61F0:01CA25DC]
X-Virus-Checked: Checked by ClamAV on apache.org


For JMX you can also look at JMXGet.java class. You can use this object to
get the data thru JMX.

Boris

On 8/24/09 1:27 AM, "Stas Oskin" <stas.oskin@gmail.com> wrote:

> Hi.
> 
> One way you can do this is thought JMX.
>> 
>> 
>> http://www.jointhegrid.com/svn/hadoop-cacti-jtg/trunk/src/com/jointhegrid/had
>> oopjmx/NameNodeStatistics.java
>> 
>> That is part of a cacti graphing application for hadoop I wrote
>> (http://www.jointhegrid.com/hadoop/)
>> 
>> Enjoy,
>> 
> 
> I'm going to try this next - you probably meant these links?
> 
> http://www.jointhegrid.com/svn/hadoop-cacti-jtg/trunk/src/com/jointhegrid/hado
> opjmx/FSNamesystemStatus.java
> 
> http://www.jointhegrid.com/svn/hadoop-cacti-jtg/trunk/src/com/jointhegrid/hado
> opjmx/FSDatasetStatus.java
> (inherits
> http://www.jointhegrid.com/svn/hadoop-cacti-jtg/trunk/src/com/jointhegrid/hado
> opjmx/JMXBase.java
> )


From common-user-return-17074-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Tue Aug 25 23:47:38 2009
Return-Path: <common-user-return-17074-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 99768 invoked from network); 25 Aug 2009 23:47:38 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 25 Aug 2009 23:47:38 -0000
Received: (qmail 2054 invoked by uid 500); 25 Aug 2009 23:48:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 1965 invoked by uid 500); 25 Aug 2009 23:48:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 1955 invoked by uid 99); 25 Aug 2009 23:48:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 23:48:00 +0000
X-ASF-Spam-Status: No, hits=-2.2 required=10.0
	tests=MIME_QP_LONG_LINE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of awittenauer@linkedin.com designates 69.28.149.24 as permitted sender)
Received: from [69.28.149.24] (HELO esv4-mav02.corp.linkedin.com) (69.28.149.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 25 Aug 2009 23:47:50 +0000
DomainKey-Signature: s=prod; d=linkedin.com; c=nofws; q=dns;
  h=X-IronPort-AV:Received:User-Agent:Date:Subject:From:To:
   Message-ID:Thread-Topic:Thread-Index:In-Reply-To:
   Mime-version:Content-type:Content-transfer-encoding;
  b=Z19wRNeZ/+jzYDOwX4U2961XmX2VIqoFOz7Dsa8MGhVIuWxx3TeelqCI
   HUOb+UihOnYJjCXYkozP3IpoUlDUV6TvRsFgDpuLUODFal/7sGqZgKZi5
   +KJgi/jWBztZ+Vt;
DKIM-Signature: v=1; a=rsa-sha256; c=simple/simple;
  d=linkedin.com; i=awittenauer@linkedin.com; q=dns/txt;
  s=proddkim; t=1251244070; x=1282780070;
  h=from:sender:reply-to:subject:date:message-id:to:cc:
   mime-version:content-transfer-encoding:content-id:
   content-description:resent-date:resent-from:resent-sender:
   resent-to:resent-cc:resent-message-id:in-reply-to:
   references:list-id:list-help:list-unsubscribe:
   list-subscribe:list-post:list-owner:list-archive;
  z=From:=20Allen=20Wittenauer=20<awittenauer@linkedin.com>
   |Subject:=20Re:=20Help.|Date:=20Tue,=2025=20Aug=202009=20
   16:47:28=20-0700|Message-ID:=20<C6B9C620.94%awittenauer@l
   inkedin.com>|To:=20<common-user@hadoop.apache.org>
   |Mime-version:=201.0|Content-transfer-encoding:=20quoted-
   printable|In-Reply-To:=20<d6d7c4410908250126ic9a8f22wc8ab
   e41d99c7d705@mail.gmail.com>;
  bh=p8GryMT9c9O7eFFXPDBrHILbHbaE3deSpyi9SN91Ygg=;
  b=TR0AHClKjoPDdI1m4o3EtTjHLR/LjTQVocV/NK0iW14IWviPM6GtWQW+
   tQ5zuprIdRAV6NEosbG9sOcEBjPKN3xy7YDZouNOGQx1tAaqUlM5A6w1a
   xAyATcgd9harXnE;
X-IronPort-AV: E=Sophos;i="4.44,275,1249282800"; 
   d="scan'208";a="8604419"
Received: from 172.16.19.135 ([172.16.19.135]) by CORP-MAIL.linkedin.biz ([172.18.46.135]) via Exchange Front-End Server mail-access.linkedin.biz ([172.18.46.133]) with Microsoft Exchange Server HTTP-DAV ;
 Tue, 25 Aug 2009 23:47:29 +0000
User-Agent: Microsoft-Entourage/12.10.0.080409
Date: Tue, 25 Aug 2009 16:47:28 -0700
Subject: Re: Help.
From: Allen Wittenauer <awittenauer@linkedin.com>
To: <common-user@hadoop.apache.org>
Message-ID: <C6B9C620.94%awittenauer@linkedin.com>
Thread-Topic: Help.
Thread-Index: Acol3mdTnA3zuDtyQEuPQWIVX1fUWA==
In-Reply-To: <d6d7c4410908250126ic9a8f22wc8abe41d99c7d705@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="GB2312"
Content-transfer-encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org


I'm also suspecting that this error can be triggered by using IPMP on
Solaris and other tricks that cause multiple nics on the host to be
represented. =20

[It doesn't appear that one can force traffic outbound on a specific nic, s=
o
when the data node does the block report to the data node it can be sent
over any of its available nics.  Since Hadoop uses IPs to keep track of suc=
h
things internally, it breaks.]

I just filed https://issues.apache.org/jira/browse/HADOOP-6210 as a result
of some of the quick tests we just ran.

On 8/25/09 1:26 AM, "Aaron Kimball" <aaron@cloudera.com> wrote:

> Are you trying to serve blocks from a shared directory e.g. NFS?
>=20
> The storageID for a node is recorded in a file named "VERSION" in
> ${dfs.data.dir}/current. If one node claims that the storage directory is
> already locked, and another node is reporting the first node's storageID,=
 it
> makes me think that you have multiple datanodes attempting to use the sam=
e
> shared directory for storage.
>=20
> This can't be done in Hadoop. Each datanode assumes it has sole access to=
 a
> storage directory. Besides, it defeats the point of using multiple datano=
des
> to distribute disk and network I/O :) If you're using NFS, reconfigure al=
l
> the datanodes to store blocks in local directories only (by moving
> dfs.data.dir) and try again.
>=20
> The mention of the namesecondary directory in there also makes me think t=
hat
> you're trying to start redundant copies of the secondarynamenode (e.g., b=
y
> listing the same node twice in the 'conf/masters' file) or that the
> fs.checkpoint.dir is the same as the dfs.data.dir. This also isn't allowe=
d
> -- dfs.data.dir, dfs.name.dir, and fs.checkpoint.dir must all refer to
> distinct physical locations.
>=20
> - Aaron
>=20
> On Fri, Aug 21, 2009 at 7:19 AM, Sujith Vellat <vtsujith@gmail.com> wrote=
:
>=20
>>=20
>>=20
>> Sent from my iPhone
>>=20
>>=20
>> On Aug 21, 2009, at 9:25 AM, Jason Venner <jason.hadoop@gmail.com> wrote=
:
>>=20
>>  It may be that the individual datanodes get different names for their i=
p
>>> addresses than the namenode does.
>>> It may also be that some subset of your namenode/datanodes do not have
>>> write
>>> access to the hdfs storage directories.
>>>=20
>>>=20
>>> On Mon, Aug 17, 2009 at 10:05 PM, qiu tian <tianqiu_527@yahoo.com.cn>
>>> wrote:
>>>=20
>>>  Hi everyone.
>>>> I installed hadoop among three pcs. When I ran the command
>>>> 'start-all.sh',
>>>> I only could start the jobtracker and tasktrackers. I use 192.*.*.x as
>>>> master and use 192.*.*.y and 192.*.*.z as slaves.
>>>>=20
>>>> The namenode log from the master 192.*.*.x is following like this:
>>>>=20
>>>> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK=
*
>>>> NameSystem.registerDatanode: node 192.*.*.y:50010 is replaced by
>>>> 192.*.*.x:50010 with the same storageID
>>>> DS-1120429845-127.0.0.1-50010-1246697164684
>>>> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology:
>>>> Removing a node: /default-rack/192.*.*.y:50010
>>>> 2009-08-18 10:48:44,543 INFO org.apache.hadoop.net.NetworkTopology:
>>>> Adding
>>>> a new node: /default-rack/192.*.*.x:50010
>>>> 2009-08-18 10:48:45,932 FATAL org.apache.hadoop.hdfs.StateChange: BLOC=
K*
>>>> NameSystem.getDatanode: Data node 192.*.*.z:50010 is attempting to rep=
ort
>>>> storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node
>>>> 192.*.*.x:50010
>>>> is expected to serve this storage.
>>>> 2009-08-18 10:48:45,932 INFO org.apache.hadoop.ipc.Server: IPC Server
>>>> handler 8 on 9000, call blockReport(DatanodeRegistration(192.*.*.z:500=
10,
>>>> storageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, infoPort=3D50075,
>>>> ipcPort=3D50020), [J@1b8ebe3) from 192.*.*.z:33177: error:
>>>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data no=
de
>>>> 192.*.*.z:50010 is attempting to report storage ID
>>>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>>>> expected to serve this storage.
>>>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data no=
de
>>>> 192.*.*.z:50010 is attempting to report storage ID
>>>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>>>> expected to serve this storage.
>>>>       at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDatanode(FSName=
syste
>>>> m.java:3800)
>>>>       at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport(FSNa=
mesys
>>>> tem.java:2771)
>>>>       at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.namenode.NameNode.blockReport(NameNode.j=
ava:6
>>>> 36)
>>>>       at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
>>>>       at
>>>>=20
>>>> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccess=
orImp
>>>> l.java:25)
>>>>       at java.lang.reflect.Method.invoke(Method.java:597)
>>>>       at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
>>>>       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)
>>>> 2009-08-18 10:48:46,398 FATAL org.apache.hadoop.hdfs.StateChange: BLOC=
K*
>>>> NameSystem.getDatanode: Data node 192.*.*.y:50010 is attempting to rep=
ort
>>>> storage ID DS-1120429845-127.0.0.1-50010-1246697164684. Node
>>>> 192.*.*.x:50010
>>>> is expected to serve this storage.
>>>> 2009-08-18 10:48:46,398 INFO org.apache.hadoop.ipc.Server: IPC Server
>>>> handler 0 on 9000, call
>>>> blockReport(DatanodeRegistration(192.9.200.y:50010,
>>>> storageID=3DDS-1120429845-127.0.0.1-50010-1246697164684, infoPort=3D50075,
>>>> ipcPort=3D50020), [J@186b634) from 192.*.*.y:47367: error:
>>>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data no=
de
>>>> 192.*.*.y:50010 is attempting to report storage ID
>>>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>>>> expected to serve this storage.
>>>> org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException: Data no=
de
>>>> 192.*.*.y:50010 is attempting to report storage ID
>>>> DS-1120429845-127.0.0.1-50010-1246697164684. Node 192.*.*.x:50010 is
>>>> expected to serve this storage.
>>>>       at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDatanode(FSName=
syste
>>>> m.java:3800)
>>>>       at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport(FSNa=
mesys
>>>> tem.java:2771)
>>>>       at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.namenode.NameNode.blockReport(NameNode.j=
ava:6
>>>> 36)
>>>>       at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
>>>>       at
>>>>=20
>>>> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccess=
orImp
>>>> l.java:25)
>>>>       at java.lang.reflect.Method.invoke(Method.java:597)
>>>>       at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
>>>>       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)
>>>> 2009-08-18 10:48:47,000 INFO
>>>> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log fro=
m
>>>> 192.*.*.x
>>>> ~
>>>>=20
>>>> The message on the shell looks like this:
>>>> 192.*.*.x: Exception in thread "main" java.io.IOException: Cannot lock
>>>> storage /home/gaojun/HadoopInstall/tmp/dfs/namesecondary. The director=
y
>>>> is
>>>> already locked.
>>>> 192.*.*.x:     at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Sto=
rage.
>>>> java:510)
>>>> 192.*.*.x:     at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeS=
torag
>>>> e(Storage.java:363)
>>>> 192.*.*.x:     at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointSto=
rage.
>>>> recoverCreate(SecondaryNameNode.java:517)
>>>> 192.*.*.x:     at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(Se=
conda
>>>> ryNameNode.java:145)
>>>> 192.*.*.x:     at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(Second=
aryNa
>>>> meNode.java:115)
>>>> 192.*.*.x:     at
>>>>=20
>>>> org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(Secondar=
yName
>>>> Node.java:469)
>>>>=20
>>>> I could not find the reason. Can someone help me?
>>>> Thanks!
>>>>=20
>>>> yan
>>>>=20
>>>>=20
>>>>=20
>>>>    ___________________________________________________________
>>>> =BA=C3=CD=E6=BA=D8=BF=A8=B5=C8=C4=E3=B7=A2=A3=AC=D3=CA=CF=E4=BA=D8=BF=A8=C8=AB=D0=C2=C9=CF=CF=DF=A3=A1
>>>> http://card.mail.cn.yahoo.com/
>>>>=20
>>>>=20
>>>=20
>>>=20
>>> --
>>> Pro Hadoop, a book to guide you from beginner to hadoop mastery,
>>> http://www.amazon.com/dp/1430219424?tag=3Djewlerymall
>>> www.prohadoopbook.com a community for Hadoop Professionals
>>>=20
>>=20


From common-user-return-17075-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 00:01:53 2009
Return-Path: <common-user-return-17075-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 3699 invoked from network); 26 Aug 2009 00:01:53 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 00:01:53 -0000
Received: (qmail 10394 invoked by uid 500); 26 Aug 2009 00:02:15 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10303 invoked by uid 500); 26 Aug 2009 00:02:15 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10293 invoked by uid 99); 26 Aug 2009 00:02:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 00:02:15 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [69.147.107.20] (HELO mrout1-b.corp.re1.yahoo.com) (69.147.107.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 00:02:04 +0000
Received: from [10.72.106.226] (heighthigh-lx.corp.yahoo.com [10.72.106.226])
	by mrout1-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7Q01ZtA000951
	for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 17:01:35 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=Thh27Tp3DdvSSvIpyf4p2duXdHrNv4kB2/+lLxESx5SCucgX//n5atl0yHMh8vcx
Message-ID: <4A947B5F.4080004@yahoo-inc.com>
Date: Tue, 25 Aug 2009 17:01:35 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.23 (Windows/20090812)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Intra-datanode balancing?
References: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com>
In-Reply-To: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


For now you are stuck with the hack. Sooner or later hadoop has to 
handle heterogeneous nodes better.

In general it tries to write to all the disks irrespective of % full 
since that gives the best performance (assuming each partition's 
capabilities are same). But it is lame at handling skews.

Regd your hack :
   1. You can copy subdir to new partition rather than deleting
      (datanodes should be shutdown).

   2. I would think it is less work to implement a better policy in 
DataNode for this case. It would be a pretty local change. When choosing 
a partition for a new block, DN already knows how much freespace is left 
on each one. for simplest implementation you skip partitions that have 
less 25% of avg freespace or choose with a probability proportional to 
relative freespace. If it works well, file a jira.

I don't think HDFS-343 is directly related to this or is likely to be 
fixed. There is another jira that makes placement policy at NameNode 
pluggable (does not affect Datanode).

Raghu.

Kris Jirapinyo wrote:
> Hi all,
>     I know this has been filed as a JIRA improvement already
> http://issues.apache.org/jira/browse/HDFS-343, but is there any good
> workaround at the moment?  What's happening is I have added a few new EBS
> volumes to half of the cluster, but Hadoop doesn't want to write to them.
> When I try to do cluster rebalancing, since the new disks make the
> percentage used lower, it fills up the first two existing local disks, which
> is exactly what I don't want to happen.  Currently, I just delete several
> subdirs from dfs, since I know that with a replication factor of 3, it'll be
> ok, so that fixes the problems in the short term.  But I still cannot get
> Hadoop to use those new larger disks efficiently.  Any thoughts?
> 
> -- Kris.
> 


From common-user-return-17076-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 00:47:11 2009
Return-Path: <common-user-return-17076-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 20425 invoked from network); 26 Aug 2009 00:47:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 00:47:11 -0000
Received: (qmail 45552 invoked by uid 500); 26 Aug 2009 00:47:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 45468 invoked by uid 500); 26 Aug 2009 00:47:33 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 45452 invoked by uid 99); 26 Aug 2009 00:47:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 00:47:33 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 209.85.222.200 is neither permitted nor denied by domain of kjirapinyo@biz360.com)
Received: from [209.85.222.200] (HELO mail-pz0-f200.google.com) (209.85.222.200)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 00:47:25 +0000
Received: by pzk38 with SMTP id 38so1878233pzk.5
        for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 17:47:05 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.194.3 with SMTP id r3mr1562682rvf.200.1251247625235; Tue, 
	25 Aug 2009 17:47:05 -0700 (PDT)
In-Reply-To: <4A947B5F.4080004@yahoo-inc.com>
References: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com> 
	<4A947B5F.4080004@yahoo-inc.com>
From: Kris Jirapinyo <kris.jirapinyo@biz360.com>
Date: Tue, 25 Aug 2009 17:46:45 -0700
Message-ID: <42a1925b0908251746i31830360o8ec79c8a79bfa245@mail.gmail.com>
Subject: Re: Intra-datanode balancing?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd29a663a6fa4047200ca9d
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd29a663a6fa4047200ca9d
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

How does copying the subdir work?  What if that partition already has the
same subdir (in the case that our partition is not new but relatively
new...with maybe 10% used)?

Thanks for the suggestions so far guys.

Kris.

On Tue, Aug 25, 2009 at 5:01 PM, Raghu Angadi <rangadi@yahoo-inc.com> wrote:

>
> For now you are stuck with the hack. Sooner or later hadoop has to handle
> heterogeneous nodes better.
>
> In general it tries to write to all the disks irrespective of % full since
> that gives the best performance (assuming each partition's capabilities are
> same). But it is lame at handling skews.
>
> Regd your hack :
>  1. You can copy subdir to new partition rather than deleting
>     (datanodes should be shutdown).
>
>  2. I would think it is less work to implement a better policy in DataNode
> for this case. It would be a pretty local change. When choosing a partition
> for a new block, DN already knows how much freespace is left on each one.
> for simplest implementation you skip partitions that have less 25% of avg
> freespace or choose with a probability proportional to relative freespace.
> If it works well, file a jira.
>
> I don't think HDFS-343 is directly related to this or is likely to be
> fixed. There is another jira that makes placement policy at NameNode
> pluggable (does not affect Datanode).
>
> Raghu.
>
>
> Kris Jirapinyo wrote:
>
>> Hi all,
>>    I know this has been filed as a JIRA improvement already
>> http://issues.apache.org/jira/browse/HDFS-343, but is there any good
>> workaround at the moment?  What's happening is I have added a few new EBS
>> volumes to half of the cluster, but Hadoop doesn't want to write to them.
>> When I try to do cluster rebalancing, since the new disks make the
>> percentage used lower, it fills up the first two existing local disks,
>> which
>> is exactly what I don't want to happen.  Currently, I just delete several
>> subdirs from dfs, since I know that with a replication factor of 3, it'll
>> be
>> ok, so that fixes the problems in the short term.  But I still cannot get
>> Hadoop to use those new larger disks efficiently.  Any thoughts?
>>
>> -- Kris.
>>
>>
>

--000e0cd29a663a6fa4047200ca9d--

From common-user-return-17077-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 01:26:25 2009
Return-Path: <common-user-return-17077-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 29171 invoked from network); 26 Aug 2009 01:26:25 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 01:26:25 -0000
Received: (qmail 92882 invoked by uid 500); 26 Aug 2009 01:26:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 92800 invoked by uid 500); 26 Aug 2009 01:26:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 92785 invoked by uid 99); 26 Aug 2009 01:26:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 01:26:47 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 01:26:36 +0000
Received: from [216.145.54.7] (socks2.corp.yahoo.com [216.145.54.7])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7Q1OZPE099456
	for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 18:24:36 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=0QA1f7LWNU6X1IuaGYDNEZ6S1L/V3Fo9ASblxq3mhprN5ns3HMzKXoVsOmssatUW
Message-ID: <4A948ED3.1000202@yahoo-inc.com>
Date: Tue, 25 Aug 2009 18:24:35 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.23 (X11/20090817)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Intra-datanode balancing?
References: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com> 	<4A947B5F.4080004@yahoo-inc.com> <42a1925b0908251746i31830360o8ec79c8a79bfa245@mail.gmail.com>
In-Reply-To: <42a1925b0908251746i31830360o8ec79c8a79bfa245@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Kris Jirapinyo wrote:
> How does copying the subdir work?  What if that partition already has the
> same subdir (in the case that our partition is not new but relatively
> new...with maybe 10% used)?

You can copy the files. There isn't really any requirement on number of 
files in  directory. something like cp -r subdir5 dest/subdir5 might do 
(or rsync without --delete option). Just make sure you delete the 
directory from the source.

Raghu.

> Thanks for the suggestions so far guys.
> 
> Kris.
> 
> On Tue, Aug 25, 2009 at 5:01 PM, Raghu Angadi <rangadi@yahoo-inc.com> wrote:
> 
>> For now you are stuck with the hack. Sooner or later hadoop has to handle
>> heterogeneous nodes better.
>>
>> In general it tries to write to all the disks irrespective of % full since
>> that gives the best performance (assuming each partition's capabilities are
>> same). But it is lame at handling skews.
>>
>> Regd your hack :
>>  1. You can copy subdir to new partition rather than deleting
>>     (datanodes should be shutdown).
>>
>>  2. I would think it is less work to implement a better policy in DataNode
>> for this case. It would be a pretty local change. When choosing a partition
>> for a new block, DN already knows how much freespace is left on each one.
>> for simplest implementation you skip partitions that have less 25% of avg
>> freespace or choose with a probability proportional to relative freespace.
>> If it works well, file a jira.
>>
>> I don't think HDFS-343 is directly related to this or is likely to be
>> fixed. There is another jira that makes placement policy at NameNode
>> pluggable (does not affect Datanode).
>>
>> Raghu.
>>
>>
>> Kris Jirapinyo wrote:
>>
>>> Hi all,
>>>    I know this has been filed as a JIRA improvement already
>>> http://issues.apache.org/jira/browse/HDFS-343, but is there any good
>>> workaround at the moment?  What's happening is I have added a few new EBS
>>> volumes to half of the cluster, but Hadoop doesn't want to write to them.
>>> When I try to do cluster rebalancing, since the new disks make the
>>> percentage used lower, it fills up the first two existing local disks,
>>> which
>>> is exactly what I don't want to happen.  Currently, I just delete several
>>> subdirs from dfs, since I know that with a replication factor of 3, it'll
>>> be
>>> ok, so that fixes the problems in the short term.  But I still cannot get
>>> Hadoop to use those new larger disks efficiently.  Any thoughts?
>>>
>>> -- Kris.
>>>
>>>
> 


From common-user-return-17078-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 02:18:05 2009
Return-Path: <common-user-return-17078-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 48271 invoked from network); 26 Aug 2009 02:18:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 02:18:05 -0000
Received: (qmail 31242 invoked by uid 500); 26 Aug 2009 02:18:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 31158 invoked by uid 500); 26 Aug 2009 02:18:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 31148 invoked by uid 500); 26 Aug 2009 02:18:27 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 31144 invoked by uid 99); 26 Aug 2009 02:18:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 02:18:27 +0000
X-ASF-Spam-Status: No, hits=-1.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zshao@facebook.com designates 69.63.179.25 as permitted sender)
Received: from [69.63.179.25] (HELO mailout-snc1.facebook.com) (69.63.179.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 02:18:15 +0000
Received: from mail.thefacebook.com (intlb01.snat.snc1.facebook.com [10.128.203.16] (may be forged))
	by pp01.snc1.tfbnw.net (8.14.1/8.14.1) with ESMTP id n7Q2HmJS018352
	(version=TLSv1/SSLv3 cipher=RC4-MD5 bits=128 verify=NOT)
	for <core-user@hadoop.apache.org>; Tue, 25 Aug 2009 19:17:48 -0700
Received: from SC-MBXC1.TheFacebook.com ([192.168.18.100]) by
 sc-hub01.TheFacebook.com ([192.168.18.104]) with mapi; Tue, 25 Aug 2009
 19:17:52 -0700
From: Zheng Shao <zshao@facebook.com>
To: "core-user@hadoop.apache.org" <core-user@hadoop.apache.org>
Date: Tue, 25 Aug 2009 19:17:45 -0700
Subject: org/apache/fop/messaging/MessageHandler not found when compiling
 hadoop
Thread-Topic: org/apache/fop/messaging/MessageHandler not found when
 compiling hadoop
Thread-Index: Acol82X8jdxocq7LSKieWjFHTzapSg==
Message-ID: <CD2E0A273BDAAD409C70BB3F48EE6A126CBE285265@SC-MBXC1.TheFacebook.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
acceptlanguage: en-US
Content-Type: multipart/alternative;
	boundary="_000_CD2E0A273BDAAD409C70BB3F48EE6A126CBE285265SCMBXC1TheFac_"
MIME-Version: 1.0
X-Proofpoint-Virus-Version: vendor=fsecure engine=1.12.8161:2.4.5,1.2.40,4.0.166 definitions=2009-08-25_07:2009-08-11,2009-08-25,2009-08-25 signatures=0
X-Proofpoint-Spam-Details: rule=notspam policy=default score=0 spamscore=0 ipscore=0 phishscore=0 bulkscore=0 adultscore=0 classifier=spam adjust=0 reason=mlx engine=5.0.0-0907200000 definitions=main-0908250213
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_CD2E0A273BDAAD409C70BB3F48EE6A126CBE285265SCMBXC1TheFac_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

I am compiling hadoop 0.20 yahoo version using the following command and go=
t an exception.
Where should I put fop.jar (I got fop from http://www.hightechimpact.com/Ap=
ache/xmlgraphics/fop/binaries/fop-0.95-bin.tar.gz ) to make it work?

Zheng

ant clean -Dversion=3D0.20.1 -Dcompile.native=3Dtrue  -Dcompile.c++=3Dtrue =
-Djava5.home=3D/usr/local/jdk1.5.0_07 \
       -Dforrest.home=3D/home/dhruba/forrest compile-core-native compile-c+=
+ tar -logfile package.log


     [exec] ---------------------------------------------------------------=
---------
     [exec] cocoon 2.1.12-dev
     [exec] Copyright (c) 1999-2007 Apache Software Foundation. All rights =
reserved.
     [exec] ---------------------------------------------------------------=
---------
     [exec]
     [exec]
     [exec] * [1/29]    [29/29]   3.033s 9.4Kb   linkmap.html
     [exec] * [2/29]    [1/28]    1.83s  21.1Kb  distcp.html
     [exec] * [3/29]    [1/28]    0.808s 18.2Kb  hdfs_permissions_guide.htm=
l
     [exec] * [4/28]    [0/0]     0.909s 2.9Kb   skin/basic.css
     [exec] * [5/29]    [2/32]    0.384s 29.4Kb  hdfs_user_guide.html
     [exec] * [6/29]    [1/28]    0.403s 22.3Kb  hdfs_shell.html
     [exec] * [7/29]    [1/29]    0.231s 13.9Kb  native_libraries.html
     [exec] * [8/29]    [1/28]    0.18s  8.3Kb   hdfs_quota_admin_guide.htm=
l
     [exec] * [9/32]    [4/31]    0.187s 7.9Kb   hod.html
     [exec] * [10/32]   [1/34]    0.228s 24.9Kb  hod_admin_guide.html
     [exec] * [11/32]   [1/30]    0.198s 17.8Kb  hod_config_guide.html
     [exec] * [12/31]   [0/0]     0.107s 0b      hod_config_guide.pdf
     [exec] Exception in thread "main" java.lang.NoClassDefFoundError: org/=
apache/fop/messaging/MessageHandler
     [exec]     at org.apache.cocoon.serialization.FOPSerializer.configure(=
FOPSerializer.java:122)
     [exec]     at org.apache.avalon.framework.container.ContainerUtil.conf=
igure(ContainerUtil.java:201)
     [exec]     at org.apache.avalon.excalibur.component.DefaultComponentFa=
ctory.newInstance(DefaultComponentFactory.java:289)
     [exec]     at org.apache.avalon.excalibur.pool.InstrumentedResourceLim=
itingPool.newPoolable(InstrumentedResourceLimitingPool.java:655)
     [exec]     at org.apache.avalon.excalibur.pool.InstrumentedResourceLim=
itingPool.get(InstrumentedResourceLimitingPool.java:371)
     [exec]     at org.apache.avalon.excalibur.component.PoolableComponentH=
andler.doGet(PoolableComponentHandler.java:198)
     [exec]     at org.apache.avalon.excalibur.component.ComponentHandler.g=
et(ComponentHandler.java:381)
     [exec]     at org.apache.avalon.excalibur.component.ExcaliburComponent=
Selector.select(ExcaliburComponentSelector.java:215)
     [exec]     at org.apache.cocoon.components.ExtendedComponentSelector.s=
elect(ExtendedComponentSelector.java:268)
     [exec]     at org.apache.cocoon.components.pipeline.AbstractProcessing=
Pipeline.setSerializer(AbstractProcessingPipeline.java:311)
     [exec]     at org.apache.cocoon.components.pipeline.impl.AbstractCachi=
ngProcessingPipeline.setSerializer(AbstractCachingProcessingPipeline.java:1=
71)
     [exec]     at org.apache.cocoon.components.treeprocessor.sitemap.Seria=
lizeNode.invoke(SerializeNode.java:120)
     [exec]     at org.apache.cocoon.components.treeprocessor.AbstractParen=
tProcessingNode.invokeNodes(AbstractParentProcessingNode.java:69)
     [exec]     at org.apache.cocoon.components.treeprocessor.sitemap.Selec=
tNode.invoke(SelectNode.java:103)
     [exec]     at org.apache.cocoon.components.treeprocessor.AbstractParen=
tProcessingNode.invokeNodes(AbstractParentProcessingNode.java:47)
     [exec]     at org.apache.cocoon.components.treeprocessor.sitemap.Prepa=
rableMatchNode.invoke(PreparableMatchNode.java:131)
     [exec]     at org.apache.cocoon.components.treeprocessor.AbstractParen=
tProcessingNode.invokeNodes(AbstractParentProcessingNode.java:69)
     [exec]     at org.apache.cocoon.components.treeprocessor.sitemap.Pipel=
ineNode.invoke(PipelineNode.java:143)
     [exec]     at org.apache.cocoon.components.treeprocessor.AbstractParen=
tProcessingNode.invokeNodes(AbstractParentProcessingNode.java:69)
     [exec]     at org.apache.cocoon.components.treeprocessor.sitemap.Pipel=
inesNode.invoke(PipelinesNode.java:93)
     [exec]     at org.apache.cocoon.components.treeprocessor.ConcreteTreeP=
rocessor.process(ConcreteTreeProcessor.java:235)
     [exec]     at org.apache.cocoon.components.treeprocessor.ConcreteTreeP=
rocessor.process(ConcreteTreeProcessor.java:177)
     [exec]     at org.apache.cocoon.components.treeprocessor.TreeProcessor=
.process(TreeProcessor.java:254)
     [exec]     at org.apache.cocoon.components.treeprocessor.sitemap.Mount=
Node.invoke(MountNode.java:118)
     [exec]     at org.apache.cocoon.components.treeprocessor.AbstractParen=
tProcessingNode.invokeNodes(AbstractParentProcessingNode.java:69)
     [exec]     at org.apache.cocoon.components.treeprocessor.sitemap.Selec=
tNode.invoke(SelectNode.java:98)
     [exec]     at org.apache.cocoon.components.treeprocessor.AbstractParen=
tProcessingNode.invokeNodes(AbstractParentProcessingNode.java:69)
     [exec]     at org.apache.cocoon.components.treeprocessor.sitemap.Pipel=
ineNode.invoke(PipelineNode.java:143)
     [exec]     at org.apache.cocoon.components.treeprocessor.AbstractParen=
tProcessingNode.invokeNodes(AbstractParentProcessingNode.java:69)
     [exec]     at org.apache.cocoon.components.treeprocessor.sitemap.Pipel=
inesNode.invoke(PipelinesNode.java:93)
     [exec]     at org.apache.cocoon.components.treeprocessor.ConcreteTreeP=
rocessor.process(ConcreteTreeProcessor.java:235)
     [exec]     at org.apache.cocoon.components.treeprocessor.ConcreteTreeP=
rocessor.process(ConcreteTreeProcessor.java:177)
     [exec]     at org.apache.cocoon.components.treeprocessor.TreeProcessor=
.process(TreeProcessor.java:254)
     [exec]     at org.apache.cocoon.Cocoon.process(Cocoon.java:699)

Zheng


--_000_CD2E0A273BDAAD409C70BB3F48EE6A126CBE285265SCMBXC1TheFac_--

From common-user-return-17079-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 06:27:28 2009
Return-Path: <common-user-return-17079-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 45712 invoked from network); 26 Aug 2009 06:27:28 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 06:27:28 -0000
Received: (qmail 59832 invoked by uid 500); 26 Aug 2009 06:27:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 59739 invoked by uid 500); 26 Aug 2009 06:27:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 59727 invoked by uid 99); 26 Aug 2009 06:27:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 06:27:25 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [199.64.220.26] (HELO az18ip008.honeywell.com) (199.64.220.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 06:27:16 +0000
X-IronPort-AV: E=Sophos;i="4.44,277,1249282800"; 
   d="scan'208,217";a="249138655"
Received: from unknown (HELO az18ex6002.global.ds.honeywell.com) ([10.192.23.91])
  by az18ip008.honeywell.com with ESMTP; 25 Aug 2009 23:26:55 -0700
Received: from IE10EV813.global.ds.honeywell.com ([199.63.32.243]) by az18ex6002.global.ds.honeywell.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Tue, 25 Aug 2009 23:26:55 -0700
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01CA2616.27EF8C70"
Subject: can't find java home
Date: Wed, 26 Aug 2009 11:56:33 +0530
Message-ID: <CEDB38A443476D40901289F9F19E288A02E8449D@IE10EV813.global.ds.honeywell.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: can't find java home
Thread-Index: AcomFifrbDDBqdYxRFaBePNHTmFZRg==
From: "Puri, Aseem" <Aseem.Puri@Honeywell.com>
To: <common-user@hadoop.apache.org>
X-OriginalArrivalTime: 26 Aug 2009 06:26:55.0206 (UTC) FILETIME=[34E55060:01CA2616]
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01CA2616.27EF8C70
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Hi

=20

I am facing an issue while starting my hadoop cluster.

=20

When I run the command:

=20

$ bin/hadoop namenode -format

=20

I found this exception:

=20

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 2:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 7:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 10:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 13:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 16:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 19:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 29:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 32:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 35:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 38:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 41:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 46:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 49:
$'\r': command not found

/home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 52:
$'\r': command not found

/bin/java: No such file or directorymin/java/jdk1.6.0_13

/bin/java: No such file or directorymin/java/jdk1.6.0_13

/bin/java: cannot execute: No such file or directorydk1.6.0_13

=20

Also in "home/HadoopAdmin/hadoop-0.18.3/bin/conf/hadoop-env.sh"I set my
java home as where I have installed java as:

=20

export JAVA_HOME=3D/home/HadoopAdmin/java/jdk1.6.0_13

=20

Please help me on this issue.

=20

Regards

Aseem Puri

=20

=20


------_=_NextPart_001_01CA2616.27EF8C70--

From common-user-return-17080-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 06:41:06 2009
Return-Path: <common-user-return-17080-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 52095 invoked from network); 26 Aug 2009 06:41:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 06:41:06 -0000
Received: (qmail 75485 invoked by uid 500); 26 Aug 2009 06:41:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 75420 invoked by uid 500); 26 Aug 2009 06:41:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 75410 invoked by uid 99); 26 Aug 2009 06:41:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 06:41:03 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pvssvikas@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 06:40:53 +0000
Received: by gxk27 with SMTP id 27so4853355gxk.12
        for <common-user@hadoop.apache.org>; Tue, 25 Aug 2009 23:40:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=daf6yki7kgeLVR05lLuX9xZuXqXsVg6S9iEfR0fYcZM=;
        b=PehBLlMH+v3fTTFAGJh45lDH3BSniWv/H4CUsf9O4b9OylPtsnCRA7qb/N3lf+DNLB
         0zGDXhB+bNaQPywP30VtF9sVjFeVQS3GPmW1Q2Hah7DMglsSy6x7bbHkfh+75dgrIUiy
         2hVZN4vbd5R+IwDVlf8vtGDirMrmGmerJr0WU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=RRraoeSjpM9KOMwXAg2DifLB8n7prnBmargWzuxSNJ8CqsCUT2MyIOAdt2wryx1PEx
         en+yr7moIflybqSfJBAOg46HhT57pigX6078S6pon05nTPYdHSfDIIwEdCiYM88FIREK
         1h5WxwUhz6TibdqnuF9cDEGuOybyhsvRB7exU=
MIME-Version: 1.0
Received: by 10.90.230.16 with SMTP id c16mr5780042agh.76.1251268832532; Tue, 
	25 Aug 2009 23:40:32 -0700 (PDT)
In-Reply-To: <CEDB38A443476D40901289F9F19E288A02E8449D@IE10EV813.global.ds.honeywell.com>
References: <CEDB38A443476D40901289F9F19E288A02E8449D@IE10EV813.global.ds.honeywell.com>
Date: Wed, 26 Aug 2009 12:10:32 +0530
Message-ID: <6cbf6c150908252340v194fc6e0p78d5fc2fb5694266@mail.gmail.com>
Subject: Re: can't find java home
From: vikas <pvssvikas@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016362841a0481858047205ba83
X-Virus-Checked: Checked by ClamAV on apache.org

--0016362841a0481858047205ba83
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

can you run "dos2unix /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/*.sh" and
then try again.

Thanks,
-Vikas.

On Wed, Aug 26, 2009 at 11:56 AM, Puri, Aseem <Aseem.Puri@honeywell.com>wrote:

> Hi
>
>
>
> I am facing an issue while starting my hadoop cluster.
>
>
>
> When I run the command:
>
>
>
> $ bin/hadoop namenode -format
>
>
>
> I found this exception:
>
>
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 2:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 7:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 10:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 13:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 16:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 19:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 29:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 32:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 35:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 38:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 41:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 46:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 49:
> $'\r': command not found
>
> /home/HadoopAdmin/hadoop-0.18.3/bin/../conf/hadoop-env.sh: line 52:
> $'\r': command not found
>
> /bin/java: No such file or directorymin/java/jdk1.6.0_13
>
> /bin/java: No such file or directorymin/java/jdk1.6.0_13
>
> /bin/java: cannot execute: No such file or directorydk1.6.0_13
>
>
>
> Also in "home/HadoopAdmin/hadoop-0.18.3/bin/conf/hadoop-env.sh"I set my
> java home as where I have installed java as:
>
>
>
> export JAVA_HOME=/home/HadoopAdmin/java/jdk1.6.0_13
>
>
>
> Please help me on this issue.
>
>
>
> Regards
>
> Aseem Puri
>
>
>
>
>
>

--0016362841a0481858047205ba83--

From common-user-return-17081-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 09:37:50 2009
Return-Path: <common-user-return-17081-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7036 invoked from network); 26 Aug 2009 09:37:49 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 09:37:49 -0000
Received: (qmail 87784 invoked by uid 500); 26 Aug 2009 09:37:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87709 invoked by uid 500); 26 Aug 2009 09:37:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 91919 invoked by uid 99); 26 Aug 2009 05:27:49 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Message-ID: <014401ca260e$14cc6e60$ba0310ac@rediff.net>
Reply-To: "ilayaraja" <ilayaraja@rediff.co.in>
From: "ilayaraja" <ilayaraja@rediff.co.in>
To: <hbase-user@hadoop.apache.org>,
	<hbase-dev@hadoop.apache.org>,
	<common-user@hadoop.apache.org>,
	<common-dev@hadoop.apache.org>
Subject: HBase master not starting
Date: Wed, 26 Aug 2009 10:58:45 +0530
Organization: rediff.com
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----=_NextPart_000_0141_01CA263C.2E6F2690"
X-Priority: 3
X-MSMail-Priority: Normal
X-Mailer: Microsoft Outlook Express 6.00.2900.3138
X-MimeOLE: Produced By Microsoft MimeOLE V6.00.2900.3350
X-Virus-Checked: Checked by ClamAV on apache.org

------=_NextPart_000_0141_01CA263C.2E6F2690
Content-Type: text/plain;
	charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Hello,

Iam trying to setup Hbase-0.20 with Hadoop-0.20 in fully distributed =
mode.
I have problem while starting the Hbase master: The stack trace is as =
follows



2009-08-26 01:18:31,454 INFO org.apache.hadoop.hbase.master.HMaster: My =
address is domU-12-31-39-00-0A-52.compute-1.internal:60000
2009-08-26 01:18:32,600 FATAL org.apache.hadoop.hbase.master.HMaster: =
Not starting HMaster because:
        at java.io.DataInputStream.readUTF(DataInputStream.java:572)
        at =
java.io.DataInputStream.readUnsignedShort(DataInputStream.java:323)
java.io.EOFException

Please help me out with this. Below is my hbase-site.xml

<configuration>
  <property>
    <name>hbase.rootdir</name>
    =
<value>hdfs://domU-12-31-39-00-28-52.compute-1.internal:40010/hbase</valu=
e>
    <description>The directory shared by region servers.
    </description>
  </property>

  <property>
    <name>hbase.master</name>
    <value>domU-12-31-39-00-28-52.compute-1.internal:60000</value>
    <description>The host and port that the HBase master runs at.
    </description>
  </property>

  <property>
    <name>hbase.master.port</name>
    <value>60000</value>
    <description>The port master should bind to.</description>
  </property>

  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
    <description>The mode the cluster will be in. Possible values are
      false: standalone and pseudo-distributed setups with managed =
Zookeeper
      true: fully-distributed with unmanaged Zookeeper Quorum (see =
hbase-env.sh)
    </description>
  </property>

</configuration>



------=_NextPart_000_0141_01CA263C.2E6F2690--


From common-user-return-17082-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 11:20:32 2009
Return-Path: <common-user-return-17082-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 49769 invoked from network); 26 Aug 2009 11:20:31 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 11:20:31 -0000
Received: (qmail 9790 invoked by uid 500); 26 Aug 2009 11:20:29 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 9723 invoked by uid 500); 26 Aug 2009 11:20:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 9713 invoked by uid 99); 26 Aug 2009 11:20:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 11:20:28 +0000
X-ASF-Spam-Status: No, hits=4.5 required=10.0
	tests=DATE_IN_FUTURE_12_24,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.20] (HELO mrout1-b.corp.re1.yahoo.com) (69.147.107.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 11:20:18 +0000
Received: from naturehistory-dr.eglbp.corp.yahoo.com (naturehistory-dr.eglbp.corp.yahoo.com [10.66.97.214])
	by mrout1-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7QBJ6cv074558
	for <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 04:19:08 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	content-type:content-transfer-encoding;
	b=xX6z1leuEjTvuydocTPASg6E2F6fVZZHTRFzfx5+xyktdqijponGml6yiJdpSHPF
Message-ID: <4A95CA58.3030608@yahoo-inc.com>
Date: Wed, 26 Aug 2009 16:50:48 -0700
From: Nikhil Sawant <nsawant@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.4 (X11/20070604)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Testing Hadoop job
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

hi

can u guys suggest some hadoop unit testing framework apart from MRUnit???
i have used MRUnit but i m not sure abt its feasibilty and support to 
hadoop 0.20.....
i could not find a proper documentation for MRUnit, is it available 
anywhere?

-- 
cheers
nikhil


From common-user-return-17083-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 13:29:34 2009
Return-Path: <common-user-return-17083-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 96127 invoked from network); 26 Aug 2009 13:29:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 13:29:34 -0000
Received: (qmail 15101 invoked by uid 500); 26 Aug 2009 13:29:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 15011 invoked by uid 500); 26 Aug 2009 13:29:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 15001 invoked by uid 99); 26 Aug 2009 13:29:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 13:29:32 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jeremy@lotame.com designates 216.32.180.15 as permitted sender)
Received: from [216.32.180.15] (HELO VA3EHSOBE006.bigfish.com) (216.32.180.15)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 13:29:22 +0000
Received: from mail96-va3-R.bigfish.com (10.7.14.239) by
 VA3EHSOBE006.bigfish.com (10.7.40.26) with Microsoft SMTP Server id
 8.1.340.0; Wed, 26 Aug 2009 13:29:01 +0000
Received: from mail96-va3 (localhost.localdomain [127.0.0.1])	by
 mail96-va3-R.bigfish.com (Postfix) with ESMTP id 8B72D4C0414	for
 <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 13:29:00 +0000 (UTC)
X-SpamScore: -15
X-BigFish: VPS-15(zza40W936eM3b5bkzz1202hzzz2fh6bh43j61h)
X-Spam-TCS-SCL: 0:0
X-FB-SS: 5,5,
Received: by mail96-va3 (MessageSwitch) id 1251293318251848_32482; Wed, 26 Aug
 2009 13:28:38 +0000 (UCT)
Received: from inmail.lotame.com (unknown [12.54.14.100])	(using TLSv1 with
 cipher RC4-MD5 (128/128 bits))	(No client certificate requested)	by
 mail96-va3.bigfish.com (Postfix) with ESMTP id 1106C1C10050	for
 <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 13:28:38 +0000 (UTC)
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-Class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01CA2650.FDDB2771"
Subject: 0.19.1 infinite loop
Date: Wed, 26 Aug 2009 09:27:42 -0400
Message-ID: <FFE8D0F9A5491746834D896CFB004CB502125C59@ltfps1.Lotame.com>
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
Thread-Topic: 0.19.1 infinite loop
Thread-Index: AcomUP0z1u9M/7bZRqybHeCUeqs4TA==
From: Jeremy Pinkham <jeremy@lotame.com>
To: <common-user@hadoop.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01CA2650.FDDB2771
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

I'm using hadoop 0.19.1 on a 60 node cluster, each node has 8GB of ram
and 4 cores.  I have several jobs that run every day, and last night one
of them triggered an infinite loop that rendered the cluster inoperable.
As the job finishes, the following is logged to the job tracker logs:

 =


2009-08-25 22:08:04,633 INFO org.apache.hadoop.mapred.JobInProgress:
Task 'attempt_200908220740_0126_r_000001_0' has completed
task_200908220740_0126_r_000001 successfully.

2009-08-25 22:08:04,633 INFO org.apache.hadoop.mapred.JobInProgress: Job
job_200908220740_0126 has completed successfully.

2009-08-25 22:08:09,897 INFO org.apache.hadoop.hdfs.DFSClient: Could not
complete file
/proc/statpump/incremental/200908260200/_logs/history/dup-jt_12509412317
25_job_200908220740_0126_hadoop_statpump-incremental retrying...

 =


That last line, "Could not complete file..." then repeats forever, at
which point the job tracker UI stops responding and no more tasks will
run.  The only way to free things up is to restart the jobtracker

 =


Both prior to and during the infinite loop, I see this in the namenode
logs.  Because it starts long before the inifinte loop I can't tell for
sure if it's related, and it is still happening now even after the
restart and with jobs finishing without issue

 =


2009-08-25 22:08:05,760 INFO org.apache.hadoop.ipc.Server: IPC Server
handler 5 on 54310, call
nextGenerationStamp(blk_2796235715791117970_4385127) from
172.21.30.2:48164: error: java.io.IOException:
blk_2796235715791117970_4385127 is already commited, storedBlock =3D=3D
null.

java.io.IOException: blk_2796235715791117970_4385127 is already
commited, storedBlock =3D=3D null.

        at
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampF
orBlock(FSNamesystem.java:4552)

        at
org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(Name
Node.java:402)

        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)

        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessor
Impl.java:25)

        at java.lang.reflect.Method.invoke(Method.java:597)

        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:481)

        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:894)

 =


And finally, this warning appears in the namenode logs just prior as
well

 =


2009-08-25 22:07:22,580 WARN
org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Inconsistent size
for block blk_-1458477261945758787_4416123 reported from
172.21.30.4:50010 current size is 5396992 reported size is 67108864

 =


Can anyone point me in a direction to determine what's going here?

 =


Thanks



The information transmitted in this email is intended only for the person(s=
) or entity to which it is addressed and may contain confidential and/or pr=
ivileged material. Any review, retransmission, dissemination or other use o=
f, or taking of any action in reliance upon, this information by persons or=
 entities other than the intended recipient is prohibited. If you received =
this email in error, please contact the sender and permanently delete the e=
mail from any computer.


------_=_NextPart_001_01CA2650.FDDB2771--

From common-user-return-17084-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 13:55:05 2009
Return-Path: <common-user-return-17084-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 10169 invoked from network); 26 Aug 2009 13:55:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 13:55:04 -0000
Received: (qmail 66225 invoked by uid 500); 26 Aug 2009 13:55:02 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 66154 invoked by uid 500); 26 Aug 2009 13:55:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 66144 invoked by uid 99); 26 Aug 2009 13:55:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 13:55:02 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 13:54:51 +0000
Received: from pcp088905pcs.unl.edu (pcp088905pcs.unl.edu [129.93.158.20])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7QDsQsX011733
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 08:54:29 -0500
Message-Id: <21A8221B-7AD4-496D-9859-83F930F71354@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <FFE8D0F9A5491746834D896CFB004CB502125C59@ltfps1.Lotame.com>
Content-Type: multipart/signed; boundary=Apple-Mail-281-257242997; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: 0.19.1 infinite loop
Date: Wed, 26 Aug 2009 08:54:25 -0500
References: <FFE8D0F9A5491746834D896CFB004CB502125C59@ltfps1.Lotame.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-281-257242997
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Hey Jeremy,

Glad someone else has run into this!

I always thought this specific infinite loop was in my code.  I had an  
issue open for it earlier, but I ultimately was not sure if it was in  
my code or HDFS, so we closed it:

https://issues.apache.org/jira/browse/HADOOP-4866

We [and others] get these daily.  It would be nice to figure out a way  
to replicate this.

Brian

On Aug 26, 2009, at 8:27 AM, Jeremy Pinkham wrote:

> I'm using hadoop 0.19.1 on a 60 node cluster, each node has 8GB of ram
> and 4 cores.  I have several jobs that run every day, and last night  
> one
> of them triggered an infinite loop that rendered the cluster  
> inoperable.
> As the job finishes, the following is logged to the job tracker logs:
>
>
>
> 2009-08-25 22:08:04,633 INFO org.apache.hadoop.mapred.JobInProgress:
> Task 'attempt_200908220740_0126_r_000001_0' has completed
> task_200908220740_0126_r_000001 successfully.
>
> 2009-08-25 22:08:04,633 INFO org.apache.hadoop.mapred.JobInProgress:  
> Job
> job_200908220740_0126 has completed successfully.
>
> 2009-08-25 22:08:09,897 INFO org.apache.hadoop.hdfs.DFSClient: Could  
> not
> complete file
> /proc/statpump/incremental/200908260200/_logs/history/dup- 
> jt_12509412317
> 25_job_200908220740_0126_hadoop_statpump-incremental retrying...
>
>
>
> That last line, "Could not complete file..." then repeats forever, at
> which point the job tracker UI stops responding and no more tasks will
> run.  The only way to free things up is to restart the jobtracker
>
>
>
> Both prior to and during the infinite loop, I see this in the namenode
> logs.  Because it starts long before the inifinte loop I can't tell  
> for
> sure if it's related, and it is still happening now even after the
> restart and with jobs finishing without issue
>
>
>
> 2009-08-25 22:08:05,760 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 5 on 54310, call
> nextGenerationStamp(blk_2796235715791117970_4385127) from
> 172.21.30.2:48164: error: java.io.IOException:
> blk_2796235715791117970_4385127 is already commited, storedBlock ==
> null.
>
> java.io.IOException: blk_2796235715791117970_4385127 is already
> commited, storedBlock == null.
>
>        at
> org 
> .apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampF
> orBlock(FSNamesystem.java:4552)
>
>        at
> org 
> .apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(Name
> Node.java:402)
>
>        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
>
>        at
> sun 
> .reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessor
> Impl.java:25)
>
>        at java.lang.reflect.Method.invoke(Method.java:597)
>
>        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:481)
>
>        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:894)
>
>
>
> And finally, this warning appears in the namenode logs just prior as
> well
>
>
>
> 2009-08-25 22:07:22,580 WARN
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Inconsistent size
> for block blk_-1458477261945758787_4416123 reported from
> 172.21.30.4:50010 current size is 5396992 reported size is 67108864
>
>
>
> Can anyone point me in a direction to determine what's going here?
>
>
>
> Thanks
>
>
>
> The information transmitted in this email is intended only for the  
> person(s) or entity to which it is addressed and may contain  
> confidential and/or privileged material. Any review, retransmission,  
> dissemination or other use of, or taking of any action in reliance  
> upon, this information by persons or entities other than the  
> intended recipient is prohibited. If you received this email in  
> error, please contact the sender and permanently delete the email  
> from any computer.
>


--Apple-Mail-281-257242997
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64

MIAGCSqGSIb3DQEHAqCAMIACAQExCzAJBgUrDgMCGgUAMIAGCSqGSIb3DQEHAQAAoIIICjCCA/gw
ggLgoAMCAQICASkwDQYJKoZIhvcNAQEFBQAwdTETMBEGCgmSJomT8ixkARkWA25ldDESMBAGCgmS
JomT8ixkARkWAkVTMQ4wDAYDVQQKEwVFU25ldDEgMB4GA1UECxMXQ2VydGlmaWNhdGUgQXV0aG9y
aXRpZXMxGDAWBgNVBAMTD0VTbmV0IFJvb3QgQ0EgMTAeFw0wMjEyMDUwODAwMDBaFw0xMzAxMjUw
ODAwMDBaMGkxEzARBgoJkiaJk/IsZAEZFgNvcmcxGDAWBgoJkiaJk/IsZAEZFghET0VHcmlkczEg
MB4GA1UECxMXQ2VydGlmaWNhdGUgQXV0aG9yaXRpZXMxFjAUBgNVBAMTDURPRUdyaWRzIENBIDEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC09dYjYaPbCD5mtbiQb7Ka3y1qAm0ZcqKC
FciWcfe8Kwcuy9tjHuIsLf9ZItdkDW4xy8sua9nJlx3KlwjtumTMtOtg35KZCknUd8KM4VGTSFdL
VG9AbNayef76caVCGM1+jyF0Lq03kauGOPTcNfZe1TZa3e1c9rc8ljV5OSWa/mfsCACyS5zFIWu0
yIDNyJdf+n0hwaPN53wllpJ30taD+JBjQ7h2k4xRWzeaznLOb9OztZVRA/1sVze+iczFh2xwa4Vd
Gy0eIIPw1pfvYwxO36rm0S109qvbsNlaroPRbxerPKakQLpKe034Xcx7gBPqUk/FxoRRWin5EWN3
rz9LAgMBAAGjgZ4wgZswDgYDVR0PAQH/BAQDAgGGMBEGCWCGSAGG+EIBAQQEAwIAhzAdBgNVHQ4E
FgQUyhkdEo5upDhdQtQxDgjb2Y0XDV0wHwYDVR0jBBgwFoAUvF1NSC/4NZRZq1yJSz7RsjoUAeow
DwYDVR0TAQH/BAUwAwEB/zAlBgNVHREEHjAcgRpET0VHcmlkcy1DQS0xQGRvZWdyaWRzLm9yZzAN
BgkqhkiG9w0BAQUFAAOCAQEAZNVrIDLqe39CEOiJt7Q7EpBPhAihMvDTSf/42u0SMbUmChww4mLm
ph5DBghZUVF8Yn59kRZMn1QLOtO1HzLqvAvPITacZVPlJgG2IXzlR636YghZFAycbIUEOJDBHR4v
tQO1KDxgZwvAbtmKIoxvhUCq2xsfFt9kCBBn+JYtQ6O5LsBJq3PmuubeMcc7mbQAfJZ7h/3Qghgk
FIhmE1+LBXPJbkuP8vgfg6h2BKoAf5TFfZECgGZKimfN110tBvfedGZwYYd3/GsJc83B0JN1gny0
gqNVPm392UchXGeBRrHnm2gkhIkr48Oq6EmNGV9/a6XfbplQW/JWbtPVPWkaizCCBAowggLyoAMC
AQICAwCB+zANBgkqhkiG9w0BAQUFADBpMRMwEQYKCZImiZPyLGQBGRYDb3JnMRgwFgYKCZImiZPy
LGQBGRYIRE9FR3JpZHMxIDAeBgNVBAsTF0NlcnRpZmljYXRlIEF1dGhvcml0aWVzMRYwFAYDVQQD
Ew1ET0VHcmlkcyBDQSAxMB4XDTA5MDYwMjE5NDExM1oXDTEwMDYwMjE5NDExM1owYTETMBEGCgmS
JomT8ixkARkWA29yZzEYMBYGCgmSJomT8ixkARkWCGRvZWdyaWRzMQ8wDQYDVQQLEwZQZW9wbGUx
HzAdBgNVBAMTFkJyaWFuIEJvY2tlbG1hbiA1MDQzMDcwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAw
ggEKAoIBAQDPWEl7hBiuFRVBSY4SwvG0HpkCZi74a0BeD0tNARgxoQVJ7jhJjR3G4y8ino0/5axt
2EEfIWUE+DVpV37IWOQl8q/wdvicnhbfjByxBbq4sfWPLepU7+Kd8k1FKHRHermARn9VxEkFLrLB
Gp7O5EX4mFHDaQy+Vv0thtA+m4qKoM+DA/8cOkJA5Rn6ZS/v/vtBzJh9HimVnhBx4+rw2cvKN+7r
lKsm7qTn9TCZmrQ97CvBEXSkHS11m8vYF6ZwcTgSCJM0M9nnX5JilupQO1vDICXSUZeWX2xpsqeL
x1PFGWgDaYXxFGtTRt2Qc9EPwf9Dr72xGPbKN8u5HylpOMDnAgMBAAGjgcIwgb8wEQYJYIZIAYb4
QgEBBAQDAgWgMA4GA1UdDwEB/wQEAwIF4DAfBgNVHSMEGDAWgBTKGR0Sjm6kOF1C1DEOCNvZjRcN
XTAYBgNVHSAEETAPMA0GCyqGSIb3TAMHAQMAMD4GA1UdHwQ3MDUwM6AxoC+GLWh0dHA6Ly9jcmwu
ZG9lZ3JpZHMub3JnLzFjM2YyY2E4LzFjM2YyY2E4LmNybDAfBgNVHREEGDAWgRRiYm9ja2VsbUBj
c2UudW5sLmVkdTANBgkqhkiG9w0BAQUFAAOCAQEAp6KjcWnfnH/MGlUkUWstE9gtPeymHp+2r4zI
w8JXigncJh/8qpSZqBcVhD24WFowI95otblrKYNZKW9f2G/hWwDSxZFqHhCDxFO12vDthrzOc3EH
CwypJPvIlZPt/E/x93XruzPxJwPz84DKKuPoJAMeNlADbd+92YtRr2y+VuMpgZaebMAoeCdWH8Cq
Y8xheNMajf8uiImBbatDuCu7qRvhwgxsMNLHEt4h853K1Zc181RlFGXG1+uL/Q/8VeKiASiCu+7L
1zpfLg7OCr6rJHb5S7wU+CeAvzSqmyy0fd2mwPeiX7huK+Cw4UjaB3yGKItzWT+KQJnV//wcSrzZ
dTGCAv0wggL5AgEBMHAwaTETMBEGCgmSJomT8ixkARkWA29yZzEYMBYGCgmSJomT8ixkARkWCERP
RUdyaWRzMSAwHgYDVQQLExdDZXJ0aWZpY2F0ZSBBdXRob3JpdGllczEWMBQGA1UEAxMNRE9FR3Jp
ZHMgQ0EgMQIDAIH7MAkGBSsOAwIaBQCgggFiMBgGCSqGSIb3DQEJAzELBgkqhkiG9w0BBwEwHAYJ
KoZIhvcNAQkFMQ8XDTA5MDgyNjEzNTQyNlowIwYJKoZIhvcNAQkEMRYEFCvbek5GpGQF7j1ZFpb0
dThRPt8VMH8GCSsGAQQBgjcQBDFyMHAwaTETMBEGCgmSJomT8ixkARkWA29yZzEYMBYGCgmSJomT
8ixkARkWCERPRUdyaWRzMSAwHgYDVQQLExdDZXJ0aWZpY2F0ZSBBdXRob3JpdGllczEWMBQGA1UE
AxMNRE9FR3JpZHMgQ0EgMQIDAIH7MIGBBgsqhkiG9w0BCRACCzFyoHAwaTETMBEGCgmSJomT8ixk
ARkWA29yZzEYMBYGCgmSJomT8ixkARkWCERPRUdyaWRzMSAwHgYDVQQLExdDZXJ0aWZpY2F0ZSBB
dXRob3JpdGllczEWMBQGA1UEAxMNRE9FR3JpZHMgQ0EgMQIDAIH7MA0GCSqGSIb3DQEBAQUABIIB
ADvjTGYS2c66rhv1rfsfjNocRXpPuZLfmxa3NQUxqkRsV6is53BlVVKAPF7Ki9BrIc18ndgz84hr
Wibdno92Z27KbhMNTLLHSwFC5GzfLK3wFzKiLa74C62kd/73NHJCmymKWNqlt+yRcUfs7YEVI3dp
dKuzYtqP1/YGbGgwcf1Lp1e6lir1rVWUG/ynFCeQPqn003fCj3cBJ2H0sCj2VJOdQzDy4VBV4QS+
eU7tsH14DcpTjgeVZ3LLpwB5QCoF9oZj2nkEDu9UzFEJ5n1kJ9jzSVPuOfYr7Oz2qQu6bs3D6AzC
wgf7uSSN71dQqvtSstdkbpH6QpYOJPjVV2PrQ9YAAAAAAAA=

--Apple-Mail-281-257242997--

From common-user-return-17085-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 14:30:24 2009
Return-Path: <common-user-return-17085-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 26315 invoked from network); 26 Aug 2009 14:30:24 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 14:30:24 -0000
Received: (qmail 43647 invoked by uid 500); 26 Aug 2009 14:30:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 43580 invoked by uid 500); 26 Aug 2009 14:30:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 43566 invoked by uid 99); 26 Aug 2009 14:30:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 14:30:21 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jason.hadoop@gmail.com designates 209.85.212.185 as permitted sender)
Received: from [209.85.212.185] (HELO mail-vw0-f185.google.com) (209.85.212.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 14:30:10 +0000
Received: by vws15 with SMTP id 15so149644vws.5
        for <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 07:29:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=m7aKC2I378SETO+LFcMb5/Pi+Q4Pys8E2HVp/dH4MO8=;
        b=t7EJ253S5NRS1rXpEUFrBBc6CZGspWRXNzeIm4pZwSv/yG/kNPlQXLEFKOTXyoBWYV
         A0K7qP0lDM/d6+2sOTJxRSp3tMwgV0aISbb833qaG5naVhY1jCggKpPAYnNuQAvhK6b2
         qE+sRQhE0U/DR1X+btaoJe3j7MPc2Nay874wI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=n3Q5pSbAw8zY/nJWSGfGg3kKPaqxrNAcnhjSKTBYCy8sFoCWTFmhwH34i7UpmllSXL
         9wo3iRJmUDbC2tZ+Yam+YGRknVcYmZCxzCqFuqZJVbmrCQTmQsnWEeyH/x3zRbiaa+Uz
         3RSjETi1G75HiBe0/j82wQs8KNmJa0T5OXWFI=
MIME-Version: 1.0
Received: by 10.220.6.78 with SMTP id 14mr10545562vcy.52.1251296989379; Wed, 
	26 Aug 2009 07:29:49 -0700 (PDT)
In-Reply-To: <4A95CA58.3030608@yahoo-inc.com>
References: <4A95CA58.3030608@yahoo-inc.com>
Date: Wed, 26 Aug 2009 07:29:49 -0700
Message-ID: <314098690908260729kbb8b5bch4ac0b3b51b559c04@mail.gmail.com>
Subject: Re: Testing Hadoop job
From: Jason Venner <jason.hadoop@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00163646d10e8f7ffe04720c4835
X-Virus-Checked: Checked by ClamAV on apache.org

--00163646d10e8f7ffe04720c4835
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I put together a framework for the Pro Hadoop book that I use quite a bit,
and has some documentation in the book examples ;)
I haven't tried it with 0.20.0 however.

The nicest thing that I did with the framework was provide a way to run a
persistent mini virtual cluster for running multiple tests on.

On Wed, Aug 26, 2009 at 4:50 PM, Nikhil Sawant <nsawant@yahoo-inc.com>wrote:

> hi
>
> can u guys suggest some hadoop unit testing framework apart from MRUnit???
> i have used MRUnit but i m not sure abt its feasibilty and support to
> hadoop 0.20.....
> i could not find a proper documentation for MRUnit, is it available
> anywhere?
>
> --
> cheers
> nikhil
>
>


-- 
Pro Hadoop, a book to guide you from beginner to hadoop mastery,
http://www.amazon.com/dp/1430219424?tag=jewlerymall
www.prohadoopbook.com a community for Hadoop Professionals

--00163646d10e8f7ffe04720c4835--

From common-user-return-17086-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 14:36:55 2009
Return-Path: <common-user-return-17086-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 30830 invoked from network); 26 Aug 2009 14:36:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 14:36:54 -0000
Received: (qmail 67028 invoked by uid 500); 26 Aug 2009 14:36:52 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 66950 invoked by uid 500); 26 Aug 2009 14:36:52 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 66940 invoked by uid 99); 26 Aug 2009 14:36:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 14:36:52 +0000
X-ASF-Spam-Status: No, hits=-1.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jeremy@lotame.com designates 65.55.88.15 as permitted sender)
Received: from [65.55.88.15] (HELO TX2EHSOBE010.bigfish.com) (65.55.88.15)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 14:36:42 +0000
Received: from mail9-tx2-R.bigfish.com (10.9.14.238) by
 TX2EHSOBE010.bigfish.com (10.9.40.30) with Microsoft SMTP Server id
 8.1.340.0; Wed, 26 Aug 2009 14:36:21 +0000
Received: from mail9-tx2 (localhost.localdomain [127.0.0.1])	by
 mail9-tx2-R.bigfish.com (Postfix) with ESMTP id 81F4AA6051B	for
 <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 14:36:21 +0000 (UTC)
X-SpamScore: -45
X-BigFish: VPS-45(zza40W542N1432R98dN936eM9371P3b5bkzz1202hzzz2fh6bh43j61h)
X-Spam-TCS-SCL: 0:0
X-FB-SS: 5,
Received: by mail9-tx2 (MessageSwitch) id 1251297378743136_3994; Wed, 26 Aug
 2009 14:36:18 +0000 (UCT)
Received: from inmail.lotame.com (unknown [12.54.14.100])	(using TLSv1 with
 cipher RC4-MD5 (128/128 bits))	(No client certificate requested)	by
 mail9-tx2.bigfish.com (Postfix) with ESMTP id 5BF1BFE805C	for
 <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 14:36:18 +0000 (UTC)
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-Class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
Subject: RE: 0.19.1 infinite loop
Date: Wed, 26 Aug 2009 10:35:26 -0400
Message-ID: <FFE8D0F9A5491746834D896CFB004CB502125CC1@ltfps1.Lotame.com>
In-Reply-To: <21A8221B-7AD4-496D-9859-83F930F71354@cse.unl.edu>
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
Thread-Topic: 0.19.1 infinite loop
Thread-Index: AcomVOYy8RxP6W0fQ6OvtAl1lnmapgABFLaA
References: <FFE8D0F9A5491746834D896CFB004CB502125C59@ltfps1.Lotame.com> <21A8221B-7AD4-496D-9859-83F930F71354@cse.unl.edu>
From: Jeremy Pinkham <jeremy@lotame.com>
To: <common-user@hadoop.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks Brian.  I'm trying to find a way to reliably replicate it, and
will certainly update this list if I manage to do so.  It is happening
with more frequency in our QA environment, which is a much smaller
cluster (only 2 nodes), but still not deterministically.  Hopefully we
can hone in on something.

-----Original Message-----
From: Brian Bockelman [mailto:bbockelm@cse.unl.edu] =

Sent: Wednesday, August 26, 2009 9:54 AM
To: common-user@hadoop.apache.org
Subject: Re: 0.19.1 infinite loop

Hey Jeremy,

Glad someone else has run into this!

I always thought this specific infinite loop was in my code.  I had an  =

issue open for it earlier, but I ultimately was not sure if it was in  =

my code or HDFS, so we closed it:

https://issues.apache.org/jira/browse/HADOOP-4866

We [and others] get these daily.  It would be nice to figure out a way  =

to replicate this.

Brian

On Aug 26, 2009, at 8:27 AM, Jeremy Pinkham wrote:

> I'm using hadoop 0.19.1 on a 60 node cluster, each node has 8GB of ram
> and 4 cores.  I have several jobs that run every day, and last night  =

> one
> of them triggered an infinite loop that rendered the cluster  =

> inoperable.
> As the job finishes, the following is logged to the job tracker logs:
>
>
>
> 2009-08-25 22:08:04,633 INFO org.apache.hadoop.mapred.JobInProgress:
> Task 'attempt_200908220740_0126_r_000001_0' has completed
> task_200908220740_0126_r_000001 successfully.
>
> 2009-08-25 22:08:04,633 INFO org.apache.hadoop.mapred.JobInProgress:  =

> Job
> job_200908220740_0126 has completed successfully.
>
> 2009-08-25 22:08:09,897 INFO org.apache.hadoop.hdfs.DFSClient: Could  =

> not
> complete file
> /proc/statpump/incremental/200908260200/_logs/history/dup- =

> jt_12509412317
> 25_job_200908220740_0126_hadoop_statpump-incremental retrying...
>
>
>
> That last line, "Could not complete file..." then repeats forever, at
> which point the job tracker UI stops responding and no more tasks will
> run.  The only way to free things up is to restart the jobtracker
>
>
>
> Both prior to and during the infinite loop, I see this in the namenode
> logs.  Because it starts long before the inifinte loop I can't tell  =

> for
> sure if it's related, and it is still happening now even after the
> restart and with jobs finishing without issue
>
>
>
> 2009-08-25 22:08:05,760 INFO org.apache.hadoop.ipc.Server: IPC Server
> handler 5 on 54310, call
> nextGenerationStamp(blk_2796235715791117970_4385127) from
> 172.21.30.2:48164: error: java.io.IOException:
> blk_2796235715791117970_4385127 is already commited, storedBlock =3D=3D
> null.
>
> java.io.IOException: blk_2796235715791117970_4385127 is already
> commited, storedBlock =3D=3D null.
>
>        at
> org =

> .apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampF
> orBlock(FSNamesystem.java:4552)
>
>        at
> org =

> .apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(Name
> Node.java:402)
>
>        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
>
>        at
> sun =

> .reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessor
> Impl.java:25)
>
>        at java.lang.reflect.Method.invoke(Method.java:597)
>
>        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:481)
>
>        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:894)
>
>
>
> And finally, this warning appears in the namenode logs just prior as
> well
>
>
>
> 2009-08-25 22:07:22,580 WARN
> org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Inconsistent size
> for block blk_-1458477261945758787_4416123 reported from
> 172.21.30.4:50010 current size is 5396992 reported size is 67108864
>
>
>
> Can anyone point me in a direction to determine what's going here?
>
>
>
> Thanks
>
>
>
> The information transmitted in this email is intended only for the  =

> person(s) or entity to which it is addressed and may contain  =

> confidential and/or privileged material. Any review, retransmission,  =

> dissemination or other use of, or taking of any action in reliance  =

> upon, this information by persons or entities other than the  =

> intended recipient is prohibited. If you received this email in  =

> error, please contact the sender and permanently delete the email  =

> from any computer.
>


The information transmitted in this email is intended only for the person(s=
) or entity to which it is addressed and may contain confidential and/or pr=
ivileged material. Any review, retransmission, dissemination or other use o=
f, or taking of any action in reliance upon, this information by persons or=
 entities other than the intended recipient is prohibited. If you received =
this email in error, please contact the sender and permanently delete the e=
mail from any computer.



From common-user-return-17087-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 16:33:13 2009
Return-Path: <common-user-return-17087-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 5996 invoked from network); 26 Aug 2009 16:33:13 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 16:33:13 -0000
Received: (qmail 92138 invoked by uid 500); 26 Aug 2009 16:33:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 92065 invoked by uid 500); 26 Aug 2009 16:33:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 92055 invoked by uid 500); 26 Aug 2009 16:33:10 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 92052 invoked by uid 99); 26 Aug 2009 16:33:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 16:33:10 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of thkunkel@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 16:33:02 +0000
Received: by gxk27 with SMTP id 27so333957gxk.12
        for <core-user@hadoop.apache.org>; Wed, 26 Aug 2009 09:32:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=YV01/pxOTQHr1Olt8QcQDlqhZ6+PjKZa8Cx2JUup5U4=;
        b=Mr9EdTu/u2kms2cro0O4UIgmuqqfz6dibDoJcD/JcYifkaaro3DCY5hp7kBEWbRf0a
         VoBIs7DX2ObFB3ea3VFCFEFNi/mHEWaj8RJnKyKYln01RZ6gzJLhr5im7ZcONS/UXqwI
         wCFOGY4Ov4EHsDIeYh+ExtgQNVbZAJM5dQJA8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=HJ74GFDDANMleqbERFw1tDTKMqR9bcgLMO70zl7F0fdicDpggTVun6QqXbDM+p8P/o
         lO8KfR4QyYTf1cyYy9u7BDlp68ZTFDC9ifBsFBxPjc3ojxeAMpv/4SqxIhE7FSYgGvex
         2Qp1vPLfCRfLzzboJbEt5CDEW7XSKMIh1JexA=
MIME-Version: 1.0
Received: by 10.90.211.6 with SMTP id j6mr6183329agg.86.1251304361471; Wed, 26 
	Aug 2009 09:32:41 -0700 (PDT)
Date: Wed, 26 Aug 2009 11:32:41 -0500
Message-ID: <8134a2730908260932j272fb4d0r5cc002b6774c6085@mail.gmail.com>
Subject: Concatenating files on HDFS
From: Turner Kunkel <thkunkel@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Is there any way to concatenate/append a local file to a file on HDFS
without copying down the HDFS file locally first?

I tried:
bin/hadoop dfs -cat file:///[local file] >> hdfs://[hdfs file]
But it just tries to look for hdfs://[hdfs file] as a local file,
since I suppose the dfs -cat command doesn't support the >> operator.

Thanks.
-- 

-Turner Kunkel

From common-user-return-17088-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 16:54:03 2009
Return-Path: <common-user-return-17088-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11158 invoked from network); 26 Aug 2009 16:54:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 16:54:03 -0000
Received: (qmail 17542 invoked by uid 500); 26 Aug 2009 16:54:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 17473 invoked by uid 500); 26 Aug 2009 16:54:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 17463 invoked by uid 99); 26 Aug 2009 16:54:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 16:54:00 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 209.85.222.177 is neither permitted nor denied by domain of kjirapinyo@biz360.com)
Received: from [209.85.222.177] (HELO mail-pz0-f177.google.com) (209.85.222.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 16:53:52 +0000
Received: by pzk7 with SMTP id 7so345212pzk.2
        for <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 09:53:32 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.178.8 with SMTP id a8mr3625767rvf.220.1251305612114; Wed, 
	26 Aug 2009 09:53:32 -0700 (PDT)
In-Reply-To: <4A948ED3.1000202@yahoo-inc.com>
References: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com> 
	<4A947B5F.4080004@yahoo-inc.com> <42a1925b0908251746i31830360o8ec79c8a79bfa245@mail.gmail.com> 
	<4A948ED3.1000202@yahoo-inc.com>
From: Kris Jirapinyo <kris.jirapinyo@biz360.com>
Date: Wed, 26 Aug 2009 09:53:12 -0700
Message-ID: <42a1925b0908260953m5bf35f80qac898f7cf2d5ecba@mail.gmail.com>
Subject: Re: Intra-datanode balancing?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd2117683fcdf04720e4a47
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd2117683fcdf04720e4a47
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

But I mean, then how does that datanode knows that these files were copied
from one partition to another, in this new directory?  I'm not sure the
inner workings of how a datanode knows what files are on itself...I was
assuming that it knows by keeping track of the subdir directory...or is that
just a placeholder name and whatever directory is under that parent
directory will be scanned and picked up by the datanode?

Kris.

On Tue, Aug 25, 2009 at 6:24 PM, Raghu Angadi <rangadi@yahoo-inc.com> wrote:

> Kris Jirapinyo wrote:
>
>> How does copying the subdir work?  What if that partition already has the
>> same subdir (in the case that our partition is not new but relatively
>> new...with maybe 10% used)?
>>
>
> You can copy the files. There isn't really any requirement on number of
> files in  directory. something like cp -r subdir5 dest/subdir5 might do (or
> rsync without --delete option). Just make sure you delete the directory from
> the source.
>
> Raghu.
>
>
>  Thanks for the suggestions so far guys.
>>
>> Kris.
>>
>> On Tue, Aug 25, 2009 at 5:01 PM, Raghu Angadi <rangadi@yahoo-inc.com>
>> wrote:
>>
>>  For now you are stuck with the hack. Sooner or later hadoop has to handle
>>> heterogeneous nodes better.
>>>
>>> In general it tries to write to all the disks irrespective of % full
>>> since
>>> that gives the best performance (assuming each partition's capabilities
>>> are
>>> same). But it is lame at handling skews.
>>>
>>> Regd your hack :
>>>  1. You can copy subdir to new partition rather than deleting
>>>    (datanodes should be shutdown).
>>>
>>>  2. I would think it is less work to implement a better policy in
>>> DataNode
>>> for this case. It would be a pretty local change. When choosing a
>>> partition
>>> for a new block, DN already knows how much freespace is left on each one.
>>> for simplest implementation you skip partitions that have less 25% of avg
>>> freespace or choose with a probability proportional to relative
>>> freespace.
>>> If it works well, file a jira.
>>>
>>> I don't think HDFS-343 is directly related to this or is likely to be
>>> fixed. There is another jira that makes placement policy at NameNode
>>> pluggable (does not affect Datanode).
>>>
>>> Raghu.
>>>
>>>
>>> Kris Jirapinyo wrote:
>>>
>>>  Hi all,
>>>>   I know this has been filed as a JIRA improvement already
>>>> http://issues.apache.org/jira/browse/HDFS-343, but is there any good
>>>> workaround at the moment?  What's happening is I have added a few new
>>>> EBS
>>>> volumes to half of the cluster, but Hadoop doesn't want to write to
>>>> them.
>>>> When I try to do cluster rebalancing, since the new disks make the
>>>> percentage used lower, it fills up the first two existing local disks,
>>>> which
>>>> is exactly what I don't want to happen.  Currently, I just delete
>>>> several
>>>> subdirs from dfs, since I know that with a replication factor of 3,
>>>> it'll
>>>> be
>>>> ok, so that fixes the problems in the short term.  But I still cannot
>>>> get
>>>> Hadoop to use those new larger disks efficiently.  Any thoughts?
>>>>
>>>> -- Kris.
>>>>
>>>>
>>>>
>>
>

--000e0cd2117683fcdf04720e4a47--

From common-user-return-17089-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 17:14:58 2009
Return-Path: <common-user-return-17089-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 20088 invoked from network); 26 Aug 2009 17:14:58 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 17:14:58 -0000
Received: (qmail 53437 invoked by uid 500); 26 Aug 2009 17:14:55 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 53347 invoked by uid 500); 26 Aug 2009 17:14:55 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 53337 invoked by uid 99); 26 Aug 2009 17:14:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 17:14:55 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 17:14:45 +0000
Received: from [10.72.106.226] (heighthigh-lx.corp.yahoo.com [10.72.106.226])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7QHDJlS019889
	for <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 10:13:19 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=ak4udmO6TbE/b9JlFNNTMlD2WdhWIdciqMSC3KnZcIlb0bGrCiBOWyTARtCLbA40
Message-ID: <4A956D2F.50509@yahoo-inc.com>
Date: Wed, 26 Aug 2009 10:13:19 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.23 (Windows/20090812)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Intra-datanode balancing?
References: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com> 	<4A947B5F.4080004@yahoo-inc.com> <42a1925b0908251746i31830360o8ec79c8a79bfa245@mail.gmail.com> 	<4A948ED3.1000202@yahoo-inc.com> <42a1925b0908260953m5bf35f80qac898f7cf2d5ecba@mail.gmail.com>
In-Reply-To: <42a1925b0908260953m5bf35f80qac898f7cf2d5ecba@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Kris Jirapinyo wrote:
> But I mean, then how does that datanode knows that these files were copied
> from one partition to another, in this new directory?  I'm not sure the
> inner workings of how a datanode knows what files are on itself...I was
> assuming that it knows by keeping track of the subdir directory...


> or is that
> just a placeholder name and whatever directory is under that parent
> directory will be scanned and picked up by the datanode?

correct. directory name does not matter. Only requirement is a block 
file and its .meta file in the same directory. When datanode starts up 
it scans all these directories and stores their path in memory.

Of course, this is still a big hack! (just making it clear for readers 
who haven't seen the full context).

Raghu.

> Kris.
> 
> On Tue, Aug 25, 2009 at 6:24 PM, Raghu Angadi <rangadi@yahoo-inc.com> wrote:
> 
>> Kris Jirapinyo wrote:
>>
>>> How does copying the subdir work?  What if that partition already has the
>>> same subdir (in the case that our partition is not new but relatively
>>> new...with maybe 10% used)?
>>>
>> You can copy the files. There isn't really any requirement on number of
>> files in  directory. something like cp -r subdir5 dest/subdir5 might do (or
>> rsync without --delete option). Just make sure you delete the directory from
>> the source.
>>
>> Raghu.
>>
>>
>>  Thanks for the suggestions so far guys.
>>> Kris.
>>>
>>> On Tue, Aug 25, 2009 at 5:01 PM, Raghu Angadi <rangadi@yahoo-inc.com>
>>> wrote:
>>>
>>>  For now you are stuck with the hack. Sooner or later hadoop has to handle
>>>> heterogeneous nodes better.
>>>>
>>>> In general it tries to write to all the disks irrespective of % full
>>>> since
>>>> that gives the best performance (assuming each partition's capabilities
>>>> are
>>>> same). But it is lame at handling skews.
>>>>
>>>> Regd your hack :
>>>>  1. You can copy subdir to new partition rather than deleting
>>>>    (datanodes should be shutdown).
>>>>
>>>>  2. I would think it is less work to implement a better policy in
>>>> DataNode
>>>> for this case. It would be a pretty local change. When choosing a
>>>> partition
>>>> for a new block, DN already knows how much freespace is left on each one.
>>>> for simplest implementation you skip partitions that have less 25% of avg
>>>> freespace or choose with a probability proportional to relative
>>>> freespace.
>>>> If it works well, file a jira.
>>>>
>>>> I don't think HDFS-343 is directly related to this or is likely to be
>>>> fixed. There is another jira that makes placement policy at NameNode
>>>> pluggable (does not affect Datanode).
>>>>
>>>> Raghu.
>>>>
>>>>
>>>> Kris Jirapinyo wrote:
>>>>
>>>>  Hi all,
>>>>>   I know this has been filed as a JIRA improvement already
>>>>> http://issues.apache.org/jira/browse/HDFS-343, but is there any good
>>>>> workaround at the moment?  What's happening is I have added a few new
>>>>> EBS
>>>>> volumes to half of the cluster, but Hadoop doesn't want to write to
>>>>> them.
>>>>> When I try to do cluster rebalancing, since the new disks make the
>>>>> percentage used lower, it fills up the first two existing local disks,
>>>>> which
>>>>> is exactly what I don't want to happen.  Currently, I just delete
>>>>> several
>>>>> subdirs from dfs, since I know that with a replication factor of 3,
>>>>> it'll
>>>>> be
>>>>> ok, so that fixes the problems in the short term.  But I still cannot
>>>>> get
>>>>> Hadoop to use those new larger disks efficiently.  Any thoughts?
>>>>>
>>>>> -- Kris.
>>>>>
>>>>>
>>>>>
> 


From common-user-return-17090-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 17:40:14 2009
Return-Path: <common-user-return-17090-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 35326 invoked from network); 26 Aug 2009 17:40:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 17:40:14 -0000
Received: (qmail 369 invoked by uid 500); 26 Aug 2009 17:40:11 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 275 invoked by uid 500); 26 Aug 2009 17:40:11 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 265 invoked by uid 99); 26 Aug 2009 17:40:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 17:40:11 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.222.177 is neither permitted nor denied by domain of kjirapinyo@biz360.com)
Received: from [209.85.222.177] (HELO mail-pz0-f177.google.com) (209.85.222.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 17:40:01 +0000
Received: by pzk7 with SMTP id 7so398256pzk.2
        for <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 10:39:40 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.158.3 with SMTP id g3mr3818844rve.181.1251308380109; Wed, 
	26 Aug 2009 10:39:40 -0700 (PDT)
In-Reply-To: <4A956D2F.50509@yahoo-inc.com>
References: <42a1925b0908251251r1d8f37e7iefe25800117c85a7@mail.gmail.com> 
	<4A947B5F.4080004@yahoo-inc.com> <42a1925b0908251746i31830360o8ec79c8a79bfa245@mail.gmail.com> 
	<4A948ED3.1000202@yahoo-inc.com> <42a1925b0908260953m5bf35f80qac898f7cf2d5ecba@mail.gmail.com> 
	<4A956D2F.50509@yahoo-inc.com>
From: Kris Jirapinyo <kris.jirapinyo@biz360.com>
Date: Wed, 26 Aug 2009 10:39:20 -0700
Message-ID: <42a1925b0908261039h78273cbdy9738ea921f5dfb22@mail.gmail.com>
Subject: Re: Intra-datanode balancing?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd216f8803ae704720eeffd
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd216f8803ae704720eeffd
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hmm then in that case, it is possible for me to manually balance load those
datanodes by moving most of the files onto the new, larger partition.  I
will try it.  Thanks!

-- Kris J.

On Wed, Aug 26, 2009 at 10:13 AM, Raghu Angadi <rangadi@yahoo-inc.com>wrote:

> Kris Jirapinyo wrote:
>
>> But I mean, then how does that datanode knows that these files were copied
>> from one partition to another, in this new directory?  I'm not sure the
>> inner workings of how a datanode knows what files are on itself...I was
>> assuming that it knows by keeping track of the subdir directory...
>>
>
>
>  or is that
>> just a placeholder name and whatever directory is under that parent
>> directory will be scanned and picked up by the datanode?
>>
>
> correct. directory name does not matter. Only requirement is a block file
> and its .meta file in the same directory. When datanode starts up it scans
> all these directories and stores their path in memory.
>
> Of course, this is still a big hack! (just making it clear for readers who
> haven't seen the full context).
>
> Raghu.
>
>
>  Kris.
>>
>> On Tue, Aug 25, 2009 at 6:24 PM, Raghu Angadi <rangadi@yahoo-inc.com>
>> wrote:
>>
>>  Kris Jirapinyo wrote:
>>>
>>>  How does copying the subdir work?  What if that partition already has
>>>> the
>>>> same subdir (in the case that our partition is not new but relatively
>>>> new...with maybe 10% used)?
>>>>
>>>>  You can copy the files. There isn't really any requirement on number of
>>> files in  directory. something like cp -r subdir5 dest/subdir5 might do
>>> (or
>>> rsync without --delete option). Just make sure you delete the directory
>>> from
>>> the source.
>>>
>>> Raghu.
>>>
>>>
>>>  Thanks for the suggestions so far guys.
>>>
>>>> Kris.
>>>>
>>>> On Tue, Aug 25, 2009 at 5:01 PM, Raghu Angadi <rangadi@yahoo-inc.com>
>>>> wrote:
>>>>
>>>>  For now you are stuck with the hack. Sooner or later hadoop has to
>>>> handle
>>>>
>>>>> heterogeneous nodes better.
>>>>>
>>>>> In general it tries to write to all the disks irrespective of % full
>>>>> since
>>>>> that gives the best performance (assuming each partition's capabilities
>>>>> are
>>>>> same). But it is lame at handling skews.
>>>>>
>>>>> Regd your hack :
>>>>>  1. You can copy subdir to new partition rather than deleting
>>>>>   (datanodes should be shutdown).
>>>>>
>>>>>  2. I would think it is less work to implement a better policy in
>>>>> DataNode
>>>>> for this case. It would be a pretty local change. When choosing a
>>>>> partition
>>>>> for a new block, DN already knows how much freespace is left on each
>>>>> one.
>>>>> for simplest implementation you skip partitions that have less 25% of
>>>>> avg
>>>>> freespace or choose with a probability proportional to relative
>>>>> freespace.
>>>>> If it works well, file a jira.
>>>>>
>>>>> I don't think HDFS-343 is directly related to this or is likely to be
>>>>> fixed. There is another jira that makes placement policy at NameNode
>>>>> pluggable (does not affect Datanode).
>>>>>
>>>>> Raghu.
>>>>>
>>>>>
>>>>> Kris Jirapinyo wrote:
>>>>>
>>>>>  Hi all,
>>>>>
>>>>>>  I know this has been filed as a JIRA improvement already
>>>>>> http://issues.apache.org/jira/browse/HDFS-343, but is there any good
>>>>>> workaround at the moment?  What's happening is I have added a few new
>>>>>> EBS
>>>>>> volumes to half of the cluster, but Hadoop doesn't want to write to
>>>>>> them.
>>>>>> When I try to do cluster rebalancing, since the new disks make the
>>>>>> percentage used lower, it fills up the first two existing local disks,
>>>>>> which
>>>>>> is exactly what I don't want to happen.  Currently, I just delete
>>>>>> several
>>>>>> subdirs from dfs, since I know that with a replication factor of 3,
>>>>>> it'll
>>>>>> be
>>>>>> ok, so that fixes the problems in the short term.  But I still cannot
>>>>>> get
>>>>>> Hadoop to use those new larger disks efficiently.  Any thoughts?
>>>>>>
>>>>>> -- Kris.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>
>

--000e0cd216f8803ae704720eeffd--

From common-user-return-17091-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Wed Aug 26 22:11:56 2009
Return-Path: <common-user-return-17091-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 45084 invoked from network); 26 Aug 2009 22:11:56 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 26 Aug 2009 22:11:56 -0000
Received: (qmail 79610 invoked by uid 500); 26 Aug 2009 22:11:54 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 79536 invoked by uid 500); 26 Aug 2009 22:11:53 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 79526 invoked by uid 99); 26 Aug 2009 22:11:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 22:11:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hadooprocks@gmail.com designates 209.85.222.177 as permitted sender)
Received: from [209.85.222.177] (HELO mail-pz0-f177.google.com) (209.85.222.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 26 Aug 2009 22:11:44 +0000
Received: by pzk7 with SMTP id 7so639449pzk.2
        for <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 15:11:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=tAgyHXSlLbENRdX7Jy/+eMCuc7fzFkeNvsPPAgZ8Edk=;
        b=w7iYduO1WiBaeP8cnhTpwLtBC6/z6afIjlOyemXDrGEeNkgIX1i2Uz/SWz6IWlTogG
         NNWwiS/bliPw0DF7tlA6ujBlQ5GJ06OsHy8WH3knCw2V/flEgovOPZtaEspwJPPzEEww
         5AT9SD01m53Kjy1sJ4O7l1bPYmM/neKm3RhRQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=WPmd+8GMHRUo51pskj9Z728iZhYH/Xlco7t+y4/kC0asBk0ljJBoBX4FO8vit4NK7k
         1NLgZCYAxl+VcBfCpFJon1WlmpTwAje9/PAovfsRx0p9dh+8KSp15dEOggcFmAjPBlkE
         nZah9e5z+3HntECWk8fqUjkaXLys2GyAwfMqY=
MIME-Version: 1.0
Received: by 10.142.6.8 with SMTP id 8mr636327wff.326.1251324683341; Wed, 26 
	Aug 2009 15:11:23 -0700 (PDT)
Date: Wed, 26 Aug 2009 15:11:23 -0700
Message-ID: <207bdf5a0908261511g4b5ddf83l7ef7433f2d6684fc@mail.gmail.com>
Subject: MapReduce read patterns
From: hadooprcoks <hadooprocks@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00504502b0ec3fcee5047212bb0f
X-Virus-Checked: Checked by ClamAV on apache.org

--00504502b0ec3fcee5047212bb0f
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,
I wanted to know about usual read patterns from MapReduce applications into
HDFS based on users' experiences here. I think large requests are more
common (32K and above) but wanted to know if small reads (512bytes - 1K) are
common too ?

Thanks.

--00504502b0ec3fcee5047212bb0f--

From common-user-return-17092-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 01:17:48 2009
Return-Path: <common-user-return-17092-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 96298 invoked from network); 27 Aug 2009 01:17:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 01:17:48 -0000
Received: (qmail 21358 invoked by uid 500); 27 Aug 2009 01:17:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21188 invoked by uid 500); 27 Aug 2009 01:17:43 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 21130 invoked by uid 500); 27 Aug 2009 01:17:43 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 21122 invoked by uid 99); 27 Aug 2009 01:17:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 01:17:43 +0000
X-ASF-Spam-Status: No, hits=0.0 required=10.0
	tests=HS_INDEX_PARAM,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bradfordstephens@gmail.com designates 209.85.216.191 as permitted sender)
Received: from [209.85.216.191] (HELO mail-px0-f191.google.com) (209.85.216.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 01:17:32 +0000
Received: by pxi29 with SMTP id 29so664101pxi.30
        for <multiple recipients>; Wed, 26 Aug 2009 18:17:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:references:message-id:from:to
         :in-reply-to:content-type:content-transfer-encoding:x-mailer
         :mime-version:subject:date:cc;
        bh=pIemCm5+H/JJ8wfytFj9/v6PQ7xOcFAO4qR3lIiwbRQ=;
        b=LRBLRYiRXCBD3sUbHRJWygvHglZzMCyExj69PFfKa51WG3ExIqz3re22snYVayKBZR
         ZUX/qr6lCQ4c5SgtZHeZ/8T+kkq1ruWcseOMJY/+EuLwfumcypyrwrg7Zu9olmhWsuxf
         MiynsXOnu9vYrslA9dK0pTMGOdt/x23c/U7dk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=references:message-id:from:to:in-reply-to:content-type
         :content-transfer-encoding:x-mailer:mime-version:subject:date:cc;
        b=j14wmkHAxmK238YJAlA+Ss+hUWmTJy8CvMyPEdOQoEGnl6h/nnRxlJ2Bac+eWwMNJ+
         hy6P70NJt3rs28WJomRNNOmNVSrfbz0ERkzHF+DxVHRh5kvTY8FSW575stroGMDLwK6A
         0gmcQfxXY4PFqJGkoxdlcbfrDKk9kqvVLbvvg=
Received: by 10.115.148.16 with SMTP id a16mr10659911wao.57.1251335830157;
        Wed, 26 Aug 2009 18:17:10 -0700 (PDT)
Received: from ?10.236.70.165? ([166.205.135.183])
        by mx.google.com with ESMTPS id f20sm609232waf.17.2009.08.26.18.17.07
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Wed, 26 Aug 2009 18:17:08 -0700 (PDT)
References: <860544ed0908251621leacbe9andc4daefdabb8d62b@mail.gmail.com>
Message-Id: <D97D9F63-3D13-4E9C-94CB-0C1D0722BFD1@gmail.com>
From: Bradford Stephens <bradfordstephens@gmail.com>
To: Bradford Stephens <bradfordstephens@gmail.com>
In-Reply-To: <860544ed0908251621leacbe9andc4daefdabb8d62b@mail.gmail.com>
Content-Type: text/plain;
	charset=us-ascii;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit
X-Mailer: iPhone Mail (7A400)
Mime-Version: 1.0 (iPhone Mail 7A400)
Subject: Re: Seattle / NW Hadoop, HBase Lucene, etc. Meetup , Wed August 26th, 6:45pm
Date: Wed, 26 Aug 2009 18:17:02 -0700
Cc: "core-user@hadoop.apache.org" <core-user@hadoop.apache.org>,
 "hbase-user@hadoop.apache.org" <hbase-user@hadoop.apache.org>,
 "solr-user@lucene.apache.org" <solr-user@lucene.apache.org>,
 "java-user@lucene.apache.org" <java-user@lucene.apache.org>,
 "pig-user@hadoop.apache.org" <pig-user@hadoop.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

My apologies, but there was a mix-up reserving our meeting location,  
and we don't have access to it.

I'm very sorry, and beer is on me next month. Promise :)

Sent from my Internets

On Aug 25, 2009, at 4:21 PM, Bradford Stephens <bradfordstephens@gmail.com 
 > wrote:

> Hey there,
>
> Apologies for this not going out sooner -- apparently it was sitting
> as a draft in my inbox. A few of you have pinged me, so thanks for
> your vigilance.
>
> It's time for another Hadoop/Lucene/Apache Stack meetup! We've had
> great attendance in the past few months, let's keep it up! I'm always
> amazed by the things I learn from everyone.
>
> We're back at the University of Washington, Allen Computer Science
> Center (not Computer Engineering)
> Map: http://www.washington.edu/home/maps/?CSE
>
> Room: 303 -or- the Entry level. If there are changes, signs will be  
> posted.
>
> More Info:
>
> The meetup is about 2 hours: we'll have two in-depth talks of 15-20
> minutes each, and then several "lightning talks" of 5 minutes. If no
> one offers, We'll then have discussion and 'social time'.  we'll just
> have general discussion. Let net know if you're interested in speaking
> or attending. We'd like to focus on education, so every presentation
> *needs* to ask some questions at the end. We can talk about these
> after the presentations, and I'll record what we've learned in a wiki
> and share that with the rest of us.
>
> Contact: Bradford Stephens, 904-415-3009, bradfordstephens@gmail.com
>
> --
> http://www.roadtofailure.com -- The Fringes of Scalability, Social
> Media, and Computer Science

From common-user-return-17093-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 01:31:12 2009
Return-Path: <common-user-return-17093-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 1661 invoked from network); 27 Aug 2009 01:31:12 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 01:31:12 -0000
Received: (qmail 39028 invoked by uid 500); 27 Aug 2009 01:31:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 38962 invoked by uid 500); 27 Aug 2009 01:31:09 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 38952 invoked by uid 99); 27 Aug 2009 01:31:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 01:31:09 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of yasuyuki@kddilabs.jp designates 192.26.91.6 as permitted sender)
Received: from [192.26.91.6] (HELO mandala.kddilabs.jp) (192.26.91.6)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 01:30:59 +0000
Received: from localhost (localhost [127.0.0.1])
	by mandala.kddilabs.jp (Postfix) with ESMTP
	id 92007EC92D; Thu, 27 Aug 2009 10:30:36 +0900 (JST)
Received: from mail.cn.kddilabs.jp (yellow.lan.kddilabs.jp [172.19.98.10])
	by mandala.kddilabs.jp (Postfix) with ESMTP
	id E8A3AEC907; Thu, 27 Aug 2009 10:29:18 +0900 (JST)
Received: from KDDI-0504PC0443.kddi.com (dhcp151.gat.cn.kddilabs.jp [172.19.119.151])
	by mail.cn.kddilabs.jp (Postfix) with ESMTP id D23DA1E0002;
	Thu, 27 Aug 2009 10:29:18 +0900 (JST)
Date: Thu, 27 Aug 2009 10:29:08 +0900
Message-ID: <82k50qvycb.wl@kddi.com>
From: Yasuyuki Watanabe <yasuyuki@kddilabs.jp>
To: common-user@hadoop.apache.org
Subject: Symlink support
User-Agent: Wanderlust/2.15.7 (Almost Unreal) Emacs/23.0 Mule/6.0
 (=?ISO-2022-JP?B?GyRCMlY7Nk4kGyhC?=)
MIME-Version: 1.0 (generated by SEMI 1.14.6 - "Maruoka")
Content-Type: text/plain; charset=US-ASCII
X-Virus-Scanned: by amavisd-new
X-Virus-Checked: Checked by ClamAV on apache.org

Hi!

Could someone tell me about the status of symbolic link support
in HDFS (HDFS-245)?

It looks like a patch is merged with latest trunk. So I would
like to know how good it works and whether or not the patch is
applicable for the current release of Hadoop.

We just start testing HDFS as a part of our ftp mirror site
(http://ftp.kddilabs.jp/). It works fine so far. But if HDFS
supports symlink feature, we could save lots of capacity :-)

Thanks.

Yasu


From common-user-return-17094-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 01:53:19 2009
Return-Path: <common-user-return-17094-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 12366 invoked from network); 27 Aug 2009 01:53:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 01:53:18 -0000
Received: (qmail 64426 invoked by uid 500); 27 Aug 2009 01:53:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 64340 invoked by uid 500); 27 Aug 2009 01:53:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 64262 invoked by uid 500); 27 Aug 2009 01:53:14 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 64241 invoked by uid 99); 27 Aug 2009 01:53:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 01:53:14 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rvernica@gmail.com designates 209.85.216.191 as permitted sender)
Received: from [209.85.216.191] (HELO mail-px0-f191.google.com) (209.85.216.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 01:53:06 +0000
Received: by pxi29 with SMTP id 29so684610pxi.30
        for <core-user@hadoop.apache.org>; Wed, 26 Aug 2009 18:52:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=UefFHb+35mxxUmIfn9FPjDKWE0qBpXoXORS1B8UHwps=;
        b=xHxNeBpKAx9p530NSa80xRSOPh+dxWIISZQtG2UiRBQ7FQHR0Iizh7bXP1pk80n7Wb
         F4BXEQ24RxJprPfqjXaJ78Dh3fmlbS72DrOOE5T78I3VUprMRUdtT0pdO5TBfF2Y0rqr
         /iiVpUkGeNyg9pcHct3GqHtkXOSXMZzykQLQI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=w32XAxwn61K8EAhuLLmS8hATFsaf3vr8gx3plsU47pl51KIVq3/co9PwylljiL/WMd
         8FSTp2Z7lH1S45AnfkXCIDnlmt22oH6fsHe3pa9U3+wutkgwsMmmv0UnVarlIjKgK2cS
         r8ciRnHmthUgPH5GsG7eeD+S02+B3CNHRUQ1E=
MIME-Version: 1.0
Received: by 10.140.166.15 with SMTP id o15mr4192155rve.12.1251337965781; Wed, 
	26 Aug 2009 18:52:45 -0700 (PDT)
Date: Wed, 26 Aug 2009 18:52:45 -0700
Message-ID: <b8208a3b0908261852x4ca72740qa746fbd6d4c9beca@mail.gmail.com>
Subject: control map to split assignment
From: Rares Vernica <rvernica@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

I wonder is there is a way to control how maps are assigned to splits
in order to balance the load across the cluster.

Here is a simplified example. I have tow types of inputs: "long" and
"short". Each input is in a different file and will be processed by a
single map task. Suppose the "long" inputs take 10s to process while
the "short" inputs take 3s to process. I have two "long" inputs and
two "short" inputs. My cluster has 2 nodes and each node can execute
only one map task at a time. A possible schedule of the tasks could be
the following:

Node 1: "long map", "short map" -> 10s + 3s = 13s
Node 2: "long map", "short map" -> 10s + 3s = 13s

So, my job will be done in 13s. Another possible schedule is:

Node 1: "long map" -> 10s
Node 2: "short map", "short map", "long map" -> 3s + 3s + 10s = 16s

And, my job will be done in 16s. Clearly, the first scheduling is better.

Is there a way to control how the schedule is build? If I can control
which inputs are processed first, I could schedule the "long" inputs
to be processed first and so they will be balanced across nodes and I
will end up with something similar to the first schedule.

I could configure the job so that a "long" input gets processed by
more that a map, and so end up balancing the work, but I noticed that
overall, this takes more time than a bad scheduling with only one map
per input.

Thanks!

Cheers,
Rares Vernica

From common-user-return-17095-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 03:04:50 2009
Return-Path: <common-user-return-17095-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 35117 invoked from network); 27 Aug 2009 03:04:49 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 03:04:49 -0000
Received: (qmail 1183 invoked by uid 500); 27 Aug 2009 03:04:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 938 invoked by uid 500); 27 Aug 2009 03:04:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 927 invoked by uid 99); 27 Aug 2009 03:04:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 03:04:46 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.211.191 as permitted sender)
Received: from [209.85.211.191] (HELO mail-yw0-f191.google.com) (209.85.211.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 03:04:37 +0000
Received: by ywh29 with SMTP id 29so908697ywh.33
        for <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 20:04:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=7Vd49NLvwB8iYhhzV19bNn/IxF58/nU4uPoE3l4k4Hs=;
        b=SkW+BzgPOpD+RpSuBE15ZoxiICdAkCPpA9E7M+lKsZO8yniPadFTirrKpCoT4sc/uN
         8nTspelkWMiNrd4DX5zIOCcTPpVYFSluUohwdiMD7IcUcUMIQ33sZLWHHvXlENiyDCg7
         bbheeNPytuetJhLnAXmW5wuMPsq1k3XmgOy1E=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=Mw6bHFGcTRzQuMSZdVQ0CX1a0ZvtlLyMCxSwrMD0eJA9cZNErBVYQ7RvV5BfSVBUA8
         sjcXRvkTC2zccB8YBRJIENwlWbPVUkuVdTIo3RzXI3DqgorhsgCwQWoItqlZ2UrsJxcU
         VoxEPKVjapTVhayXVeSY+U+qcXHml9nOC65C4=
MIME-Version: 1.0
Received: by 10.101.7.25 with SMTP id k25mr8736726ani.192.1251342256750; Wed, 
	26 Aug 2009 20:04:16 -0700 (PDT)
Date: Thu, 27 Aug 2009 11:04:16 +0800
Message-ID: <3b1311780908262004ua8e0269hc4d914d51b9ea751@mail.gmail.com>
Subject: How does reducer get intermediate output?
From: "inifok.song" <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636c92af7b4c157047216d2d4
X-Virus-Checked: Checked by ClamAV on apache.org

--001636c92af7b4c157047216d2d4
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi all,

In my cluster, the reducer often can't fetch mapper's output. I know there
are many reasons for this situation. And I think it's necessary to find out
how does reducer get intermediate output. I have read the source code.
However, I'm not clear about the whole process. Could you tell me the
process of it? How does each node communicate with each other and how does
class ReduceCopier work?

Thank you.

Inifok

--001636c92af7b4c157047216d2d4--

From common-user-return-17096-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 04:29:46 2009
Return-Path: <common-user-return-17096-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 47997 invoked from network); 27 Aug 2009 04:29:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 04:29:46 -0000
Received: (qmail 53017 invoked by uid 500); 27 Aug 2009 04:29:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 52822 invoked by uid 500); 27 Aug 2009 04:29:43 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 52812 invoked by uid 99); 27 Aug 2009 04:29:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 04:29:43 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.216.191 as permitted sender)
Received: from [209.85.216.191] (HELO mail-px0-f191.google.com) (209.85.216.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 04:29:34 +0000
Received: by pxi29 with SMTP id 29so783433pxi.30
        for <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 21:29:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=DX1nfXvAGwBlELZ+Gio2f51h8cp1Wx6p/ORu9DiS4wY=;
        b=jhYZ+eC0k65ab4SSNCX9pWSgO0nQZ1hvx8w73pz2O5WFCO9JXV4z2HQd9dah0S8wkC
         yCD6x2ZmyRVCUXlnK14glrAegzc28plH1Pyg61cJ2FZ8TJTS8O2ZEic1WSROaDfkuJ6T
         rVVLFA5+rOFAAi7fC6MQrU4kwjL4C8Q/XeAuI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=g85LDPloPTHV1eDz0FOHOgmUfQpgC6WMtjitfwVIFk7CwO9KnU8S04wCKoSRgu4Uyv
         sdHspxWvau/gg47qXThc14HAS6X4hgGdRQN1s2+iI+uHKQljYRCfR9rBbIw4jDNZsG6D
         qDf/xabnHnOnzScFHtOmd+h3/aEWrn0N2dcxs=
MIME-Version: 1.0
Received: by 10.143.138.5 with SMTP id q5mr949789wfn.55.1251347353177; Wed, 26 
	Aug 2009 21:29:13 -0700 (PDT)
In-Reply-To: <3b1311780908262004ua8e0269hc4d914d51b9ea751@mail.gmail.com>
References: <3b1311780908262004ua8e0269hc4d914d51b9ea751@mail.gmail.com>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Thu, 27 Aug 2009 09:58:53 +0530
Message-ID: <e01b80590908262128k7e9b1a36y657b5c95a31613e6@mail.gmail.com>
Subject: Re: How does reducer get intermediate output?
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd51d627a0d7f04721802eb
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd51d627a0d7f04721802eb
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 27, 2009 at 8:34 AM, inifok.song <hadoop.inifok@gmail.com>wrote:

> Hi all,
>
> In my cluster, the reducer often can't fetch mapper's output. I know there
> are many reasons for this situation. And I think it's necessary to find out
> how does reducer get intermediate output. I have read the source code.
> However, I'm not clear about the whole process. Could you tell me the
> process of it? How does each node communicate with each other and how does
> class ReduceCopier work?
>
> Thank you.
>
> Inifok
>

Each TaskTracker runs a Jetty webserver which is responsible for serving
requests for intermediate map-outputs. The ReduceTask process receives
notifications regarding completed MapTasks from its TaskTracker (which in
turn receives that info from the JobTracker). Once it receives these
notifications, the ReduceTask will start fetching these map-outputs via HTTP
by requesting the corresponding TT's Jetty webserver.

-- 
Harish Mallipeddi
http://blog.poundbang.in

--000e0cd51d627a0d7f04721802eb--

From common-user-return-17097-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 05:36:32 2009
Return-Path: <common-user-return-17097-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63744 invoked from network); 27 Aug 2009 05:36:32 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 05:36:32 -0000
Received: (qmail 91443 invoked by uid 500); 27 Aug 2009 05:36:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91333 invoked by uid 500); 27 Aug 2009 05:36:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91304 invoked by uid 99); 27 Aug 2009 05:36:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 05:36:26 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 05:36:15 +0000
Received: from localhost (humannice-lx.eglbp.corp.yahoo.com [10.66.76.219])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7R5YVQE040355;
	Wed, 26 Aug 2009 22:34:31 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=date:from:to:cc:message-id:in-reply-to:subject:
	mime-version:content-type:content-transfer-encoding;
	b=jl9YlvdAbpsvKcr7XIpYgnOdLZy06VgwC2qhSUP3og6INE2EqId17VY94jGI9pU9
Date: Thu, 27 Aug 2009 11:04:30 +0530 (GMT+05:30)
From: Ankur Goel <gankur@yahoo-inc.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Message-ID: <31852133.201251351266400.JavaMail.ankur@ankur-laptop>
In-Reply-To: <26341399.181251350814351.JavaMail.ankur@ankur-laptop>
Subject: Re: Concatenating files on HDFS
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

HDFS files are write once so you cannot append to them (at the moment).
What you can do is copy your local file to HDFS dir containing the same file you want to append to.
Once that is done you can run a simple (Identity Mapper & Identity Reducer) mapreduce job with input
as this directory and number of reducers = 1. 

----- Original Message -----
From: "Turner Kunkel" <thkunkel@gmail.com>
To: core-user@hadoop.apache.org
Sent: Wednesday, August 26, 2009 10:02:41 PM GMT +05:30 Chennai, Kolkata, Mumbai, New Delhi
Subject: Concatenating files on HDFS

Is there any way to concatenate/append a local file to a file on HDFS
without copying down the HDFS file locally first?

I tried:
bin/hadoop dfs -cat file:///[local file] >> hdfs://[hdfs file]
But it just tries to look for hdfs://[hdfs file] as a local file,
since I suppose the dfs -cat command doesn't support the >> operator.

Thanks.
-- 

-Turner Kunkel

From common-user-return-17098-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 05:36:34 2009
Return-Path: <common-user-return-17098-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63824 invoked from network); 27 Aug 2009 05:36:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 05:36:34 -0000
Received: (qmail 91482 invoked by uid 500); 27 Aug 2009 05:36:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91337 invoked by uid 500); 27 Aug 2009 05:36:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91309 invoked by uid 500); 27 Aug 2009 05:36:26 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 91304 invoked by uid 99); 27 Aug 2009 05:36:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 05:36:26 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 05:36:15 +0000
Received: from localhost (humannice-lx.eglbp.corp.yahoo.com [10.66.76.219])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7R5YVQE040355;
	Wed, 26 Aug 2009 22:34:31 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=date:from:to:cc:message-id:in-reply-to:subject:
	mime-version:content-type:content-transfer-encoding;
	b=jl9YlvdAbpsvKcr7XIpYgnOdLZy06VgwC2qhSUP3og6INE2EqId17VY94jGI9pU9
Date: Thu, 27 Aug 2009 11:04:30 +0530 (GMT+05:30)
From: Ankur Goel <gankur@yahoo-inc.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Message-ID: <31852133.201251351266400.JavaMail.ankur@ankur-laptop>
In-Reply-To: <26341399.181251350814351.JavaMail.ankur@ankur-laptop>
Subject: Re: Concatenating files on HDFS
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

HDFS files are write once so you cannot append to them (at the moment).
What you can do is copy your local file to HDFS dir containing the same file you want to append to.
Once that is done you can run a simple (Identity Mapper & Identity Reducer) mapreduce job with input
as this directory and number of reducers = 1. 

----- Original Message -----
From: "Turner Kunkel" <thkunkel@gmail.com>
To: core-user@hadoop.apache.org
Sent: Wednesday, August 26, 2009 10:02:41 PM GMT +05:30 Chennai, Kolkata, Mumbai, New Delhi
Subject: Concatenating files on HDFS

Is there any way to concatenate/append a local file to a file on HDFS
without copying down the HDFS file locally first?

I tried:
bin/hadoop dfs -cat file:///[local file] >> hdfs://[hdfs file]
But it just tries to look for hdfs://[hdfs file] as a local file,
since I suppose the dfs -cat command doesn't support the >> operator.

Thanks.
-- 

-Turner Kunkel

From common-user-return-17099-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 06:41:22 2009
Return-Path: <common-user-return-17099-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 97035 invoked from network); 27 Aug 2009 06:41:22 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 06:41:22 -0000
Received: (qmail 64596 invoked by uid 500); 27 Aug 2009 06:41:19 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 64545 invoked by uid 500); 27 Aug 2009 06:41:19 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 64535 invoked by uid 99); 27 Aug 2009 06:41:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 06:41:19 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.132.251 as permitted sender)
Received: from [209.85.132.251] (HELO an-out-0708.google.com) (209.85.132.251)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 06:41:10 +0000
Received: by an-out-0708.google.com with SMTP id c38so272529ana.29
        for <common-user@hadoop.apache.org>; Wed, 26 Aug 2009 23:40:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=YxOOamMyKDiP8qghjOHQMQ7cHfJBPhauJBXfainrcL0=;
        b=nXfPoGcPt5TK3VFQuloCIi9i77PB52WYtYHAGZlTEjPiC7fD/BSp+QuvvR+xH8A/ut
         2Ei/mgtkeUTme/QnmTrGgoFv0pNoohxlxOhkZ7JdJIq4zQUKyiz/KMpEtwMFi5XJxH08
         D1V+GRpDKqjd4H+swHi4mPH9u3XMUWZXIfAo0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=n2WDAoIMhnKVXoxhsnr1iZSqZpKzlaPLnZOg+0k/NzlO46Rn2L1m/hXcktDqJwsrKQ
         8bferZ7gQJLDzecziTDyrzkXgQlFar7NEimCdnMMhidMOdwPtX4+EABin2nWGxaVfUip
         kEG2F1Quj4YaNuNSuDbG/c9zWUT1MlmR7SFwQ=
MIME-Version: 1.0
Received: by 10.100.236.26 with SMTP id j26mr9114576anh.8.1251355249593; Wed, 
	26 Aug 2009 23:40:49 -0700 (PDT)
In-Reply-To: <e01b80590908262128k7e9b1a36y657b5c95a31613e6@mail.gmail.com>
References: <3b1311780908262004ua8e0269hc4d914d51b9ea751@mail.gmail.com>
	 <e01b80590908262128k7e9b1a36y657b5c95a31613e6@mail.gmail.com>
Date: Thu, 27 Aug 2009 14:40:49 +0800
Message-ID: <3b1311780908262340i3cbdd80er9f9568ec6a46de60@mail.gmail.com>
Subject: Re: How does reducer get intermediate output?
From: Inifok Song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636b2b47723cebe047219d9b6
X-Virus-Checked: Checked by ClamAV on apache.org

--001636b2b47723cebe047219d9b6
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hello Harish,

I find taskLogUrl.openConnection() often cause IOException. And I suspect
that the connection pool is too small. Could you tell me how can I get
settings of jetty for hadoop?

Thank you.

Inifok

2009/8/27 Harish Mallipeddi <harish.mallipeddi@gmail.com>

> On Thu, Aug 27, 2009 at 8:34 AM, inifok.song <hadoop.inifok@gmail.com
> >wrote:
>
> > Hi all,
> >
> > In my cluster, the reducer often can't fetch mapper's output. I know
> there
> > are many reasons for this situation. And I think it's necessary to find
> out
> > how does reducer get intermediate output. I have read the source code.
> > However, I'm not clear about the whole process. Could you tell me the
> > process of it? How does each node communicate with each other and how
> does
> > class ReduceCopier work?
> >
> > Thank you.
> >
> > Inifok
> >
>
> Each TaskTracker runs a Jetty webserver which is responsible for serving
> requests for intermediate map-outputs. The ReduceTask process receives
> notifications regarding completed MapTasks from its TaskTracker (which in
> turn receives that info from the JobTracker). Once it receives these
> notifications, the ReduceTask will start fetching these map-outputs via
> HTTP
> by requesting the corresponding TT's Jetty webserver.
>
> --
> Harish Mallipeddi
> http://blog.poundbang.in
>

--001636b2b47723cebe047219d9b6--

From common-user-return-17100-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 08:51:05 2009
Return-Path: <common-user-return-17100-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 25177 invoked from network); 27 Aug 2009 08:51:05 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 08:51:05 -0000
Received: (qmail 91513 invoked by uid 500); 27 Aug 2009 08:51:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91414 invoked by uid 500); 27 Aug 2009 08:51:02 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91404 invoked by uid 99); 27 Aug 2009 08:51:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 08:51:02 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [84.16.224.225] (HELO hell.kostyrka.org) (84.16.224.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 08:50:52 +0000
Received: by hell.kostyrka.org (Postfix, from userid 5001)
	id D5304118010; Thu, 27 Aug 2009 10:32:39 +0200 (CEST)
X-Spam-Checker-Version: SpamAssassin 3.2.5 (2008-06-10) on hell.kostyrka.org
X-Spam-Level: 
Received: from [127.0.1.1] (93-82-14-216.adsl.highway.telekom.at [93.82.14.216])
	by hell.kostyrka.org (Postfix) with ESMTPA id DC74211800A
	for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 10:32:38 +0200 (CEST)
Subject: Re: Concatenating files on HDFS
From: Andreas Kostyrka <andreas@kostyrka.org>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
In-Reply-To: <31852133.201251351266400.JavaMail.ankur@ankur-laptop>
References: <31852133.201251351266400.JavaMail.ankur@ankur-laptop>
Content-Type: multipart/signed; micalg="pgp-sha1";
	protocol="application/pgp-signature";
	boundary="=-bVrwjfuQHgRTXpI4CWbP"
Date: Thu, 27 Aug 2009 10:50:23 +0200
Message-Id: <1251363023.14706.113.camel@andi-lap>
Mime-Version: 1.0
X-Mailer: Evolution 2.27.90 
X-Virus-Checked: Checked by ClamAV on apache.org
X-Old-Spam-Status: No, score=-4.3 required=4.0 tests=ALL_TRUSTED,AWL,BAYES_00
	autolearn=ham version=3.2.5

--=-bVrwjfuQHgRTXpI4CWbP
Content-Type: text/plain
Content-Transfer-Encoding: quoted-printable

Actually, for many use cases it's enough to keep a directory where all
parts of a given "logical" file are kept:

-) for input in hadoop jobs you just specify the directory.
-) if you need it in one piece externally, you can cat the whole
directory into one file.

Hence in my experience one does not need to concat files inside HDFS
usually.

Andreas


Am Donnerstag, den 27.08.2009, 11:04 +0530 schrieb Ankur Goel:
> HDFS files are write once so you cannot append to them (at the moment).
> What you can do is copy your local file to HDFS dir containing the same f=
ile you want to append to.
> Once that is done you can run a simple (Identity Mapper & Identity Reduce=
r) mapreduce job with input
> as this directory and number of reducers =3D 1.=20
>=20
> ----- Original Message -----
> From: "Turner Kunkel" <thkunkel@gmail.com>
> To: core-user@hadoop.apache.org
> Sent: Wednesday, August 26, 2009 10:02:41 PM GMT +05:30 Chennai, Kolkata,=
 Mumbai, New Delhi
> Subject: Concatenating files on HDFS
>=20
> Is there any way to concatenate/append a local file to a file on HDFS
> without copying down the HDFS file locally first?
>=20
> I tried:
> bin/hadoop dfs -cat file:///[local file] >> hdfs://[hdfs file]
> But it just tries to look for hdfs://[hdfs file] as a local file,
> since I suppose the dfs -cat command doesn't support the >> operator.
>=20
> Thanks.


--=-bVrwjfuQHgRTXpI4CWbP
Content-Type: application/pgp-signature; name="signature.asc"
Content-Description: Dies ist ein digital signierter Nachrichtenteil

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (GNU/Linux)

iEYEABECAAYFAkqWSM8ACgkQHJdudm4KnO0D5QCeI8HbD2isFP93Vhx+i8NXq9gf
14oAoNn2+Bo4Fjf0W3MPYea+Bf/Tf38N
=/ep0
-----END PGP SIGNATURE-----

--=-bVrwjfuQHgRTXpI4CWbP--

From common-user-return-17101-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 09:06:59 2009
Return-Path: <common-user-return-17101-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 30288 invoked from network); 27 Aug 2009 09:06:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 09:06:59 -0000
Received: (qmail 16140 invoked by uid 500); 27 Aug 2009 09:06:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 16066 invoked by uid 500); 27 Aug 2009 09:06:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 16056 invoked by uid 500); 27 Aug 2009 09:06:56 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 16053 invoked by uid 99); 27 Aug 2009 09:06:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 09:06:56 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 09:06:48 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1Mgaw7-0006fr-Ht
	for core-user@hadoop.apache.org; Thu, 27 Aug 2009 02:06:27 -0700
Message-ID: <25167322.post@talk.nabble.com>
Date: Thu, 27 Aug 2009 02:06:27 -0700 (PDT)
From: "radar.sxl" <radar.sxl@gmail.com>
To: core-user@hadoop.apache.org
Subject: How running hadoop without command line?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: radar.sxl@gmail.com
X-Virus-Checked: Checked by ClamAV on apache.org


When run a hadoop project jar, We'll use 
$ bin/hadoop jar ***.jar 
but if I hava a java app, i want to run mapreduce job inside it use hadoop
cluster, is three anyway?
-- 
View this message in context: http://www.nabble.com/How-running-hadoop-without-command-line--tp25167322p25167322.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-17102-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 11:52:53 2009
Return-Path: <common-user-return-17102-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 88737 invoked from network); 27 Aug 2009 11:52:53 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 11:52:53 -0000
Received: (qmail 4321 invoked by uid 500); 27 Aug 2009 11:52:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 4251 invoked by uid 500); 27 Aug 2009 11:52:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 4237 invoked by uid 99); 27 Aug 2009 11:52:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 11:52:49 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rkhatwani@gmail.com designates 209.85.216.191 as permitted sender)
Received: from [209.85.216.191] (HELO mail-px0-f191.google.com) (209.85.216.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 11:52:41 +0000
Received: by pxi29 with SMTP id 29so1066392pxi.30
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 04:52:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=ijqmHTRb3YQUfo0hGbZKkYOneKgh3HEQqgtQR2N/iaQ=;
        b=HkN5qDJrRcLB60IahIDDtO8XyyDETZ/NkwfL+GXfpHIsGZynIAeCsV5KBoc8k3RhKR
         W2gj4gOFu+pDgv8dCoyWEUbu5ifkv9bHAoyTwuFweTESfvygovLLOhg2igp573uR4iml
         OFC/3L2Pla/ErCFhNWqU+8vtxZSWQgDDeJOGI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=MGhbKrCoPD0+AJk2zqQvO1cWu/u2zosAwXX9ZcdOdMM3rSOfwF3S4IlmqtyRL+dvm9
         DN6ZOfzlE2jnxI8nuL7aJ216sS0R5bh1l9z7otm2J+zbPu9bGbj1bf3m4c1T3wdzRfGp
         3Bghc9Hh32uqZH/GpAmYbc+RyUpWjH04+jLys=
MIME-Version: 1.0
Received: by 10.114.165.20 with SMTP id n20mr12741217wae.6.1251373940930; Thu, 
	27 Aug 2009 04:52:20 -0700 (PDT)
Date: Thu, 27 Aug 2009 17:22:20 +0530
Message-ID: <2aa3aff80908270452h4a72104fm42f554df180a6a7@mail.gmail.com>
Subject: Doubt in reducer
From: Rakhi Khatwani <rkhatwani@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016367f93163af93f04721e33b8
X-Virus-Checked: Checked by ClamAV on apache.org

--0016367f93163af93f04721e33b8
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,
        I am running a map reduce program which reads data from a file,
processes it and writes the output into another file.
i run 4 maps and 4 reduces, and my output is as follows:
09/08/27 17:34:37 INFO mapred.JobClient: Running job: job_200908271142_0026
09/08/27 17:34:38 INFO mapred.JobClient: map 0% reduce 0%
09/08/27 17:34:45 INFO mapred.JobClient: map 25% reduce 0%
09/08/27 17:34:47 INFO mapred.JobClient: map 50% reduce 0%
09/08/27 17:34:48 INFO mapred.JobClient: map 75% reduce 0%
09/08/27 17:34:50 INFO mapred.JobClient: map 100% reduce 0%
09/08/27 17:35:00 INFO mapred.JobClient: map 100% reduce 4%
09/08/27 17:35:03 INFO mapred.JobClient: map 100% reduce 25%
09/08/27 17:35:12 INFO mapred.JobClient: map 100% reduce 50%
09/08/27 17:35:21 INFO mapred.JobClient: map 100% reduce 75%
09/08/27 17:35:30 INFO mapred.JobClient: map 100% reduce 100%
09/08/27 17:35:31 INFO mapred.JobClient: Job complete: job_200908271142_0026
09/08/27 17:35:31 INFO mapred.JobClient: Counters: 15
09/08/27 17:35:31 INFO mapred.JobClient: File Systems
09/08/27 17:35:31 INFO mapred.JobClient: HDFS bytes read=6666974
09/08/27 17:35:31 INFO mapred.JobClient: Local bytes read=24
09/08/27 17:35:31 INFO mapred.JobClient: Local bytes written=520
09/08/27 17:35:31 INFO mapred.JobClient: Job Counters
09/08/27 17:35:31 INFO mapred.JobClient: Launched reduce tasks=4
09/08/27 17:35:31 INFO mapred.JobClient: Launched map tasks=4
09/08/27 17:35:31 INFO mapred.JobClient: Data-local map tasks=4
09/08/27 17:35:31 INFO mapred.JobClient: Map-Reduce Framework
09/08/27 17:35:31 INFO mapred.JobClient: Reduce input groups=0
09/08/27 17:35:31 INFO mapred.JobClient: Combine output records=0
09/08/27 17:35:31 INFO mapred.JobClient: Map input records=8940
09/08/27 17:35:31 INFO mapred.JobClient: Reduce output records=0
09/08/27 17:35:31 INFO mapred.JobClient: Map output bytes=0
09/08/27 17:35:31 INFO mapred.JobClient: Map input bytes=6663028
09/08/27 17:35:31 INFO mapred.JobClient: Combine input records=0
09/08/27 17:35:31 INFO mapred.JobClient: Map output records=0
09/08/27 17:35:31 INFO mapred.JobClient: Reduce input records=0


but i want my reduce to run , tht is if 25% map is done, thn i want the
reduce 2 save that much data. even if the 2nd map fails, i dont loose data.
any pointers?
Regards,
Raakhi

--0016367f93163af93f04721e33b8--

From common-user-return-17103-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 12:26:19 2009
Return-Path: <common-user-return-17103-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 6557 invoked from network); 27 Aug 2009 12:26:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 12:26:19 -0000
Received: (qmail 43092 invoked by uid 500); 27 Aug 2009 12:26:17 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 43016 invoked by uid 500); 27 Aug 2009 12:26:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 43006 invoked by uid 99); 27 Aug 2009 12:26:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 12:26:16 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rkhatwani@gmail.com designates 209.85.222.178 as permitted sender)
Received: from [209.85.222.178] (HELO mail-pz0-f178.google.com) (209.85.222.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 12:26:08 +0000
Received: by pzk8 with SMTP id 8so1097222pzk.22
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 05:25:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=npBzpIlktKhCPTVckFm8SJ0jcRN8e+P9C1uBzJ3jB6o=;
        b=U/1c20HPpXBabMTHkJCIV6mR0Y+6yWdTQH0Pkzj0VrZgQEn9O75C60+uTvQhUmpWuD
         arDNyCDG074inlsQonROiJVu8YsAU1wxVG9xiCds98TbIQDKUZfWJlpqCMeSwpYXTVx6
         KW9KO7TrrNwTML63kxo7YfvkvaR+t0Gq0zxp0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=bcQGLaBqFaZXqRWfkMOAYiyQcRsruTbpTNAb6RyZoNR21W6+jMjnd5yxUWNqoUBzWD
         h2wzh98NXInfE1rwNemE7nhFhAYFcY1bw1o6ECng1ssA0OZa4SO6kPsLv3v38QxRNEdd
         JXigsgHNr+eLlsT/+ioyXHEUMlllp0bqPUj58=
MIME-Version: 1.0
Received: by 10.115.67.8 with SMTP id u8mr11645775wak.190.1251375948639; Thu, 
	27 Aug 2009 05:25:48 -0700 (PDT)
Date: Thu, 27 Aug 2009 17:55:48 +0530
Message-ID: <2aa3aff80908270525uafe39e8q83c9796528da15f7@mail.gmail.com>
Subject: difference between mapper and map runnable
From: Rakhi Khatwani <rkhatwani@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64ce5b8e62f4104721eaad0
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64ce5b8e62f4104721eaad0
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi,
        Whats the difference between a mapper and map runnable and its
usage?
Regards
Raakhi

--0016e64ce5b8e62f4104721eaad0--

From common-user-return-17104-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 12:31:54 2009
Return-Path: <common-user-return-17104-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 9025 invoked from network); 27 Aug 2009 12:31:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 12:31:54 -0000
Received: (qmail 50277 invoked by uid 500); 27 Aug 2009 12:31:51 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 50210 invoked by uid 500); 27 Aug 2009 12:31:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 50200 invoked by uid 99); 27 Aug 2009 12:31:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 12:31:51 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of harish.mallipeddi@gmail.com designates 209.85.222.178 as permitted sender)
Received: from [209.85.222.178] (HELO mail-pz0-f178.google.com) (209.85.222.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 12:31:44 +0000
Received: by pzk8 with SMTP id 8so1100361pzk.22
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 05:31:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=aJDCEhx6yyaxwnnkqg1QXgpXaYhoD6PipW5MrTnBveM=;
        b=ktdKDfgIpW9hf5UlptOPhsnQZ45cqj/Sc44nfEw4/fEZJaF7tTvU2qyND6vIDLb3bB
         9thTvUWG4jOKaxCyIlPz8vnJuDpnmTx26YXASK+WFOX/bCzcUsoLmoLRR5SddX3Mq52O
         L7dWsLFGLBZpldX3aGoOHr4yTj7WKtoMyV0U8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=hQQTMT9Mxe2FRitj9b19yrf1h7nS5m/GKh//tY94FVMLPwyFyc03yOMv80uNcJTo6j
         Oai3LrF0dKdJzXiuwSgljHygqO+ELSiNn2BkR9heVbrq2+oGwDufQ36MM7pxbKfIy8bQ
         tTNxR2KmZ5xT7kQgsODHFdrcdTHfgy3aZrvbs=
MIME-Version: 1.0
Received: by 10.142.8.20 with SMTP id 20mr772782wfh.77.1251376284250; Thu, 27 
	Aug 2009 05:31:24 -0700 (PDT)
In-Reply-To: <2aa3aff80908270452h4a72104fm42f554df180a6a7@mail.gmail.com>
References: <2aa3aff80908270452h4a72104fm42f554df180a6a7@mail.gmail.com>
From: Harish Mallipeddi <harish.mallipeddi@gmail.com>
Date: Thu, 27 Aug 2009 18:01:04 +0530
Message-ID: <e01b80590908270531g1f2b6900vdc566d9c53ee5f2d@mail.gmail.com>
Subject: Re: Doubt in reducer
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00504502bc2ee7332a04721ebe26
X-Virus-Checked: Checked by ClamAV on apache.org

--00504502bc2ee7332a04721ebe26
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On Thu, Aug 27, 2009 at 5:22 PM, Rakhi Khatwani <rkhatwani@gmail.com> wrote:

>
> but i want my reduce to run , tht is if 25% map is done, thn i want the
> reduce 2 save that much data. even if the 2nd map fails, i dont loose data.
> any pointers?
> Regards,
> Raakhi
>

What you're asking for will break the semantics of reduce(). Reduce can only
proceed after receiving all the map-outputs.

-- 
Harish Mallipeddi
http://blog.poundbang.in

--00504502bc2ee7332a04721ebe26--

From common-user-return-17105-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 14:00:50 2009
Return-Path: <common-user-return-17105-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 44343 invoked from network); 27 Aug 2009 14:00:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 14:00:50 -0000
Received: (qmail 59615 invoked by uid 500); 27 Aug 2009 14:00:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 59522 invoked by uid 500); 27 Aug 2009 14:00:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 59512 invoked by uid 500); 27 Aug 2009 14:00:47 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 59509 invoked by uid 500); 27 Aug 2009 14:00:47 -0000
Delivered-To: apmail-lucene-hadoop-user@lucene.apache.org
Received: (qmail 59506 invoked by uid 99); 27 Aug 2009 14:00:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 14:00:47 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=FS_REPLICA,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of andyliu1227@gmail.com designates 209.85.212.177 as permitted sender)
Received: from [209.85.212.177] (HELO mail-vw0-f177.google.com) (209.85.212.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 14:00:39 +0000
Received: by vws7 with SMTP id 7so780967vws.29
        for <hadoop-user@lucene.apache.org>; Thu, 27 Aug 2009 07:00:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=1SmxbyQdEe1jxpS0wRdPIby0FgClDSiIt7vbhdb3JDg=;
        b=hJ8u4ehMF78FXn6y34EgyvRzAg4uOk3BFnvirGLQIhqW6xBiVs0AC+abXqnCfVwHko
         +DHSte4nXJQuH3Ux7oIPZfC6Hd6Chs0x7Gzf9sPT4qEJHzmHNIXK+ISHShHIb/3plC+y
         Q+pf9PxQ1S5myVXtbaAi/rBHO2QqbKlwwTVBY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=DcbYmwPAs5oEwT4Ro/LrV2M2DEgv13oRyEfH127J/7VmseyC9/DOk0Xrylae1R4RBO
         qlldaj8WVsJghIwje1VKRF3RbPtnX1SsFdsrWr4DvBWGN1LvRzGIT2LkGRbNlfFaW1sN
         H9lwADclzXx2+yzWGAmo1+6VKMcbsS0pfexxc=
MIME-Version: 1.0
Received: by 10.220.113.211 with SMTP id b19mr13042924vcq.60.1251381619055; 
	Thu, 27 Aug 2009 07:00:19 -0700 (PDT)
Date: Thu, 27 Aug 2009 10:00:19 -0400
Message-ID: <32dca9ed0908270700x4b3818ddm2c5a456a05cfec96@mail.gmail.com>
Subject: Delete replicated blocks?
From: Andy Liu <andyliu1227@gmail.com>
To: hadoop-user@lucene.apache.org
Content-Type: multipart/alternative; boundary=001485ecf984e1dbad04721ffca7
X-Virus-Checked: Checked by ClamAV on apache.org

--001485ecf984e1dbad04721ffca7
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I'm running a test Hadoop cluster, which had

--001485ecf984e1dbad04721ffca7--

From common-user-return-17106-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 14:04:49 2009
Return-Path: <common-user-return-17106-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 46553 invoked from network); 27 Aug 2009 14:04:49 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 14:04:49 -0000
Received: (qmail 65791 invoked by uid 500); 27 Aug 2009 14:04:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 65731 invoked by uid 500); 27 Aug 2009 14:04:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 65721 invoked by uid 500); 27 Aug 2009 14:04:46 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 65718 invoked by uid 500); 27 Aug 2009 14:04:46 -0000
Delivered-To: apmail-lucene-hadoop-user@lucene.apache.org
Received: (qmail 65715 invoked by uid 99); 27 Aug 2009 14:04:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 14:04:46 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=FS_REPLICA,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of andyliu1227@gmail.com designates 209.85.212.177 as permitted sender)
Received: from [209.85.212.177] (HELO mail-vw0-f177.google.com) (209.85.212.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 14:04:38 +0000
Received: by vws7 with SMTP id 7so784322vws.29
        for <hadoop-user@lucene.apache.org>; Thu, 27 Aug 2009 07:04:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=BTAw+jQUPAVMzl/U/oG5Dk4kOgXqWMb8YWRhohPhBkM=;
        b=k5OOOJPJB9r3/4w40egrpddW8d333ZapMdG3L4V0szdWx7HmLoHLG1wvISKmYrmahr
         xk+lmNPbHB2MMpXvamK9x4RMA4wecSDleykFTMQnA+kGbetvqHCZg4O4f4AEJGhMbm0a
         pfVb3N+SP7Om2lIXEn8ZMrTgxn4fnHigAkT4U=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=ioNzCxyx6JEG/vHQ26EDh0fxN7tyjJKVL4vvd/4f+pkCWFx+nEqqU3wAnpv/VGi9n1
         3unC1kVSHRd72xh7lpu64AymDNiSceFwPGz7EQwJdeP4KXM/K+8/aJ7+1KMyAbj/ikrQ
         N5syrGwluie2cagJub2qLeMxJIh3hZuJ1O6Zk=
MIME-Version: 1.0
Received: by 10.220.18.78 with SMTP id v14mr12960299vca.102.1251381857819; 
	Thu, 27 Aug 2009 07:04:17 -0700 (PDT)
Date: Thu, 27 Aug 2009 10:04:17 -0400
Message-ID: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com>
Subject: Delete replicated blocks?
From: Andy Liu <andyliu1227@gmail.com>
To: hadoop-user@lucene.apache.org
Content-Type: multipart/alternative; boundary=00163646d5a01d1d3a0472200b66
X-Virus-Checked: Checked by ClamAV on apache.org

--00163646d5a01d1d3a0472200b66
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I'm running a test Hadoop cluster, which had a dfs.replication value of 3.
I'm now running out of disk space, so I've reduced dfs.replication to 1 and
restarted my datanodes.  Is there a way to free up the over-replicated
blocks, or does this happen automatically at some point?

Thanks,
Andy

--00163646d5a01d1d3a0472200b66--

From common-user-return-17107-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 14:13:42 2009
Return-Path: <common-user-return-17107-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 49898 invoked from network); 27 Aug 2009 14:13:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 14:13:42 -0000
Received: (qmail 83579 invoked by uid 500); 27 Aug 2009 14:13:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 83491 invoked by uid 500); 27 Aug 2009 14:13:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 83475 invoked by uid 500); 27 Aug 2009 14:13:37 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 83469 invoked by uid 99); 27 Aug 2009 14:13:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 14:13:37 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 14:13:26 +0000
Received: from pcp089096pcs.unl.edu (pcp089096pcs.unl.edu [129.93.158.211])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7RED06v006742
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT);
	Thu, 27 Aug 2009 09:13:02 -0500
Cc: core-user@hadoop.apache.org
Message-Id: <3B38751F-4771-480C-869B-407B928B6DE9@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <1251363023.14706.113.camel@andi-lap>
Content-Type: multipart/signed; boundary=Apple-Mail-3-344757087; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: Concatenating files on HDFS
Date: Thu, 27 Aug 2009 09:13:00 -0500
References: <31852133.201251351266400.JavaMail.ankur@ankur-laptop> <1251363023.14706.113.camel@andi-lap>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-3-344757087
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Does

http://hadoop.apache.org/common/docs/current/hdfs_shell.html#getmerge

Help you any?

Note that ">>" has nothing to do with file systems - it's a  
metacharacter in your shell.

Do note that "append" isn't supported in HDFS in current releases;  
there's quite an effort going on to get it in for 0.21.0.  I'd guess  
that will come out in the October-November timeframe, but someone can  
probably correct me on that.

Brian

On Aug 27, 2009, at 3:50 AM, Andreas Kostyrka wrote:

> Actually, for many use cases it's enough to keep a directory where all
> parts of a given "logical" file are kept:
>
> -) for input in hadoop jobs you just specify the directory.
> -) if you need it in one piece externally, you can cat the whole
> directory into one file.
>
> Hence in my experience one does not need to concat files inside HDFS
> usually.
>
> Andreas
>
>
> Am Donnerstag, den 27.08.2009, 11:04 +0530 schrieb Ankur Goel:
>> HDFS files are write once so you cannot append to them (at the  
>> moment).
>> What you can do is copy your local file to HDFS dir containing the  
>> same file you want to append to.
>> Once that is done you can run a simple (Identity Mapper & Identity  
>> Reducer) mapreduce job with input
>> as this directory and number of reducers = 1.
>>
>> ----- Original Message -----
>> From: "Turner Kunkel" <thkunkel@gmail.com>
>> To: core-user@hadoop.apache.org
>> Sent: Wednesday, August 26, 2009 10:02:41 PM GMT +05:30 Chennai,  
>> Kolkata, Mumbai, New Delhi
>> Subject: Concatenating files on HDFS
>>
>> Is there any way to concatenate/append a local file to a file on HDFS
>> without copying down the HDFS file locally first?
>>
>> I tried:
>> bin/hadoop dfs -cat file:///[local file] >> hdfs://[hdfs file]
>> But it just tries to look for hdfs://[hdfs file] as a local file,
>> since I suppose the dfs -cat command doesn't support the >> operator.
>>
>> Thanks.
>


--Apple-Mail-3-344757087
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64

MIAGCSqGSIb3DQEHAqCAMIACAQExCzAJBgUrDgMCGgUAMIAGCSqGSIb3DQEHAQAAoIIICjCCA/gw
ggLgoAMCAQICASkwDQYJKoZIhvcNAQEFBQAwdTETMBEGCgmSJomT8ixkARkWA25ldDESMBAGCgmS
JomT8ixkARkWAkVTMQ4wDAYDVQQKEwVFU25ldDEgMB4GA1UECxMXQ2VydGlmaWNhdGUgQXV0aG9y
aXRpZXMxGDAWBgNVBAMTD0VTbmV0IFJvb3QgQ0EgMTAeFw0wMjEyMDUwODAwMDBaFw0xMzAxMjUw
ODAwMDBaMGkxEzARBgoJkiaJk/IsZAEZFgNvcmcxGDAWBgoJkiaJk/IsZAEZFghET0VHcmlkczEg
MB4GA1UECxMXQ2VydGlmaWNhdGUgQXV0aG9yaXRpZXMxFjAUBgNVBAMTDURPRUdyaWRzIENBIDEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC09dYjYaPbCD5mtbiQb7Ka3y1qAm0ZcqKC
FciWcfe8Kwcuy9tjHuIsLf9ZItdkDW4xy8sua9nJlx3KlwjtumTMtOtg35KZCknUd8KM4VGTSFdL
VG9AbNayef76caVCGM1+jyF0Lq03kauGOPTcNfZe1TZa3e1c9rc8ljV5OSWa/mfsCACyS5zFIWu0
yIDNyJdf+n0hwaPN53wllpJ30taD+JBjQ7h2k4xRWzeaznLOb9OztZVRA/1sVze+iczFh2xwa4Vd
Gy0eIIPw1pfvYwxO36rm0S109qvbsNlaroPRbxerPKakQLpKe034Xcx7gBPqUk/FxoRRWin5EWN3
rz9LAgMBAAGjgZ4wgZswDgYDVR0PAQH/BAQDAgGGMBEGCWCGSAGG+EIBAQQEAwIAhzAdBgNVHQ4E
FgQUyhkdEo5upDhdQtQxDgjb2Y0XDV0wHwYDVR0jBBgwFoAUvF1NSC/4NZRZq1yJSz7RsjoUAeow
DwYDVR0TAQH/BAUwAwEB/zAlBgNVHREEHjAcgRpET0VHcmlkcy1DQS0xQGRvZWdyaWRzLm9yZzAN
BgkqhkiG9w0BAQUFAAOCAQEAZNVrIDLqe39CEOiJt7Q7EpBPhAihMvDTSf/42u0SMbUmChww4mLm
ph5DBghZUVF8Yn59kRZMn1QLOtO1HzLqvAvPITacZVPlJgG2IXzlR636YghZFAycbIUEOJDBHR4v
tQO1KDxgZwvAbtmKIoxvhUCq2xsfFt9kCBBn+JYtQ6O5LsBJq3PmuubeMcc7mbQAfJZ7h/3Qghgk
FIhmE1+LBXPJbkuP8vgfg6h2BKoAf5TFfZECgGZKimfN110tBvfedGZwYYd3/GsJc83B0JN1gny0
gqNVPm392UchXGeBRrHnm2gkhIkr48Oq6EmNGV9/a6XfbplQW/JWbtPVPWkaizCCBAowggLyoAMC
AQICAwCB+zANBgkqhkiG9w0BAQUFADBpMRMwEQYKCZImiZPyLGQBGRYDb3JnMRgwFgYKCZImiZPy
LGQBGRYIRE9FR3JpZHMxIDAeBgNVBAsTF0NlcnRpZmljYXRlIEF1dGhvcml0aWVzMRYwFAYDVQQD
Ew1ET0VHcmlkcyBDQSAxMB4XDTA5MDYwMjE5NDExM1oXDTEwMDYwMjE5NDExM1owYTETMBEGCgmS
JomT8ixkARkWA29yZzEYMBYGCgmSJomT8ixkARkWCGRvZWdyaWRzMQ8wDQYDVQQLEwZQZW9wbGUx
HzAdBgNVBAMTFkJyaWFuIEJvY2tlbG1hbiA1MDQzMDcwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAw
ggEKAoIBAQDPWEl7hBiuFRVBSY4SwvG0HpkCZi74a0BeD0tNARgxoQVJ7jhJjR3G4y8ino0/5axt
2EEfIWUE+DVpV37IWOQl8q/wdvicnhbfjByxBbq4sfWPLepU7+Kd8k1FKHRHermARn9VxEkFLrLB
Gp7O5EX4mFHDaQy+Vv0thtA+m4qKoM+DA/8cOkJA5Rn6ZS/v/vtBzJh9HimVnhBx4+rw2cvKN+7r
lKsm7qTn9TCZmrQ97CvBEXSkHS11m8vYF6ZwcTgSCJM0M9nnX5JilupQO1vDICXSUZeWX2xpsqeL
x1PFGWgDaYXxFGtTRt2Qc9EPwf9Dr72xGPbKN8u5HylpOMDnAgMBAAGjgcIwgb8wEQYJYIZIAYb4
QgEBBAQDAgWgMA4GA1UdDwEB/wQEAwIF4DAfBgNVHSMEGDAWgBTKGR0Sjm6kOF1C1DEOCNvZjRcN
XTAYBgNVHSAEETAPMA0GCyqGSIb3TAMHAQMAMD4GA1UdHwQ3MDUwM6AxoC+GLWh0dHA6Ly9jcmwu
ZG9lZ3JpZHMub3JnLzFjM2YyY2E4LzFjM2YyY2E4LmNybDAfBgNVHREEGDAWgRRiYm9ja2VsbUBj
c2UudW5sLmVkdTANBgkqhkiG9w0BAQUFAAOCAQEAp6KjcWnfnH/MGlUkUWstE9gtPeymHp+2r4zI
w8JXigncJh/8qpSZqBcVhD24WFowI95otblrKYNZKW9f2G/hWwDSxZFqHhCDxFO12vDthrzOc3EH
CwypJPvIlZPt/E/x93XruzPxJwPz84DKKuPoJAMeNlADbd+92YtRr2y+VuMpgZaebMAoeCdWH8Cq
Y8xheNMajf8uiImBbatDuCu7qRvhwgxsMNLHEt4h853K1Zc181RlFGXG1+uL/Q/8VeKiASiCu+7L
1zpfLg7OCr6rJHb5S7wU+CeAvzSqmyy0fd2mwPeiX7huK+Cw4UjaB3yGKItzWT+KQJnV//wcSrzZ
dTGCAv0wggL5AgEBMHAwaTETMBEGCgmSJomT8ixkARkWA29yZzEYMBYGCgmSJomT8ixkARkWCERP
RUdyaWRzMSAwHgYDVQQLExdDZXJ0aWZpY2F0ZSBBdXRob3JpdGllczEWMBQGA1UEAxMNRE9FR3Jp
ZHMgQ0EgMQIDAIH7MAkGBSsOAwIaBQCgggFiMBgGCSqGSIb3DQEJAzELBgkqhkiG9w0BBwEwHAYJ
KoZIhvcNAQkFMQ8XDTA5MDgyNzE0MTMwMFowIwYJKoZIhvcNAQkEMRYEFKpVlyIZZkukyvDO7wRv
6kOqBGXQMH8GCSsGAQQBgjcQBDFyMHAwaTETMBEGCgmSJomT8ixkARkWA29yZzEYMBYGCgmSJomT
8ixkARkWCERPRUdyaWRzMSAwHgYDVQQLExdDZXJ0aWZpY2F0ZSBBdXRob3JpdGllczEWMBQGA1UE
AxMNRE9FR3JpZHMgQ0EgMQIDAIH7MIGBBgsqhkiG9w0BCRACCzFyoHAwaTETMBEGCgmSJomT8ixk
ARkWA29yZzEYMBYGCgmSJomT8ixkARkWCERPRUdyaWRzMSAwHgYDVQQLExdDZXJ0aWZpY2F0ZSBB
dXRob3JpdGllczEWMBQGA1UEAxMNRE9FR3JpZHMgQ0EgMQIDAIH7MA0GCSqGSIb3DQEBAQUABIIB
AE0ixoPPrEsOJ2OndcZ8JD3tOMvOwTxygirv8H7ZwUVundlXC8HtSwgo0JQvntisb2xlUTtkR5Ce
9dFHA2/3nXUahrFSjutwB5eTXXS8YYBB9tOapdCrfx6lwipRZOzlI/NrYXjpJhpGUMCUBy82zf64
UJxPHAXxERfNsbs8h1G+8tiY7gwzOy765w0Qwd7lNlcs7e8N1gRqpfJy77WzuCTVLRfwrh20NEgS
HKwN744iLXVKpOI/eWqmtaK3OaMMDm6I15Ja7kAx2yJEs0SkcSRm10LuL6dfe/Rxy0ZhWN+rlOLm
WTCbmBCBa95blnHvgrrfzDN2NL92W0BCO4U19LwAAAAAAAA=

--Apple-Mail-3-344757087--

From common-user-return-17108-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 14:13:43 2009
Return-Path: <common-user-return-17108-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 49931 invoked from network); 27 Aug 2009 14:13:42 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 14:13:42 -0000
Received: (qmail 83611 invoked by uid 500); 27 Aug 2009 14:13:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 83493 invoked by uid 500); 27 Aug 2009 14:13:37 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 83469 invoked by uid 99); 27 Aug 2009 14:13:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 14:13:37 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 14:13:26 +0000
Received: from pcp089096pcs.unl.edu (pcp089096pcs.unl.edu [129.93.158.211])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7RED06v006742
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT);
	Thu, 27 Aug 2009 09:13:02 -0500
Cc: core-user@hadoop.apache.org
Message-Id: <3B38751F-4771-480C-869B-407B928B6DE9@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <1251363023.14706.113.camel@andi-lap>
Content-Type: multipart/signed; boundary=Apple-Mail-3-344757087; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: Concatenating files on HDFS
Date: Thu, 27 Aug 2009 09:13:00 -0500
References: <31852133.201251351266400.JavaMail.ankur@ankur-laptop> <1251363023.14706.113.camel@andi-lap>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-3-344757087
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Does

http://hadoop.apache.org/common/docs/current/hdfs_shell.html#getmerge

Help you any?

Note that ">>" has nothing to do with file systems - it's a  
metacharacter in your shell.

Do note that "append" isn't supported in HDFS in current releases;  
there's quite an effort going on to get it in for 0.21.0.  I'd guess  
that will come out in the October-November timeframe, but someone can  
probably correct me on that.

Brian

On Aug 27, 2009, at 3:50 AM, Andreas Kostyrka wrote:

> Actually, for many use cases it's enough to keep a directory where all
> parts of a given "logical" file are kept:
>
> -) for input in hadoop jobs you just specify the directory.
> -) if you need it in one piece externally, you can cat the whole
> directory into one file.
>
> Hence in my experience one does not need to concat files inside HDFS
> usually.
>
> Andreas
>
>
> Am Donnerstag, den 27.08.2009, 11:04 +0530 schrieb Ankur Goel:
>> HDFS files are write once so you cannot append to them (at the  
>> moment).
>> What you can do is copy your local file to HDFS dir containing the  
>> same file you want to append to.
>> Once that is done you can run a simple (Identity Mapper & Identity  
>> Reducer) mapreduce job with input
>> as this directory and number of reducers = 1.
>>
>> ----- Original Message -----
>> From: "Turner Kunkel" <thkunkel@gmail.com>
>> To: core-user@hadoop.apache.org
>> Sent: Wednesday, August 26, 2009 10:02:41 PM GMT +05:30 Chennai,  
>> Kolkata, Mumbai, New Delhi
>> Subject: Concatenating files on HDFS
>>
>> Is there any way to concatenate/append a local file to a file on HDFS
>> without copying down the HDFS file locally first?
>>
>> I tried:
>> bin/hadoop dfs -cat file:///[local file] >> hdfs://[hdfs file]
>> But it just tries to look for hdfs://[hdfs file] as a local file,
>> since I suppose the dfs -cat command doesn't support the >> operator.
>>
>> Thanks.
>


--Apple-Mail-3-344757087
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-3-344757087--

From common-user-return-17109-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 16:06:04 2009
Return-Path: <common-user-return-17109-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 4634 invoked from network); 27 Aug 2009 16:06:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 16:06:03 -0000
Received: (qmail 67111 invoked by uid 500); 27 Aug 2009 16:06:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 67053 invoked by uid 500); 27 Aug 2009 16:06:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 67043 invoked by uid 99); 27 Aug 2009 16:06:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 16:06:00 +0000
X-ASF-Spam-Status: No, hits=2.4 required=10.0
	tests=FS_REPLICA,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.171] (HELO mrout1.yahoo.com) (216.145.54.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 16:05:48 +0000
Received: from [216.145.54.7] (socks2.corp.yahoo.com [216.145.54.7])
	by mrout1.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7RG54YB044346
	for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 09:05:04 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=2K1c+BhXkgqRAdUNjfvDgElQTqUPIX5NXU6nenPPWGn8CJ+r/lCAR9kI4ojWkhRq
Message-ID: <4A96AEAF.2030203@yahoo-inc.com>
Date: Thu, 27 Aug 2009 09:05:03 -0700
From: Raghu Angadi <rangadi@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.23 (X11/20090817)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Re: Delete replicated blocks?
References: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com>
In-Reply-To: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


This setting would apply only to new files. For existing files you need 
to change explicitly. you can use 'hadoop fs -setsep' for changing 
replication for a file or directory.

Andy Liu wrote:
> I'm running a test Hadoop cluster, which had a dfs.replication value of 3.
> I'm now running out of disk space, so I've reduced dfs.replication to 1 and
> restarted my datanodes.  Is there a way to free up the over-replicated
> blocks, or does this happen automatically at some point?
> 
> Thanks,
> Andy
> 


From common-user-return-17110-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 16:11:07 2009
Return-Path: <common-user-return-17110-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 6939 invoked from network); 27 Aug 2009 16:11:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 16:11:07 -0000
Received: (qmail 74653 invoked by uid 500); 27 Aug 2009 16:11:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 74585 invoked by uid 500); 27 Aug 2009 16:11:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 70539 invoked by uid 500); 27 Aug 2009 14:06:11 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Delivered-To: apmail-lucene-hadoop-user@lucene.apache.org
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=FS_REPLICA,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vklimontovich@iponweb.net designates 209.85.219.222 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:subject:mime-version
         :content-type:from:in-reply-to:date:cc:content-transfer-encoding
         :message-id:references:to:x-mailer;
        bh=R99gvnAQkmN2+xEJcGKcY7Qras7I5wBjMpnkP+v9qLA=;
        b=iRInsSiVDaMagp8PAf+yJlD/3CQYwjushanCrBHNMy3ERxzOoY8jt61O/aRaJMahZZ
         dhcccmhCNYepI6yFlnGerfxacn3IRrTJnMdPNebh2HXWHHLRFm4AEmO21znWLB46PL3I
         OFY1zg5ZxpzCjI5KGR+Ewv/N04KV569wmxr/0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=subject:mime-version:content-type:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to:x-mailer;
        b=kLQw8ok+6FiXUg+jZ7pn5XgaXbWRMCAXMm8S67kHZLT/q++k3lTIBKIcg6r1dRvAQ4
         PNAgZpZXJb4Av0k0y/qmBub1GHM4d/shCjByJHHwdEhI8loZvZhpED/FvCkOXGsvokGm
         uvj1jnsE+k/u3/p42AyvNBku8c5iH+WoVZSFQ=
Subject: Re: Delete replicated blocks?
Mime-Version: 1.0 (Apple Message framework v1075.2)
Content-Type: text/plain; charset=us-ascii; format=flowed; delsp=yes
From: Vladimir Klimontovich <klimontovich@gmail.com>
In-Reply-To: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com>
Date: Thu, 27 Aug 2009 18:05:37 +0400
Cc: hadoop-user@lucene.apache.org
Content-Transfer-Encoding: 7bit
Message-Id: <5C832190-BC7F-4D16-89E7-43D917C9D9A0@gmail.com>
References: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com>
To: common-user@hadoop.apache.org
X-Mailer: Apple Mail (2.1075.2)
X-Virus-Checked: Checked by ClamAV on apache.org

This will happen automatically.
On Aug 27, 2009, at 6:04 PM, Andy Liu wrote:

> I'm running a test Hadoop cluster, which had a dfs.replication value  
> of 3.
> I'm now running out of disk space, so I've reduced dfs.replication  
> to 1 and
> restarted my datanodes.  Is there a way to free up the over-replicated
> blocks, or does this happen automatically at some point?
>
> Thanks,
> Andy

---
Vladimir Klimontovich,
skype: klimontovich
GoogleTalk/Jabber: klimontovich@gmail.com
Cell phone: +7926 890 2349


From common-user-return-17111-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 16:11:18 2009
Return-Path: <common-user-return-17111-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7065 invoked from network); 27 Aug 2009 16:11:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 16:11:18 -0000
Received: (qmail 76430 invoked by uid 500); 27 Aug 2009 16:11:15 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 76379 invoked by uid 500); 27 Aug 2009 16:11:15 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 70526 invoked by uid 99); 27 Aug 2009 14:06:11 -0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=FS_REPLICA,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vklimontovich@iponweb.net designates 74.125.78.24 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:subject:mime-version
         :content-type:from:in-reply-to:date:cc:content-transfer-encoding
         :message-id:references:to:x-mailer;
        bh=R99gvnAQkmN2+xEJcGKcY7Qras7I5wBjMpnkP+v9qLA=;
        b=iRInsSiVDaMagp8PAf+yJlD/3CQYwjushanCrBHNMy3ERxzOoY8jt61O/aRaJMahZZ
         dhcccmhCNYepI6yFlnGerfxacn3IRrTJnMdPNebh2HXWHHLRFm4AEmO21znWLB46PL3I
         OFY1zg5ZxpzCjI5KGR+Ewv/N04KV569wmxr/0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=subject:mime-version:content-type:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to:x-mailer;
        b=kLQw8ok+6FiXUg+jZ7pn5XgaXbWRMCAXMm8S67kHZLT/q++k3lTIBKIcg6r1dRvAQ4
         PNAgZpZXJb4Av0k0y/qmBub1GHM4d/shCjByJHHwdEhI8loZvZhpED/FvCkOXGsvokGm
         uvj1jnsE+k/u3/p42AyvNBku8c5iH+WoVZSFQ=
Subject: Re: Delete replicated blocks?
Mime-Version: 1.0 (Apple Message framework v1075.2)
Content-Type: text/plain; charset=us-ascii; format=flowed; delsp=yes
From: Vladimir Klimontovich <klimontovich@gmail.com>
In-Reply-To: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com>
Date: Thu, 27 Aug 2009 18:05:37 +0400
Cc: hadoop-user@lucene.apache.org
Content-Transfer-Encoding: 7bit
Message-Id: <5C832190-BC7F-4D16-89E7-43D917C9D9A0@gmail.com>
References: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com>
To: common-user@hadoop.apache.org
X-Mailer: Apple Mail (2.1075.2)
X-Virus-Checked: Checked by ClamAV on apache.org

This will happen automatically.
On Aug 27, 2009, at 6:04 PM, Andy Liu wrote:

> I'm running a test Hadoop cluster, which had a dfs.replication value  
> of 3.
> I'm now running out of disk space, so I've reduced dfs.replication  
> to 1 and
> restarted my datanodes.  Is there a way to free up the over-replicated
> blocks, or does this happen automatically at some point?
>
> Thanks,
> Andy

---
Vladimir Klimontovich,
skype: klimontovich
GoogleTalk/Jabber: klimontovich@gmail.com
Cell phone: +7926 890 2349


From common-user-return-17112-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 16:11:29 2009
Return-Path: <common-user-return-17112-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7263 invoked from network); 27 Aug 2009 16:11:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 16:11:29 -0000
Received: (qmail 78637 invoked by uid 500); 27 Aug 2009 16:11:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 78575 invoked by uid 500); 27 Aug 2009 16:11:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 55741 invoked by uid 500); 27 Aug 2009 14:51:53 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vklimontovich@iponweb.net designates 209.85.219.209 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:subject:mime-version
         :content-type:from:in-reply-to:date:cc:content-transfer-encoding
         :message-id:references:to:x-mailer;
        bh=+Cj4yWt3cVS79HXHo+zwpNfGOomcIdPNCU0LPz3K9I0=;
        b=bWHn3SKXJ5diPuhLvuWSvaSX1ZrmiCCuRvVCToOTlvTR6zRY3B2NFuvDGOHPcoGpvN
         vsiB9NOmOvHPI9q4D2myygR1ACtNv+vM7C2Xp6STwO/ttFGnpAIfpgv/OQ+MdYMde5Mu
         F8EqMlJGmnUB65a1mJPjBz6Ld7r/WLdmP45hg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=subject:mime-version:content-type:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to:x-mailer;
        b=ZH1dUxbDga3pw3zozuTPXogOdKVsMLqYC8QbOXWpV6qbLsZHRJDh3SMa6f7FgB7yp6
         sUu0b2Jz+VyYMZj5nFY/AC3Mw8VDDyV3q8IKvYFLFZD98RvyminOd91HwiQp7Z69Cpyc
         OC7EwnIhs/icprp0g/1WcRLvhjw2HkaFjbWfc=
Subject: Re: How running hadoop without command line?
Mime-Version: 1.0 (Apple Message framework v1075.2)
Content-Type: text/plain; charset=us-ascii; format=flowed; delsp=yes
From: Vladimir Klimontovich <klimontovich@gmail.com>
In-Reply-To: <25167322.post@talk.nabble.com>
Date: Thu, 27 Aug 2009 18:51:18 +0400
Cc: core-user@hadoop.apache.org
Content-Transfer-Encoding: 7bit
Message-Id: <5BCBDA7F-DED4-4B9D-B0AA-BB0A5E9D67C9@gmail.com>
References: <25167322.post@talk.nabble.com>
To: common-user@hadoop.apache.org
X-Mailer: Apple Mail (2.1075.2)
X-Virus-Checked: Checked by ClamAV on apache.org

There is a class called JobClient. You can run jobs using these class  
from java app.
Also hadoop jar adds $HADOOP_HOME/conf/hadoop-site.xml and  
$HADOOP_HOME/conf/hadoop-conf.xml
xml to classpath, so JobClient already knows which jobtracker and FS  
should be used for running map process.

So when you are running hadoop jobs inside other application you  
should take care of setting valid properties
for jobtracker address, FS address and etc. You can set it manually or  
use Configuratio.addResource for
adding $HADOOP_HOME/conf/hadoop-conf.xml and $HADOOP_HOME/conf/hadoop- 
site.xml .

On Aug 27, 2009, at 1:06 PM, radar.sxl wrote:

>
> When run a hadoop project jar, We'll use
> $ bin/hadoop jar ***.jar
> but if I hava a java app, i want to run mapreduce job inside it use  
> hadoop
> cluster, is three anyway?
> -- 
> View this message in context: http://www.nabble.com/How-running-hadoop-without-command-line--tp25167322p25167322.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>

---
Vladimir Klimontovich,
skype: klimontovich
GoogleTalk/Jabber: klimontovich@gmail.com
Cell phone: +7926 890 2349


From common-user-return-17113-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 16:11:38 2009
Return-Path: <common-user-return-17113-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7371 invoked from network); 27 Aug 2009 16:11:37 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 16:11:37 -0000
Received: (qmail 80389 invoked by uid 500); 27 Aug 2009 16:11:35 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 80345 invoked by uid 500); 27 Aug 2009 16:11:35 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 55736 invoked by uid 99); 27 Aug 2009 14:51:53 -0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vklimontovich@iponweb.net designates 209.85.219.209 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:subject:mime-version
         :content-type:from:in-reply-to:date:cc:content-transfer-encoding
         :message-id:references:to:x-mailer;
        bh=+Cj4yWt3cVS79HXHo+zwpNfGOomcIdPNCU0LPz3K9I0=;
        b=bWHn3SKXJ5diPuhLvuWSvaSX1ZrmiCCuRvVCToOTlvTR6zRY3B2NFuvDGOHPcoGpvN
         vsiB9NOmOvHPI9q4D2myygR1ACtNv+vM7C2Xp6STwO/ttFGnpAIfpgv/OQ+MdYMde5Mu
         F8EqMlJGmnUB65a1mJPjBz6Ld7r/WLdmP45hg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=subject:mime-version:content-type:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to:x-mailer;
        b=ZH1dUxbDga3pw3zozuTPXogOdKVsMLqYC8QbOXWpV6qbLsZHRJDh3SMa6f7FgB7yp6
         sUu0b2Jz+VyYMZj5nFY/AC3Mw8VDDyV3q8IKvYFLFZD98RvyminOd91HwiQp7Z69Cpyc
         OC7EwnIhs/icprp0g/1WcRLvhjw2HkaFjbWfc=
Subject: Re: How running hadoop without command line?
Mime-Version: 1.0 (Apple Message framework v1075.2)
Content-Type: text/plain; charset=us-ascii; format=flowed; delsp=yes
From: Vladimir Klimontovich <klimontovich@gmail.com>
In-Reply-To: <25167322.post@talk.nabble.com>
Date: Thu, 27 Aug 2009 18:51:18 +0400
Cc: core-user@hadoop.apache.org
Content-Transfer-Encoding: 7bit
Message-Id: <5BCBDA7F-DED4-4B9D-B0AA-BB0A5E9D67C9@gmail.com>
References: <25167322.post@talk.nabble.com>
To: common-user@hadoop.apache.org
X-Mailer: Apple Mail (2.1075.2)
X-Virus-Checked: Checked by ClamAV on apache.org

There is a class called JobClient. You can run jobs using these class  
from java app.
Also hadoop jar adds $HADOOP_HOME/conf/hadoop-site.xml and  
$HADOOP_HOME/conf/hadoop-conf.xml
xml to classpath, so JobClient already knows which jobtracker and FS  
should be used for running map process.

So when you are running hadoop jobs inside other application you  
should take care of setting valid properties
for jobtracker address, FS address and etc. You can set it manually or  
use Configuratio.addResource for
adding $HADOOP_HOME/conf/hadoop-conf.xml and $HADOOP_HOME/conf/hadoop- 
site.xml .

On Aug 27, 2009, at 1:06 PM, radar.sxl wrote:

>
> When run a hadoop project jar, We'll use
> $ bin/hadoop jar ***.jar
> but if I hava a java app, i want to run mapreduce job inside it use  
> hadoop
> cluster, is three anyway?
> -- 
> View this message in context: http://www.nabble.com/How-running-hadoop-without-command-line--tp25167322p25167322.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>

---
Vladimir Klimontovich,
skype: klimontovich
GoogleTalk/Jabber: klimontovich@gmail.com
Cell phone: +7926 890 2349


From common-user-return-17114-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 16:11:48 2009
Return-Path: <common-user-return-17114-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7469 invoked from network); 27 Aug 2009 16:11:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 16:11:48 -0000
Received: (qmail 82193 invoked by uid 500); 27 Aug 2009 16:11:45 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82127 invoked by uid 500); 27 Aug 2009 16:11:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 83335 invoked by uid 99); 27 Aug 2009 15:12:44 -0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vklimontovich@iponweb.net designates 74.125.78.26 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:content-type:mime-version
         :subject:from:in-reply-to:date:content-transfer-encoding:message-id
         :references:to:x-mailer;
        bh=w9THLDVrAd3WwCe6c008sQcfFg47Nyz4D0v1yjBCw7Y=;
        b=nW013Tdhw/7lU3is1BzAjsYvpHdlSenD3l2TEq6TzYFNshqFLcD8dkpoa+5LJ5fo2j
         Thx58xL0mgjsEj11D8ROgjjYuZ+KinteF91Z5ytdXTYx7tBBgb7GuOihVQLlvGGp/8Af
         G/Ip1132ChaqBUMDnurhhK0dsbFpyAqjiZrvY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to:x-mailer;
        b=pycCV+JeD8oX8+iOPoIs4k0Izf33Haya2/F976K5FC23bUlTsL9o2u6MW8IGjRJLeC
         mZ12iOW/q05uB/VxCo9EuGqAbuCrZE/nIV9mDRZwDXPnh6p0Ge8ejXqhKxRKvVFy5hMg
         mkQnzdC+drFcYY6+Z6EO4aekenExuFcaqMKGI=
Content-Type: text/plain; charset=us-ascii; format=flowed; delsp=yes
Mime-Version: 1.0 (Apple Message framework v1075.2)
Subject: Re: Doubt in reducer
From: Vladimir Klimontovich <klimontovich@gmail.com>
In-Reply-To: <e01b80590908270531g1f2b6900vdc566d9c53ee5f2d@mail.gmail.com>
Date: Thu, 27 Aug 2009 19:12:06 +0400
Content-Transfer-Encoding: 7bit
Message-Id: <A01B01DA-6313-4140-BB14-285FEE0280FD@gmail.com>
References: <2aa3aff80908270452h4a72104fm42f554df180a6a7@mail.gmail.com> <e01b80590908270531g1f2b6900vdc566d9c53ee5f2d@mail.gmail.com>
To: common-user@hadoop.apache.org
X-Mailer: Apple Mail (2.1075.2)
X-Virus-Checked: Checked by ClamAV on apache.org

But reducer can do some preparations during map process. It can
distribute map output across nodes that will work as reducers.

Copying and sorting map output is also time costuming process (maybe,
more consuming than reduce itself). For example, piece job run log on  
40node cluster
could be like that:

09/08/27 11:08:24 INFO job.JobRunningListener:  map 36% reduce 10%
09/08/27 11:08:28 INFO job.JobRunningListener:  map 37% reduce 10%
09/08/27 11:08:29 INFO job.JobRunningListener:  map 37% reduce 11%

But if you run job on single node cluster reduce will start only after  
map finished.

On Aug 27, 2009, at 4:31 PM, Harish Mallipeddi wrote:

> On Thu, Aug 27, 2009 at 5:22 PM, Rakhi Khatwani  
> <rkhatwani@gmail.com> wrote:
>
>>
>> but i want my reduce to run , tht is if 25% map is done, thn i want  
>> the
>> reduce 2 save that much data. even if the 2nd map fails, i dont  
>> loose data.
>> any pointers?
>> Regards,
>> Raakhi
>>
>
> What you're asking for will break the semantics of reduce(). Reduce  
> can only
> proceed after receiving all the map-outputs.
>
> -- 
> Harish Mallipeddi
> http://blog.poundbang.in

---
Vladimir Klimontovich,
skype: klimontovich
GoogleTalk/Jabber: klimontovich@gmail.com
Cell phone: +7926 890 2349


From common-user-return-17116-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 16:18:35 2009
Return-Path: <common-user-return-17116-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 10303 invoked from network); 27 Aug 2009 16:18:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 16:18:35 -0000
Received: (qmail 88012 invoked by uid 500); 27 Aug 2009 16:18:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87894 invoked by uid 500); 27 Aug 2009 16:18:30 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87879 invoked by uid 500); 27 Aug 2009 16:18:29 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 87872 invoked by uid 500); 27 Aug 2009 16:18:29 -0000
Delivered-To: apmail-lucene-hadoop-user@lucene.apache.org
Received: (qmail 87867 invoked by uid 99); 27 Aug 2009 16:18:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 16:18:29 +0000
X-ASF-Spam-Status: No, hits=2.4 required=10.0
	tests=FS_REPLICA,SPF_HELO_PASS,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [64.81.36.244] (HELO foobar.kobold.org) (64.81.36.244)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 16:18:21 +0000
Received: from owl.kobold.org (owl.kobold.org [192.168.1.7])
	(authenticated bits=0)
	by foobar.kobold.org (8.14.1/8.14.1) with ESMTP id n7RFno5V020696
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO);
	Thu, 27 Aug 2009 08:49:51 -0700
Message-ID: <4A96B1B8.6030407@hep.caltech.edu>
Date: Thu, 27 Aug 2009 09:18:00 -0700
From: Michael Thomas <thomas@hep.caltech.edu>
User-Agent: Thunderbird 2.0.0.21 (X11/20090320)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
CC: hadoop-user@lucene.apache.org
Subject: Re: Delete replicated blocks?
References: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com> <5C832190-BC7F-4D16-89E7-43D917C9D9A0@gmail.com>
In-Reply-To: <5C832190-BC7F-4D16-89E7-43D917C9D9A0@gmail.com>
X-Enigmail-Version: 0.95.2
Content-Type: multipart/signed; protocol="application/x-pkcs7-signature"; micalg=sha1; boundary="------------ms030605010605060905050800"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------ms030605010605060905050800
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

dfs.replication is only used by the client at the time the files are
written.  Changing this setting will not automatically change the
replication level on existing files.  To do that, you need to use the
hadoop cli:

hadoop fs -setrep -R 1 /

--Mike


Vladimir Klimontovich wrote:
> This will happen automatically.
> On Aug 27, 2009, at 6:04 PM, Andy Liu wrote:
> 
>> I'm running a test Hadoop cluster, which had a dfs.replication value
>> of 3.
>> I'm now running out of disk space, so I've reduced dfs.replication to
>> 1 and
>> restarted my datanodes.  Is there a way to free up the over-replicated
>> blocks, or does this happen automatically at some point?
>>
>> Thanks,
>> Andy
> 
> ---
> Vladimir Klimontovich,
> skype: klimontovich
> GoogleTalk/Jabber: klimontovich@gmail.com
> Cell phone: +7926 890 2349
> 


--------------ms030605010605060905050800
Content-Type: application/x-pkcs7-signature; name="smime.p7s"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="smime.p7s"
Content-Description: S/MIME Cryptographic Signature
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--------------ms030605010605060905050800--

From common-user-return-17115-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 16:18:35 2009
Return-Path: <common-user-return-17115-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 10295 invoked from network); 27 Aug 2009 16:18:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 16:18:35 -0000
Received: (qmail 87978 invoked by uid 500); 27 Aug 2009 16:18:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87892 invoked by uid 500); 27 Aug 2009 16:18:30 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87867 invoked by uid 99); 27 Aug 2009 16:18:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 16:18:29 +0000
X-ASF-Spam-Status: No, hits=2.4 required=10.0
	tests=FS_REPLICA,SPF_HELO_PASS,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [64.81.36.244] (HELO foobar.kobold.org) (64.81.36.244)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 16:18:21 +0000
Received: from owl.kobold.org (owl.kobold.org [192.168.1.7])
	(authenticated bits=0)
	by foobar.kobold.org (8.14.1/8.14.1) with ESMTP id n7RFno5V020696
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO);
	Thu, 27 Aug 2009 08:49:51 -0700
Message-ID: <4A96B1B8.6030407@hep.caltech.edu>
Date: Thu, 27 Aug 2009 09:18:00 -0700
From: Michael Thomas <thomas@hep.caltech.edu>
User-Agent: Thunderbird 2.0.0.21 (X11/20090320)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
CC: hadoop-user@lucene.apache.org
Subject: Re: Delete replicated blocks?
References: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com> <5C832190-BC7F-4D16-89E7-43D917C9D9A0@gmail.com>
In-Reply-To: <5C832190-BC7F-4D16-89E7-43D917C9D9A0@gmail.com>
X-Enigmail-Version: 0.95.2
Content-Type: multipart/signed; protocol="application/x-pkcs7-signature"; micalg=sha1; boundary="------------ms030605010605060905050800"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------ms030605010605060905050800
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

dfs.replication is only used by the client at the time the files are
written.  Changing this setting will not automatically change the
replication level on existing files.  To do that, you need to use the
hadoop cli:

hadoop fs -setrep -R 1 /

--Mike


Vladimir Klimontovich wrote:
> This will happen automatically.
> On Aug 27, 2009, at 6:04 PM, Andy Liu wrote:
> 
>> I'm running a test Hadoop cluster, which had a dfs.replication value
>> of 3.
>> I'm now running out of disk space, so I've reduced dfs.replication to
>> 1 and
>> restarted my datanodes.  Is there a way to free up the over-replicated
>> blocks, or does this happen automatically at some point?
>>
>> Thanks,
>> Andy
> 
> ---
> Vladimir Klimontovich,
> skype: klimontovich
> GoogleTalk/Jabber: klimontovich@gmail.com
> Cell phone: +7926 890 2349
> 


--------------ms030605010605060905050800
Content-Type: application/x-pkcs7-signature; name="smime.p7s"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="smime.p7s"
Content-Description: S/MIME Cryptographic Signature
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--------------ms030605010605060905050800--

From common-user-return-17117-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 16:40:41 2009
Return-Path: <common-user-return-17117-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 20581 invoked from network); 27 Aug 2009 16:40:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 16:40:41 -0000
Received: (qmail 26060 invoked by uid 500); 27 Aug 2009 16:40:38 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 25999 invoked by uid 500); 27 Aug 2009 16:40:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 25989 invoked by uid 99); 27 Aug 2009 16:40:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 16:40:37 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rvernica@gmail.com designates 209.85.222.173 as permitted sender)
Received: from [209.85.222.173] (HELO mail-pz0-f173.google.com) (209.85.222.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 16:40:28 +0000
Received: by pzk3 with SMTP id 3so1238160pzk.31
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 09:40:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=UefFHb+35mxxUmIfn9FPjDKWE0qBpXoXORS1B8UHwps=;
        b=sDip0BXpWPmmGWuhKwqKqAbEty+vMNgCVLkleTmuc831gg0Qa2DLBU1J2Z1Bf9YK6+
         dXGeHR1JoW0GxJvlhZ68lzTaPb/kYi13VQRCWQXJ4DNPntWUwwaymmMpzZKjtQAyAkj0
         JuaBZEhid+GvJIfoLUasbPiayh4nI+EMG+viM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=Ui5RkHpGYmA/L0FRjy0uOc0ylxcdrPMvNRuT5qV+GnzVpuN1ySCZ5Rx9memSrMz0sj
         LyorGBQR6W7rDAkp+awqIyoK9HLPobbjd8+tT+0U/RFKK56lEqzXIeTAQqGCco6TdMkJ
         qLQf7V7eC/buiHKamb4KzI7j1PTBkmzPNLQv0=
MIME-Version: 1.0
Received: by 10.140.157.9 with SMTP id f9mr4298078rve.116.1251391207643; Thu, 
	27 Aug 2009 09:40:07 -0700 (PDT)
Date: Thu, 27 Aug 2009 09:40:07 -0700
Message-ID: <b8208a3b0908270940h48821ed9g6a1b51657f472366@mail.gmail.com>
Subject: control map to split assignment
From: Rares Vernica <rvernica@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

I wonder is there is a way to control how maps are assigned to splits
in order to balance the load across the cluster.

Here is a simplified example. I have tow types of inputs: "long" and
"short". Each input is in a different file and will be processed by a
single map task. Suppose the "long" inputs take 10s to process while
the "short" inputs take 3s to process. I have two "long" inputs and
two "short" inputs. My cluster has 2 nodes and each node can execute
only one map task at a time. A possible schedule of the tasks could be
the following:

Node 1: "long map", "short map" -> 10s + 3s = 13s
Node 2: "long map", "short map" -> 10s + 3s = 13s

So, my job will be done in 13s. Another possible schedule is:

Node 1: "long map" -> 10s
Node 2: "short map", "short map", "long map" -> 3s + 3s + 10s = 16s

And, my job will be done in 16s. Clearly, the first scheduling is better.

Is there a way to control how the schedule is build? If I can control
which inputs are processed first, I could schedule the "long" inputs
to be processed first and so they will be balanced across nodes and I
will end up with something similar to the first schedule.

I could configure the job so that a "long" input gets processed by
more that a map, and so end up balancing the work, but I noticed that
overall, this takes more time than a bad scheduling with only one map
per input.

Thanks!

Cheers,
Rares Vernica

From common-user-return-17118-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 17:57:24 2009
Return-Path: <common-user-return-17118-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 74696 invoked from network); 27 Aug 2009 17:57:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 17:57:23 -0000
Received: (qmail 44082 invoked by uid 500); 27 Aug 2009 17:57:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 44004 invoked by uid 500); 27 Aug 2009 17:57:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 43993 invoked by uid 99); 27 Aug 2009 17:57:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 17:57:21 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 17:57:13 +0000
Received: by iwn6 with SMTP id 6so677912iwn.5
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 10:56:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.231.122.162 with SMTP id l34mr418419ibr.20.1251395811868; Thu, 
	27 Aug 2009 10:56:51 -0700 (PDT)
In-Reply-To: <b8208a3b0908261852x4ca72740qa746fbd6d4c9beca@mail.gmail.com>
References: <b8208a3b0908261852x4ca72740qa746fbd6d4c9beca@mail.gmail.com>
Date: Thu, 27 Aug 2009 10:56:51 -0700
Message-ID: <623d9cf40908271056i257010cbo1fd0282f7d05924b@mail.gmail.com>
Subject: Re: control map to split assignment
From: Alex Loddengaard <alex@cloudera.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64608e4d6ff6a0472234a25
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64608e4d6ff6a0472234a25
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Hi Rares,

Unfortunately there isn't a way to control the scheduling of individual
tasks, at least as far as I know.  Might you be able to split this up into
two jobs: one for the "short" inputs; another for the "long" inputs?  Just a
thought.

Alex

On Wed, Aug 26, 2009 at 6:52 PM, Rares Vernica <rvernica@gmail.com> wrote:

> Hello,
>
> I wonder is there is a way to control how maps are assigned to splits
> in order to balance the load across the cluster.
>
> Here is a simplified example. I have tow types of inputs: "long" and
> "short". Each input is in a different file and will be processed by a
> single map task. Suppose the "long" inputs take 10s to process while
> the "short" inputs take 3s to process. I have two "long" inputs and
> two "short" inputs. My cluster has 2 nodes and each node can execute
> only one map task at a time. A possible schedule of the tasks could be
> the following:
>
> Node 1: "long map", "short map" -> 10s + 3s = 13s
> Node 2: "long map", "short map" -> 10s + 3s = 13s
>
> So, my job will be done in 13s. Another possible schedule is:
>
> Node 1: "long map" -> 10s
> Node 2: "short map", "short map", "long map" -> 3s + 3s + 10s = 16s
>
> And, my job will be done in 16s. Clearly, the first scheduling is better.
>
> Is there a way to control how the schedule is build? If I can control
> which inputs are processed first, I could schedule the "long" inputs
> to be processed first and so they will be balanced across nodes and I
> will end up with something similar to the first schedule.
>
> I could configure the job so that a "long" input gets processed by
> more that a map, and so end up balancing the work, but I noticed that
> overall, this takes more time than a bad scheduling with only one map
> per input.
>
> Thanks!
>
> Cheers,
> Rares Vernica
>

--0016e64608e4d6ff6a0472234a25--

From common-user-return-17119-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 18:00:54 2009
Return-Path: <common-user-return-17119-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 76627 invoked from network); 27 Aug 2009 18:00:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 18:00:54 -0000
Received: (qmail 51596 invoked by uid 500); 27 Aug 2009 18:00:52 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 51529 invoked by uid 500); 27 Aug 2009 18:00:51 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 51519 invoked by uid 99); 27 Aug 2009 18:00:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 18:00:51 +0000
X-ASF-Spam-Status: No, hits=4.6 required=10.0
	tests=FS_REPLICA,HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 18:00:42 +0000
Received: by iwn6 with SMTP id 6so679127iwn.5
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 11:00:21 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.231.122.162 with SMTP id l34mr424930ibr.20.1251396021329; Thu, 
	27 Aug 2009 11:00:21 -0700 (PDT)
In-Reply-To: <4A96B1B8.6030407@hep.caltech.edu>
References: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com>
	 <5C832190-BC7F-4D16-89E7-43D917C9D9A0@gmail.com>
	 <4A96B1B8.6030407@hep.caltech.edu>
Date: Thu, 27 Aug 2009 11:00:21 -0700
Message-ID: <623d9cf40908271100q111b583dx972b160f7d2b123d@mail.gmail.com>
Subject: Re: Delete replicated blocks?
From: Alex Loddengaard <alex@cloudera.com>
To: common-user@hadoop.apache.org
Cc: hadoop-user@lucene.apache.org
Content-Type: multipart/alternative; boundary=0016e64608e4531e5804722357c4
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64608e4531e5804722357c4
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I don't know for sure, but running the rebalancer might do this for you.

<
http://hadoop.apache.org/common/docs/r0.20.0/hdfs_user_guide.html#Rebalancer
>

Alex

On Thu, Aug 27, 2009 at 9:18 AM, Michael Thomas <thomas@hep.caltech.edu>wrote:

> dfs.replication is only used by the client at the time the files are
> written.  Changing this setting will not automatically change the
> replication level on existing files.  To do that, you need to use the
> hadoop cli:
>
> hadoop fs -setrep -R 1 /
>
> --Mike
>
>
> Vladimir Klimontovich wrote:
> > This will happen automatically.
> > On Aug 27, 2009, at 6:04 PM, Andy Liu wrote:
> >
> >> I'm running a test Hadoop cluster, which had a dfs.replication value
> >> of 3.
> >> I'm now running out of disk space, so I've reduced dfs.replication to
> >> 1 and
> >> restarted my datanodes.  Is there a way to free up the over-replicated
> >> blocks, or does this happen automatically at some point?
> >>
> >> Thanks,
> >> Andy
> >
> > ---
> > Vladimir Klimontovich,
> > skype: klimontovich
> > GoogleTalk/Jabber: klimontovich@gmail.com
> > Cell phone: +7926 890 2349
> >
>
>

--0016e64608e4531e5804722357c4--

From common-user-return-17120-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 18:00:57 2009
Return-Path: <common-user-return-17120-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 76710 invoked from network); 27 Aug 2009 18:00:57 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 18:00:57 -0000
Received: (qmail 51895 invoked by uid 500); 27 Aug 2009 18:00:52 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 51804 invoked by uid 500); 27 Aug 2009 18:00:52 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 51706 invoked by uid 500); 27 Aug 2009 18:00:52 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 51616 invoked by uid 500); 27 Aug 2009 18:00:52 -0000
Delivered-To: apmail-lucene-hadoop-user@lucene.apache.org
Received: (qmail 51530 invoked by uid 99); 27 Aug 2009 18:00:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 18:00:51 +0000
X-ASF-Spam-Status: No, hits=4.6 required=10.0
	tests=FS_REPLICA,HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.223.200] (HELO mail-iw0-f200.google.com) (209.85.223.200)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 18:00:42 +0000
Received: by iwn38 with SMTP id 38so655264iwn.29
        for <hadoop-user@lucene.apache.org>; Thu, 27 Aug 2009 11:00:21 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.231.122.162 with SMTP id l34mr424930ibr.20.1251396021329; Thu, 
	27 Aug 2009 11:00:21 -0700 (PDT)
In-Reply-To: <4A96B1B8.6030407@hep.caltech.edu>
References: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com>
	 <5C832190-BC7F-4D16-89E7-43D917C9D9A0@gmail.com>
	 <4A96B1B8.6030407@hep.caltech.edu>
Date: Thu, 27 Aug 2009 11:00:21 -0700
Message-ID: <623d9cf40908271100q111b583dx972b160f7d2b123d@mail.gmail.com>
Subject: Re: Delete replicated blocks?
From: Alex Loddengaard <alex@cloudera.com>
To: common-user@hadoop.apache.org
Cc: hadoop-user@lucene.apache.org
Content-Type: multipart/alternative; boundary=0016e64608e4531e5804722357c4
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64608e4531e5804722357c4
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

I don't know for sure, but running the rebalancer might do this for you.

<
http://hadoop.apache.org/common/docs/r0.20.0/hdfs_user_guide.html#Rebalancer
>

Alex

On Thu, Aug 27, 2009 at 9:18 AM, Michael Thomas <thomas@hep.caltech.edu>wrote:

> dfs.replication is only used by the client at the time the files are
> written.  Changing this setting will not automatically change the
> replication level on existing files.  To do that, you need to use the
> hadoop cli:
>
> hadoop fs -setrep -R 1 /
>
> --Mike
>
>
> Vladimir Klimontovich wrote:
> > This will happen automatically.
> > On Aug 27, 2009, at 6:04 PM, Andy Liu wrote:
> >
> >> I'm running a test Hadoop cluster, which had a dfs.replication value
> >> of 3.
> >> I'm now running out of disk space, so I've reduced dfs.replication to
> >> 1 and
> >> restarted my datanodes.  Is there a way to free up the over-replicated
> >> blocks, or does this happen automatically at some point?
> >>
> >> Thanks,
> >> Andy
> >
> > ---
> > Vladimir Klimontovich,
> > skype: klimontovich
> > GoogleTalk/Jabber: klimontovich@gmail.com
> > Cell phone: +7926 890 2349
> >
>
>

--0016e64608e4531e5804722357c4--

From common-user-return-17121-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 18:19:03 2009
Return-Path: <common-user-return-17121-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 90510 invoked from network); 27 Aug 2009 18:19:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 18:19:03 -0000
Received: (qmail 69018 invoked by uid 500); 27 Aug 2009 18:19:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 68929 invoked by uid 500); 27 Aug 2009 18:19:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 68919 invoked by uid 99); 27 Aug 2009 18:19:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 18:19:00 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=FS_REPLICA,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 18:18:52 +0000
Received: by bwz10 with SMTP id 10so253867bwz.29
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 11:18:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=03Ea6IxzfNBjRu7TxwC5PZIVk7zjMkgCNDYz9X4Gaeo=;
        b=nHWLJI6mhhao3TdTTrUMsYgtxGJ6M6678K5JmsXMXL4HMxRj1Gr5Fz7a+l/AxMjl6g
         DNKqLRFUSdQqEcwN7Ddba7Hy5oM4ysIh6oYJ4k8x4lkhiOw0nDMxW4r6VQyFrEkUmPCO
         8D2smudOFodZ0ndllC1EhJFQX4e8xeZW7Sveo=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=etYSIjgjhiSs+CHLnKKv9eqW4thB+0z7YMTQFzqCLGe0Rpaot+iEECFRKdQU54OUeR
         CkgMJQyUo9opXi9iywOz5dtYg+IowzX2QaFZvWJaHGecEwPpWOw1WWKbs7gCPTX63zac
         820b4IYnUCRevXE3UdEf7qztpmXFWkkQW0q9A=
MIME-Version: 1.0
Received: by 10.223.143.79 with SMTP id t15mr31245fau.6.1251397110726; Thu, 27 
	Aug 2009 11:18:30 -0700 (PDT)
In-Reply-To: <623d9cf40908271100q111b583dx972b160f7d2b123d@mail.gmail.com>
References: <32dca9ed0908270704x3a074770y59ca394d867d2a91@mail.gmail.com>
	 <5C832190-BC7F-4D16-89E7-43D917C9D9A0@gmail.com>
	 <4A96B1B8.6030407@hep.caltech.edu>
	 <623d9cf40908271100q111b583dx972b160f7d2b123d@mail.gmail.com>
Date: Thu, 27 Aug 2009 21:18:30 +0300
Message-ID: <77938bc20908271118y2f7a7d0fgaaf590fa349debfd@mail.gmail.com>
Subject: Re: Delete replicated blocks?
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0023545bda284200da0472239845
X-Virus-Checked: Checked by ClamAV on apache.org

--0023545bda284200da0472239845
Content-Type: text/plain; charset=ISO-8859-1

Hi.

Following on this issue, any idea if all the bugs were worked out in 0.20,
with replication value of 2?

I remember 0.18.3 had some issues with this, and actually caused a lost of
data to some uni.

Regards.

2009/8/27 Alex Loddengaard <alex@cloudera.com>

> I don't know for sure, but running the rebalancer might do this for you.
>
> <
>
> http://hadoop.apache.org/common/docs/r0.20.0/hdfs_user_guide.html#Rebalancer
> >
>
> Alex
>
> On Thu, Aug 27, 2009 at 9:18 AM, Michael Thomas <thomas@hep.caltech.edu
> >wrote:
>
> > dfs.replication is only used by the client at the time the files are
> > written.  Changing this setting will not automatically change the
> > replication level on existing files.  To do that, you need to use the
> > hadoop cli:
> >
> > hadoop fs -setrep -R 1 /
> >
> > --Mike
> >
> >
> > Vladimir Klimontovich wrote:
> > > This will happen automatically.
> > > On Aug 27, 2009, at 6:04 PM, Andy Liu wrote:
> > >
> > >> I'm running a test Hadoop cluster, which had a dfs.replication value
> > >> of 3.
> > >> I'm now running out of disk space, so I've reduced dfs.replication to
> > >> 1 and
> > >> restarted my datanodes.  Is there a way to free up the over-replicated
> > >> blocks, or does this happen automatically at some point?
> > >>
> > >> Thanks,
> > >> Andy
> > >
> > > ---
> > > Vladimir Klimontovich,
> > > skype: klimontovich
> > > GoogleTalk/Jabber: klimontovich@gmail.com
> > > Cell phone: +7926 890 2349
> > >
> >
> >
>

--0023545bda284200da0472239845--

From common-user-return-17122-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 18:33:19 2009
Return-Path: <common-user-return-17122-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 99000 invoked from network); 27 Aug 2009 18:33:19 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 18:33:19 -0000
Received: (qmail 84536 invoked by uid 500); 27 Aug 2009 18:33:17 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 84469 invoked by uid 500); 27 Aug 2009 18:33:17 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 84459 invoked by uid 99); 27 Aug 2009 18:33:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 18:33:16 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 18:33:06 +0000
Received: from wlanvpn-mc2e-246-26.corp.yahoo.com (wlanvpn-mc2e-246-26.corp.yahoo.com [172.21.148.26])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7RIW0Kh088265
	for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 11:32:00 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:from:to:in-reply-to:content-type:
	content-transfer-encoding:mime-version:subject:date:references:x-mailer;
	b=L9sgyxhnp4DWf3VIx0pZVwYApwdTtkHPMqZdbaTHZHTbKKUuKVEWzFOn36gNSQQM
Message-Id: <714D34EE-8ECA-48F4-94FC-98C853EF93DF@yahoo-inc.com>
From: Arun C Murthy <acm@yahoo-inc.com>
To: common-user@hadoop.apache.org
In-Reply-To: <d6d7c4410908241749j6fa32ec1pb46e66eae1d14f28@mail.gmail.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: How to speed up the copy phrase?
Date: Thu, 27 Aug 2009 11:31:59 -0700
References: <3b1311780908232349s56df94b9k321a48255adcdd85@mail.gmail.com>  <616DA47B2EF5B944B91846785B512FF4CFADEA70F9@EGL-EX07VS01.ds.corp.yahoo.com> <d6d7c4410908241749j6fa32ec1pb46e66eae1d14f28@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org


On Aug 24, 2009, at 5:49 PM, Aaron Kimball wrote:

> If you've got 20 nodes, then you want to have 20-ish reduce tasks.  
> Maybe 40
> if you want it to run in two waves. (Assuming 1 core/node. Multiply  
> by N for
> N cores...) As it is, each node has 500-ish map tasks that it has to  
> read
> from and for each of these, it needs to generate 500 separate reduce  
> task
> output files.  That's going to take Hadoop a long time to do.

Maps do not produce one output file per reduce, the entire map-output  
is in a single file.

Arun

From common-user-return-17123-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 19:42:49 2009
Return-Path: <common-user-return-17123-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 19939 invoked from network); 27 Aug 2009 19:42:49 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 19:42:49 -0000
Received: (qmail 87914 invoked by uid 500); 27 Aug 2009 19:42:46 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87849 invoked by uid 500); 27 Aug 2009 19:42:46 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87839 invoked by uid 99); 27 Aug 2009 19:42:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 19:42:46 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [67.195.23.94] (HELO web112107.mail.gq1.yahoo.com) (67.195.23.94)
    by apache.org (qpsmtpd/0.29) with SMTP; Thu, 27 Aug 2009 19:42:35 +0000
Received: (qmail 69195 invoked by uid 60001); 27 Aug 2009 19:42:14 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1251402134; bh=SuyvL13L6LbjyMlwGEyBPM2Tk5aFUCfRNYjdoFlYkbI=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:Cc:In-Reply-To:MIME-Version:Content-Type; b=oMD2A+uq7VXNSg33n7jxNpe22dtSBb6gBb4OaklIbHIr/iRnlh7Uyr3j1I/HcRBOoZBkyx92RvVMHvRfc2Kkp/5Tdq17ZMmHu3ZWdlAiI70/nXPo9JpYi1CW3W2upveVBjgUg6SSj9qrdgsff+8kRKGiu7t4CSeAF9miIrwsTM0=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:Cc:In-Reply-To:MIME-Version:Content-Type;
  b=6g1nZAei9Y8IoQwWq0T0ypd6pZmqeBlB05lNbemNnPDxAg/PZSoFoNIZZ1DMf3eHXPQq6a1X6nIdDxH+6Zjw5/inhsWcgh7/i1po9Gc/gEkhsftAOTosMCodCCUosSupXGMejZeV38T6ORbA493e7a+BwWSYbEnq+obPSwesYEM=;
Message-ID: <6395.68829.qm@web112107.mail.gq1.yahoo.com>
X-YMail-OSG: MTo1aDgVM1nCil4uQoXAYGekNY5wMVt81Vie3eRaXEouNnOtIEo6M_t24lwfyi9C6j7VFzAp08vo8Z5a8o7_AGAFiUXT2aBEsbEXh6djHWPnr9dK8aki27DeQaadWUxNVqUcsZe4Mz19xMJcLAd9Tf4dioLnsAsTsMOk8jYwuZgM9X30VBPZyvDx_ogW8yBtHKfthvSC9pClyIzomPXiII3.SrE.E0D2bTBPgujITliXApiLFUCmfQ0dnci5h8hYq5TrYqhieeBNhzsVGo.8XnxxYmyFu1lPhYNaXXzSP0JSs2xiL4nI4T4XrB26SnObJkeQjlZwpsPGmBY4I8Tsgg--
Received: from [64.172.17.3] by web112107.mail.gq1.yahoo.com via HTTP; Thu, 27 Aug 2009 12:42:13 PDT
X-Mailer: YahooMailClassic/6.1.2 YahooMailWebService/0.7.338.2
Date: Thu, 27 Aug 2009 12:42:13 -0700 (PDT)
From: Steve Gao <steve.gao@yahoo.com>
Subject: Why "java.util.zip.ZipOutputStream" need to use /tmp?
To: common-user@hadoop.apache.org
Cc: common-dev@hadoop.apache.org
In-Reply-To: <714D34EE-8ECA-48F4-94FC-98C853EF93DF@yahoo-inc.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-148727429-1251402133=:68829"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-148727429-1251402133=:68829
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable



The hadoop version is 0.18.3 . Recently we got "out of space" issue. It's f=
rom "java.util.zip.ZipOutputStream".
We found that /tmp is full and after cleaning /tmp the problem is solved.

However why hadoop needs to use /tmp? We had already configured hadoop tmp =
to a local disk in: hadoop-site.xml

<property>
=A0 <name>hadoop.tmp.dir</name>
=A0 <value> ... some large local disk ... </value>
</property>


Could it because java.util.zip.ZipOutputStream uses /tmp even if we configu=
red hadoop.tmp.dir to a large local disk?

The error log is here FYI:

java.io.IOException: No space left on device=A0=A0=A0=A0=A0=A0=A0 =A0
at java.io.FileOutputStream.write(Native Method)=A0=A0=A0=A0=A0=A0 =A0
=A0at java.util.zip.ZipOutputStream.writeInt(ZipOutputStream.java:445)=A0=
=A0=A0=A0=A0=A0=A0 =A0
at java.util.zip.ZipOutputStream.writeEXT(ZipOutputStream.java:362)=A0=A0=
=A0=A0=A0=A0=A0 =A0
at java.util.zip.ZipOutputStream.closeEntry(ZipOutputStream.java:220)=A0=A0=
=A0=A0=A0=A0=A0 =A0
at java.util.zip.ZipOutputStream.finish(ZipOutputStream.java:301)=A0=A0=A0=
=A0=A0=A0=A0 =A0
at java.util.zip.DeflaterOutputStream.close(DeflaterOutputStream.java:146)=
=A0=A0=A0=A0=A0=A0=A0 =A0
at java.util.zip.ZipOutputStream.close(ZipOutputStream.java:321)=A0=A0=A0=
=A0=A0=A0=A0 =A0
at org.apache.hadoop.streaming.JarBuilder.merge(JarBuilder.java:79)=A0=A0=
=A0=A0=A0=A0=A0 =A0
at org.apache.hadoop.streaming.StreamJob.packageJobJar(StreamJob.java:628)=
=A0=A0=A0=A0=A0=A0=A0 =A0
at org.apache.hadoop.streaming.StreamJob.setJobConf(StreamJob.java:843)=A0=
=A0=A0=A0=A0=A0=A0 =A0
at org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:110)=A0=A0=A0=A0=
=A0=A0=A0 =A0
at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:33=
)=A0=A0=A0=A0=A0=A0=A0 =A0
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)=A0=A0=A0=A0=
=A0=A0=A0 =A0
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav=
a:39)=A0=A0=A0=A0=A0=A0=A0 =A0
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessor=
Impl.java:25)=A0=A0=A0=A0=A0=A0=A0 =A0
at java.lang.reflect.Method.invoke(Method.java:597)=A0=A0=A0=A0=A0=A0=A0 =
=A0
at org.apache.hadoop.util.RunJar.main(RunJar.java:155)=A0=A0=A0=A0=A0=A0=A0=
 =A0
at org.apache.hadoop.mapred.JobShell.run(JobShell.java:194)=A0=A0=A0=A0=A0=
=A0=A0 =A0
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)=A0=A0=A0=A0=A0=
=A0=A0 =A0
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)=A0=A0=A0=A0=A0=
=A0=A0 =A0
at org.apache.hadoop.mapred.JobShell.main(JobShell.java:220) =A0
Executing Hadoop job failure

=0A=0A=0A      
--0-148727429-1251402133=:68829--

From common-user-return-17124-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 19:52:30 2009
Return-Path: <common-user-return-17124-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 22565 invoked from network); 27 Aug 2009 19:52:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 19:52:30 -0000
Received: (qmail 354 invoked by uid 500); 27 Aug 2009 19:52:27 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 289 invoked by uid 500); 27 Aug 2009 19:52:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 279 invoked by uid 99); 27 Aug 2009 19:52:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 19:52:27 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rvernica@gmail.com designates 209.85.216.191 as permitted sender)
Received: from [209.85.216.191] (HELO mail-px0-f191.google.com) (209.85.216.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 19:52:19 +0000
Received: by pxi29 with SMTP id 29so1379580pxi.30
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 12:51:58 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=JImZiEMUnnry9RNBCUdC+12lFI936cUDAyAbqCdCHyw=;
        b=fli0oCX8i4DhwfwxHbf3BFjQxp8w/CVu+I8fQiRoWMRRTNKVMxjf5mcFmtTLMgY8kt
         ER/EYyM72e3AEKDhPHFjaXnxfvdt+uv2PYAvhzQfngv6N67uURz3ReLMktdLcQ0/gJM5
         ZK1OMEYB0Zv0w+2400T4LRkLJkdzZyhlmaMpM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=l9x7NzU5J2EOoqhEhx3dFXUte+C27yXPjEs8n6qHPO9/u77TrhZpOu+xozeieg59Fg
         526GsV6LmGkywQ2CcarGekdGYEebZqBZlDK+th6M/KrMxYh2zAdbylsHwqGgyEGOMd0o
         Fhup2ZzqPtLH3ri+aEw32kT011OZUKD+K3iqc=
MIME-Version: 1.0
Received: by 10.140.172.7 with SMTP id u7mr154106rve.45.1251402718887; Thu, 27 
	Aug 2009 12:51:58 -0700 (PDT)
Date: Thu, 27 Aug 2009 12:51:58 -0700
Message-ID: <b8208a3b0908271251o5cd89920m683b326755be7e0f@mail.gmail.com>
Subject: understand merge phase performance
From: Rares Vernica <rvernica@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

I need some help in understanding the performance of the merge phase.
I am surprised how a merge phase for a task processing a smaller
amount of data takes more that the merge phase for a task processing a
larger amount of data.

I have two jobs. Both are executed on the same 1 Node cluster (4 Map
and 4 Reduce in parallel). Job 1 is doing word count while Job 2 is
building an inverted list index (from word to records). They both take
the same input data. As you can imagine, the amount of data transfered
between the Job 1 Map and the Job 1 Reduce is smaller that the amount
of data transfered between Job 2 Map and Job 2 Reduce. Still, the
merge phase of Job 1 takes 2 seconds while the merge phase of Job 2
takes less that 1 second (it is reported as taking 0 seconds). Another
difference is the fact that the keys for Job 1 are Text, while the
keys for Job 2 are IntWritable (words are converted to integers).

Here are some relevant statistics.

Job 1
---
Reduce input groups  	450,693
Map output bytes 	3,152,970,981
Map input bytes 	3,169,519,473

Job 2
---
Reduce input groups  	450,633
Map output bytes 	8,349,926,960
Map input bytes 	3,169,519,473

Here are some excerpts from the logs which might be relevant:

Job 1
---
2009-08-27 12:10:04,171 INFO org.apache.hadoop.mapred.ReduceTask:
Interleaved on-disk merge complete: 0 files left.
2009-08-27 12:10:04,172 INFO org.apache.hadoop.mapred.ReduceTask:
In-memory merge complete: 4 files left.
2009-08-27 12:10:04,197 INFO org.apache.hadoop.mapred.Merger: Merging
4 sorted segments
2009-08-27 12:10:04,197 INFO org.apache.hadoop.mapred.Merger: Down to
the last merge-pass, with 4 segments left of total size: 13139424
bytes
2009-08-27 12:10:04,203 INFO org.apache.hadoop.io.compress.CodecPool:
Got brand-new compressor
2009-08-27 12:10:06,695 INFO org.apache.hadoop.mapred.ReduceTask:
Merged 4 segments, 13139424 bytes to disk to satisfy reduce memory
limit
2009-08-27 12:10:06,696 INFO org.apache.hadoop.mapred.ReduceTask:
Merging 1 files, 2952848 bytes from disk
2009-08-27 12:10:06,696 INFO org.apache.hadoop.mapred.ReduceTask:
Merging 0 segments, 0 bytes from memory into reduce
2009-08-27 12:10:06,696 INFO org.apache.hadoop.mapred.Merger: Merging
1 sorted segments
2009-08-27 12:10:06,699 INFO org.apache.hadoop.io.compress.CodecPool:
Got brand-new decompressor
2009-08-27 12:10:06,700 INFO org.apache.hadoop.mapred.Merger: Down to
the last merge-pass, with 1 segments left of total size: 2952844 bytes

Job 2
---
2009-08-27 11:01:42,851 INFO org.apache.hadoop.mapred.ReduceTask:
Interleaved on-disk merge complete: 4 files left.
2009-08-27 11:01:42,851 INFO org.apache.hadoop.mapred.ReduceTask:
In-memory merge complete: 0 files left.
2009-08-27 11:01:42,862 INFO org.apache.hadoop.mapred.ReduceTask:
Merging 4 files, 508528572 bytes from disk
2009-08-27 11:01:42,862 INFO org.apache.hadoop.mapred.ReduceTask:
Merging 0 segments, 0 bytes from memory into reduce
2009-08-27 11:01:42,866 INFO org.apache.hadoop.mapred.Merger: Merging
4 sorted segments
2009-08-27 11:01:42,873 INFO org.apache.hadoop.io.compress.CodecPool:
Got brand-new decompressor
2009-08-27 11:01:42,874 INFO org.apache.hadoop.io.compress.CodecPool:
Got brand-new decompressor
2009-08-27 11:01:42,876 INFO org.apache.hadoop.io.compress.CodecPool:
Got brand-new decompressor
2009-08-27 11:01:42,876 INFO org.apache.hadoop.io.compress.CodecPool:
Got brand-new decompressor
2009-08-27 11:01:42,877 INFO org.apache.hadoop.mapred.Merger: Down to
the last merge-pass, with 4 segments left of total size: 508528556
bytes

>From the performance, I feel that the Job 1 sort is done on disk while
the Job 2 sort is done in memory. This is strange because Job 1 Map
output is smaller than Job 2 Map output.

Thanks a lot!
Rares Vernica

From common-user-return-17125-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 20:01:36 2009
Return-Path: <common-user-return-17125-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 25150 invoked from network); 27 Aug 2009 20:01:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 20:01:35 -0000
Received: (qmail 17446 invoked by uid 500); 27 Aug 2009 20:01:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 17365 invoked by uid 500); 27 Aug 2009 20:01:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 17347 invoked by uid 99); 27 Aug 2009 20:01:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 20:01:31 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of saseith@gmail.com designates 209.85.212.185 as permitted sender)
Received: from [209.85.212.185] (HELO mail-vw0-f185.google.com) (209.85.212.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 20:01:22 +0000
Received: by vws15 with SMTP id 15so1133619vws.5
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 13:01:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=mMNw1f8lUVZnvU0mIubp7ji1YpXWVPlLcXNVLaXYTxw=;
        b=AqYzn16t4Ksjr/Mw44ozjOYYk9nJa0AjjQQshEo2WCVI4svUDN4B3Sj8mn6lF2xktG
         BwZciKbqnKdYONiJGk+xuHh+mC/bS63FFd21LJXPHXjNR10e3PJjYJKKsJmKAP3W4vKz
         jgjnnmA/Dtsj6WbAmYDX5tMlGkszJB/QlxGx4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=FdDNE6n3FW7YxiPvHZ+WrUHWD342FG7+NAq2kFFFVvGG+otiN2qjDdxAM3HxhWBMUq
         zz4y3A+6fz3PKNQPO4aGCj2G6fn7OpBASLUHRkQm0KqMREAlglrfRmu96hrP3tLt8zel
         Fw0pMtM0ZcWfk0pT96ZXUF1SZWrw2LJNxKBKE=
MIME-Version: 1.0
Received: by 10.220.89.25 with SMTP id c25mr363023vcm.8.1251403261491; Thu, 27 
	Aug 2009 13:01:01 -0700 (PDT)
Date: Thu, 27 Aug 2009 15:01:01 -0500
Message-ID: <b500f92e0908271301q1c5ccc31taf1ef87735195aa1@mail.gmail.com>
Subject: HOD client-side hodring issue
From: Seb Seith <saseith@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

   I have been working on setting up a Hadoop on Demand cluster on
three machines and have run into a bit of a snag.  I went through the
admin and user guides and have successfully installed torque and HOD.
When I run "hod allocate" it successfully starts hodring on 2 of the
machines but not the third.  The result is that I have a working
Namenode and Jobtracker (though its UI does not seem to work
presently) but no slave nodes.

   Even at level 4 debug in all sections there is nothing to indicate
a failure as the ringmaster has no problem communicating with the
running hodring jobs and pbsdsh returns without error.  I can find no
logs on any of the machines indicating a torque issue (though I admit
I am not terribly familiar with torque) and no logs at all for HOD on
the machine that is not running hodring.

   It would appear that the pbsdsh job simply isn't starting hodring
on the one node given the lack of any HOD log on that machine.  Either
it is not recognizing the node (seems somewhat unlikely as it comes up
in pbsnodes as free) or there is a relatively silent failure
somewhere.  If you have any suggestions I would much appreciate them.

   One quick side note is I have successfully run a standard
hadoop-0.20.0 cluster on these three machines with no difficulty,
which should rule out connection, ssh or firewall issues.

Thanks,

Seb

From common-user-return-17126-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 20:04:02 2009
Return-Path: <common-user-return-17126-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 26313 invoked from network); 27 Aug 2009 20:04:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 20:04:02 -0000
Received: (qmail 21735 invoked by uid 500); 27 Aug 2009 20:03:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 21660 invoked by uid 500); 27 Aug 2009 20:03:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 39699 invoked by uid 99); 27 Aug 2009 19:11:14 -0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saseith@gmail.com designates 209.85.212.185 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=AJDUi22rJmIMVpcwP9oSsCUJTPa/q/psmJkz1q2e8qA=;
        b=pTpyP9psCagdckVJ/T2sG2b6RlAQRxZniySSdvjg8lEiz39Egzxx9PyOSs6u9E0bgN
         yQU/s4ktQ7hTe0k53Ar47QjLgrFpPQpjqHtmnT0lzYsqqo65Of/nUP+EQLQg55d2RXvB
         DPI4z04uay58kwTEFkKu4c8uiKmirsOdl1jdw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=jsTHKu6BZdKY6rGTEpGUlnZfWYkzbDId+3ou80QCyDePQzKHwmmSrApzrMeH2QeK18
         /piMSVzrjNSzfjY+jiNCBH+ZAWTn/Ioo7jb/n0etgPOVJLNJnZ4FKptojqtlefg1AH5W
         Er+CGZA/ElIKtJPdwBsWyVUtrYtqwGNZwqz2E=
MIME-Version: 1.0
Date: Thu, 27 Aug 2009 14:10:45 -0500
Message-ID: <b500f92e0908271210i1e370658jeb5a02796c39e350@mail.gmail.com>
Subject: HOD client-side hodring issue
From: Seb Seith <saseith@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,


    I have been working on setting up a Hadoop on Demand cluster on
three machines and have run into a bit of a snag.  I went through the
admin and user guides and have successfully installed torque and HOD.
When I run "hod allocate" it successfully starts hodring on 2 of the
machines but not the third.  The result is that I have a working
Namenode and Jobtracker (though its UI does not seem to work
presently) but no slave nodes.

    Even at level 4 debug in all sections there is nothing to indicate
a failure as the ringmaster has no problem communicating with the
running hodring jobs and pbsdsh returns without error.  I can find no
logs on any of the machines indicating a torque issue (though I admit
I am not terribly familiar with torque) and no logs at all for HOD on
the machine that is not running hodring.

    It would appear that the pbsdsh job simply isn't starting hodring
on the one node given the lack of any HOD log on that machine.  Either
it is not recognizing the node (seems somewhat unlikely as it comes up
in pbsnodes as free) or there is a relatively silent failure
somewhere.  If you have any suggestions I would much appreciate them.

    One quick side note is I have successfully run a standard
hadoop-0.20.0 cluster on these three machines with no difficulty,
which should rule out connection, ssh or firewall issues.

Thanks,

Seb

From common-user-return-17127-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 20:12:26 2009
Return-Path: <common-user-return-17127-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 29017 invoked from network); 27 Aug 2009 20:12:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 20:12:26 -0000
Received: (qmail 32490 invoked by uid 500); 27 Aug 2009 20:12:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 32420 invoked by uid 500); 27 Aug 2009 20:12:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 32410 invoked by uid 99); 27 Aug 2009 20:12:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 20:12:23 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saseith@gmail.com designates 209.85.212.185 as permitted sender)
Received: from [209.85.212.185] (HELO mail-vw0-f185.google.com) (209.85.212.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 20:12:15 +0000
Received: by vws15 with SMTP id 15so1140236vws.5
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 13:11:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=6sYI8TD/tYR8C1kfzXF7i4HxhAb4bUWxKfrSPKkM/d4=;
        b=npjdadIUeGhmHqlhNhIaIp6MDwxggOAs1Igsw+vH8vgtSsdFwFM0vHqA77EzfZlJyF
         0fMEgbw6yvlsTCvLVPiLZy3ID36MqJY23GOdRDRyzkobPFS5ChddwzqkT9EsUVxB9LGJ
         1/4sraJxEE8SypjLvLGg9LSW6EpcostnaxEyE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=YQsFpiXQrJRDmELiKvAvuP9GTz4Hz5p/o3wP/xplh9E8sua8hOd40HsFlSe1NhFQI5
         DhkXMIrhlbQKD5weM/VdYmzbTsn8LguNc/mjp+V7xoy5R1uxYxvax5BTLnpKqzlCzxAs
         m+timGaddUFq+q8XsdgmY12/HdeauYsouuO/c=
MIME-Version: 1.0
Received: by 10.220.89.205 with SMTP id f13mr364837vcm.23.1251403914654; Thu, 
	27 Aug 2009 13:11:54 -0700 (PDT)
In-Reply-To: <b500f92e0908271301q1c5ccc31taf1ef87735195aa1@mail.gmail.com>
References: <b500f92e0908271301q1c5ccc31taf1ef87735195aa1@mail.gmail.com>
Date: Thu, 27 Aug 2009 15:11:54 -0500
Message-ID: <b500f92e0908271311l7f248f28vea090898983021c1@mail.gmail.com>
Subject: Re: HOD client-side hodring issue
From: Seb Seith <saseith@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

I just realized that it finally posted my original message moments
after I resent it.  I had assumed after that period of time that it
had not been successfully received by the system since I had not seen
it come up on the archive or on the list itself.  Sorry for the double
posting there.

On Thu, Aug 27, 2009 at 3:01 PM, Seb Seith<saseith@gmail.com> wrote:
> Hello,
>
> =A0 I have been working on setting up a Hadoop on Demand cluster on
> three machines and have run into a bit of a snag. =A0I went through the
> admin and user guides and have successfully installed torque and HOD.
> When I run "hod allocate" it successfully starts hodring on 2 of the
> machines but not the third. =A0The result is that I have a working
> Namenode and Jobtracker (though its UI does not seem to work
> presently) but no slave nodes.
>
> =A0 Even at level 4 debug in all sections there is nothing to indicate
> a failure as the ringmaster has no problem communicating with the
> running hodring jobs and pbsdsh returns without error. =A0I can find no
> logs on any of the machines indicating a torque issue (though I admit
> I am not terribly familiar with torque) and no logs at all for HOD on
> the machine that is not running hodring.
>
> =A0 It would appear that the pbsdsh job simply isn't starting hodring
> on the one node given the lack of any HOD log on that machine. =A0Either
> it is not recognizing the node (seems somewhat unlikely as it comes up
> in pbsnodes as free) or there is a relatively silent failure
> somewhere. =A0If you have any suggestions I would much appreciate them.
>
> =A0 One quick side note is I have successfully run a standard
> hadoop-0.20.0 cluster on these three machines with no difficulty,
> which should rule out connection, ssh or firewall issues.
>
> Thanks,
>
> Seb
>

From common-user-return-17128-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Thu Aug 27 21:13:07 2009
Return-Path: <common-user-return-17128-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 47401 invoked from network); 27 Aug 2009 21:13:07 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 27 Aug 2009 21:13:07 -0000
Received: (qmail 11108 invoked by uid 500); 27 Aug 2009 21:13:04 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 11029 invoked by uid 500); 27 Aug 2009 21:13:04 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 11019 invoked by uid 99); 27 Aug 2009 21:13:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 21:13:04 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rvernica@gmail.com designates 209.85.216.191 as permitted sender)
Received: from [209.85.216.191] (HELO mail-px0-f191.google.com) (209.85.216.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 27 Aug 2009 21:12:56 +0000
Received: by pxi29 with SMTP id 29so1425263pxi.30
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 14:12:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=8B4BG8MMJY+H7uH4BhBM6L2U6m6WthnY4167KECcedQ=;
        b=lNGJpMpUpWsvrv/qKlPTF6POY3uipDD6wG5cdm5hoY22Pog2Cw5rxpW0DMHkKrOIdp
         4V2cxsBYBSmMa/x9abbzjepX0u6NIo4VxN449+WFFTsx/vtnMQo7CX3HXMZm4TWqEVuK
         v4NWtl66ciFeW0rNNw14IOCLtomQduiNV/2Pw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=jZzURQjTy0OZxvhSBYZEyvgjOIWW+mzYmETsLFUq9SndJz/KU+/4NVPoD1hGcTVCqz
         kRo5NGgzy9H0mE2wAeksduIIy+9HlBZQAzEXVFlD2UUB3s9dDbzMY/whPNkovloGxoPx
         /kjj5hXz09tkYDzHU/JRTshRkmyjvqR5dNpKY=
MIME-Version: 1.0
Received: by 10.140.204.4 with SMTP id b4mr203235rvg.80.1251407556175; Thu, 27 
	Aug 2009 14:12:36 -0700 (PDT)
In-Reply-To: <b8208a3b0908271251o5cd89920m683b326755be7e0f@mail.gmail.com>
References: <b8208a3b0908271251o5cd89920m683b326755be7e0f@mail.gmail.com>
Date: Thu, 27 Aug 2009 14:12:36 -0700
Message-ID: <b8208a3b0908271412o77de58b8yc01051b0522e837@mail.gmail.com>
Subject: Re: understand merge phase performance
From: Rares Vernica <rvernica@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

On Thu, Aug 27, 2009 at 12:51 PM, Rares Vernica<rvernica@gmail.com> wrote:
>
> Another difference is the fact that the keys for Job 1 are Text, while the
> keys for Job 2 are IntWritable (words are converted to integers).

I changed the key type of Job 2 from IntWritable to Text and the merge
phase performance is the same. The Map output bytes increased
slightly.

It seems that merging data from disk only is faster than merging data
from memory and disk...

Cheers,
Rares Vernica

From common-user-return-17129-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 00:12:43 2009
Return-Path: <common-user-return-17129-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 10696 invoked from network); 28 Aug 2009 00:12:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 00:12:43 -0000
Received: (qmail 59077 invoked by uid 500); 28 Aug 2009 00:12:41 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 59003 invoked by uid 500); 28 Aug 2009 00:12:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 58993 invoked by uid 99); 28 Aug 2009 00:12:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 00:12:40 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of gmporter@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 00:12:31 +0000
Received: by iwn6 with SMTP id 6so781786iwn.5
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 17:12:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=mQwMw0sqS4Vmxh1pf88KYt/YLNcyC3cH7SNIhtY4aek=;
        b=ao09Z7WxgcTWNZagrk1jflFyfaQ7VgUDabQ9CtBKVS+sFYm9X9RivSycwwQ36PMPNz
         mYSjsvO3OAbQZCugrSsRhWck+7sXWWZDWJkngEVHpQMFoN0vud4ZAdzC8LUkfSmg/flf
         3D3ymPsE1y7Pq+QezX8Tug8ebNYGtT4t7pLBg=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=PtL9EnFW1mqX2Uzcv/s4OcsNa8bYwLQqeIGfAckv/GFUbWvs9ovZs9wLXfd8LNhGwp
         lLnKFofJwc1IBw37CAknI1VF2uktc5mCIHYwA1mGXn3409ju8D9p3L5a9e8vAfnZ0hhF
         5BclclSAp3MrXH5WKoPxfBLRqZ134g93pIRx8=
MIME-Version: 1.0
Received: by 10.231.121.93 with SMTP id g29mr180599ibr.13.1251418330286; Thu, 
	27 Aug 2009 17:12:10 -0700 (PDT)
In-Reply-To: <714D34EE-8ECA-48F4-94FC-98C853EF93DF@yahoo-inc.com>
References: <3b1311780908232349s56df94b9k321a48255adcdd85@mail.gmail.com>
	 <616DA47B2EF5B944B91846785B512FF4CFADEA70F9@EGL-EX07VS01.ds.corp.yahoo.com>
	 <d6d7c4410908241749j6fa32ec1pb46e66eae1d14f28@mail.gmail.com>
	 <714D34EE-8ECA-48F4-94FC-98C853EF93DF@yahoo-inc.com>
Date: Thu, 27 Aug 2009 17:12:10 -0700
Message-ID: <cd40e6450908271712q3043f679k7889c9f3e56b537b@mail.gmail.com>
Subject: Re: How to speed up the copy phrase?
From: George Porter <gmporter@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Interesting.  In this case, how does Jetty dole out the proper
partitions of the intermediate data to the appropriate reducers if
they are located in the same files?

Thanks,
George

On Thu, Aug 27, 2009 at 11:31 AM, Arun C Murthy<acm@yahoo-inc.com> wrote:
>
> On Aug 24, 2009, at 5:49 PM, Aaron Kimball wrote:
>
>> If you've got 20 nodes, then you want to have 20-ish reduce tasks. Maybe
>> 40
>> if you want it to run in two waves. (Assuming 1 core/node. Multiply by N
>> for
>> N cores...) As it is, each node has 500-ish map tasks that it has to rea=
d
>> from and for each of these, it needs to generate 500 separate reduce tas=
k
>> output files. =A0That's going to take Hadoop a long time to do.
>
> Maps do not produce one output file per reduce, the entire map-output is =
in
> a single file.
>
> Arun
>

From common-user-return-17130-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 01:03:29 2009
Return-Path: <common-user-return-17130-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 29208 invoked from network); 28 Aug 2009 01:03:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 01:03:29 -0000
Received: (qmail 97492 invoked by uid 500); 28 Aug 2009 01:03:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 97438 invoked by uid 500); 28 Aug 2009 01:03:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 97428 invoked by uid 99); 28 Aug 2009 01:03:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 01:03:26 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of owen.omalley@gmail.com designates 209.85.216.191 as permitted sender)
Received: from [209.85.216.191] (HELO mail-px0-f191.google.com) (209.85.216.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 01:03:15 +0000
Received: by pxi29 with SMTP id 29so1541282pxi.30
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 18:02:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:message-id:from:to
         :in-reply-to:content-type:content-transfer-encoding:x-mailer
         :mime-version:subject:date:references;
        bh=uV0ufKibUU/+dg3TlitI+F0LSfgp+WJrNHYigBSU0q0=;
        b=ooibWFn/Ik+muEXJl6mRIVtXlPp36qoN/1jLQyYPRS0ZuXa9nW5ER6wDmSIH5xVGke
         KIzyvTBTJ0/xFDySheV0FF9htgbRJjjyb3/gqiI3oPEW2cfJCatC7ceQOimR724mXvbH
         +wqwLpLlFptSoZ2Aut5jfRyXNFtKdZH2SlWww=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=message-id:from:to:in-reply-to:content-type
         :content-transfer-encoding:x-mailer:mime-version:subject:date
         :references;
        b=IWMSQscA/B2eUySuvsebxYtvtS06BMOujcauNLXNdYqNTvWR7l0yOFoFombiwfTI1o
         K0UEaZ9fjolsiF6X9OD81qbad2GT+bTwB6Gyj1VjuY6bsK1vaEDqu0HYTh0ItwFM4r8s
         s9U+D7nfDsWL/Ks/luaRsciLVvFXMmFYDUFg8=
Received: by 10.115.85.6 with SMTP id n6mr642231wal.74.1251421374497;
        Thu, 27 Aug 2009 18:02:54 -0700 (PDT)
Received: from ?10.169.236.183? ([166.205.130.234])
        by mx.google.com with ESMTPS id v39sm1701649wah.62.2009.08.27.18.02.52
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Thu, 27 Aug 2009 18:02:53 -0700 (PDT)
Message-Id: <0DB5AF64-97E0-4640-B830-BB06FBA9BDBF@gmail.com>
From: Owen O'Malley <owen.omalley@gmail.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
In-Reply-To: <cd40e6450908271712q3043f679k7889c9f3e56b537b@mail.gmail.com>
Content-Type: text/plain;
	charset=us-ascii;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit
X-Mailer: iPhone Mail (7A400)
Mime-Version: 1.0 (iPhone Mail 7A400)
Subject: Re: How to speed up the copy phrase?
Date: Thu, 27 Aug 2009 18:02:44 -0700
References: <3b1311780908232349s56df94b9k321a48255adcdd85@mail.gmail.com> <616DA47B2EF5B944B91846785B512FF4CFADEA70F9@EGL-EX07VS01.ds.corp.yahoo.com> <d6d7c4410908241749j6fa32ec1pb46e66eae1d14f28@mail.gmail.com> <714D34EE-8ECA-48F4-94FC-98C853EF93DF@yahoo-inc.com> <cd40e6450908271712q3043f679k7889c9f3e56b537b@mail.gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org

There is an index with the offset of each reduce's first byte. The  
index is written to disk, but is also cached by the task tracker.

-- Owen

On Aug 27, 2009, at 17:12, George Porter <gmporter@gmail.com> wrote:

> Interesting.  In this case, how does Jetty dole out the proper
> partitions of the intermediate data to the appropriate reducers if
> they are located in the same files?
>
> Thanks,
> George
>
> On Thu, Aug 27, 2009 at 11:31 AM, Arun C Murthy<acm@yahoo-inc.com>  
> wrote:
>>
>> On Aug 24, 2009, at 5:49 PM, Aaron Kimball wrote:
>>
>>> If you've got 20 nodes, then you want to have 20-ish reduce tasks.  
>>> Maybe
>>> 40
>>> if you want it to run in two waves. (Assuming 1 core/node.  
>>> Multiply by N
>>> for
>>> N cores...) As it is, each node has 500-ish map tasks that it has  
>>> to read
>>> from and for each of these, it needs to generate 500 separate  
>>> reduce task
>>> output files.  That's going to take Hadoop a long time to do.
>>
>> Maps do not produce one output file per reduce, the entire map- 
>> output is in
>> a single file.
>>
>> Arun
>>

From common-user-return-17131-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 03:36:45 2009
Return-Path: <common-user-return-17131-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 89578 invoked from network); 28 Aug 2009 03:36:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 03:36:45 -0000
Received: (qmail 9719 invoked by uid 500); 28 Aug 2009 03:36:43 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 9545 invoked by uid 500); 28 Aug 2009 03:36:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 9534 invoked by uid 99); 28 Aug 2009 03:36:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 03:36:42 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.132.240 as permitted sender)
Received: from [209.85.132.240] (HELO an-out-0708.google.com) (209.85.132.240)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 03:36:34 +0000
Received: by an-out-0708.google.com with SMTP id c38so604009ana.29
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 20:36:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=KD3SYHpAlIVgtkyPphPT4e9FoJkpK3acqJyBWjCfrXU=;
        b=fI1JhHTiyDVyYDBgIEPgAKC5QQH6rehpiF4gjDnbXgL1cBo44EIH9noiE6AljAmelg
         pKdEpbZg0lMwGkth18JMaD3wCnPM7pwp4X3YiyINaWIeugJRKQ4yYsf26hk49JuMAFEI
         3ds/BbbbiJQ2aeCMtdbZu2TPZUV0piZmrETFQ=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=w1JTv3fW4gTlYtVZWdZtZmzqtG9rvQ3fYroC6JuHNVmMrHDDoEAfiCxeZZIkJCyoLL
         p1CVKQFLmxaoZI4NWiOBUcN2a2zjLPX9D2BML3aowAdckvlzyMxwzC8weB6Co+IWd2bq
         Mc6PxQWGK93S2LzjaEPpKMvYNrQVV7rSmfQDI=
MIME-Version: 1.0
Received: by 10.101.80.14 with SMTP id h14mr480798anl.129.1251430573520; Thu, 
	27 Aug 2009 20:36:13 -0700 (PDT)
Date: Fri, 28 Aug 2009 11:36:13 +0800
Message-ID: <3b1311780908272036s143c63fh1b207b8ed6aca4a4@mail.gmail.com>
Subject: Difference between copyOutput() and fetchOutputs()
From: Inifok Song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636ed670fcbb90104722b6256
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed670fcbb90104722b6256
Content-Type: text/plain; charset=ISO-8859-1

Hello all,

In class ReduceTask, there are a lot of methods to deal with fetching
intermediate output. And I think copyOutput() and fetchOutputs() are the
most important. However, they are invoked by different methods. I wonder
know whether they deal with the same thing? What's the difference between
them?

Thank you.

Inifok

--001636ed670fcbb90104722b6256--

From common-user-return-17132-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 03:44:39 2009
Return-Path: <common-user-return-17132-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 90365 invoked from network); 28 Aug 2009 03:44:39 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 03:44:39 -0000
Received: (qmail 18115 invoked by uid 500); 28 Aug 2009 03:44:37 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 17958 invoked by uid 500); 28 Aug 2009 03:44:36 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 17948 invoked by uid 99); 28 Aug 2009 03:44:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 03:44:36 +0000
X-ASF-Spam-Status: No, hits=4.5 required=10.0
	tests=DATE_IN_FUTURE_12_24,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.20] (HELO mrout1-b.corp.re1.yahoo.com) (69.147.107.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 03:44:25 +0000
Received: from naturehistory-dr.eglbp.corp.yahoo.com (naturehistory-dr.eglbp.corp.yahoo.com [10.66.97.214])
	by mrout1-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7S3hnCo054658
	for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 20:43:50 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:date:from:user-agent:mime-version:to:subject:
	references:in-reply-to:content-type:content-transfer-encoding;
	b=miitsNPruxQWVdZ7JN2iPDRdjY1gC3Y7qKIgXfzcfzJ43Lh32GogiPtI5GVPR1pA
Message-ID: <4A9802A3.2010603@yahoo-inc.com>
Date: Fri, 28 Aug 2009 09:15:31 -0700
From: Nikhil Sawant <nsawant@yahoo-inc.com>
User-Agent: Thunderbird 2.0.0.4 (X11/20070604)
MIME-Version: 1.0
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Subject: Re: Testing Hadoop job
References: <4A95CA58.3030608@yahoo-inc.com> <314098690908260729kbb8b5bch4ac0b3b51b559c04@mail.gmail.com>
In-Reply-To: <314098690908260729kbb8b5bch4ac0b3b51b559c04@mail.gmail.com>
Content-Type: text/plain; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

hi
thanks Jason, for prompt reply i will go through "pro hadoop". already 
on my to-do list

any idea abt the MRUnit??? has anyone used it?
i think it is useful as it allows dummy map and reduce drivers which 
accepts (K,V) pair/s and checks the o/p (K,V) pair/s with the expected 
(K,V)......it gives gr8 debugging capabilities while implementing 
complex logics. (all "System.outs" can be seen on console itself!!)
i have used the basic functionalities of MRUnit testing framework
i would like to know the limitations (e.g. i found out that MRUnit does 
not check the partioner logic) and its feasibility with hadoop 0.20...
No proper documentation i found ! :(

cheers
nikhil

Jason Venner wrote:
> I put together a framework for the Pro Hadoop book that I use quite a bit,
> and has some documentation in the book examples ;)
> I haven't tried it with 0.20.0 however.
>
> The nicest thing that I did with the framework was provide a way to run a
> persistent mini virtual cluster for running multiple tests on.
>
> On Wed, Aug 26, 2009 at 4:50 PM, Nikhil Sawant <nsawant@yahoo-inc.com>wrote:
>
>   
>> hi
>>
>> can u guys suggest some hadoop unit testing framework apart from MRUnit???
>> i have used MRUnit but i m not sure abt its feasibilty and support to
>> hadoop 0.20.....
>> i could not find a proper documentation for MRUnit, is it available
>> anywhere?
>>
>> --
>> cheers
>> nikhil
>>
>>
>>     
>
>
>   

From common-user-return-17133-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 03:48:03 2009
Return-Path: <common-user-return-17133-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 90612 invoked from network); 28 Aug 2009 03:48:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 03:48:03 -0000
Received: (qmail 20565 invoked by uid 500); 28 Aug 2009 03:48:00 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 20473 invoked by uid 500); 28 Aug 2009 03:48:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 20459 invoked by uid 99); 28 Aug 2009 03:48:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 03:48:00 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 03:47:47 +0000
Received: from SNV-EXPF01.ds.corp.yahoo.com (snv-expf01.ds.corp.yahoo.com [207.126.227.250])
	by mrout3.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7S3kN1h024126
	for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 20:46:23 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:user-agent:date:subject:from:to:message-id:
	thread-topic:thread-index:in-reply-to:mime-version:content-type:
	content-transfer-encoding:x-originalarrivaltime;
	b=OHs2wonvZE5N7AjC+CiCMimF6qFpquKWayFm5SGvcDC10+sDteG1gCNINGiDwWO+
Received: from SNV-EXVS08.ds.corp.yahoo.com ([207.126.227.8]) by SNV-EXPF01.ds.corp.yahoo.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Thu, 27 Aug 2009 20:46:22 -0700
Received: from 10.66.92.213 ([10.66.92.213]) by SNV-EXVS08.ds.corp.yahoo.com ([207.126.227.58]) with Microsoft Exchange Server HTTP-DAV ;
 Fri, 28 Aug 2009 03:46:21 +0000
User-Agent: Microsoft-Entourage/12.20.0.090605
Date: Fri, 28 Aug 2009 09:16:19 +0530
Subject: Re: Difference between copyOutput() and fetchOutputs()
From: Jothi Padmanabhan <jothipn@yahoo-inc.com>
To: <common-user@hadoop.apache.org>
Message-ID: <C6BD50E3.1D4FD%jothipn@yahoo-inc.com>
Thread-Topic: Difference between copyOutput() and fetchOutputs()
Thread-Index: AconkhoYb4fh20hQtEGjRam5tKB0vA==
In-Reply-To: <3b1311780908272036s143c63fh1b207b8ed6aca4a4@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-OriginalArrivalTime: 28 Aug 2009 03:46:22.0832 (UTC) FILETIME=[1C612F00:01CA2792]
X-Virus-Checked: Checked by ClamAV on apache.org

Reduce Task creates a ReduceCopier object and invokes fetchOutput method on
this object to start the fetch process.

fetchOutputs internally launches several MapOutputCopier threads to do the
fetching and each of these thread do the copyOutput.

Jothi 


On 8/28/09 9:06 AM, "Inifok Song" <hadoop.inifok@gmail.com> wrote:

> Hello all,
> 
> In class ReduceTask, there are a lot of methods to deal with fetching
> intermediate output. And I think copyOutput() and fetchOutputs() are the
> most important. However, they are invoked by different methods. I wonder
> know whether they deal with the same thing? What's the difference between
> them?
> 
> Thank you.
> 
> Inifok


From common-user-return-17134-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 05:30:54 2009
Return-Path: <common-user-return-17134-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 11037 invoked from network); 28 Aug 2009 05:30:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 05:30:54 -0000
Received: (qmail 77982 invoked by uid 500); 28 Aug 2009 05:30:52 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 77890 invoked by uid 500); 28 Aug 2009 05:30:52 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 77872 invoked by uid 99); 28 Aug 2009 05:30:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 05:30:51 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.211.191 as permitted sender)
Received: from [209.85.211.191] (HELO mail-yw0-f191.google.com) (209.85.211.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 05:30:43 +0000
Received: by ywh29 with SMTP id 29so2334017ywh.33
        for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 22:30:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=VSd4Ge31LNmViYiSMuIJ25tLJB2V6tiKHiCK95YrFps=;
        b=iY2g7B3pZ1Ak4I6VpIn+EBIBD30fHcEYwvYKEUgPUnSNryD/fOx7reD7Ffk2Hk9wUe
         OTjzS9hxdOYwn2paHWNRBjcbEIIxKPLYBGBEUVPyIaGaC2xLb2WOvZmJtEj4yz87c/Tb
         eXyggKzuVvrG7XwXa1CBnjQMWmvaKJ+sUIDb0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        b=oQOKc1LMEh+KWysO5WBZun86tTfSO/4MzONZ7RYmkFRXgQb/4Dk9O/T6SEMNRqE3uc
         cUwwAhDGD4/Mx4hQiuqObWxm+p779soO8EJSxw9BmOV7OY/5U2qZG8+/Hle1MVYNmysF
         X6n7gaIQKYD2EspgFIzWwKe79I6pmWQ6mTGQY=
MIME-Version: 1.0
Received: by 10.101.81.19 with SMTP id i19mr569584anl.94.1251437423103; Thu, 
	27 Aug 2009 22:30:23 -0700 (PDT)
In-Reply-To: <C6BD50E3.1D4FD%jothipn@yahoo-inc.com>
References: <3b1311780908272036s143c63fh1b207b8ed6aca4a4@mail.gmail.com>
	 <C6BD50E3.1D4FD%jothipn@yahoo-inc.com>
Date: Fri, 28 Aug 2009 13:30:23 +0800
Message-ID: <3b1311780908272230p4ec7558eo71ddee6735df1dc2@mail.gmail.com>
Subject: Re: Difference between copyOutput() and fetchOutputs()
From: Inifok Song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Cc: jothipn@yahoo-inc.com
Content-Type: multipart/alternative; boundary=001636ed6a8210108504722cfb8d
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed6a8210108504722cfb8d
Content-Type: text/plain; charset=ISO-8859-1

Oops! I'm so careless that haven't noticed it. This is really a rookie
question. Thanks for your answer.

2009/8/28 Jothi Padmanabhan <jothipn@yahoo-inc.com>

> Reduce Task creates a ReduceCopier object and invokes fetchOutput method on
> this object to start the fetch process.
>
> fetchOutputs internally launches several MapOutputCopier threads to do the
> fetching and each of these thread do the copyOutput.
>
> Jothi
>
>
> On 8/28/09 9:06 AM, "Inifok Song" <hadoop.inifok@gmail.com> wrote:
>
> > Hello all,
> >
> > In class ReduceTask, there are a lot of methods to deal with fetching
> > intermediate output. And I think copyOutput() and fetchOutputs() are the
> > most important. However, they are invoked by different methods. I wonder
> > know whether they deal with the same thing? What's the difference between
> > them?
> >
> > Thank you.
> >
> > Inifok
>
>

--001636ed6a8210108504722cfb8d--

From common-user-return-17135-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 06:04:02 2009
Return-Path: <common-user-return-17135-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 26495 invoked from network); 28 Aug 2009 06:04:01 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 06:04:01 -0000
Received: (qmail 7979 invoked by uid 500); 28 Aug 2009 06:03:59 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 7905 invoked by uid 500); 28 Aug 2009 06:03:59 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 7895 invoked by uid 99); 28 Aug 2009 06:03:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 06:03:59 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=NO_RDNS_DOTCOM_HELO,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 06:03:48 +0000
Received: from EGL-EX07CAS01.ds.corp.yahoo.com (egl-ex07cas01.eglbp.corp.yahoo.com [203.83.248.208])
	by mrout2.yahoo.com (8.13.6/8.13.6/y.out) with ESMTP id n7S62A1b042151
	for <common-user@hadoop.apache.org>; Thu, 27 Aug 2009 23:02:10 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=received:from:to:date:subject:thread-topic:thread-index:
	message-id:references:in-reply-to:accept-language:
	content-language:x-ms-has-attach:x-ms-tnef-correlator:acceptlanguage:
	content-type:content-transfer-encoding:mime-version;
	b=ZBb8P2eLaobyDUjVkiFjMADpnMXDhyqBkUJAmqtOyOJYAknNCJrmH8VqTpVCs1nD
Received: from EGL-EX07VS01.ds.corp.yahoo.com ([203.83.248.206]) by
 EGL-EX07CAS01.ds.corp.yahoo.com ([203.83.248.215]) with mapi; Fri, 28 Aug
 2009 11:32:10 +0530
From: Amogh Vasekar <amogh@yahoo-inc.com>
To: "common-user@hadoop.apache.org" <common-user@hadoop.apache.org>
Date: Fri, 28 Aug 2009 11:30:54 +0530
Subject: RE: difference between mapper and map runnable
Thread-Topic: difference between mapper and map runnable
Thread-Index: AconILAQmU6L6ZckTf2w3CmpNB0dbwAg7PPQ
Message-ID: <616DA47B2EF5B944B91846785B512FF4CFADEA72A9@EGL-EX07VS01.ds.corp.yahoo.com>
References: <2aa3aff80908270525uafe39e8q83c9796528da15f7@mail.gmail.com>
In-Reply-To: <2aa3aff80908270525uafe39e8q83c9796528da15f7@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
acceptlanguage: en-US
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,
Mapper is used to process the <K,V> pair passed to it, MapRunnable is an in=
terface, when implemented is responsible for generating a conforming <K,V> =
pair and pass it to Mapper.

Cheers!
Amogh

-----Original Message-----
From: Rakhi Khatwani [mailto:rkhatwani@gmail.com]=20
Sent: Thursday, August 27, 2009 5:56 PM
To: common-user@hadoop.apache.org
Subject: difference between mapper and map runnable

Hi,
        Whats the difference between a mapper and map runnable and its
usage?
Regards
Raakhi

From common-user-return-17144-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 17:04:44 2009
Return-Path: <common-user-return-17144-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 10358 invoked from network); 28 Aug 2009 17:04:44 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 17:04:44 -0000
Received: (qmail 3750 invoked by uid 500); 28 Aug 2009 15:15:23 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 3673 invoked by uid 500); 28 Aug 2009 15:15:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 3653 invoked by uid 99); 28 Aug 2009 15:15:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 15:15:21 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bharathvissapragada1990@gmail.com designates 209.85.221.175 as permitted sender)
Received: from [209.85.221.175] (HELO mail-qy0-f175.google.com) (209.85.221.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 15:15:12 +0000
Received: by qyk5 with SMTP id 5so1313816qyk.30
        for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 08:14:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=iyn2PpAwaL8sk2ZeX3t/SklvS+TCGAniFI5+X5M4AiY=;
        b=FeweyHLejoKrBTQMmzf28rxv1O9d1x+fUwy7L5IqyIVVmoxugGAa2KbVZGhczJ09Cy
         3Rc2to1TZuRpZIp5BatMyAl1av3PG/Pd6244nTcjLhQvtoDFx2f2p4ckKfpVPuE51euH
         BE6hHmXvyy4sTHpe+1qwDZZV5kVfD2RLEL5ik=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=jhEFb1bUPboj2nidUyH08G3G8ZMg+9r5FDPTx9PLn8AzkHiIi9FfVbXdhOTLnhe3gA
         iaxoBdmNXf7utheOfS3QCUqxLBWsuNOsW3Hv/qwrFC0UDCX0996aBbcg8Y2v5CWF9JpV
         UUy0PcQKngqWjYkX+MBMAgMDsjeL7p5hRfeqE=
MIME-Version: 1.0
Received: by 10.229.54.143 with SMTP id q15mr553117qcg.74.1251472491127; Fri, 
	28 Aug 2009 08:14:51 -0700 (PDT)
In-Reply-To: <45d9159d0908280641m262129bdq7c8d2dd81435fae1@mail.gmail.com>
References: <73d592f60908280416o22832698qa70e52ef1f751701@mail.gmail.com> 
	<45d9159d0908280641m262129bdq7c8d2dd81435fae1@mail.gmail.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Fri, 28 Aug 2009 20:44:31 +0530
Message-ID: <73d592f60908280814u1cb6c541te17972c11df84266@mail.gmail.com>
Subject: Re: Cloudera Video - Hadoop build on eclipse
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00151773e2d647a31a047235253d
X-Virus-Checked: Checked by ClamAV on apache.org

--00151773e2d647a31a047235253d
Content-Type: text/plain; charset=ISO-8859-1

I saw ur mail to this list , but no-one replied to it . Yes iam behind my
institute proxy ..
Thanks for your reply , I'll try using it frm my home-broadband connection .
:)

On Fri, Aug 28, 2009 at 7:11 PM, ashish pareek <pareekash@gmail.com> wrote:

> Hello Bharath,
>
>                   Earlier even I faced the same problem. I think your are
> accessing internet through proxy.So try using direct broadband connection.
> Hope this will solve your problem.
>
> Ashish Pareek
>
> On Fri, Aug 28, 2009 at 4:46 PM, bharath vissapragada <
> bharathvissapragada1990@gmail.com> wrote:
>
> > Hi all,
> >
> > Iam trying to build hadoop on eclipse with the help of Cloudera Video on
> > it's site . I have successfully checkedout from the hadoop svn .. Then
> the
> > problem is iam not able to build the file "build.xml" using ant build. I
> am
> > getting the error
> >
> > ivy-download:
> >      [get] Getting:
> >
> >
> http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.0.0-rc2/ivy-2.0.0-rc2.jar
> >      [get] To: /home/rip/workspace/hadoop-trunk/ivy/ivy-2.0.0-rc2.jar
> > [get] Error getting
> >
> >
> http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.0.0-rc2/ivy-2.0.0-rc2.jarto
> > /home/rip/workspace/hadoop-trunk/ivy/ivy-2.0.0-rc2.jar<
> http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.0.0-rc2/ivy-2.0.0-rc2.jarto%0A/home/rip/workspace/hadoop-trunk/ivy/ivy-2.0.0-rc2.jar
> >
> >
> > BUILD FAILED
> > /home/rip/workspace/hadoop-trunk/build.xml:1174:
> java.net.ConnectException:
> > Connection timed out
> >
> > Total time: 3 minutes 10 seconds
> >
>

--00151773e2d647a31a047235253d--

From common-user-return-17145-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 17:14:00 2009
Return-Path: <common-user-return-17145-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 23740 invoked from network); 28 Aug 2009 17:13:59 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 17:13:59 -0000
Received: (qmail 10301 invoked by uid 500); 28 Aug 2009 17:13:57 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 10253 invoked by uid 500); 28 Aug 2009 17:13:56 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 10243 invoked by uid 99); 28 Aug 2009 17:13:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 17:13:56 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rvernica@gmail.com designates 209.85.216.191 as permitted sender)
Received: from [209.85.216.191] (HELO mail-px0-f191.google.com) (209.85.216.191)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 17:13:48 +0000
Received: by pxi29 with SMTP id 29so2127306pxi.30
        for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 10:13:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=/TbMP/eUhtbYV/rtbTIlkR6XGDRnYsyPe/f4jrR/t4s=;
        b=sE0PfYtwyFGQiiat5s0KMxVmNqN93SXNNjVlkNgZutrHFXWShWkWqwegjwH0E2WmOJ
         YX523kgOvbTPFX2Xdz38XqcHU4OkcwCqsFTJrRJ61zMQYSMRwZUXQHL+YKKwOerT1AjB
         xIhi3vs7tgbKocRY7LGkFSylxXBecAPMcbbo0=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=lL9qwqBnQQVotuTjIhQQ5wvX5a1XLTmX1pwwEJ8nC2VJ61Pi40G47x/T4iI5J/9gxP
         1ua57Gnr1XegHWnhHJ2pxvsgg21rblBjVmfdeF/1JtUcDH8s99gHXHbF9Ksa2TRODcgO
         bjzU3pG6Q5+4cwNe9GbG6o7bJB5X8jpEyfmpo=
MIME-Version: 1.0
Received: by 10.140.204.4 with SMTP id b4mr590858rvg.80.1251479608341; Fri, 28 
	Aug 2009 10:13:28 -0700 (PDT)
In-Reply-To: <C6BDC184.1D606%jothipn@yahoo-inc.com>
References: <b8208a3b0908271251o5cd89920m683b326755be7e0f@mail.gmail.com>
	 <C6BDC184.1D606%jothipn@yahoo-inc.com>
Date: Fri, 28 Aug 2009 10:13:28 -0700
Message-ID: <b8208a3b0908281013m7014d896j5225e50e02f5762d@mail.gmail.com>
Subject: Re: understand merge phase performance
From: Rares Vernica <rvernica@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

On Fri, Aug 28, 2009 at 4:46 AM, Jothi Padmanabhan<jothipn@yahoo-inc.com> wrote:
>
> Could you attach the complete reducer logs for the two runs?

Attached.

> How many maps did the Jobs have?

Both jobs had 4 maps.

> And what were there map output sizes?

The sizes in bytes are in the first email. Here are the number of records.

Job 1: Map output records        181,755,130
          Combine output records   31,641,028

Job 2: Map output records          43,538,720
(does not have a combiner)

Thanks!
Rares Vernica

From common-user-return-17146-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 17:15:21 2009
Return-Path: <common-user-return-17146-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 24879 invoked from network); 28 Aug 2009 17:15:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 17:15:21 -0000
Received: (qmail 13251 invoked by uid 500); 28 Aug 2009 17:15:18 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 13160 invoked by uid 500); 28 Aug 2009 17:15:18 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 13150 invoked by uid 99); 28 Aug 2009 17:15:18 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 17:15:18 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rvernica@gmail.com designates 209.85.222.173 as permitted sender)
Received: from [209.85.222.173] (HELO mail-pz0-f173.google.com) (209.85.222.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 17:15:10 +0000
Received: by pzk3 with SMTP id 3so2122358pzk.31
        for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 10:14:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=MTziWQCPX2sskc00X2IxB2oY1iHohTtREciSObxfUgA=;
        b=MrvES2cnXvJpmep2TBqOzT45Dzqf2ntCgWQPsIkMnDMlTZvjBjwKpynARcLTftOsFl
         4kXeP3Tb8d23tkvDoP2NaUZtU1zsnlJssFh2UPTrq6ZFMR0Dx9/MeCgTlEYozaAw5oMp
         Vdhz5RVCpiW9i9Xd/HjHeMym8HQAG8ecV7+cE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=StH112QEgYv222FAe4qVvJKkSLHAkMrJI1Od8Un7iXJW6mEsJdNPSX7l0NcaG5I32k
         VIbQCGccbFz3FHFfnjl75Zm7iei2H9Q4uuEnqSyblM7RDMUb3KrTmalWcW1ZSByttUXj
         1r7VYww+giT27oNLNuFj8vcigcZr22QRaNJ10=
MIME-Version: 1.0
Received: by 10.141.29.11 with SMTP id g11mr603168rvj.99.1251479689905; Fri, 
	28 Aug 2009 10:14:49 -0700 (PDT)
In-Reply-To: <b8208a3b0908281013m7014d896j5225e50e02f5762d@mail.gmail.com>
References: <b8208a3b0908271251o5cd89920m683b326755be7e0f@mail.gmail.com>
	 <C6BDC184.1D606%jothipn@yahoo-inc.com>
	 <b8208a3b0908281013m7014d896j5225e50e02f5762d@mail.gmail.com>
Date: Fri, 28 Aug 2009 10:14:49 -0700
Message-ID: <b8208a3b0908281014k4ef3b71dqcc444b7b121839ff@mail.gmail.com>
Subject: Re: understand merge phase performance
From: Rares Vernica <rvernica@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/mixed; boundary=000e0cd1799c5c47e2047236d263
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd1799c5c47e2047236d263
Content-Type: text/plain; charset=ISO-8859-1

On Fri, Aug 28, 2009 at 10:13 AM, Rares Vernica<rvernica@gmail.com> wrote:
>
> On Fri, Aug 28, 2009 at 4:46 AM, Jothi Padmanabhan<jothipn@yahoo-inc.com> wrote:
>>
>> Could you attach the complete reducer logs for the two runs?
>
> Attached.

Forgot the attachments... Here they are.

Cheers!
Rares Vernica

--000e0cd1799c5c47e2047236d263
Content-Type: text/plain; charset=US-ASCII; name="syslog.Job1.reduce.txt"
Content-Disposition: attachment; filename="syslog.Job1.reduce.txt"
Content-Transfer-Encoding: base64
X-Attachment-Id: f_fyx6ohrl0
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--000e0cd1799c5c47e2047236d263
Content-Type: text/plain; charset=US-ASCII; name="syslog.Job2.reduce.txt"
Content-Disposition: attachment; filename="syslog.Job2.reduce.txt"
Content-Transfer-Encoding: base64
X-Attachment-Id: f_fyx6oq6p1
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--000e0cd1799c5c47e2047236d263--

From common-user-return-17147-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 17:34:48 2009
Return-Path: <common-user-return-17147-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 50768 invoked from network); 28 Aug 2009 17:34:47 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 17:34:47 -0000
Received: (qmail 45832 invoked by uid 500); 28 Aug 2009 17:34:45 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 45743 invoked by uid 500); 28 Aug 2009 17:34:45 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 45733 invoked by uid 500); 28 Aug 2009 17:34:45 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 45730 invoked by uid 99); 28 Aug 2009 17:34:45 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 17:34:45 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 17:34:35 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1Mh5L4-0001Pe-Bu
	for core-user@hadoop.apache.org; Fri, 28 Aug 2009 10:34:14 -0700
Message-ID: <25193896.post@talk.nabble.com>
Date: Fri, 28 Aug 2009 10:34:14 -0700 (PDT)
From: mpiller <mark@themidnightcoders.com>
To: core-user@hadoop.apache.org
Subject: DistCp - NoClassDefFoundError
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: mark@themidnightcoders.com
X-Virus-Checked: Checked by ClamAV on apache.org


Hi,

I am using the DistCp class inside of my application to copy final output
files out into S3 (this is per Amazon's recommendation). However, when I run
the program I get the following exception:

java.lang.NoClassDefFoundError: org/apache/hadoop/tools/DistCp
        at apppuncher.Aggregator.main(Aggregator.java:130)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:165)
        at org.apache.hadoop.mapred.JobShell.run(JobShell.java:54)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.mapred.JobShell.main(JobShell.java:68)

Is there something special I need to do so DistCp (and other Hadoop tools
classes) would be recognized in the JVM?

Thanks,
Mark
-- 
View this message in context: http://www.nabble.com/DistCp---NoClassDefFoundError-tp25193896p25193896.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-17142-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 17:46:26 2009
Return-Path: <common-user-return-17142-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 65088 invoked from network); 28 Aug 2009 17:46:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 17:46:26 -0000
Received: (qmail 63267 invoked by uid 500); 28 Aug 2009 13:42:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 63181 invoked by uid 500); 28 Aug 2009 13:42:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 63171 invoked by uid 99); 28 Aug 2009 13:42:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 13:42:25 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pareekash@gmail.com designates 209.85.222.173 as permitted sender)
Received: from [209.85.222.173] (HELO mail-pz0-f173.google.com) (209.85.222.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 13:42:15 +0000
Received: by pzk3 with SMTP id 3so1981674pzk.31
        for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 06:41:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=cDf51SZoLs/n/2L8tEgAGE5bCe6Nz3zEeGVqGxRCQdU=;
        b=xhG9IwEs97Av7eNLKhIhP4CctDOJVHDz7usiO6L/5VgBKZhQPS0cx9ghPLG5RicvqQ
         Fj6I9F/V0HoZ+lJXvaQEcQdxc7ucMw0fVMuosMkHHT71hcgwPF2PthWQ3/gKPp47TNQy
         KPpGCEqMlOwnfxjPuv1SLf78xEsqX4/rCIdjc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=d1uWk8d0IN2qYPe8nqhcg9sqnrgF0Zo6DMhTWfFyRGjUKBLK23qVb6u3CpKhDhyCOA
         pZ9Xd+jVJzFXpKNyYfcAclvTpx7v52kSDV7oTag2dNC5ZB1JQztkFrUWcccEfjbsHdGJ
         QhPbUXsMiY45DTHbPx7XMYCKiooTy9KYsVaaI=
MIME-Version: 1.0
Received: by 10.115.134.4 with SMTP id l4mr1629809wan.118.1251466914502; Fri, 
	28 Aug 2009 06:41:54 -0700 (PDT)
In-Reply-To: <73d592f60908280416o22832698qa70e52ef1f751701@mail.gmail.com>
References: <73d592f60908280416o22832698qa70e52ef1f751701@mail.gmail.com>
Date: Fri, 28 Aug 2009 19:11:54 +0530
Message-ID: <45d9159d0908280641m262129bdq7c8d2dd81435fae1@mail.gmail.com>
Subject: Re: Cloudera Video - Hadoop build on eclipse
From: ashish pareek <pareekash@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e64b16a2e319bf047233d8fe
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e64b16a2e319bf047233d8fe
Content-Type: text/plain; charset=ISO-8859-1

Hello Bharath,

                   Earlier even I faced the same problem. I think your are
accessing internet through proxy.So try using direct broadband connection.
Hope this will solve your problem.

Ashish Pareek

On Fri, Aug 28, 2009 at 4:46 PM, bharath vissapragada <
bharathvissapragada1990@gmail.com> wrote:

> Hi all,
>
> Iam trying to build hadoop on eclipse with the help of Cloudera Video on
> it's site . I have successfully checkedout from the hadoop svn .. Then the
> problem is iam not able to build the file "build.xml" using ant build. I am
> getting the error
>
> ivy-download:
>      [get] Getting:
>
> http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.0.0-rc2/ivy-2.0.0-rc2.jar
>      [get] To: /home/rip/workspace/hadoop-trunk/ivy/ivy-2.0.0-rc2.jar
> [get] Error getting
>
> http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.0.0-rc2/ivy-2.0.0-rc2.jarto
> /home/rip/workspace/hadoop-trunk/ivy/ivy-2.0.0-rc2.jar<http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.0.0-rc2/ivy-2.0.0-rc2.jarto%0A/home/rip/workspace/hadoop-trunk/ivy/ivy-2.0.0-rc2.jar>
>
> BUILD FAILED
> /home/rip/workspace/hadoop-trunk/build.xml:1174: java.net.ConnectException:
> Connection timed out
>
> Total time: 3 minutes 10 seconds
>

--0016e64b16a2e319bf047233d8fe--

From common-user-return-17143-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 18:13:48 2009
Return-Path: <common-user-return-17143-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 93685 invoked from network); 28 Aug 2009 18:13:48 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 18:13:48 -0000
Received: (qmail 91835 invoked by uid 500); 28 Aug 2009 14:09:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 91768 invoked by uid 500); 28 Aug 2009 14:09:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 91753 invoked by uid 99); 28 Aug 2009 14:09:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 14:09:45 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hadoop.inifok@gmail.com designates 209.85.210.197 as permitted sender)
Received: from [209.85.210.197] (HELO mail-yx0-f197.google.com) (209.85.210.197)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 14:09:37 +0000
Received: by yxe35 with SMTP id 35so211551yxe.2
        for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 07:09:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=LotCMkoeyZJo+IaZ7FvWLSEtJpMF8LO2BZ0cYmbDxJo=;
        b=wuraBu8w+TplLKdT/bMLLt/RT3Hd48duCwXeBs7rhiImnpRoN7JaQichD6zP730so9
         s77Z7YZYWjvy1M+tjFtQZDjAxO/nJhMqkEQIpqJ2l77AJzJK26eAKKa4cOeyO5jHPuxl
         K8l+h7K3N5G4aBe4bhRnISVj1tITM0OytJWdI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=mwAV+x2WUgiKXynTXM/mPlkbZg4VekO11S944evBWx2ZysFeb/sWL/ZCMysVhAdDb7
         J6rXEJlSioZPVCBbBLvt+jtXj5Fa2tT04O9Tb1gtSFfWZ1lhhWfgQkWDPmK1CCjWmnr6
         NS3bJTnbsq/21zn8KQc7Yei+Go2TkF6NvW8CY=
MIME-Version: 1.0
Received: by 10.101.161.6 with SMTP id n6mr1081046ano.173.1251468556949; Fri, 
	28 Aug 2009 07:09:16 -0700 (PDT)
Date: Fri, 28 Aug 2009 22:09:16 +0800
Message-ID: <3b1311780908280709s6fe8f935y96edc27fed9ced11@mail.gmail.com>
Subject: How to deal with SocketTimeoutException?
From: Inifok Song <hadoop.inifok@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636ed6b1cc8dacb0472343a9b
X-Virus-Checked: Checked by ClamAV on apache.org

--001636ed6b1cc8dacb0472343a9b
Content-Type: text/plain; charset=ISO-8859-1

Hi all,

In my cluster, reduce tasks often throw SocketTimeoutException when there
are a lot of tasks. The critical log is below

at
org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getInputStream(ReduceTask.java:1357)

at
org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(ReduceTask.java:1293)

at
org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:1196)

So I think it may be caused by jetty. How can I get jetty's settings and
modify it? Is it really caused by jetty or there are other reason? I need
your help, my friends.

Thank you.

Inifok

--001636ed6b1cc8dacb0472343a9b--

From common-user-return-17148-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 18:19:38 2009
Return-Path: <common-user-return-17148-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 95413 invoked from network); 28 Aug 2009 18:19:38 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 18:19:38 -0000
Received: (qmail 19947 invoked by uid 500); 28 Aug 2009 18:19:36 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 19885 invoked by uid 500); 28 Aug 2009 18:19:36 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 19875 invoked by uid 99); 28 Aug 2009 18:19:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:19:36 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [67.195.23.94] (HELO web112107.mail.gq1.yahoo.com) (67.195.23.94)
    by apache.org (qpsmtpd/0.29) with SMTP; Fri, 28 Aug 2009 18:19:26 +0000
Received: (qmail 34780 invoked by uid 60001); 28 Aug 2009 18:19:05 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1251483545; bh=3WyN+Sns58aXmSiVOZQLx85cjl1T7Bbl5KSKG2DepOU=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:Cc:In-Reply-To:MIME-Version:Content-Type; b=lS1QupSYnMjde6zmJnGwAqPYl11okHW0z02eWI/8k04duGTnfYtYqq8ZdhhxwNho81Ux9pZuCzyWJudRCU5m86BMKaRkLr90CeRvfkahpWQidCzqI+0RrO8pqjDEWrauH5Hodt1yA+T0QNpSZNVgXkN+R+YhOxTYTGKWEipBORg=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:Cc:In-Reply-To:MIME-Version:Content-Type;
  b=uGwtLC0eMZdWJ2reAJLH1uuoYOAPEJxuwjUllBf6yOv+cqCigfzJewMZVygw0cDaNScE49Jyy9tAaXkowLR5BxBMaUMOp58vg497AUao7+wImzcPv5ygm9HcSxlOHB+CGslA8hgd9xDP5p08ZZ5pAYzvIhUcHIPD64pdI0w63Cw=;
Message-ID: <764438.34770.qm@web112107.mail.gq1.yahoo.com>
X-YMail-OSG: 3AxM6BgVM1luwmvWWYz.1kva45WeR3Qj5BsLuFHuwiZje0EucftqJz_iIgypYbOLyuBj4bb8dISCVktlEdImbxDwj7RTCFJz.QXnOXLCoNGwHEIOISn8qOAw9k7ZmHhOjo4Wn0GUNefBY2KU0FYDHQ77JMhrBcdubkFIn_DNKs_BAOLlmOXx.GGwok9YxvbsW7vJMXZA4KM2BDaE0LIl5Jtkw0y77cS8kgobPq.GAid1oD0AXq.6wV7RPDOBBn5KQJS6LZx.PCQe19Fep0dcrwweJDZepi74oJ7QZq6eyQQ50M3GGUA4DBPNYetZ
Received: from [64.172.17.3] by web112107.mail.gq1.yahoo.com via HTTP; Fri, 28 Aug 2009 11:19:05 PDT
X-Mailer: YahooMailClassic/6.1.2 YahooMailWebService/0.7.338.2
Date: Fri, 28 Aug 2009 11:19:05 -0700 (PDT)
From: Steve Gao <steve.gao@yahoo.com>
Subject: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
To: common-user@hadoop.apache.org
Cc: common-dev@hadoop.apache.org
In-Reply-To: <6395.68829.qm@web112107.mail.gq1.yahoo.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-621872753-1251483545=:34770"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-621872753-1251483545=:34770
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

would someone give us a hint? Thanks.
Why "java.util.zip.ZipOutputStream" need to use /tmp?

The hadoop version is 0.18.3 . Recently we got "out of space" issue. It's f=
rom "java.util.zip.ZipOutputStream".
We found that /tmp is full and after cleaning /tmp the problem is solved.

However why hadoop needs to use /tmp? We had already configured hadoop tmp =
to a local disk in: hadoop-site.xml

<property>
=A0 <name>hadoop.tmp.dir</name>
=A0 <value> ... some large local disk ... </value>
</property>


Could it because java.util.zip.ZipOutputStream uses /tmp even if we configu=
red hadoop.tmp.dir to a large local disk?

The error log is here FYI:

java.io.IOException: No space left on device=A0=A0=A0=A0=A0=A0=A0 =A0
at java.io.FileOutputStream.write(Native Method)=A0=A0=A0=A0=A0=A0 =A0
=A0at java.util.zip.ZipOutputStream.writeInt(ZipOutputStream.java:445)=A0=
=A0=A0=A0=A0=A0=A0 =A0
at java.util.zip.ZipOutputStream.writeEXT(ZipOutputStream.java:362)=A0=A0=
=A0=A0=A0=A0=A0 =A0
at java.util.zip.ZipOutputStream.closeEntry(ZipOutputStream.java:220)=A0=A0=
=A0=A0=A0=A0=A0 =A0
at java.util.zip.ZipOutputStream.finish(ZipOutputStream.java:301)=A0=A0=A0=
=A0=A0=A0=A0 =A0
at java.util.zip.DeflaterOutputStream.close(DeflaterOutputStream.java:146)=
=A0=A0=A0=A0=A0=A0=A0 =A0
at java.util.zip.ZipOutputStream.close(ZipOutputStream.java:321)=A0=A0=A0=
=A0=A0=A0=A0 =A0
at org.apache.hadoop.streaming.JarBuilder.merge(JarBuilder.java:79)=A0=A0=
=A0=A0=A0=A0=A0 =A0
at org.apache.hadoop.streaming.StreamJob.packageJobJar(StreamJob.java:628)=
=A0=A0=A0=A0=A0=A0=A0 =A0
at org.apache.hadoop.streaming.StreamJob.setJobConf(StreamJob.java:843)=A0=
=A0=A0=A0=A0=A0=A0 =A0
at org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:110)=A0=A0=A0=A0=
=A0=A0=A0 =A0
at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:33=
)=A0=A0=A0=A0=A0=A0=A0 =A0
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)=A0=A0=A0=A0=
=A0=A0=A0 =A0
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav=
a:39)=A0=A0=A0=A0=A0=A0=A0 =A0
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessor=
Impl.java:25)=A0=A0=A0=A0=A0=A0=A0 =A0
at java.lang.reflect.Method.invoke(Method.java:597)=A0=A0=A0=A0=A0=A0=A0 =
=A0
at org.apache.hadoop.util.RunJar.main(RunJar.java:155)=A0=A0=A0=A0=A0=A0=A0=
 =A0
at org.apache.hadoop.mapred.JobShell.run(JobShell.java:194)=A0=A0=A0=A0=A0=
=A0=A0 =A0
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)=A0=A0=A0=A0=A0=
=A0=A0 =A0
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)=A0=A0=A0=A0=A0=
=A0=A0 =A0
at org.apache.hadoop.mapred.JobShell.main(JobShell.java:220) =A0
Executing Hadoop job failure




=A0 =A0 =A0 =0A=0A=0A      
--0-621872753-1251483545=:34770--

From common-user-return-17149-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 18:24:04 2009
Return-Path: <common-user-return-17149-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 97074 invoked from network); 28 Aug 2009 18:24:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 18:24:04 -0000
Received: (qmail 26503 invoked by uid 500); 28 Aug 2009 18:24:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26421 invoked by uid 500); 28 Aug 2009 18:24:01 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 26407 invoked by uid 99); 28 Aug 2009 18:24:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:24:01 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vliaskov@gmail.com designates 209.85.212.185 as permitted sender)
Received: from [209.85.212.185] (HELO mail-vw0-f185.google.com) (209.85.212.185)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:23:52 +0000
Received: by vws15 with SMTP id 15so1703978vws.5
        for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 11:23:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type:content-transfer-encoding;
        bh=kX3vyNTVeTPYFDLFtCq2h+r4eVqTt8PSmmVwSJpjUJ8=;
        b=H3+z4RLSKaIdtTIb3kbrB49SkZBpnBNhWxfmaWZTApflEM+CeLcONZAF0JstBS4bJi
         9jhrWirPk/Ac4RYrLvoH4+8vheKp/eDTaF8WOFF3XR3RbZ6/6fQc1OVC74KaZKSe8d+q
         V3y3Vess3HY9eWooVWLossINGVr2+XtyKpVxE=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        b=FCbLEtb1zJYk/joHOBz5al22z2+W4LCBaDy8pp0O5w3uSw22qniJLNYGegIPudpmJS
         sZkSU21qpWLf013irJQvkz9w70j5X4Qq8Ye37/Tky2cp1t1nZEXOrBA5BwGLFY5rIbcg
         T3HGi+eWln28aukhSCUPB+RfELBJh+Ezyz0IE=
MIME-Version: 1.0
Received: by 10.220.88.209 with SMTP id b17mr1585829vcm.98.1251483810300; Fri, 
	28 Aug 2009 11:23:30 -0700 (PDT)
Date: Fri, 28 Aug 2009 13:23:30 -0500
Message-ID: <bec373e0908281123o4d83f393m10b96d7bc55a767d@mail.gmail.com>
Subject: performance counters & vaidya diagnostics help
From: Vasilis Liaskovitis <vliaskov@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

a) Is there a wiki page or other documentation explaining the exact
meaning of the job / filesystem / mapreduce counters reported after
every job run?

9/08/27 15:04:10 INFO mapred.JobClient: Job complete: job_200908271428_0002
09/08/27 15:04:10 INFO mapred.JobClient: Counters: 19
09/08/27 15:04:10 INFO mapred.JobClient:   Job Counters
09/08/27 15:04:10 INFO mapred.JobClient:     Launched reduce tasks=3D72
09/08/27 15:04:10 INFO mapred.JobClient:     Rack-local map tasks=3D9
09/08/27 15:04:10 INFO mapred.JobClient:     Launched map tasks=3D480
09/08/27 15:04:10 INFO mapred.JobClient:     Data-local map tasks=3D471
09/08/27 15:04:10 INFO mapred.JobClient:   FileSystemCounters
09/08/27 15:04:10 INFO mapred.JobClient:     FILE_BYTES_READ=3D32254488881
09/08/27 15:04:10 INFO mapred.JobClient:     HDFS_BYTES_READ=3D32326069128
09/08/27 15:04:10 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=3D645100158=
10
09/08/27 15:04:10 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=3D323187985=
19
09/08/27 15:04:10 INFO mapred.JobClient:   Map-Reduce Framework
09/08/27 15:04:10 INFO mapred.JobClient:     Reduce input groups=3D3064894
09/08/27 15:04:10 INFO mapred.JobClient:     Combine output records=3D0
09/08/27 15:04:10 INFO mapred.JobClient:     Map input records=3D3064894
09/08/27 15:04:10 INFO mapred.JobClient:     Reduce shuffle bytes=3D3219784=
4126
09/08/27 15:04:10 INFO mapred.JobClient:     Reduce output records=3D306489=
4
09/08/27 15:04:10 INFO mapred.JobClient:     Spilled Records=3D6129788
09/08/27 15:04:10 INFO mapred.JobClient:     Map output bytes=3D32237256375
09/08/27 15:04:10 INFO mapred.JobClient:     Map input bytes=3D32318791307
09/08/27 15:04:10 INFO mapred.JobClient:     Combine input records=3D0
09/08/27 15:04:10 INFO mapred.JobClient:     Map output records=3D3064894
09/08/27 15:04:10 INFO mapred.JobClient:     Reduce input records=3D3064894

Do spilled records refer to the mapper output phase only, to the
merge/reduce phase only, or both?

Is it possible to enable more of these counters (in case not all of
them are on by default)?

b) I am trying to use vaidya in hadoop-0.20.0 to do post-run
performance analysis of a simple sort job. I am specifying my job
configuration and history log found under logs/history in my local
filesystem. However I get an exception while the log is being
processed.

headnode:~/hadoop-0.20.0 # java -classpath
hadoop-0.20.0-core.jar:contrib/vaidya/hadoop-0.20.0-vaidya.jar:lib/commons-=
logging-1.0.4.jar
org.apache.hadoop.vaidya.postexdiagnosis.PostExPerformanceDiagnoser
-jobconf file://localhost/home/vliaskov/hadoop-0.20.0/logs/history/headnode=
_1251401328090_job_200908271428_0004_conf.xml
-joblog file://localhost/home/vliaskov/hadoop-0.20.0/logs/history/headnode_=
1251401328090_job_200908271428_0004_root_sorter

Pattern:<{(org.apache.hadoop.mapred.JobInProgress$Counter)(Job
Counters )[(TOTAL_LAUNCHED_REDUCES)(Launched reduce
tasks)(72)][(RACK_LOCAL_MAPS)(Rack-local map
tasks)(2)][(TOTAL_LAUNCHED_MAPS)(Launched map
tasks)(480)][(DATA_LOCAL_MAPS)(Data-local map
tasks)(478)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FI=
LE_BYTES_READ)(32254488881)][(HDFS_BYTES_READ)(HDFS_BYTES_READ)(32326069128=
)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(64510015810)][(HDFS_BYTES_WRITT=
EN)(HDFS_BYTES_WRITTEN)(32318798519)]}{(org.apache.hadoop.mapred.Task$Count=
er)(Map-Reduce
Framework)[(REDUCE_INPUT_GROUPS)(Reduce input
groups)(3064894)][(COMBINE_OUTPUT_RECORDS)(Combine output
records)(0)][(MAP_INPUT_RECORDS)(Map input
records)(3064894)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle
bytes)(32193406838)][(REDUCE_OUTPUT_RECORDS)(Reduce output
records)(3064894)][(SPILLED_RECORDS)(Spilled
Records)(6129788)][(MAP_OUTPUT_BYTES)(Map output
bytes)(32237256375)][(MAP_INPUT_BYTES)(Map input
bytes)(32318791307)][(MAP_OUTPUT_RECORDS)(Map output
records)(3064894)][(COMBINE_INPUT_RECORDS)(Combine input
records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(3064894)]}>
=3D=3D> NOT INCLUDED IN PERFORMANCE ADVISOR
JobHistory.Keys.JOB_PRIORITY : NOT INCLUDED IN PERFORMANCE ADVISOR COUNTERS
JobHistory.Keys.STATE_STRING : NOT INCLUDED IN PERFORMANCE ADVISOR MAP COUN=
TERS
JobHistory.Keys.HTTP_PORT : NOT INCLUDED IN PERFORMANCE ADVISOR MAP COUNTER=
S
[snip lots of output...]
Pattern:<{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_B=
YTES_READ)(447950837)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(447950837)]=
[(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(448842224)]}{(org.apache.hadoop.m=
apred.Task$Counter)(Map-Reduce
Framework)[(REDUCE_INPUT_GROUPS)(Reduce input
groups)(42528)][(COMBINE_OUTPUT_RECORDS)(Combine output
records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle
bytes)(447117550)][(REDUCE_OUTPUT_RECORDS)(Reduce output
records)(42528)][(SPILLED_RECORDS)(Spilled
Records)(42528)][(COMBINE_INPUT_RECORDS)(Combine input
records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(42528)]}>
=3D=3D> NOT INCLUDED IN PERFORMANCE ADVISOR MAP TASK
JobHistory.Keys.STATE_STRING : NOT INCLUDED IN PERFORMANCE ADVISOR
REDUCE COUNTERS
JobHistory.Keys.SPLITS : NOT INCLUDED IN PERFORMANCE ADVISOR REDUCE COUNTER=
S
JobHistory.Keys.TRACKER_NAME : NOT INCLUDED IN PERFORMANCE ADVISOR
REDUCE COUNTERS
JobHistory.Keys.HTTP_PORT : NOT INCLUDED IN PERFORMANCE ADVISOR REDUCE COUN=
TERS
Pattern:<{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_B=
YTES_READ)(449120596)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(449120596)]=
[(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(450015816)]}{(org.apache.hadoop.m=
apred.Task$Counter)(Map-Reduce
Framework)[(REDUCE_INPUT_GROUPS)(Reduce input
groups)(42659)][(COMBINE_OUTPUT_RECORDS)(Combine output
records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle
bytes)(448196646)][(REDUCE_OUTPUT_RECORDS)(Reduce output
records)(42659)][(SPILLED_RECORDS)(Spilled
Records)(42659)][(COMBINE_INPUT_RECORDS)(Combine input
records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(42659)]}>
=3D=3D> NOT INCLUDED IN PERFORMANCE ADVISOR MAP TASK
Exception:java.lang.NumberFormatException:
nulljava.lang.NumberFormatException: null
        at java.lang.Long.parseLong(Unknown Source)
        at java.lang.Long.parseLong(Unknown Source)
        at org.apache.hadoop.vaidya.statistics.job.TaskStatistics.getLongVa=
lue(TaskStatistics.java:37)
        at org.apache.hadoop.vaidya.statistics.job.JobStatistics$ReduceCoun=
terComparator.compare(JobStatistics.java:570)
        at org.apache.hadoop.vaidya.statistics.job.JobStatistics$ReduceCoun=
terComparator.compare(JobStatistics.java:557)
        at java.util.Arrays.mergeSort(Unknown Source)
        at java.util.Arrays.mergeSort(Unknown Source)
        at java.util.Arrays.mergeSort(Unknown Source)
        at java.util.Arrays.mergeSort(Unknown Source)
        at java.util.Arrays.mergeSort(Unknown Source)
        at java.util.Arrays.sort(Unknown Source)
        at java.util.Collections.sort(Unknown Source)
        at org.apache.hadoop.vaidya.statistics.job.JobStatistics.sortReduce=
TasksByKey(JobStatistics.java:553)
        at org.apache.hadoop.vaidya.statistics.job.JobStatistics.getReduceT=
askList(JobStatistics.java:544)
        at org.apache.hadoop.vaidya.postexdiagnosis.tests.BalancedReducePar=
titioning.evaluate(BalancedReducePartitioning.java:61)
        at org.apache.hadoop.vaidya.DiagnosticTest.run(DiagnosticTest.java:=
240)
        at org.apache.hadoop.vaidya.postexdiagnosis.PostExPerformanceDiagno=
ser.main(PostExPerformanceDiagnoser.java:250)

it seems that some perfomance counters are not enabled or that the
analyzer does not process some counter values - does it even find any
values? The job summary does report some non-zero counters when it
finishes (see the output from my first question above). Any ideas on
what goes wrong? I have also tried to explicitly specify the default
test-diagnosis xml file by adding "-testconf
src/contrib/vaidya/src/java/org/apache/hadoop/vaidya/postexdiagnosis/tests/=
postex_diagnosis_tests.xml"
on my command line switch but the results are the same.

thanks for any help,

- Vasilis

From common-user-return-17150-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 18:26:04 2009
Return-Path: <common-user-return-17150-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 99633 invoked from network); 28 Aug 2009 18:26:04 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 18:26:04 -0000
Received: (qmail 31818 invoked by uid 500); 28 Aug 2009 18:26:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 31750 invoked by uid 500); 28 Aug 2009 18:26:01 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 31740 invoked by uid 99); 28 Aug 2009 18:26:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:26:01 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [76.13.12.149] (HELO web59703.mail.ac4.yahoo.com) (76.13.12.149)
    by apache.org (qpsmtpd/0.29) with SMTP; Fri, 28 Aug 2009 18:25:52 +0000
Received: (qmail 79645 invoked by uid 60001); 28 Aug 2009 18:25:30 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1251483930; bh=RQ08X7Ng9FoikWuiV0sxrx1XMMJe5vFuajx820qS2nY=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:Cc:In-Reply-To:MIME-Version:Content-Type; b=L1geNLkMQMGrP0Ofo77qlXO28P/9RgAjPCIqPEOCR/qBXpyS25qjCyUADRDrpSfX01hJXfyyNtTBLfm8kqT/fgMrVM3F0aPHMUMOCDwLLPFYgi/jW1ROv1QnYU1N2Fp+6p0XwSahLstpu+SA7Lsg/EaaZTfVAy47HzGv8uKWk7k=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:Cc:In-Reply-To:MIME-Version:Content-Type;
  b=k0o6gw1/sYb/OYj8lmazQH1gQ4XNM7EOuBVgWgA0Lz3c2fIK64aZXbFfeg/tZGrdv0EoQxjBYZcYkbg/42ef7WPfXVDjKGdzolQdz51SpSxn5oHt9QKBm8v8kJZkLis1jlHAeMCDXzUBAq7yvWbMVhhT5hnGIK+DBkjx6D8Qh+k=;
Message-ID: <695855.79137.qm@web59703.mail.ac4.yahoo.com>
X-YMail-OSG: V8f4kd0VM1nx3f56frKmgwbCdy3n5VMVREV6gyOzUDjRaXSN1NdxQzxpmuogXdEvTXmHyj3O1H3OYuFojRdBqPezDPx..SNjyXnNhALk6e1GtcLclWkXU29gWcWZQAqMUlOVHbj6lXOXdBmBM6u3FoXcgVOuZ8mN7lMexcUIodS.pVbTknoObJhwO6WJV0S1GUnmE.kV2pWBbVSPmhfn3rjuKE3HDUbdxJf9EaBlW8qfjJ_qDav1TsA4UYIxQo.MTNToxhtM87k3KA--
Received: from [64.172.17.3] by web59703.mail.ac4.yahoo.com via HTTP; Fri, 28 Aug 2009 11:25:30 PDT
X-Mailer: YahooMailClassic/6.1.2 YahooMailWebService/0.7.338.2
Date: Fri, 28 Aug 2009 11:25:30 -0700 (PDT)
From: Gopal Gandhi <gopal.gandhi2008@yahoo.com>
Subject: Who are the gurus in Hive and/or Hbase?
To: common-user@hadoop.apache.org, common-dev@hadoop.apache.org
Cc: common-dev@hadoop.apache.org
In-Reply-To: <764438.34770.qm@web112107.mail.gq1.yahoo.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-1055131661-1251483930=:79137"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-1055131661-1251483930=:79137
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

We are inviting gurus or major contributors of Hive and/or Hbase (or anythi=
ng=A0related to Hadoop)=A0to give us presentations about the products. Woul=
d you name a few names? The gurus must be in bay area.=20
Thanks. =0A=0A=0A      
--0-1055131661-1251483930=:79137--

From common-user-return-17151-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 18:27:03 2009
Return-Path: <common-user-return-17151-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 419 invoked from network); 28 Aug 2009 18:27:02 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 18:27:02 -0000
Received: (qmail 36239 invoked by uid 500); 28 Aug 2009 18:26:58 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 36095 invoked by uid 500); 28 Aug 2009 18:26:58 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 35867 invoked by uid 99); 28 Aug 2009 18:26:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:26:57 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [76.13.13.71] (HELO n1b.bullet.mail.ac4.yahoo.com) (76.13.13.71)
    by apache.org (qpsmtpd/0.29) with SMTP; Fri, 28 Aug 2009 18:26:45 +0000
Received: from [76.13.13.26] by n1.bullet.mail.ac4.yahoo.com with NNFMP; 28 Aug 2009 18:26:24 -0000
Received: from [76.13.10.172] by t3.bullet.mail.ac4.yahoo.com with NNFMP; 28 Aug 2009 18:26:24 -0000
Received: from [127.0.0.1] by omp113.mail.ac4.yahoo.com with NNFMP; 28 Aug 2009 18:26:24 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 562484.33637.bm@omp113.mail.ac4.yahoo.com
Received: (qmail 1431 invoked by uid 60001); 28 Aug 2009 18:26:24 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1251483984; bh=7c64R1QwHx+4QyNdQHOjajOzzQr9I/LMsOKk7/u3x6E=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:Cc:MIME-Version:Content-Type; b=nQdl0PyVUHTrmx4cV+IGJN/tKM1aEkHAVRPqGBw5ke5exa41GjijEDfA1gco3e6r9KKMuwbBopAqz23st5z629FsENPgMk9+G3n2Z+aNUZRJOKX0SemKiiQVcA7ScBkCVAhbluxuMXENp18cZStZHbg8S0EYkZ40PdyxVpEBo6E=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:Cc:MIME-Version:Content-Type;
  b=tNSH3j0d7qN163b0vidrQFVkTsWROuQ748F7a+ADER2DffRG/7w1AwUc+3l+XvCXApXlARLez78DZQpFO9teQxMAM/fPtljPPAVhUJzRgKUtzRywxPXB1QbwKGuuLJ8/7ojG3NrAJNFNd2mihZrsUdYsBEyFjzrPX6Q2VrYhG8c=;
Message-ID: <427969.1418.qm@web59712.mail.ac4.yahoo.com>
X-YMail-OSG: KuX47dIVM1lcQq3ZOq6aMJ0EMiayV.cbPhySTq2UYZldQPtwSQWKL1NX4vXxyAH7TU7vTmeEFPpipyhy8_wN13jshOgn7v9dCc2PEcYcGx88usJGqg4CiHJwpIHKYhbWOq.1_uS2U2biZNhmZt5hHUe7ftym67ZMnaoD4er2cpw7LJIoXg0dBOME4VP4qYik5zkNpirFxRLVVPuyF9imcr.pkaLCkTrepX_6XJRVJmNZMUhRQYAfDUMCbJ.Wyow_4IOSpGCMrc_8Fd6CR21o
Received: from [64.172.17.3] by web59712.mail.ac4.yahoo.com via HTTP; Fri, 28 Aug 2009 11:26:24 PDT
X-Mailer: YahooMailClassic/6.1.2 YahooMailWebService/0.7.338.2
Date: Fri, 28 Aug 2009 11:26:24 -0700 (PDT)
From: Gopal Gandhi <gopal.gandhi2008@yahoo.com>
Subject: Re: Who are the major contributors to Hive and/or Hbase?
To: common-user@hadoop.apache.org, common-dev@hadoop.apache.org
Cc: common-dev@hadoop.apache.org
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-970846235-1251483984=:1418"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-970846235-1251483984=:1418
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

May be I should change the title?

--- On Fri, 8/28/09, Gopal Gandhi <gopal.gandhi2008@yahoo.com> wrote:


From: Gopal Gandhi <gopal.gandhi2008@yahoo.com>
Subject: Who are the gurus in Hive and/or Hbase?
To: common-user@hadoop.apache.org, common-dev@hadoop.apache.org
Cc: common-dev@hadoop.apache.org
Date: Friday, August 28, 2009, 6:25 PM







We are inviting gurus or major contributors of Hive and/or Hbase (or anythi=
ng=A0related to Hadoop)=A0to give us presentations about the products. Woul=
d you name a few names? The gurus must be in bay area.=20
Thanks.=20
=0A=0A=0A      
--0-970846235-1251483984=:1418--


From common-user-return-17152-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 18:28:35 2009
Return-Path: <common-user-return-17152-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 1871 invoked from network); 28 Aug 2009 18:28:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 18:28:35 -0000
Received: (qmail 45351 invoked by uid 500); 28 Aug 2009 18:28:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 45283 invoked by uid 500); 28 Aug 2009 18:28:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 45273 invoked by uid 99); 28 Aug 2009 18:28:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:28:32 +0000
X-ASF-Spam-Status: No, hits=1.8 required=10.0
	tests=MISSING_HEADERS,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:28:21 +0000
Received: from pcp089093pcs.unl.edu (pcp089093pcs.unl.edu [129.93.158.208])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7SIRuG9023857
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 13:27:59 -0500
Cc: common-user@hadoop.apache.org
Message-Id: <3461C3F6-016D-467F-B93F-B64F2F3F71AB@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
In-Reply-To: <764438.34770.qm@web112107.mail.gq1.yahoo.com>
Content-Type: multipart/signed; boundary=Apple-Mail-28-446453137; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
Date: Fri, 28 Aug 2009 13:27:56 -0500
References: <764438.34770.qm@web112107.mail.gq1.yahoo.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-28-446453137
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Hey Steve,

Correct, java.util.zip.* does not necessarily respect hadoop settings.

Try setting TMPDIR in the environment to your large local disk space.   
It might respect that, if Java decides to act like a unix utility.

http://en.wikipedia.org/wiki/TMPDIR

Brian

On Aug 28, 2009, at 1:19 PM, Steve Gao wrote:

> would someone give us a hint? Thanks.
> Why "java.util.zip.ZipOutputStream" need to use /tmp?
>
> The hadoop version is 0.18.3 . Recently we got "out of space" issue.  
> It's from "java.util.zip.ZipOutputStream".
> We found that /tmp is full and after cleaning /tmp the problem is  
> solved.
>
> However why hadoop needs to use /tmp? We had already configured  
> hadoop tmp to a local disk in: hadoop-site.xml
>
> <property>
>   <name>hadoop.tmp.dir</name>
>   <value> ... some large local disk ... </value>
> </property>
>
>
> Could it because java.util.zip.ZipOutputStream uses /tmp even if we  
> configured hadoop.tmp.dir to a large local disk?
>
> The error log is here FYI:
>
> java.io.IOException: No space left on device
> at java.io.FileOutputStream.write(Native Method)
>  at java.util.zip.ZipOutputStream.writeInt(ZipOutputStream.java:445)
> at java.util.zip.ZipOutputStream.writeEXT(ZipOutputStream.java:362)
> at java.util.zip.ZipOutputStream.closeEntry(ZipOutputStream.java:220)
> at java.util.zip.ZipOutputStream.finish(ZipOutputStream.java:301)
> at  
> java.util.zip.DeflaterOutputStream.close(DeflaterOutputStream.java: 
> 146)
> at java.util.zip.ZipOutputStream.close(ZipOutputStream.java:321)
> at org.apache.hadoop.streaming.JarBuilder.merge(JarBuilder.java:79)
> at  
> org.apache.hadoop.streaming.StreamJob.packageJobJar(StreamJob.java: 
> 628)
> at org.apache.hadoop.streaming.StreamJob.setJobConf(StreamJob.java: 
> 843)
> at org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:110)
> at  
> org 
> .apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:33)
> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> at  
> sun 
> .reflect 
> .NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> at  
> sun 
> .reflect 
> .DelegatingMethodAccessorImpl 
> .invoke(DelegatingMethodAccessorImpl.java:25)
> at java.lang.reflect.Method.invoke(Method.java:597)
> at org.apache.hadoop.util.RunJar.main(RunJar.java:155)
> at org.apache.hadoop.mapred.JobShell.run(JobShell.java:194)
> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
> at org.apache.hadoop.mapred.JobShell.main(JobShell.java:220)
> Executing Hadoop job failure
>
>
>
>
>
>
>


--Apple-Mail-28-446453137
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-28-446453137--

From common-user-return-17153-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 18:32:27 2009
Return-Path: <common-user-return-17153-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 4206 invoked from network); 28 Aug 2009 18:32:27 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 18:32:27 -0000
Received: (qmail 49116 invoked by uid 500); 28 Aug 2009 18:32:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 49030 invoked by uid 500); 28 Aug 2009 18:32:25 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 49016 invoked by uid 99); 28 Aug 2009 18:32:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:32:25 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [67.195.22.89] (HELO web112111.mail.gq1.yahoo.com) (67.195.22.89)
    by apache.org (qpsmtpd/0.29) with SMTP; Fri, 28 Aug 2009 18:32:15 +0000
Received: (qmail 60531 invoked by uid 60001); 28 Aug 2009 18:31:53 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1251484313; bh=KjhJ4DExqOMMNLiUIVdGX++BSKo1iGA/YfuQIgf7ICk=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=Dnkmse5HFamRq3SGxqbOkvvsdh0UcX1uwS0XPlcBjbOM4DXTmXi/sGnFnNSTjXvgMj+2jpi3fcsOHeVWsmIUGXsLElvydPqlzUU6xs3FPfRmjruQYwzpim2xnLFHgdfM1jZl7dvwa5ME9SF1PJOmeQnc9iFCTcl0jB/TpYiIsIw=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=wy/2YB6UYx1ljJezSVbco5rBy4r6SP8tMrFsQo3wQU8EIOFHlKrJfs4SYI5D4aA9048UbEw+cGbL1iB6E0R/Hyl24SRPVuwx9hGvKuagvzZ5cS8rCjfUdkO2kp2LZDFemVcLG1WaL3w6MPK8Fu4NZsNB7iZwbbZJHB/to/JnjcE=;
Message-ID: <852058.58699.qm@web112111.mail.gq1.yahoo.com>
X-YMail-OSG: YQSKikgVM1kf_PKBV_nFx3hGTPxZ0puglHQi8JV8T3fAP0xGHD7lKE1f5XYARwpdr3YtRy14eBO9MPy07bA8yPe2kP0JfrGaSmrnmMFzVvJ2zCbN97DMhzl_cpCDWV7NgB.Cl7zJ4M2SHv5_Kcqokqul_OaBPlUWhB.DgoQKZG9eCV9Xfx1bFFUKs4SNPJujKkjXXQ3VjOK_qMpD_lgk7NH8LXGQuPjL6TIpVdnSDHeDiElQ85TI3AVzcwjDvizahaBrTogKSCuPCfvhCayAXloh
Received: from [64.172.17.3] by web112111.mail.gq1.yahoo.com via HTTP; Fri, 28 Aug 2009 11:31:53 PDT
X-Mailer: YahooMailClassic/6.1.2 YahooMailWebService/0.7.338.2
Date: Fri, 28 Aug 2009 11:31:53 -0700 (PDT)
From: Steve Gao <steve.gao@yahoo.com>
Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
To: common-user@hadoop.apache.org
In-Reply-To: <3461C3F6-016D-467F-B93F-B64F2F3F71AB@cse.unl.edu>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-190809530-1251484313=:58699"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-190809530-1251484313=:58699
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

Thanks lot, Brian. It seems to be a design flaw of hadoop that it can not m=
anage (or pass in) the temp of "java.util.zip". Can we create a jira ticket=
 for this?

--- On Fri, 8/28/09, Brian Bockelman <bbockelm@cse.unl.edu> wrote:

From: Brian Bockelman <bbockelm@cse.unl.edu>
Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
To:=20
Cc: common-user@hadoop.apache.org
Date: Friday, August 28, 2009, 2:27 PM

Hey Steve,

Correct, java.util.zip.* does not necessarily respect hadoop settings.

Try setting TMPDIR in the environment to your large local disk space.=A0 It=
 might respect that, if Java decides to act like a unix utility.

http://en.wikipedia.org/wiki/TMPDIR

Brian

On Aug 28, 2009, at 1:19 PM, Steve Gao wrote:

> would someone give us a hint? Thanks.
> Why "java.util.zip.ZipOutputStream" need to use /tmp?
>=20
> The hadoop version is 0.18.3 . Recently we got "out of space" issue. It's=
 from "java.util.zip.ZipOutputStream".
> We found that /tmp is full and after cleaning /tmp the problem is solved.
>=20
> However why hadoop needs to use /tmp? We had already configured hadoop tm=
p to a local disk in: hadoop-site.xml
>=20
> <property>
>=A0=A0=A0<name>hadoop.tmp.dir</name>
>=A0=A0=A0<value> ... some large local disk ... </value>
> </property>
>=20
>=20
> Could it because java.util.zip.ZipOutputStream uses /tmp even if we confi=
gured hadoop.tmp.dir to a large local disk?
>=20
> The error log is here FYI:
>=20
> java.io.IOException: No space left on device
> at java.io.FileOutputStream.write(Native Method)
>=A0 at java.util.zip.ZipOutputStream.writeInt(ZipOutputStream.java:445)
> at java.util.zip.ZipOutputStream.writeEXT(ZipOutputStream.java:362)
> at java.util.zip.ZipOutputStream.closeEntry(ZipOutputStream.java:220)
> at java.util.zip.ZipOutputStream.finish(ZipOutputStream.java:301)
> at java.util.zip.DeflaterOutputStream.close(DeflaterOutputStream.java:146=
)
> at java.util.zip.ZipOutputStream.close(ZipOutputStream.java:321)
> at org.apache.hadoop.streaming.JarBuilder.merge(JarBuilder.java:79)
> at org.apache.hadoop.streaming.StreamJob.packageJobJar(StreamJob.java:628=
)
> at org.apache.hadoop.streaming.StreamJob.setJobConf(StreamJob.java:843)
> at org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:110)
> at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:=
33)
> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.j=
ava:39)
> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccess=
orImpl.java:25)
> at java.lang.reflect.Method.invoke(Method.java:597)
> at org.apache.hadoop.util.RunJar.main(RunJar.java:155)
> at org.apache.hadoop.mapred.JobShell.run(JobShell.java:194)
> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
> at org.apache.hadoop.mapred.JobShell.main(JobShell.java:220)
> Executing Hadoop job failure
>=20
>=20
>=20
>=20
>=20
>=20
>=20

=0A=0A=0A      
--0-190809530-1251484313=:58699--

From common-user-return-17154-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 18:38:35 2009
Return-Path: <common-user-return-17154-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 12348 invoked from network); 28 Aug 2009 18:38:35 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 18:38:35 -0000
Received: (qmail 58094 invoked by uid 500); 28 Aug 2009 18:38:33 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 57990 invoked by uid 500); 28 Aug 2009 18:38:33 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 57980 invoked by uid 99); 28 Aug 2009 18:38:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:38:33 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:38:22 +0000
Received: from pcp089093pcs.unl.edu (pcp089093pcs.unl.edu [129.93.158.208])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7SIbxBH024979
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 13:38:01 -0500
Message-Id: <C7A7AEF8-9878-4408-8F63-DF3F5F137AAF@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <852058.58699.qm@web112111.mail.gq1.yahoo.com>
Content-Type: multipart/signed; boundary=Apple-Mail-29-447055907; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
Date: Fri, 28 Aug 2009 13:37:59 -0500
References: <852058.58699.qm@web112111.mail.gq1.yahoo.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-29-447055907
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

Actually, poking the code, it seems that the streaming package does  
set this value:

     String tmp = jobConf_.get("stream.tmpdir"); //, "/tmp/$ 
{user.name}/"

Try setting stream.tmpdir to a different directory maybe?

Brian

On Aug 28, 2009, at 1:31 PM, Steve Gao wrote:

> Thanks lot, Brian. It seems to be a design flaw of hadoop that it  
> can not manage (or pass in) the temp of "java.util.zip". Can we  
> create a jira ticket for this?
>
> --- On Fri, 8/28/09, Brian Bockelman <bbockelm@cse.unl.edu> wrote:
>
> From: Brian Bockelman <bbockelm@cse.unl.edu>
> Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use / 
> tmp?
> To:
> Cc: common-user@hadoop.apache.org
> Date: Friday, August 28, 2009, 2:27 PM
>
> Hey Steve,
>
> Correct, java.util.zip.* does not necessarily respect hadoop settings.
>
> Try setting TMPDIR in the environment to your large local disk  
> space.  It might respect that, if Java decides to act like a unix  
> utility.
>
> http://en.wikipedia.org/wiki/TMPDIR
>
> Brian
>
> On Aug 28, 2009, at 1:19 PM, Steve Gao wrote:
>
>> would someone give us a hint? Thanks.
>> Why "java.util.zip.ZipOutputStream" need to use /tmp?
>>
>> The hadoop version is 0.18.3 . Recently we got "out of space"  
>> issue. It's from "java.util.zip.ZipOutputStream".
>> We found that /tmp is full and after cleaning /tmp the problem is  
>> solved.
>>
>> However why hadoop needs to use /tmp? We had already configured  
>> hadoop tmp to a local disk in: hadoop-site.xml
>>
>> <property>
>>    <name>hadoop.tmp.dir</name>
>>    <value> ... some large local disk ... </value>
>> </property>
>>
>>
>> Could it because java.util.zip.ZipOutputStream uses /tmp even if we  
>> configured hadoop.tmp.dir to a large local disk?
>>
>> The error log is here FYI:
>>
>> java.io.IOException: No space left on device
>> at java.io.FileOutputStream.write(Native Method)
>>   at java.util.zip.ZipOutputStream.writeInt(ZipOutputStream.java:445)
>> at java.util.zip.ZipOutputStream.writeEXT(ZipOutputStream.java:362)
>> at java.util.zip.ZipOutputStream.closeEntry(ZipOutputStream.java:220)
>> at java.util.zip.ZipOutputStream.finish(ZipOutputStream.java:301)
>> at  
>> java.util.zip.DeflaterOutputStream.close(DeflaterOutputStream.java: 
>> 146)
>> at java.util.zip.ZipOutputStream.close(ZipOutputStream.java:321)
>> at org.apache.hadoop.streaming.JarBuilder.merge(JarBuilder.java:79)
>> at  
>> org.apache.hadoop.streaming.StreamJob.packageJobJar(StreamJob.java: 
>> 628)
>> at org.apache.hadoop.streaming.StreamJob.setJobConf(StreamJob.java: 
>> 843)
>> at org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:110)
>> at  
>> org 
>> .apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java: 
>> 33)
>> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>> at  
>> sun 
>> .reflect 
>> .NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
>> at  
>> sun 
>> .reflect 
>> .DelegatingMethodAccessorImpl 
>> .invoke(DelegatingMethodAccessorImpl.java:25)
>> at java.lang.reflect.Method.invoke(Method.java:597)
>> at org.apache.hadoop.util.RunJar.main(RunJar.java:155)
>> at org.apache.hadoop.mapred.JobShell.run(JobShell.java:194)
>> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
>> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
>> at org.apache.hadoop.mapred.JobShell.main(JobShell.java:220)
>> Executing Hadoop job failure
>>
>>
>>
>>
>>
>>
>>
>
>
>
>


--Apple-Mail-29-447055907
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-29-447055907--

From common-user-return-17155-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 18:58:21 2009
Return-Path: <common-user-return-17155-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 16386 invoked from network); 28 Aug 2009 18:58:21 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 18:58:21 -0000
Received: (qmail 82815 invoked by uid 500); 28 Aug 2009 18:58:19 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 82731 invoked by uid 500); 28 Aug 2009 18:58:18 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 82721 invoked by uid 99); 28 Aug 2009 18:58:18 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:58:18 +0000
X-ASF-Spam-Status: No, hits=1.2 required=10.0
	tests=SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [69.147.107.21] (HELO mrout2-b.corp.re1.yahoo.com) (69.147.107.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 18:58:08 +0000
Received: from walkduty-lm.corp.yahoo.com (walkduty-lm.corp.yahoo.com [10.72.104.13])
	by mrout2-b.corp.re1.yahoo.com (8.13.8/8.13.8/y.out) with ESMTP id n7SIuW0G018460
	for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 11:56:32 -0700 (PDT)
DomainKey-Signature: a=rsa-sha1; s=serpent; d=yahoo-inc.com; c=nofws; q=dns;
	h=message-id:from:to:in-reply-to:content-type:
	content-transfer-encoding:mime-version:subject:date:references:x-mailer;
	b=c7cLAwRzZ3G18bdODU9lhJx+/SF0c2gBSObMwVEMepa1poTDIuzIdXF6VSM0DQbx
Message-Id: <F00E0623-1FB4-4C64-901D-7E7FCC9D0E18@yahoo-inc.com>
From: Arun C Murthy <acm@yahoo-inc.com>
To: common-user@hadoop.apache.org
In-Reply-To: <2aa3aff80908270525uafe39e8q83c9796528da15f7@mail.gmail.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: difference between mapper and map runnable
Date: Fri, 28 Aug 2009 11:56:31 -0700
References: <2aa3aff80908270525uafe39e8q83c9796528da15f7@mail.gmail.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org


On Aug 27, 2009, at 5:25 AM, Rakhi Khatwani wrote:

> Hi,
>        Whats the difference between a mapper and map runnable and its
> usage?

MapRunnable has more control. It has the iterator to the input keys/ 
values...

The new Map-Reduce api (context objects, available in hadoop-0.20  
onwards) you have both MapRunnable and ReduceRunnable.

Arun

From common-user-return-17156-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 19:04:39 2009
Return-Path: <common-user-return-17156-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 18855 invoked from network); 28 Aug 2009 19:04:39 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 19:04:39 -0000
Received: (qmail 3052 invoked by uid 500); 28 Aug 2009 19:04:36 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 2968 invoked by uid 500); 28 Aug 2009 19:04:36 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 2958 invoked by uid 99); 28 Aug 2009 19:04:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 19:04:36 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [67.195.23.90] (HELO web112103.mail.gq1.yahoo.com) (67.195.23.90)
    by apache.org (qpsmtpd/0.29) with SMTP; Fri, 28 Aug 2009 19:04:25 +0000
Received: (qmail 6611 invoked by uid 60001); 28 Aug 2009 19:04:03 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1251486243; bh=O+GS5VQ4HCBDuyvLDaqklj680iym9piiVoLHYhq048s=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=K1S1EquFD2mJ6tMKr3FQ7yG19+iHU6WjJ5GjcZFoJKgAB7rqTo2CQhX+QFQ0EIEuoN8vqOb4ioZJ6VXknjhjpLT5oSTHZm5NQ8eT9jBAhV5ejwxlapFl5xxf+9nP8a/QVZfyD9DMOuiM/nFZXSnHOrIsjlvBXTaoWnPCSnADt14=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=zW98SHA6/vhQUWPAsLIRuDAz3c9MYoDX4AkStm7SeJY2ve1A+uC9aL/uRbpXYcxBPugBnOuCzLircvEXdivTy0eDyjEyzm/ncpd7zgMY2tAZ7pQ7FSqFrhJBwW0cfU2olycik1nCc39pkiuS9VSxs1zgFGpbnrQS5oOv/np40c8=;
Message-ID: <133615.5831.qm@web112103.mail.gq1.yahoo.com>
X-YMail-OSG: T.O690MVM1m6WuW2aKFDdyCAq1OVoIojtmkszlj3CFROljsNvgqXnQcfZDzn3F7aHCfL8dwPouwYTJX8bjRFg_6t7X0hvDuV7z5fOLOQPm1oqInxCYLEZ3MwYiPUhfzcyUAS57f.opA4o2JB.ujtINLV0PDFTYdXOhj9RSQx3CgfIGYmMcac6mDhATzkohuhdRHgE2rAALAppYWKrqeuviGQoslIxIz0dGpJJn3g7I9.uM3VwQMx6.oFwC39
Received: from [64.172.17.3] by web112103.mail.gq1.yahoo.com via HTTP; Fri, 28 Aug 2009 12:04:02 PDT
X-Mailer: YahooMailClassic/6.1.2 YahooMailWebService/0.7.338.2
Date: Fri, 28 Aug 2009 12:04:02 -0700 (PDT)
From: Steve Gao <steve.gao@yahoo.com>
Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
To: common-user@hadoop.apache.org
In-Reply-To: <C7A7AEF8-9878-4408-8F63-DF3F5F137AAF@cse.unl.edu>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-1767985075-1251486242=:5831"
X-Virus-Checked: Checked by ClamAV on apache.org

--0-1767985075-1251486242=:5831
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

Thanks, Brian. Would you tell me what is the filename of the code snippet?

--- On Fri, 8/28/09, Brian Bockelman <bbockelm@cse.unl.edu> wrote:

From: Brian Bockelman <bbockelm@cse.unl.edu>
Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
To: common-user@hadoop.apache.org
Date: Friday, August 28, 2009, 2:37 PM

Actually, poking the code, it seems that the streaming package does set thi=
s value:

=A0 =A0 String tmp =3D jobConf_.get("stream.tmpdir"); //, "/tmp/${user.name=
}/"

Try setting stream.tmpdir to a different directory maybe?

Brian

On Aug 28, 2009, at 1:31 PM, Steve Gao wrote:

> Thanks lot, Brian. It seems to be a design flaw of hadoop that it can not=
 manage (or pass in) the temp of "java.util.zip". Can we create a jira tick=
et for this?
>=20
> --- On Fri, 8/28/09, Brian Bockelman <bbockelm@cse.unl.edu> wrote:
>=20
> From: Brian Bockelman <bbockelm@cse.unl.edu>
> Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
> To:
> Cc: common-user@hadoop.apache.org
> Date: Friday, August 28, 2009, 2:27 PM
>=20
> Hey Steve,
>=20
> Correct, java.util.zip.* does not necessarily respect hadoop settings.
>=20
> Try setting TMPDIR in the environment to your large local disk space.=A0 =
It might respect that, if Java decides to act like a unix utility.
>=20
> http://en.wikipedia.org/wiki/TMPDIR
>=20
> Brian
>=20
> On Aug 28, 2009, at 1:19 PM, Steve Gao wrote:
>=20
>> would someone give us a hint? Thanks.
>> Why "java.util.zip.ZipOutputStream" need to use /tmp?
>>=20
>> The hadoop version is 0.18.3 . Recently we got "out of space" issue. It'=
s from "java.util.zip.ZipOutputStream".
>> We found that /tmp is full and after cleaning /tmp the problem is solved=
.
>>=20
>> However why hadoop needs to use /tmp? We had already configured hadoop t=
mp to a local disk in: hadoop-site.xml
>>=20
>> <property>
>>=A0 =A0 <name>hadoop.tmp.dir</name>
>>=A0 =A0 <value> ... some large local disk ... </value>
>> </property>
>>=20
>>=20
>> Could it because java.util.zip.ZipOutputStream uses /tmp even if we conf=
igured hadoop.tmp.dir to a large local disk?
>>=20
>> The error log is here FYI:
>>=20
>> java.io.IOException: No space left on device
>> at java.io.FileOutputStream.write(Native Method)
>>=A0=A0=A0at java.util.zip.ZipOutputStream.writeInt(ZipOutputStream.java:4=
45)
>> at java.util.zip.ZipOutputStream.writeEXT(ZipOutputStream.java:362)
>> at java.util.zip.ZipOutputStream.closeEntry(ZipOutputStream.java:220)
>> at java.util.zip.ZipOutputStream.finish(ZipOutputStream.java:301)
>> at java.util.zip.DeflaterOutputStream.close(DeflaterOutputStream.java:14=
6)
>> at java.util.zip.ZipOutputStream.close(ZipOutputStream.java:321)
>> at org.apache.hadoop.streaming.JarBuilder.merge(JarBuilder.java:79)
>> at org.apache.hadoop.streaming.StreamJob.packageJobJar(StreamJob.java:62=
8)
>> at org.apache.hadoop.streaming.StreamJob.setJobConf(StreamJob.java:843)
>> at org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:110)
>> at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java=
:33)
>> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>> at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.=
java:39)
>> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces=
sorImpl.java:25)
>> at java.lang.reflect.Method.invoke(Method.java:597)
>> at org.apache.hadoop.util.RunJar.main(RunJar.java:155)
>> at org.apache.hadoop.mapred.JobShell.run(JobShell.java:194)
>> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
>> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
>> at org.apache.hadoop.mapred.JobShell.main(JobShell.java:220)
>> Executing Hadoop job failure
>>=20
>>=20
>>=20
>>=20
>>=20
>>=20
>>=20
>=20
>=20
>=20
>=20

=0A=0A=0A      
--0-1767985075-1251486242=:5831--

From common-user-return-17157-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 19:07:30 2009
Return-Path: <common-user-return-17157-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 19502 invoked from network); 28 Aug 2009 19:07:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 19:07:30 -0000
Received: (qmail 9238 invoked by uid 500); 28 Aug 2009 19:07:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 9153 invoked by uid 500); 28 Aug 2009 19:07:28 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 9143 invoked by uid 99); 28 Aug 2009 19:07:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 19:07:28 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [129.93.181.2] (HELO mathstat.unl.edu) (129.93.181.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 19:07:17 +0000
Received: from pcp089093pcs.unl.edu (pcp089093pcs.unl.edu [129.93.158.208])
	(authenticated bits=0)
	by mathstat.unl.edu (8.13.8/8.13.8) with ESMTP id n7SJ6rke028102
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 14:06:56 -0500
Message-Id: <8A401328-A0B0-4815-8FD6-FF06D62804FA@cse.unl.edu>
From: Brian Bockelman <bbockelm@cse.unl.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <133615.5831.qm@web112103.mail.gq1.yahoo.com>
Content-Type: multipart/signed; boundary=Apple-Mail-30-448790506; micalg=sha1; protocol="application/pkcs7-signature"
Mime-Version: 1.0 (Apple Message framework v936)
Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
Date: Fri, 28 Aug 2009 14:06:53 -0500
References: <133615.5831.qm@web112103.mail.gq1.yahoo.com>
X-Mailer: Apple Mail (2.936)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-30-448790506
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed;
	delsp=yes
Content-Transfer-Encoding: 7bit

I saw this in:

>> org.apache.hadoop.streaming.StreamJob.packageJobJar

Brian

On Aug 28, 2009, at 2:04 PM, Steve Gao wrote:

> Thanks, Brian. Would you tell me what is the filename of the code  
> snippet?
>
> --- On Fri, 8/28/09, Brian Bockelman <bbockelm@cse.unl.edu> wrote:
>
> From: Brian Bockelman <bbockelm@cse.unl.edu>
> Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use / 
> tmp?
> To: common-user@hadoop.apache.org
> Date: Friday, August 28, 2009, 2:37 PM
>
> Actually, poking the code, it seems that the streaming package does  
> set this value:
>
>     String tmp = jobConf_.get("stream.tmpdir"); //, "/tmp/$ 
> {user.name}/"
>
> Try setting stream.tmpdir to a different directory maybe?
>
> Brian
>
> On Aug 28, 2009, at 1:31 PM, Steve Gao wrote:
>
>> Thanks lot, Brian. It seems to be a design flaw of hadoop that it  
>> can not manage (or pass in) the temp of "java.util.zip". Can we  
>> create a jira ticket for this?
>>
>> --- On Fri, 8/28/09, Brian Bockelman <bbockelm@cse.unl.edu> wrote:
>>
>> From: Brian Bockelman <bbockelm@cse.unl.edu>
>> Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to  
>> use /tmp?
>> To:
>> Cc: common-user@hadoop.apache.org
>> Date: Friday, August 28, 2009, 2:27 PM
>>
>> Hey Steve,
>>
>> Correct, java.util.zip.* does not necessarily respect hadoop  
>> settings.
>>
>> Try setting TMPDIR in the environment to your large local disk  
>> space.  It might respect that, if Java decides to act like a unix  
>> utility.
>>
>> http://en.wikipedia.org/wiki/TMPDIR
>>
>> Brian
>>
>> On Aug 28, 2009, at 1:19 PM, Steve Gao wrote:
>>
>>> would someone give us a hint? Thanks.
>>> Why "java.util.zip.ZipOutputStream" need to use /tmp?
>>>
>>> The hadoop version is 0.18.3 . Recently we got "out of space"  
>>> issue. It's from "java.util.zip.ZipOutputStream".
>>> We found that /tmp is full and after cleaning /tmp the problem is  
>>> solved.
>>>
>>> However why hadoop needs to use /tmp? We had already configured  
>>> hadoop tmp to a local disk in: hadoop-site.xml
>>>
>>> <property>
>>>     <name>hadoop.tmp.dir</name>
>>>     <value> ... some large local disk ... </value>
>>> </property>
>>>
>>>
>>> Could it because java.util.zip.ZipOutputStream uses /tmp even if  
>>> we configured hadoop.tmp.dir to a large local disk?
>>>
>>> The error log is here FYI:
>>>
>>> java.io.IOException: No space left on device
>>> at java.io.FileOutputStream.write(Native Method)
>>>    at java.util.zip.ZipOutputStream.writeInt(ZipOutputStream.java: 
>>> 445)
>>> at java.util.zip.ZipOutputStream.writeEXT(ZipOutputStream.java:362)
>>> at java.util.zip.ZipOutputStream.closeEntry(ZipOutputStream.java: 
>>> 220)
>>> at java.util.zip.ZipOutputStream.finish(ZipOutputStream.java:301)
>>> at  
>>> java.util.zip.DeflaterOutputStream.close(DeflaterOutputStream.java: 
>>> 146)
>>> at java.util.zip.ZipOutputStream.close(ZipOutputStream.java:321)
>>> at org.apache.hadoop.streaming.JarBuilder.merge(JarBuilder.java:79)
>>> at  
>>> org.apache.hadoop.streaming.StreamJob.packageJobJar(StreamJob.java: 
>>> 628)
>>> at org.apache.hadoop.streaming.StreamJob.setJobConf(StreamJob.java: 
>>> 843)
>>> at org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:110)
>>> at  
>>> org 
>>> .apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java: 
>>> 33)
>>> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>>> at  
>>> sun 
>>> .reflect 
>>> .NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
>>> at  
>>> sun 
>>> .reflect 
>>> .DelegatingMethodAccessorImpl 
>>> .invoke(DelegatingMethodAccessorImpl.java:25)
>>> at java.lang.reflect.Method.invoke(Method.java:597)
>>> at org.apache.hadoop.util.RunJar.main(RunJar.java:155)
>>> at org.apache.hadoop.mapred.JobShell.run(JobShell.java:194)
>>> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
>>> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
>>> at org.apache.hadoop.mapred.JobShell.main(JobShell.java:220)
>>> Executing Hadoop job failure
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>
>
>
>


--Apple-Mail-30-448790506
Content-Disposition: attachment;
	filename=smime.p7s
Content-Type: application/pkcs7-signature;
	name=smime.p7s
Content-Transfer-Encoding: base64
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--Apple-Mail-30-448790506--

From common-user-return-17158-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 19:32:14 2009
Return-Path: <common-user-return-17158-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 24597 invoked from network); 28 Aug 2009 19:32:14 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 19:32:14 -0000
Received: (qmail 36949 invoked by uid 500); 28 Aug 2009 19:32:12 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 36878 invoked by uid 500); 28 Aug 2009 19:32:12 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 36868 invoked by uid 99); 28 Aug 2009 19:32:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 19:32:11 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [128.2.11.95] (HELO smtp.andrew.cmu.edu) (128.2.11.95)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 19:32:02 +0000
Received: from CMU-255281.WV.CC.CMU.EDU (CMU-255281.WV.CC.CMU.EDU [128.237.231.32])
	(user=jcipar mech=PLAIN (0 bits))
	by smtp.andrew.cmu.edu (8.14.3/8.14.3) with ESMTP id n7SJUhjl009330
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 15:31:40 -0400
Message-Id: <54CB5104-DC7A-4013-BFB2-C364F0D5C3AB@andrew.cmu.edu>
From: James Cipar <jcipar@andrew.cmu.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <133615.5831.qm@web112103.mail.gq1.yahoo.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v935.3)
Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
Date: Fri, 28 Aug 2009 15:31:40 -0400
References: <133615.5831.qm@web112103.mail.gq1.yahoo.com>
X-Mailer: Apple Mail (2.935.3)
X-PMX-Version: 5.5.5.374460, Antispam-Engine: 2.7.1.369594, Antispam-Data: 2009.8.28.191823
X-SMTP-Spam-Clean: 8% (
 BODY_SIZE_4000_4999 0, BODY_SIZE_5000_LESS 0, BODY_SIZE_7000_LESS 0, TO_NO_NAME 0, __BOUNCE_CHALLENGE_SUBJ 0, __CP_URI_IN_BODY 0, __CT 0, __CTE 0, __CT_TEXT_PLAIN 0, __HAS_MSGID 0, __HAS_X_MAILER 0, __MIME_TEXT_ONLY 0, __MIME_VERSION 0, __MSGID_APPLEMAIL 0, __SANE_MSGID 0, __TO_MALFORMED_2 0)
X-SMTP-Spam-Score: 8%
X-Scanned-By: MIMEDefang 2.60 on 128.2.11.95
X-Virus-Checked: Checked by ClamAV on apache.org


I would agree with removing it from the default build for now.

I only used thrift because that's what we were using for all of the
RPC at the time.  I'd rather that we just settle on one RPC to rule
them all, and I will change the code accordingly.


On Aug 28, 2009, at 3:04 PM, Steve Gao wrote:

> Thanks, Brian. Would you tell me what is the filename of the code  
> snippet?
>
> --- On Fri, 8/28/09, Brian Bockelman <bbockelm@cse.unl.edu> wrote:
>
> From: Brian Bockelman <bbockelm@cse.unl.edu>
> Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use / 
> tmp?
> To: common-user@hadoop.apache.org
> Date: Friday, August 28, 2009, 2:37 PM
>
> Actually, poking the code, it seems that the streaming package does  
> set this value:
>
>     String tmp = jobConf_.get("stream.tmpdir"); //, "/tmp/$ 
> {user.name}/"
>
> Try setting stream.tmpdir to a different directory maybe?
>
> Brian
>
> On Aug 28, 2009, at 1:31 PM, Steve Gao wrote:
>
>> Thanks lot, Brian. It seems to be a design flaw of hadoop that it  
>> can not manage (or pass in) the temp of "java.util.zip". Can we  
>> create a jira ticket for this?
>>
>> --- On Fri, 8/28/09, Brian Bockelman <bbockelm@cse.unl.edu> wrote:
>>
>> From: Brian Bockelman <bbockelm@cse.unl.edu>
>> Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to  
>> use /tmp?
>> To:
>> Cc: common-user@hadoop.apache.org
>> Date: Friday, August 28, 2009, 2:27 PM
>>
>> Hey Steve,
>>
>> Correct, java.util.zip.* does not necessarily respect hadoop  
>> settings.
>>
>> Try setting TMPDIR in the environment to your large local disk  
>> space.  It might respect that, if Java decides to act like a unix  
>> utility.
>>
>> http://en.wikipedia.org/wiki/TMPDIR
>>
>> Brian
>>
>> On Aug 28, 2009, at 1:19 PM, Steve Gao wrote:
>>
>>> would someone give us a hint? Thanks.
>>> Why "java.util.zip.ZipOutputStream" need to use /tmp?
>>>
>>> The hadoop version is 0.18.3 . Recently we got "out of space"  
>>> issue. It's from "java.util.zip.ZipOutputStream".
>>> We found that /tmp is full and after cleaning /tmp the problem is  
>>> solved.
>>>
>>> However why hadoop needs to use /tmp? We had already configured  
>>> hadoop tmp to a local disk in: hadoop-site.xml
>>>
>>> <property>
>>>     <name>hadoop.tmp.dir</name>
>>>     <value> ... some large local disk ... </value>
>>> </property>
>>>
>>>
>>> Could it because java.util.zip.ZipOutputStream uses /tmp even if  
>>> we configured hadoop.tmp.dir to a large local disk?
>>>
>>> The error log is here FYI:
>>>
>>> java.io.IOException: No space left on device
>>> at java.io.FileOutputStream.write(Native Method)
>>>    at java.util.zip.ZipOutputStream.writeInt(ZipOutputStream.java: 
>>> 445)
>>> at java.util.zip.ZipOutputStream.writeEXT(ZipOutputStream.java:362)
>>> at java.util.zip.ZipOutputStream.closeEntry(ZipOutputStream.java: 
>>> 220)
>>> at java.util.zip.ZipOutputStream.finish(ZipOutputStream.java:301)
>>> at  
>>> java.util.zip.DeflaterOutputStream.close(DeflaterOutputStream.java: 
>>> 146)
>>> at java.util.zip.ZipOutputStream.close(ZipOutputStream.java:321)
>>> at org.apache.hadoop.streaming.JarBuilder.merge(JarBuilder.java:79)
>>> at  
>>> org.apache.hadoop.streaming.StreamJob.packageJobJar(StreamJob.java: 
>>> 628)
>>> at org.apache.hadoop.streaming.StreamJob.setJobConf(StreamJob.java: 
>>> 843)
>>> at org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:110)
>>> at  
>>> org 
>>> .apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java: 
>>> 33)
>>> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>>> at  
>>> sun 
>>> .reflect 
>>> .NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
>>> at  
>>> sun 
>>> .reflect 
>>> .DelegatingMethodAccessorImpl 
>>> .invoke(DelegatingMethodAccessorImpl.java:25)
>>> at java.lang.reflect.Method.invoke(Method.java:597)
>>> at org.apache.hadoop.util.RunJar.main(RunJar.java:155)
>>> at org.apache.hadoop.mapred.JobShell.run(JobShell.java:194)
>>> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
>>> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
>>> at org.apache.hadoop.mapred.JobShell.main(JobShell.java:220)
>>> Executing Hadoop job failure
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>
>
>
>


From common-user-return-17159-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 19:32:50 2009
Return-Path: <common-user-return-17159-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 24770 invoked from network); 28 Aug 2009 19:32:50 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 19:32:50 -0000
Received: (qmail 39891 invoked by uid 500); 28 Aug 2009 19:32:47 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 39815 invoked by uid 500); 28 Aug 2009 19:32:47 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 39797 invoked by uid 99); 28 Aug 2009 19:32:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 19:32:47 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [128.2.11.95] (HELO smtp.andrew.cmu.edu) (128.2.11.95)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 28 Aug 2009 19:32:38 +0000
Received: from CMU-255281.WV.CC.CMU.EDU (CMU-255281.WV.CC.CMU.EDU [128.237.231.32])
	(user=jcipar mech=PLAIN (0 bits))
	by smtp.andrew.cmu.edu (8.14.3/8.14.3) with ESMTP id n7SJUhjn009330
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NOT)
	for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 15:32:17 -0400
Message-Id: <D7AE9147-B145-4870-B26A-B9CEC0FECFCB@andrew.cmu.edu>
From: James Cipar <jcipar@andrew.cmu.edu>
To: common-user@hadoop.apache.org
In-Reply-To: <133615.5831.qm@web112103.mail.gq1.yahoo.com>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Apple Message framework v935.3)
Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use /tmp?
Date: Fri, 28 Aug 2009 15:32:16 -0400
References: <133615.5831.qm@web112103.mail.gq1.yahoo.com>
X-Mailer: Apple Mail (2.935.3)
X-PMX-Version: 5.5.5.374460, Antispam-Engine: 2.7.1.369594, Antispam-Data: 2009.8.28.191823
X-SMTP-Spam-Clean: 8% (
 BODY_SIZE_4000_4999 0, BODY_SIZE_5000_LESS 0, BODY_SIZE_7000_LESS 0, TO_NO_NAME 0, __BOUNCE_CHALLENGE_SUBJ 0, __CP_URI_IN_BODY 0, __CT 0, __CTE 0, __CT_TEXT_PLAIN 0, __HAS_MSGID 0, __HAS_X_MAILER 0, __MIME_TEXT_ONLY 0, __MIME_VERSION 0, __MSGID_APPLEMAIL 0, __SANE_MSGID 0, __TO_MALFORMED_2 0)
X-SMTP-Spam-Score: 8%
X-Scanned-By: MIMEDefang 2.60 on 128.2.11.95
X-Virus-Checked: Checked by ClamAV on apache.org

Sorry that last one, I replied to the wrong message.



On Aug 28, 2009, at 3:04 PM, Steve Gao wrote:

> Thanks, Brian. Would you tell me what is the filename of the code  
> snippet?
>
> --- On Fri, 8/28/09, Brian Bockelman <bbockelm@cse.unl.edu> wrote:
>
> From: Brian Bockelman <bbockelm@cse.unl.edu>
> Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to use / 
> tmp?
> To: common-user@hadoop.apache.org
> Date: Friday, August 28, 2009, 2:37 PM
>
> Actually, poking the code, it seems that the streaming package does  
> set this value:
>
>     String tmp = jobConf_.get("stream.tmpdir"); //, "/tmp/$ 
> {user.name}/"
>
> Try setting stream.tmpdir to a different directory maybe?
>
> Brian
>
> On Aug 28, 2009, at 1:31 PM, Steve Gao wrote:
>
>> Thanks lot, Brian. It seems to be a design flaw of hadoop that it  
>> can not manage (or pass in) the temp of "java.util.zip". Can we  
>> create a jira ticket for this?
>>
>> --- On Fri, 8/28/09, Brian Bockelman <bbockelm@cse.unl.edu> wrote:
>>
>> From: Brian Bockelman <bbockelm@cse.unl.edu>
>> Subject: Re: [Help] Why "java.util.zip.ZipOutputStream" need to  
>> use /tmp?
>> To:
>> Cc: common-user@hadoop.apache.org
>> Date: Friday, August 28, 2009, 2:27 PM
>>
>> Hey Steve,
>>
>> Correct, java.util.zip.* does not necessarily respect hadoop  
>> settings.
>>
>> Try setting TMPDIR in the environment to your large local disk  
>> space.  It might respect that, if Java decides to act like a unix  
>> utility.
>>
>> http://en.wikipedia.org/wiki/TMPDIR
>>
>> Brian
>>
>> On Aug 28, 2009, at 1:19 PM, Steve Gao wrote:
>>
>>> would someone give us a hint? Thanks.
>>> Why "java.util.zip.ZipOutputStream" need to use /tmp?
>>>
>>> The hadoop version is 0.18.3 . Recently we got "out of space"  
>>> issue. It's from "java.util.zip.ZipOutputStream".
>>> We found that /tmp is full and after cleaning /tmp the problem is  
>>> solved.
>>>
>>> However why hadoop needs to use /tmp? We had already configured  
>>> hadoop tmp to a local disk in: hadoop-site.xml
>>>
>>> <property>
>>>     <name>hadoop.tmp.dir</name>
>>>     <value> ... some large local disk ... </value>
>>> </property>
>>>
>>>
>>> Could it because java.util.zip.ZipOutputStream uses /tmp even if  
>>> we configured hadoop.tmp.dir to a large local disk?
>>>
>>> The error log is here FYI:
>>>
>>> java.io.IOException: No space left on device
>>> at java.io.FileOutputStream.write(Native Method)
>>>    at java.util.zip.ZipOutputStream.writeInt(ZipOutputStream.java: 
>>> 445)
>>> at java.util.zip.ZipOutputStream.writeEXT(ZipOutputStream.java:362)
>>> at java.util.zip.ZipOutputStream.closeEntry(ZipOutputStream.java: 
>>> 220)
>>> at java.util.zip.ZipOutputStream.finish(ZipOutputStream.java:301)
>>> at  
>>> java.util.zip.DeflaterOutputStream.close(DeflaterOutputStream.java: 
>>> 146)
>>> at java.util.zip.ZipOutputStream.close(ZipOutputStream.java:321)
>>> at org.apache.hadoop.streaming.JarBuilder.merge(JarBuilder.java:79)
>>> at  
>>> org.apache.hadoop.streaming.StreamJob.packageJobJar(StreamJob.java: 
>>> 628)
>>> at org.apache.hadoop.streaming.StreamJob.setJobConf(StreamJob.java: 
>>> 843)
>>> at org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:110)
>>> at  
>>> org 
>>> .apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java: 
>>> 33)
>>> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>>> at  
>>> sun 
>>> .reflect 
>>> .NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
>>> at  
>>> sun 
>>> .reflect 
>>> .DelegatingMethodAccessorImpl 
>>> .invoke(DelegatingMethodAccessorImpl.java:25)
>>> at java.lang.reflect.Method.invoke(Method.java:597)
>>> at org.apache.hadoop.util.RunJar.main(RunJar.java:155)
>>> at org.apache.hadoop.mapred.JobShell.run(JobShell.java:194)
>>> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
>>> at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
>>> at org.apache.hadoop.mapred.JobShell.main(JobShell.java:220)
>>> Executing Hadoop job failure
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>
>
>
>


From common-user-return-17160-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Fri Aug 28 20:55:32 2009
Return-Path: <common-user-return-17160-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 58040 invoked from network); 28 Aug 2009 20:55:32 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 28 Aug 2009 20:55:32 -0000
Received: (qmail 26839 invoked by uid 500); 28 Aug 2009 20:55:30 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26759 invoked by uid 500); 28 Aug 2009 20:55:29 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Delivered-To: moderator for common-user@hadoop.apache.org
Received: (qmail 9118 invoked by uid 99); 28 Aug 2009 20:38:01 -0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of gaurav.gs.sharma@gmail.com designates 209.85.219.218 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:cc:content-type;
        bh=YeaFzW0P5mWo9YF+kDNVBOt25YW7tqGntnIPkSC1J+E=;
        b=igTAs4OkUPV1lVrM6xZw/vqtQDsV/50R1fOLcE1e1tMu6mJevjv8LLKR6tgy6JbyKG
         0LBB/cEI/3qPtBXKX8cmThLgj6OsmjV9HUybNvhjY61pkjxfpaAF2QC0DzVaGtSqyOkC
         tDywafQjSToSL+tZ0jDR/fjR09EPn45XuOofw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        b=nbBV3V7FZjm16dKq0w/s5JlQInV5OtqD+98l4EU7Kqvh2BkcuLiyi6B/T2mcNn/Qvr
         +QUG2aBf5OeaQ1+NvDGPucsiI/Qs6uH4/jXy9YGNVipuAV/2GEYtqOLJ2ys3nzhDTiYc
         /j6b0PgpMC+goA09IAkIg9WyNlp78GWpgqge8=
MIME-Version: 1.0
In-Reply-To: <427969.1418.qm@web59712.mail.ac4.yahoo.com>
References: <427969.1418.qm@web59712.mail.ac4.yahoo.com>
From: Gaurav Sharma <gaurav.gs.sharma@gmail.com>
Date: Fri, 28 Aug 2009 15:36:45 -0500
Message-ID: <8f54e0b0908281336u47bbd097rafe468348c8b3e2e@mail.gmail.com>
Subject: Re: Who are the major contributors to Hive and/or Hbase?
To: Gopal Gandhi <gopal.gandhi2008@yahoo.com>
Cc: common-user@hadoop.apache.org, common-dev@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00504502d0d4acd3dc047239a59d
X-Virus-Checked: Checked by ClamAV on apache.org

--00504502d0d4acd3dc047239a59d
Content-Type: text/plain; charset=ISO-8859-1

Hope this helps:
  http://hadoop.apache.org/hive/credits.html
  http://hadoop.apache.org/hbase/credits.html


On Fri, Aug 28, 2009 at 1:26 PM, Gopal Gandhi <gopal.gandhi2008@yahoo.com>wrote:

> May be I should change the title?
>
> --- On Fri, 8/28/09, Gopal Gandhi <gopal.gandhi2008@yahoo.com> wrote:
>
>
> From: Gopal Gandhi <gopal.gandhi2008@yahoo.com>
> Subject: Who are the gurus in Hive and/or Hbase?
> To: common-user@hadoop.apache.org, common-dev@hadoop.apache.org
> Cc: common-dev@hadoop.apache.org
> Date: Friday, August 28, 2009, 6:25 PM
>
>
>
>
>
>
>
> We are inviting gurus or major contributors of Hive and/or Hbase (or
> anything related to Hadoop) to give us presentations about the products.
> Would you name a few names? The gurus must be in bay area.
> Thanks.
>
>
>
>

--00504502d0d4acd3dc047239a59d--

From common-user-return-17161-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 29 00:51:27 2009
Return-Path: <common-user-return-17161-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 29957 invoked from network); 29 Aug 2009 00:51:27 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 29 Aug 2009 00:51:27 -0000
Received: (qmail 73567 invoked by uid 500); 29 Aug 2009 00:51:25 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 73496 invoked by uid 500); 29 Aug 2009 00:51:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 73486 invoked by uid 99); 29 Aug 2009 00:51:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 00:51:24 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [74.125.92.24] (HELO qw-out-2122.google.com) (74.125.92.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 00:51:15 +0000
Received: by qw-out-2122.google.com with SMTP id 8so621138qwh.35
        for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 17:50:54 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.224.50.81 with SMTP id y17mr1712471qaf.109.1251507054340; Fri, 
	28 Aug 2009 17:50:54 -0700 (PDT)
In-Reply-To: <4A9802A3.2010603@yahoo-inc.com>
References: <4A95CA58.3030608@yahoo-inc.com> <314098690908260729kbb8b5bch4ac0b3b51b559c04@mail.gmail.com> 
	<4A9802A3.2010603@yahoo-inc.com>
From: Aaron Kimball <aaron@cloudera.com>
Date: Fri, 28 Aug 2009 17:50:34 -0700
Message-ID: <d6d7c4410908281750x3fd09765oefc48dc8796b2456@mail.gmail.com>
Subject: Re: Testing Hadoop job
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016361377ea686f5104723d3125
X-Virus-Checked: Checked by ClamAV on apache.org

--0016361377ea686f5104723d3125
Content-Type: text/plain; charset=ISO-8859-1

Hi Nikhil,

MRUnit now supports the 0.20 API as of
https://issues.apache.org/jira/browse/MAPREDUCE-800. There are no plans to
involve partitioners in MRUnit; it is for mappers and reducers only, and not
for full jobs involving input/output formats, partitioners, etc. Use the
LocalJobRunner for that.

See www.cloudera.com/hadoop-mrunit for more (slightly out-of-date)
information.
- Aaron

On Fri, Aug 28, 2009 at 9:15 AM, Nikhil Sawant <nsawant@yahoo-inc.com>wrote:

> hi
> thanks Jason, for prompt reply i will go through "pro hadoop". already on
> my to-do list
>
> any idea abt the MRUnit??? has anyone used it?
> i think it is useful as it allows dummy map and reduce drivers which
> accepts (K,V) pair/s and checks the o/p (K,V) pair/s with the expected
> (K,V)......it gives gr8 debugging capabilities while implementing complex
> logics. (all "System.outs" can be seen on console itself!!)
> i have used the basic functionalities of MRUnit testing framework
> i would like to know the limitations (e.g. i found out that MRUnit does not
> check the partioner logic) and its feasibility with hadoop 0.20...
> No proper documentation i found ! :(
>
> cheers
> nikhil
>
>
> Jason Venner wrote:
>
>> I put together a framework for the Pro Hadoop book that I use quite a bit,
>> and has some documentation in the book examples ;)
>> I haven't tried it with 0.20.0 however.
>>
>> The nicest thing that I did with the framework was provide a way to run a
>> persistent mini virtual cluster for running multiple tests on.
>>
>> On Wed, Aug 26, 2009 at 4:50 PM, Nikhil Sawant <nsawant@yahoo-inc.com
>> >wrote:
>>
>>
>>
>>> hi
>>>
>>> can u guys suggest some hadoop unit testing framework apart from
>>> MRUnit???
>>> i have used MRUnit but i m not sure abt its feasibilty and support to
>>> hadoop 0.20.....
>>> i could not find a proper documentation for MRUnit, is it available
>>> anywhere?
>>>
>>> --
>>> cheers
>>> nikhil
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>

--0016361377ea686f5104723d3125--

From common-user-return-17162-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 29 01:59:12 2009
Return-Path: <common-user-return-17162-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 40927 invoked from network); 29 Aug 2009 01:59:12 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 29 Aug 2009 01:59:12 -0000
Received: (qmail 98998 invoked by uid 500); 29 Aug 2009 01:59:10 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 98923 invoked by uid 500); 29 Aug 2009 01:59:10 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 98913 invoked by uid 500); 29 Aug 2009 01:59:09 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 98910 invoked by uid 99); 29 Aug 2009 01:59:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 01:59:09 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 01:58:59 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MhDDC-0003h4-Sd
	for core-user@hadoop.apache.org; Fri, 28 Aug 2009 18:58:38 -0700
Message-ID: <25199284.post@talk.nabble.com>
Date: Fri, 28 Aug 2009 18:58:38 -0700 (PDT)
From: indoos <indoos@gmail.com>
To: core-user@hadoop.apache.org
Subject: Re: Where does System.out.println() go?
In-Reply-To: <c9b0d8bd0908241822u1987a610wf87ed64eef22f53b@mail.gmail.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: indoos@gmail.com
References: <c9b0d8bd0908241822u1987a610wf87ed64eef22f53b@mail.gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org


Hi, sysout for Map Reduce should be visible in 50030 task tracker UI against
the individual Map Reduce tasks for executed JOB. This UI anyways uses the
individual logs created against each attempt in logs/userlogs/attempt****
folders.
Regards,Sanjay
 

Mark Kerzner-2 wrote:
> 
> Hi,
> 
> when I run Hadoop in pseudo-distributed mode, I can't find the log which
> System.out.println() goes.
> 
> When I run in the IDE, I see it. When I run on EC2, it's part of the
> output
> logs. But here - do I need to set something up?
> 
> Thank you,
> Mark
> 
> 

-- 
View this message in context: http://www.nabble.com/Where-does-System.out.println%28%29-go--tp25126757p25199284.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-17163-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 29 02:11:47 2009
Return-Path: <common-user-return-17163-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 42936 invoked from network); 29 Aug 2009 02:11:46 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 29 Aug 2009 02:11:46 -0000
Received: (qmail 3774 invoked by uid 500); 29 Aug 2009 02:11:44 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 3681 invoked by uid 500); 29 Aug 2009 02:11:44 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 3670 invoked by uid 99); 29 Aug 2009 02:11:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 02:11:44 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rvernica@gmail.com designates 209.85.222.174 as permitted sender)
Received: from [209.85.222.174] (HELO mail-pz0-f174.google.com) (209.85.222.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 02:11:35 +0000
Received: by pzk4 with SMTP id 4so2499303pzk.29
        for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 19:11:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=TVm1HMKHi1dak9m9wB3+fBGrkJkcSvQJdHmDZ1fMTXk=;
        b=SrNbLHcq/3Yn6nPpuwlAdTcdVxGkh2R+vWX/n/BjRdUE826JlkCOiluPlGZGQoYd0S
         BDvJ0/2NbxTZf+EmWVgAnCtKLcYc+gp0ohFIXte3Hf1LUFGTBX0mMR3DbyGDFXEA8nKw
         oQi8EFSMgtAFxtyO0Hn18Vx7vyJmoGLA8maYI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=plKaE9vErRE6S7kMQYR8xdQaYjtywER6G12RRloM6/R2uNIiQ5PlqkmgYjWwGD2HMF
         a40PA9008XCnS5CQSTdLPsj5kch4xJYfHdcG/boXMyFbx6jufsjgMinPvRw163iKvMAD
         xhHWLr55qc4Usjmj/EUN0xfGs488mlIEWp/CM=
MIME-Version: 1.0
Received: by 10.140.135.8 with SMTP id i8mr927972rvd.290.1251511873771; Fri, 
	28 Aug 2009 19:11:13 -0700 (PDT)
Date: Fri, 28 Aug 2009 19:11:13 -0700
Message-ID: <b8208a3b0908281911q55f97c7bxc6d29063388c7872@mail.gmail.com>
Subject: add custom timestamps to the Job log
From: Rares Vernica <rvernica@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

The job log has some very important timestamps that show the start/end
time of various stages of a task attempt. I was wondering it it is
possible to add custom timestamps to it.

For example, for a reduce task attempt, the job job will contain something like:

ReduceAttempt TASK_TYPE="REDUCE" SHUFFLE_FINISHED="1251226468482"
SORT_FINISHED="1251226505088" FINISH_TIME="1251226513547"...

Is it possible/easy to add more timestamps, like SOMETHING_FINISHED="..."?

Thanks!
Rares Vernica

From common-user-return-17164-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 29 02:38:30 2009
Return-Path: <common-user-return-17164-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 45703 invoked from network); 29 Aug 2009 02:38:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 29 Aug 2009 02:38:30 -0000
Received: (qmail 11140 invoked by uid 500); 29 Aug 2009 02:38:28 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 11048 invoked by uid 500); 29 Aug 2009 02:38:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 11038 invoked by uid 500); 29 Aug 2009 02:38:27 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 11035 invoked by uid 99); 29 Aug 2009 02:38:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 02:38:27 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 02:38:18 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MhDpG-0004zP-2R
	for core-user@hadoop.apache.org; Fri, 28 Aug 2009 19:37:58 -0700
Message-ID: <25199508.post@talk.nabble.com>
Date: Fri, 28 Aug 2009 19:37:57 -0700 (PDT)
From: indoos <indoos@gmail.com>
To: core-user@hadoop.apache.org
Subject: Re: cost model for MR programs
In-Reply-To: <73d592f60908242000x1c2980bbjdd1053560c9d0cae@mail.gmail.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: indoos@gmail.com
References: <73d592f60908242000x1c2980bbjdd1053560c9d0cae@mail.gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org


Hi,
My suggestion would be that we should not be compelling ourselves to compare
databases with Hadoop.
However, here is something not probably even close to what you may require,
but might be helpful-
1. Number of nodes - these are the parameters to look for -
- average time taken by a single Map and Reduce task (available as part of
history-analytics), 
- Max Input file size vs block size. Lets take an example- A 6GB input file
with 64 MB block size would  ideally require ~1000 Maps. The more you want
to run these 1000 Maps in parallel, more the number of nodes. A 10 node
cluster with 10 Maps would have to run ~10 times in a kind of sequential
mode :-( 
- ultimately it is the time vs cost factor to decide the number of nodes. So
for this example, if a map takes at least 2 minutes, the ~minimum time would
be 2*10=20 minutes. Less time would mean more nodes.
- The number of Jobs that you might decide to run at the same time would
also affect the number of nodes. Effectively every individual job task
(map/reduce) runs in a sequential kind of mode waiting in the queue for the
existing/executing map/reduce block to finish. (Off course, we have some
prioritization support - this does not however help to finish everything in
parallel)
2. RAM - a general thumb rule is, 1 GB RAM each for Name Node, Job Tracker,
Secondary Name node on the masters side. On slave side- 1 GB RAM each for
task tracker and data node which leaves practically not much for good
computing on a commodity 8GB machine. The remaining 5-6 GB can then be used
for Map Reduce tasks. So with our example of running 10 Maps, we would have
at the most a Map using at max 400-500 MB heap. Anything beyond this would
require either the Maps to be reduced or the RAM to be increased.
3. Network speed- Hadoop recommends(I think I did read it
somewhere-apologies if otherwise) using at least 1 GB/s networks for the
heavy data transfer. My experiences with 100 MB/sec in even a dev env have
been disastrous
4. Hard disk- again a thumb rule- Only 1/4 memory would be effectively
available. So given a 4TB hard disk, effectively only 1 TB can be used for
real data with 2 TB used for replication (3-ideal replication factor) and 1
TB for temp usage
Regards,
Sanjay            
 

bharath vissapragada-2 wrote:
> 
> Hi all ,
> 
> Is there any general cost model that can be used to guess the run time of
> a
> program (similar to Page IO/s , selectivity factors in RDBMS) in terms of
> any config aspects such as number of nodes/page IO/s etc .
> 
> 

-- 
View this message in context: http://www.nabble.com/cost-model-for-MR-programs-tp25127531p25199508.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-17165-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 29 06:14:55 2009
Return-Path: <common-user-return-17165-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 86253 invoked from network); 29 Aug 2009 06:14:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 29 Aug 2009 06:14:55 -0000
Received: (qmail 77082 invoked by uid 500); 29 Aug 2009 06:14:50 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 77005 invoked by uid 500); 29 Aug 2009 06:14:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 76983 invoked by uid 99); 29 Aug 2009 06:14:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 06:14:49 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.221.175] (HELO mail-qy0-f175.google.com) (209.85.221.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 06:14:38 +0000
Received: by qyk5 with SMTP id 5so1705465qyk.30
        for <multiple recipients>; Fri, 28 Aug 2009 23:14:16 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.229.43.68 with SMTP id v4mr1025163qce.95.1251526456251; Fri, 
	28 Aug 2009 23:14:16 -0700 (PDT)
In-Reply-To: <25199508.post@talk.nabble.com>
References: <73d592f60908242000x1c2980bbjdd1053560c9d0cae@mail.gmail.com>
	 <25199508.post@talk.nabble.com>
Date: Fri, 28 Aug 2009 23:14:16 -0700
Message-ID: <c9118d4c0908282314l143eeca7ob670fa49acbce7fb@mail.gmail.com>
Subject: Re: cost model for MR programs
From: Jeff Hammerbacher <hammer@cloudera.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f6c360da15cf047241b5af
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f6c360da15cf047241b5af
Content-Type: text/plain; charset=ISO-8859-1

Hey Bharath,
There has been some work in the research community on predicting the runtime
of Hadoop MapReduce, Pig, and Hive jobs, though the approaches are not
always cost-based. At the University of Washington, they've worked on
progress indicators for Pig; see
ftp://ftp.cs.washington.edu/tr/2009/07/UW-CSE-09-07-01.PDF. At the
University of California, Berkeley, they've worked on predicting multiple
metrics about query progress, first in NeoView, and subsequently in Hadoop;
see http://www.cs.berkeley.edu/~archanag/publications/ICDE09.pdf for the
NeoView results.

Some preliminary design work has been done in the Hive project for
collecting statistics on Hive tables. See
https://issues.apache.org/jira/browse/HIVE-33. Any contributions to this
work would be much appreciated!

Regards,
Jeff

On Fri, Aug 28, 2009 at 7:37 PM, indoos <indoos@gmail.com> wrote:

>
> Hi,
> My suggestion would be that we should not be compelling ourselves to
> compare
> databases with Hadoop.
> However, here is something not probably even close to what you may require,
> but might be helpful-
> 1. Number of nodes - these are the parameters to look for -
> - average time taken by a single Map and Reduce task (available as part of
> history-analytics),
> - Max Input file size vs block size. Lets take an example- A 6GB input file
> with 64 MB block size would  ideally require ~1000 Maps. The more you want
> to run these 1000 Maps in parallel, more the number of nodes. A 10 node
> cluster with 10 Maps would have to run ~10 times in a kind of sequential
> mode :-(
> - ultimately it is the time vs cost factor to decide the number of nodes.
> So
> for this example, if a map takes at least 2 minutes, the ~minimum time
> would
> be 2*10=20 minutes. Less time would mean more nodes.
> - The number of Jobs that you might decide to run at the same time would
> also affect the number of nodes. Effectively every individual job task
> (map/reduce) runs in a sequential kind of mode waiting in the queue for the
> existing/executing map/reduce block to finish. (Off course, we have some
> prioritization support - this does not however help to finish everything in
> parallel)
> 2. RAM - a general thumb rule is, 1 GB RAM each for Name Node, Job Tracker,
> Secondary Name node on the masters side. On slave side- 1 GB RAM each for
> task tracker and data node which leaves practically not much for good
> computing on a commodity 8GB machine. The remaining 5-6 GB can then be used
> for Map Reduce tasks. So with our example of running 10 Maps, we would have
> at the most a Map using at max 400-500 MB heap. Anything beyond this would
> require either the Maps to be reduced or the RAM to be increased.
> 3. Network speed- Hadoop recommends(I think I did read it
> somewhere-apologies if otherwise) using at least 1 GB/s networks for the
> heavy data transfer. My experiences with 100 MB/sec in even a dev env have
> been disastrous
> 4. Hard disk- again a thumb rule- Only 1/4 memory would be effectively
> available. So given a 4TB hard disk, effectively only 1 TB can be used for
> real data with 2 TB used for replication (3-ideal replication factor) and 1
> TB for temp usage
> Regards,
> Sanjay
>
>
> bharath vissapragada-2 wrote:
> >
> > Hi all ,
> >
> > Is there any general cost model that can be used to guess the run time of
> > a
> > program (similar to Page IO/s , selectivity factors in RDBMS) in terms of
> > any config aspects such as number of nodes/page IO/s etc .
> >
> >
>
> --
> View this message in context:
> http://www.nabble.com/cost-model-for-MR-programs-tp25127531p25199508.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>
>

--001485f6c360da15cf047241b5af--

From common-user-return-17166-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 29 06:14:55 2009
Return-Path: <common-user-return-17166-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 86247 invoked from network); 29 Aug 2009 06:14:55 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 29 Aug 2009 06:14:55 -0000
Received: (qmail 77115 invoked by uid 500); 29 Aug 2009 06:14:50 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 77007 invoked by uid 500); 29 Aug 2009 06:14:50 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 76988 invoked by uid 500); 29 Aug 2009 06:14:49 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 76983 invoked by uid 99); 29 Aug 2009 06:14:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 06:14:49 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.221.175] (HELO mail-qy0-f175.google.com) (209.85.221.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 06:14:38 +0000
Received: by qyk5 with SMTP id 5so1705465qyk.30
        for <multiple recipients>; Fri, 28 Aug 2009 23:14:16 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.229.43.68 with SMTP id v4mr1025163qce.95.1251526456251; Fri, 
	28 Aug 2009 23:14:16 -0700 (PDT)
In-Reply-To: <25199508.post@talk.nabble.com>
References: <73d592f60908242000x1c2980bbjdd1053560c9d0cae@mail.gmail.com>
	 <25199508.post@talk.nabble.com>
Date: Fri, 28 Aug 2009 23:14:16 -0700
Message-ID: <c9118d4c0908282314l143eeca7ob670fa49acbce7fb@mail.gmail.com>
Subject: Re: cost model for MR programs
From: Jeff Hammerbacher <hammer@cloudera.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f6c360da15cf047241b5af
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f6c360da15cf047241b5af
Content-Type: text/plain; charset=ISO-8859-1

Hey Bharath,
There has been some work in the research community on predicting the runtime
of Hadoop MapReduce, Pig, and Hive jobs, though the approaches are not
always cost-based. At the University of Washington, they've worked on
progress indicators for Pig; see
ftp://ftp.cs.washington.edu/tr/2009/07/UW-CSE-09-07-01.PDF. At the
University of California, Berkeley, they've worked on predicting multiple
metrics about query progress, first in NeoView, and subsequently in Hadoop;
see http://www.cs.berkeley.edu/~archanag/publications/ICDE09.pdf for the
NeoView results.

Some preliminary design work has been done in the Hive project for
collecting statistics on Hive tables. See
https://issues.apache.org/jira/browse/HIVE-33. Any contributions to this
work would be much appreciated!

Regards,
Jeff

On Fri, Aug 28, 2009 at 7:37 PM, indoos <indoos@gmail.com> wrote:

>
> Hi,
> My suggestion would be that we should not be compelling ourselves to
> compare
> databases with Hadoop.
> However, here is something not probably even close to what you may require,
> but might be helpful-
> 1. Number of nodes - these are the parameters to look for -
> - average time taken by a single Map and Reduce task (available as part of
> history-analytics),
> - Max Input file size vs block size. Lets take an example- A 6GB input file
> with 64 MB block size would  ideally require ~1000 Maps. The more you want
> to run these 1000 Maps in parallel, more the number of nodes. A 10 node
> cluster with 10 Maps would have to run ~10 times in a kind of sequential
> mode :-(
> - ultimately it is the time vs cost factor to decide the number of nodes.
> So
> for this example, if a map takes at least 2 minutes, the ~minimum time
> would
> be 2*10=20 minutes. Less time would mean more nodes.
> - The number of Jobs that you might decide to run at the same time would
> also affect the number of nodes. Effectively every individual job task
> (map/reduce) runs in a sequential kind of mode waiting in the queue for the
> existing/executing map/reduce block to finish. (Off course, we have some
> prioritization support - this does not however help to finish everything in
> parallel)
> 2. RAM - a general thumb rule is, 1 GB RAM each for Name Node, Job Tracker,
> Secondary Name node on the masters side. On slave side- 1 GB RAM each for
> task tracker and data node which leaves practically not much for good
> computing on a commodity 8GB machine. The remaining 5-6 GB can then be used
> for Map Reduce tasks. So with our example of running 10 Maps, we would have
> at the most a Map using at max 400-500 MB heap. Anything beyond this would
> require either the Maps to be reduced or the RAM to be increased.
> 3. Network speed- Hadoop recommends(I think I did read it
> somewhere-apologies if otherwise) using at least 1 GB/s networks for the
> heavy data transfer. My experiences with 100 MB/sec in even a dev env have
> been disastrous
> 4. Hard disk- again a thumb rule- Only 1/4 memory would be effectively
> available. So given a 4TB hard disk, effectively only 1 TB can be used for
> real data with 2 TB used for replication (3-ideal replication factor) and 1
> TB for temp usage
> Regards,
> Sanjay
>
>
> bharath vissapragada-2 wrote:
> >
> > Hi all ,
> >
> > Is there any general cost model that can be used to guess the run time of
> > a
> > program (similar to Page IO/s , selectivity factors in RDBMS) in terms of
> > any config aspects such as number of nodes/page IO/s etc .
> >
> >
>
> --
> View this message in context:
> http://www.nabble.com/cost-model-for-MR-programs-tp25127531p25199508.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>
>

--001485f6c360da15cf047241b5af--

From common-user-return-17167-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sat Aug 29 06:20:30 2009
Return-Path: <common-user-return-17167-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 86943 invoked from network); 29 Aug 2009 06:20:30 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 29 Aug 2009 06:20:30 -0000
Received: (qmail 84093 invoked by uid 500); 29 Aug 2009 06:20:27 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 83997 invoked by uid 500); 29 Aug 2009 06:20:27 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 83987 invoked by uid 99); 29 Aug 2009 06:20:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 06:20:27 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bharathvissapragada1990@gmail.com designates 209.85.221.175 as permitted sender)
Received: from [209.85.221.175] (HELO mail-qy0-f175.google.com) (209.85.221.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 29 Aug 2009 06:20:17 +0000
Received: by qyk5 with SMTP id 5so1706512qyk.30
        for <common-user@hadoop.apache.org>; Fri, 28 Aug 2009 23:19:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=Ly3CuP1bTn9o0b+S/2fuRg5T31P/BUr1TZ13/4IxFhg=;
        b=LIpvBCEDV82l0K8/2ZBTFepPBAgTFPWW+idxGSzwO5Eu4Mrk4MBD6Lqgw5QIg/5y7T
         UOc7PLZe/1GVfdmtHpHJhOg5H2f2Jz/krmTHsyt5lZSht0a5ZClgynACZqBGhsHVjQnA
         7lPiRODPXet+wl5ENd3O+xfrnz6/qYNyX03YY=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=pfENrL5qBv1+Igqf1H9grnZey48Ima9sEvnUoD0nGFzTmKpwvSzfjqMyeQUHcAAWE5
         tHQ0PilgJVuRc7GJGkR7zuBUQ8gAqKUSQNsfaweijBW6GJnbE45DxSOpR4FuMAcN5Nl7
         ES/tFvP+6YMV3yaU3v6QhJYD6kI5NCGxfDT14=
MIME-Version: 1.0
Received: by 10.229.16.73 with SMTP id n9mr1045584qca.70.1251526796120; Fri, 
	28 Aug 2009 23:19:56 -0700 (PDT)
In-Reply-To: <c9118d4c0908282314l143eeca7ob670fa49acbce7fb@mail.gmail.com>
References: <73d592f60908242000x1c2980bbjdd1053560c9d0cae@mail.gmail.com> 
	<25199508.post@talk.nabble.com> <c9118d4c0908282314l143eeca7ob670fa49acbce7fb@mail.gmail.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Sat, 29 Aug 2009 11:49:36 +0530
Message-ID: <73d592f60908282319q232fba68raa137b35f4f7269a@mail.gmail.com>
Subject: Re: cost model for MR programs
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015175cb4ca1c1481047241ca0d
X-Virus-Checked: Checked by ClamAV on apache.org

--0015175cb4ca1c1481047241ca0d
Content-Type: text/plain; charset=ISO-8859-1

@sanjay

Thanks for your reply .. I too was thinking in the same lines .

@Jeff

I found those links very useful... iam working on similar things . Thanks
for reply! :)



On Sat, Aug 29, 2009 at 11:44 AM, Jeff Hammerbacher <hammer@cloudera.com>wrote:

> Hey Bharath,
> There has been some work in the research community on predicting the
> runtime
> of Hadoop MapReduce, Pig, and Hive jobs, though the approaches are not
> always cost-based. At the University of Washington, they've worked on
> progress indicators for Pig; see
> ftp://ftp.cs.washington.edu/tr/2009/07/UW-CSE-09-07-01.PDF. At the
> University of California, Berkeley, they've worked on predicting multiple
> metrics about query progress, first in NeoView, and subsequently in Hadoop;
> see http://www.cs.berkeley.edu/~archanag/publications/ICDE09.pdf<http://www.cs.berkeley.edu/%7Earchanag/publications/ICDE09.pdf>for the
> NeoView results.
>
> Some preliminary design work has been done in the Hive project for
> collecting statistics on Hive tables. See
> https://issues.apache.org/jira/browse/HIVE-33. Any contributions to this
> work would be much appreciated!
>
> Regards,
> Jeff
>
> On Fri, Aug 28, 2009 at 7:37 PM, indoos <indoos@gmail.com> wrote:
>
> >
> > Hi,
> > My suggestion would be that we should not be compelling ourselves to
> > compare
> > databases with Hadoop.
> > However, here is something not probably even close to what you may
> require,
> > but might be helpful-
> > 1. Number of nodes - these are the parameters to look for -
> > - average time taken by a single Map and Reduce task (available as part
> of
> > history-analytics),
> > - Max Input file size vs block size. Lets take an example- A 6GB input
> file
> > with 64 MB block size would  ideally require ~1000 Maps. The more you
> want
> > to run these 1000 Maps in parallel, more the number of nodes. A 10 node
> > cluster with 10 Maps would have to run ~10 times in a kind of sequential
> > mode :-(
> > - ultimately it is the time vs cost factor to decide the number of nodes.
> > So
> > for this example, if a map takes at least 2 minutes, the ~minimum time
> > would
> > be 2*10=20 minutes. Less time would mean more nodes.
> > - The number of Jobs that you might decide to run at the same time would
> > also affect the number of nodes. Effectively every individual job task
> > (map/reduce) runs in a sequential kind of mode waiting in the queue for
> the
> > existing/executing map/reduce block to finish. (Off course, we have some
> > prioritization support - this does not however help to finish everything
> in
> > parallel)
> > 2. RAM - a general thumb rule is, 1 GB RAM each for Name Node, Job
> Tracker,
> > Secondary Name node on the masters side. On slave side- 1 GB RAM each for
> > task tracker and data node which leaves practically not much for good
> > computing on a commodity 8GB machine. The remaining 5-6 GB can then be
> used
> > for Map Reduce tasks. So with our example of running 10 Maps, we would
> have
> > at the most a Map using at max 400-500 MB heap. Anything beyond this
> would
> > require either the Maps to be reduced or the RAM to be increased.
> > 3. Network speed- Hadoop recommends(I think I did read it
> > somewhere-apologies if otherwise) using at least 1 GB/s networks for the
> > heavy data transfer. My experiences with 100 MB/sec in even a dev env
> have
> > been disastrous
> > 4. Hard disk- again a thumb rule- Only 1/4 memory would be effectively
> > available. So given a 4TB hard disk, effectively only 1 TB can be used
> for
> > real data with 2 TB used for replication (3-ideal replication factor) and
> 1
> > TB for temp usage
> > Regards,
> > Sanjay
> >
> >
> > bharath vissapragada-2 wrote:
> > >
> > > Hi all ,
> > >
> > > Is there any general cost model that can be used to guess the run time
> of
> > > a
> > > program (similar to Page IO/s , selectivity factors in RDBMS) in terms
> of
> > > any config aspects such as number of nodes/page IO/s etc .
> > >
> > >
> >
> > --
> > View this message in context:
> >
> http://www.nabble.com/cost-model-for-MR-programs-tp25127531p25199508.html
> > Sent from the Hadoop core-user mailing list archive at Nabble.com.
> >
> >
>

--0015175cb4ca1c1481047241ca0d--

From common-user-return-17168-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 30 02:22:26 2009
Return-Path: <common-user-return-17168-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 74987 invoked from network); 30 Aug 2009 02:22:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 30 Aug 2009 02:22:26 -0000
Received: (qmail 96069 invoked by uid 500); 30 Aug 2009 02:22:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95971 invoked by uid 500); 30 Aug 2009 02:22:24 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95961 invoked by uid 99); 30 Aug 2009 02:22:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 02:22:23 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of markkerzner@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 02:22:13 +0000
Received: by bwz10 with SMTP id 10so1363232bwz.29
        for <common-user@hadoop.apache.org>; Sat, 29 Aug 2009 19:21:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=2Y99WJcJI8ROclaknFjGAMihm6CJRGIULXk8bmIuH4k=;
        b=RnfdTtuXNXVTwIBFMWYvsbgfkKWSF95vyL4c3vsKo6dNwhXmkKak+i3IyBHabgy8/p
         9mnl0Bjk4pLF5FNMVpESRp52eVE1aNMQx8muEbDz98PkY0hmnY2zkBgn7IEhEdprTHxF
         7/HhSv9CF6HC0ZlG9Rl4HjRHvPOqw19I2P6W4=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=BdrgwyHIUZapQf/nvPutnrG8BxnzJOrGqJx5GYGR66Y9iDzZ6CynXhAFrMoOWsjQLk
         rKvDvEbQqaI5xTPUQFERCqxVanFePSaWy667T2buviM6V/4tqCovyGIJHQYSSrfSRyo5
         Kj3uv7RW0dru9p0DeDRpxpp0kt7QqKJBXMjQU=
MIME-Version: 1.0
Received: by 10.204.24.2 with SMTP id t2mr2676777bkb.65.1251598913201; Sat, 29 
	Aug 2009 19:21:53 -0700 (PDT)
In-Reply-To: <25199284.post@talk.nabble.com>
References: <c9b0d8bd0908241822u1987a610wf87ed64eef22f53b@mail.gmail.com>
	 <25199284.post@talk.nabble.com>
Date: Sat, 29 Aug 2009 21:21:53 -0500
Message-ID: <c9b0d8bd0908291921q60cdc4e4m708a0a6328409816@mail.gmail.com>
Subject: Re: Where does System.out.println() go?
From: Mark Kerzner <markkerzner@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00032555b3369f681c047252943c
X-Virus-Checked: Checked by ClamAV on apache.org

--00032555b3369f681c047252943c
Content-Type: text/plain; charset=ISO-8859-1

Thank you

On Fri, Aug 28, 2009 at 8:58 PM, indoos <indoos@gmail.com> wrote:

>
> Hi, sysout for Map Reduce should be visible in 50030 task tracker UI
> against
> the individual Map Reduce tasks for executed JOB. This UI anyways uses the
> individual logs created against each attempt in logs/userlogs/attempt****
> folders.
> Regards,Sanjay
>
>
> Mark Kerzner-2 wrote:
> >
> > Hi,
> >
> > when I run Hadoop in pseudo-distributed mode, I can't find the log which
> > System.out.println() goes.
> >
> > When I run in the IDE, I see it. When I run on EC2, it's part of the
> > output
> > logs. But here - do I need to set something up?
> >
> > Thank you,
> > Mark
> >
> >
>
> --
> View this message in context:
> http://www.nabble.com/Where-does-System.out.println%28%29-go--tp25126757p25199284.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>
>

--00032555b3369f681c047252943c--

From common-user-return-17169-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 30 11:32:23 2009
Return-Path: <common-user-return-17169-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61062 invoked from network); 30 Aug 2009 11:32:23 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 30 Aug 2009 11:32:23 -0000
Received: (qmail 46768 invoked by uid 500); 30 Aug 2009 11:32:20 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 46695 invoked by uid 500); 30 Aug 2009 11:32:20 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 46685 invoked by uid 500); 30 Aug 2009 11:32:20 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 46682 invoked by uid 99); 30 Aug 2009 11:32:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 11:32:20 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lists@nabble.com designates 216.139.236.158 as permitted sender)
Received: from [216.139.236.158] (HELO kuber.nabble.com) (216.139.236.158)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 11:32:10 +0000
Received: from isper.nabble.com ([192.168.236.156])
	by kuber.nabble.com with esmtp (Exim 4.63)
	(envelope-from <lists@nabble.com>)
	id 1MhidR-0004fv-C7
	for core-user@hadoop.apache.org; Sun, 30 Aug 2009 04:31:49 -0700
Message-ID: <25210767.post@talk.nabble.com>
Date: Sun, 30 Aug 2009 04:31:49 -0700 (PDT)
From: HHB <hubaghdadi@yahoo.ca>
To: core-user@hadoop.apache.org
Subject: Start learning and using Hadoop
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Nabble-From: hubaghdadi@yahoo.ca
X-Virus-Checked: Checked by ClamAV on apache.org


Hey,
I want to start learning and using about Hadoop (not the srouce code) but I
don't know where to start, there are many projects.
http://hadoop.apache.org/
Thanks.

-- 
View this message in context: http://www.nabble.com/Start-learning-and-using-Hadoop-tp25210767p25210767.html
Sent from the Hadoop core-user mailing list archive at Nabble.com.


From common-user-return-17170-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 30 11:37:19 2009
Return-Path: <common-user-return-17170-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 62075 invoked from network); 30 Aug 2009 11:37:18 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 30 Aug 2009 11:37:18 -0000
Received: (qmail 50226 invoked by uid 500); 30 Aug 2009 11:37:16 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 50137 invoked by uid 500); 30 Aug 2009 11:37:16 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 50127 invoked by uid 99); 30 Aug 2009 11:37:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 11:37:16 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of timrobertson100@gmail.com designates 209.85.219.208 as permitted sender)
Received: from [209.85.219.208] (HELO mail-ew0-f208.google.com) (209.85.219.208)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 11:37:07 +0000
Received: by ewy4 with SMTP id 4so798498ewy.36
        for <common-user@hadoop.apache.org>; Sun, 30 Aug 2009 04:36:46 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=uzRvoDye5YyWeAD+koykvYThzndcj2CgbyUGeKEKx2E=;
        b=WXdePojMz3JxPyw1silx6+1J2lGqHKPeIeqEl/FpetM5zdijaGS0bxcB/F5wvNYoK6
         ztijPs/8Jx7v0ciIj4BQd8UBL3Dgf85asJQ1OEJSDh4V2seuZov92mi8hrc6Q99UTQ+m
         WZ6i3iQXKbLt1PA9Rs4Vw2z8qrKzvPcCvPXh8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=x5jF4w/S6CHusmBs5TxKOdXFCwy2dTDvNFOaEA+3yy4tEM9B5bOfH9MxsMVI1uqV/a
         tAvxAOdU6YzmUvdvBTtsJQKH4BmUrf6OrNKeVsYjg90gxSrKRkC2hgpWuwL316KqQILx
         t6U27dCiMhoYe0J+JJyNOJ10hCHI9IhFoQRRI=
MIME-Version: 1.0
Received: by 10.216.0.208 with SMTP id 58mr764361web.216.1251632205890; Sun, 
	30 Aug 2009 04:36:45 -0700 (PDT)
In-Reply-To: <25210767.post@talk.nabble.com>
References: <25210767.post@talk.nabble.com>
Date: Sun, 30 Aug 2009 07:36:45 -0400
Message-ID: <32120a6a0908300436q7c8d99c0x4f3aa791121bd1ed@mail.gmail.com>
Subject: Re: Start learning and using Hadoop
From: tim robertson <timrobertson100@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I would suggest starting by getting a single node cluster working
using: http://wiki.apache.org/hadoop/GettingStartedWithHadoop

Then try some of the examples that come with Hadoop (word count etc)

Cheers,

Tim

On Sun, Aug 30, 2009 at 7:31 AM, HHB<hubaghdadi@yahoo.ca> wrote:
>
> Hey,
> I want to start learning and using about Hadoop (not the srouce code) but I
> don't know where to start, there are many projects.
> http://hadoop.apache.org/
> Thanks.
>
> --
> View this message in context: http://www.nabble.com/Start-learning-and-using-Hadoop-tp25210767p25210767.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>
>

From common-user-return-17171-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 30 14:23:29 2009
Return-Path: <common-user-return-17171-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 88496 invoked from network); 30 Aug 2009 14:23:29 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 30 Aug 2009 14:23:29 -0000
Received: (qmail 4493 invoked by uid 500); 30 Aug 2009 14:23:26 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 4384 invoked by uid 500); 30 Aug 2009 14:23:26 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 4374 invoked by uid 99); 30 Aug 2009 14:23:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 14:23:26 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bharathvissapragada1990@gmail.com designates 74.125.92.27 as permitted sender)
Received: from [74.125.92.27] (HELO qw-out-2122.google.com) (74.125.92.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 14:23:17 +0000
Received: by qw-out-2122.google.com with SMTP id 8so816882qwh.35
        for <common-user@hadoop.apache.org>; Sun, 30 Aug 2009 07:22:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :from:date:message-id:subject:to:content-type;
        bh=wbryZpdZAqXd+4SwEToRBmiX1JXkBDywRq+nGIKfEL4=;
        b=NhR3dNcJAbiGQweGXxwHTxTM2BFxIoUL+sfxHMy//ADqLZ4xJ/K8zbMlCmZ7ju/L8n
         aHyU0sH/rPZ+0ihsmHWSaJ8meXI/M/PfsBrkzSFk4XzbuSKa9LTGdOprxup+24Yhk/wW
         NRh2PTBF1hXcRLIRs4Q5hVPZNsX1P+vxLdAKM=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        b=ORxP4lS2rTOh9nv4xSwlj1sTlM9NmgTmniB30htFcjN2jCrxLtX4EP3Zn0f6HSTqdS
         aLmkic0RkAA5p5MaVtVeyd/N7ZJe93skGjlLhh83/KsWvkI2EBO64eG2wrOwQGC9WTum
         FOZHWPBvbrstYET0C4mPQqlbA1WNr8GVUpp84=
MIME-Version: 1.0
Received: by 10.229.37.74 with SMTP id w10mr1243753qcd.73.1251642176264; Sun, 
	30 Aug 2009 07:22:56 -0700 (PDT)
In-Reply-To: <25210767.post@talk.nabble.com>
References: <25210767.post@talk.nabble.com>
From: bharath vissapragada <bharathvissapragada1990@gmail.com>
Date: Sun, 30 Aug 2009 19:52:36 +0530
Message-ID: <73d592f60908300722w29c846d6ld03fda7aaf351e4a@mail.gmail.com>
Subject: Re: Start learning and using Hadoop
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001636426c874d5a8c04725ca778
X-Virus-Checked: Checked by ClamAV on apache.org

--001636426c874d5a8c04725ca778
Content-Type: text/plain; charset=ISO-8859-1

I feel that Yahoo tutorial on hadoop is much better compared to the
remaining ones .. It can be found at the following link

http://developer.yahoo.com/hadoop/tutorial/

The following link describes in detail how to install and run the basic
commands of hadoop and HDFS

http://www.michael-noll.com/wiki/Running_Hadoop_On_Ubuntu_Linux_%28Single-Node_Cluster%29

Hope these links are useful to you .

Thanks.

On Sun, Aug 30, 2009 at 5:01 PM, HHB <hubaghdadi@yahoo.ca> wrote:

>
> Hey,
> I want to start learning and using about Hadoop (not the srouce code) but I
> don't know where to start, there are many projects.
> http://hadoop.apache.org/
> Thanks.
>
> --
> View this message in context:
> http://www.nabble.com/Start-learning-and-using-Hadoop-tp25210767p25210767.html
> Sent from the Hadoop core-user mailing list archive at Nabble.com.
>
>

--001636426c874d5a8c04725ca778--

From common-user-return-17172-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 30 16:27:43 2009
Return-Path: <common-user-return-17172-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 4987 invoked from network); 30 Aug 2009 16:27:43 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 30 Aug 2009 16:27:43 -0000
Received: (qmail 57548 invoked by uid 500); 30 Aug 2009 16:27:41 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 57453 invoked by uid 500); 30 Aug 2009 16:27:40 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 57443 invoked by uid 99); 30 Aug 2009 16:27:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 16:27:40 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 209.85.132.243 is neither permitted nor denied by domain of mnagendr@asu.edu)
Received: from [209.85.132.243] (HELO an-out-0708.google.com) (209.85.132.243)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 16:27:31 +0000
Received: by an-out-0708.google.com with SMTP id c38so1433898ana.29
        for <common-user@hadoop.apache.org>; Sun, 30 Aug 2009 09:27:09 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.100.27.12 with SMTP id a12mr4103349ana.110.1251649628912; Sun, 
	30 Aug 2009 09:27:08 -0700 (PDT)
In-Reply-To: <73d592f60908300722w29c846d6ld03fda7aaf351e4a@mail.gmail.com>
References: <25210767.post@talk.nabble.com>
	 <73d592f60908300722w29c846d6ld03fda7aaf351e4a@mail.gmail.com>
Date: Sun, 30 Aug 2009 19:27:08 +0300
Message-ID: <77f4f8890908300927gc5311a8o52f9ec3069d43bde@mail.gmail.com>
Subject: Re: Start learning and using Hadoop
From: Mithila Nagendra <mnagendr@asu.edu>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=001485f80d6a83be9904725e63d8
X-Virus-Checked: Checked by ClamAV on apache.org

--001485f80d6a83be9904725e63d8
Content-Type: text/plain; charset=ISO-8859-1

If you are trying to setup a Hadoop installation I would suggest going
through the article by Michael G Noll. Here's the link:
http://www.michael-noll.com/wiki/Running_Hadoop_On_Ubuntu_Linux_(Single-Node_Cluster)

<http://www.michael-noll.com/wiki/Running_Hadoop_On_Ubuntu_Linux_(Single-Node_Cluster)>
Mithila

On Sun, Aug 30, 2009 at 5:22 PM, bharath vissapragada <
bharathvissapragada1990@gmail.com> wrote:

> I feel that Yahoo tutorial on hadoop is much better compared to the
> remaining ones .. It can be found at the following link
>
> http://developer.yahoo.com/hadoop/tutorial/
>
> The following link describes in detail how to install and run the basic
> commands of hadoop and HDFS
>
>
> http://www.michael-noll.com/wiki/Running_Hadoop_On_Ubuntu_Linux_%28Single-Node_Cluster%29
>
> Hope these links are useful to you .
>
> Thanks.
>
> On Sun, Aug 30, 2009 at 5:01 PM, HHB <hubaghdadi@yahoo.ca> wrote:
>
> >
> > Hey,
> > I want to start learning and using about Hadoop (not the srouce code) but
> I
> > don't know where to start, there are many projects.
> > http://hadoop.apache.org/
> > Thanks.
> >
> > --
> > View this message in context:
> >
> http://www.nabble.com/Start-learning-and-using-Hadoop-tp25210767p25210767.html
> > Sent from the Hadoop core-user mailing list archive at Nabble.com.
> >
> >
>

--001485f80d6a83be9904725e63d8--

From common-user-return-17173-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Sun Aug 30 22:11:41 2009
Return-Path: <common-user-return-17173-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 63946 invoked from network); 30 Aug 2009 22:11:41 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 30 Aug 2009 22:11:41 -0000
Received: (qmail 49064 invoked by uid 500); 30 Aug 2009 22:11:39 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 48964 invoked by uid 500); 30 Aug 2009 22:11:38 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 48954 invoked by uid 99); 30 Aug 2009 22:11:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 22:11:38 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [209.85.221.186] (HELO mail-qy0-f186.google.com) (209.85.221.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 30 Aug 2009 22:11:29 +0000
Received: by qyk16 with SMTP id 16so657651qyk.20
        for <common-user@hadoop.apache.org>; Sun, 30 Aug 2009 15:11:07 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.229.106.219 with SMTP id y27mr1395749qco.49.1251670266381; 
	Sun, 30 Aug 2009 15:11:06 -0700 (PDT)
In-Reply-To: <77f4f8890908300927gc5311a8o52f9ec3069d43bde@mail.gmail.com>
References: <25210767.post@talk.nabble.com>
	 <73d592f60908300722w29c846d6ld03fda7aaf351e4a@mail.gmail.com>
	 <77f4f8890908300927gc5311a8o52f9ec3069d43bde@mail.gmail.com>
Date: Sun, 30 Aug 2009 15:11:06 -0700
Message-ID: <c9118d4c0908301511y9a7ad0eyc2ec9aaac5c2e436@mail.gmail.com>
Subject: Re: Start learning and using Hadoop
From: Jeff Hammerbacher <hammer@cloudera.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0023544710709a89ab04726331e4
X-Virus-Checked: Checked by ClamAV on apache.org

--0023544710709a89ab04726331e4
Content-Type: text/plain; charset=ISO-8859-1

Hey,
If you prefer video format for your tutorials, you can find some interesting
content at http://www.cloudera.com/hadoop-training.

Later,
Jeff

On Sun, Aug 30, 2009 at 9:27 AM, Mithila Nagendra <mnagendr@asu.edu> wrote:

> If you are trying to setup a Hadoop installation I would suggest going
> through the article by Michael G Noll. Here's the link:
>
> http://www.michael-noll.com/wiki/Running_Hadoop_On_Ubuntu_Linux_(Single-Node_Cluster)
>
> <
> http://www.michael-noll.com/wiki/Running_Hadoop_On_Ubuntu_Linux_(Single-Node_Cluster)
> >
> Mithila
>
> On Sun, Aug 30, 2009 at 5:22 PM, bharath vissapragada <
> bharathvissapragada1990@gmail.com> wrote:
>
> > I feel that Yahoo tutorial on hadoop is much better compared to the
> > remaining ones .. It can be found at the following link
> >
> > http://developer.yahoo.com/hadoop/tutorial/
> >
> > The following link describes in detail how to install and run the basic
> > commands of hadoop and HDFS
> >
> >
> >
> http://www.michael-noll.com/wiki/Running_Hadoop_On_Ubuntu_Linux_%28Single-Node_Cluster%29
> >
> > Hope these links are useful to you .
> >
> > Thanks.
> >
> > On Sun, Aug 30, 2009 at 5:01 PM, HHB <hubaghdadi@yahoo.ca> wrote:
> >
> > >
> > > Hey,
> > > I want to start learning and using about Hadoop (not the srouce code)
> but
> > I
> > > don't know where to start, there are many projects.
> > > http://hadoop.apache.org/
> > > Thanks.
> > >
> > > --
> > > View this message in context:
> > >
> >
> http://www.nabble.com/Start-learning-and-using-Hadoop-tp25210767p25210767.html
> > > Sent from the Hadoop core-user mailing list archive at Nabble.com.
> > >
> > >
> >
>

--0023544710709a89ab04726331e4--

From common-user-return-17175-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 09:20:01 2009
Return-Path: <common-user-return-17175-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 8434 invoked from network); 31 Aug 2009 09:20:01 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 09:20:01 -0000
Received: (qmail 94808 invoked by uid 500); 31 Aug 2009 09:19:55 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 94669 invoked by uid 500); 31 Aug 2009 09:19:55 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 94483 invoked by uid 500); 31 Aug 2009 09:19:54 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 94476 invoked by uid 99); 31 Aug 2009 09:19:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 09:19:54 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of cpbhagtani@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 09:19:45 +0000
Received: by gxk27 with SMTP id 27so5142033gxk.12
        for <multiple recipients>; Mon, 31 Aug 2009 02:19:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=kAqrvX36yLlc1n2xSgyji0X95Bd1JSYxR0+l9an7C/k=;
        b=EaGYMWSE8fJ8tn7876a0FET6wvy7U3LXlQr3zQdQCiEUgNPpLkgA+WaMHK9k1uXzX/
         yfuwv7o2rKxc3XvJVpdPVh0uXDjDjCVUN8e6p/vRLgE0ZIPZTm9EKFmyQJugSwZcVu8J
         cyQ/ATtKSj0MEQc1Y9buGWxVUG22k4iY2vizk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        b=DYphWp4+E9PZ9FnUKZRfjArQ93jdQ37fRyWhCNQYa0YCOG2YiC2/P5BiCF9F6ZNPzG
         5wHC1AgzZFkGMZ/tn4mUBQl78bXSh/Q4sEWOBuGEJkIQmKfs9luJuy2/luqCVmlbN0x2
         JXIb3xRVYSyhrpZSkUgiiLVYGNlJbE4MhhyFQ=
MIME-Version: 1.0
Received: by 10.150.59.4 with SMTP id h4mr2158698yba.299.1251710364326; Mon, 
	31 Aug 2009 02:19:24 -0700 (PDT)
In-Reply-To: <8211a1320908241749x71f4d762j3256e6a0be0e22f3@mail.gmail.com>
References: <8211a1320908241749x71f4d762j3256e6a0be0e22f3@mail.gmail.com>
Date: Mon, 31 Aug 2009 14:49:24 +0530
Message-ID: <4061df20908310219w17e32c36mc57eabd31b86af9c@mail.gmail.com>
Subject: Re: Does hadoop delete the intermediate data
From: Chandraprakash Bhagtani <cpbhagtani@gmail.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd6a808a09bc204726c875f
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd6a808a09bc204726c875f
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Hadoop does delete the intermediate data after the job completes.
Jobtracker sends signal to Tasktracker to delete intermediate data
when the job completes.

The problem in your case might be some of your running job might not
have been killed gracefully or Jobtracker failed for some reason.

--=20
Thanks & Regards,
Chandra Prakash Bhagtani,

On Tue, Aug 25, 2009 at 6:19 AM, zhang jianfeng <zjffdu@gmail.com> wrote:

> Hi all,
>
> I found my cluster=92s space usage increase over time although I did not
> upload new data.  And there's a lot of files under folder /tmp .
>
> So I guess hadoop won=92t delete the intermediate data(output of mapper).
>
> Am I right ?
>
>
> Thank you.
>
> Jeff zhang
>

--000e0cd6a808a09bc204726c875f--

From common-user-return-17174-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 09:20:01 2009
Return-Path: <common-user-return-17174-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 8420 invoked from network); 31 Aug 2009 09:20:01 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 09:20:01 -0000
Received: (qmail 94777 invoked by uid 500); 31 Aug 2009 09:19:55 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 94596 invoked by uid 500); 31 Aug 2009 09:19:55 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 94476 invoked by uid 99); 31 Aug 2009 09:19:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 09:19:54 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of cpbhagtani@gmail.com designates 209.85.217.227 as permitted sender)
Received: from [209.85.217.227] (HELO mail-gx0-f227.google.com) (209.85.217.227)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 09:19:45 +0000
Received: by gxk27 with SMTP id 27so5142033gxk.12
        for <multiple recipients>; Mon, 31 Aug 2009 02:19:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=kAqrvX36yLlc1n2xSgyji0X95Bd1JSYxR0+l9an7C/k=;
        b=EaGYMWSE8fJ8tn7876a0FET6wvy7U3LXlQr3zQdQCiEUgNPpLkgA+WaMHK9k1uXzX/
         yfuwv7o2rKxc3XvJVpdPVh0uXDjDjCVUN8e6p/vRLgE0ZIPZTm9EKFmyQJugSwZcVu8J
         cyQ/ATtKSj0MEQc1Y9buGWxVUG22k4iY2vizk=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        b=DYphWp4+E9PZ9FnUKZRfjArQ93jdQ37fRyWhCNQYa0YCOG2YiC2/P5BiCF9F6ZNPzG
         5wHC1AgzZFkGMZ/tn4mUBQl78bXSh/Q4sEWOBuGEJkIQmKfs9luJuy2/luqCVmlbN0x2
         JXIb3xRVYSyhrpZSkUgiiLVYGNlJbE4MhhyFQ=
MIME-Version: 1.0
Received: by 10.150.59.4 with SMTP id h4mr2158698yba.299.1251710364326; Mon, 
	31 Aug 2009 02:19:24 -0700 (PDT)
In-Reply-To: <8211a1320908241749x71f4d762j3256e6a0be0e22f3@mail.gmail.com>
References: <8211a1320908241749x71f4d762j3256e6a0be0e22f3@mail.gmail.com>
Date: Mon, 31 Aug 2009 14:49:24 +0530
Message-ID: <4061df20908310219w17e32c36mc57eabd31b86af9c@mail.gmail.com>
Subject: Re: Does hadoop delete the intermediate data
From: Chandraprakash Bhagtani <cpbhagtani@gmail.com>
To: common-user@hadoop.apache.org
Cc: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd6a808a09bc204726c875f
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd6a808a09bc204726c875f
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Hadoop does delete the intermediate data after the job completes.
Jobtracker sends signal to Tasktracker to delete intermediate data
when the job completes.

The problem in your case might be some of your running job might not
have been killed gracefully or Jobtracker failed for some reason.

--=20
Thanks & Regards,
Chandra Prakash Bhagtani,

On Tue, Aug 25, 2009 at 6:19 AM, zhang jianfeng <zjffdu@gmail.com> wrote:

> Hi all,
>
> I found my cluster=92s space usage increase over time although I did not
> upload new data.  And there's a lot of files under folder /tmp .
>
> So I guess hadoop won=92t delete the intermediate data(output of mapper).
>
> Am I right ?
>
>
> Thank you.
>
> Jeff zhang
>

--000e0cd6a808a09bc204726c875f--

From common-user-return-17176-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 10:41:12 2009
Return-Path: <common-user-return-17176-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 27320 invoked from network); 31 Aug 2009 10:41:11 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 10:41:11 -0000
Received: (qmail 95543 invoked by uid 500); 31 Aug 2009 10:41:09 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 95489 invoked by uid 500); 31 Aug 2009 10:41:09 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 95398 invoked by uid 500); 31 Aug 2009 10:41:09 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 95388 invoked by uid 99); 31 Aug 2009 10:41:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 10:41:09 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 10:40:59 +0000
Received: by bwz10 with SMTP id 10so1852250bwz.29
        for <core-user@hadoop.apache.org>; Mon, 31 Aug 2009 03:40:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:date:message-id:subject
         :from:to:content-type;
        bh=Pi8aReiY8TNcFVVGAUeclZrkfQMcG+3viWs6ysjr1FY=;
        b=JEWKvhwkd4RxqIDhCCz4xENtVa9Q6SjlwT+fghazjJ1VLJ/HpQIXQdje230Uh1qnWv
         xKkJ4zEA9tS7mtHBAdmFmWnFaJ2c/ZNH3gWxozZ+DkQ7sYtO3B/8q2HwozFzE4LQWmiv
         gb6QC5ltjAagmy4FI/58okJYbUnuOXBYL6K9E=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:date:message-id:subject:from:to:content-type;
        b=ni3t8YOrntjSLCfoSqPjRYHDKntU5ezRwbvQv+FBMTVBcUdc3nfTStM3NloPCltIJf
         C6AzQx3xsS1T5MDNc2wrXSxHc7TWt2PD0iDrSDew2XTFMPwmOpRl5j9JQ1jxTbVgLShR
         r9l94drMyYEyk/xnQNQmimKJxQl8VL8j47yys=
MIME-Version: 1.0
Received: by 10.223.4.149 with SMTP id 21mr1522543far.28.1251715238261; Mon, 
	31 Aug 2009 03:40:38 -0700 (PDT)
Date: Mon, 31 Aug 2009 13:40:38 +0300
Message-ID: <77938bc20908310340g63c6b29aw25a4edd16f1fc840@mail.gmail.com>
Subject: Datanode high memory usage
From: Stas Oskin <stas.oskin@gmail.com>
To: core-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0ce0253622f28704726daa7d
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0ce0253622f28704726daa7d
Content-Type: text/plain; charset=ISO-8859-1

Hi.

I measured the Datanode memory usage, and noticed they take up to 700 MB of
RAM.

As their main job is to store files to disk, any idea why they take so much
RAM?

Thanks for any information.

--000e0ce0253622f28704726daa7d--

From common-user-return-17177-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 13:16:34 2009
Return-Path: <common-user-return-17177-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 61393 invoked from network); 31 Aug 2009 13:16:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 13:16:34 -0000
Received: (qmail 88397 invoked by uid 500); 31 Aug 2009 13:16:32 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 88334 invoked by uid 500); 31 Aug 2009 13:16:32 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 88324 invoked by uid 99); 31 Aug 2009 13:16:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 13:16:32 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [128.8.132.61] (HELO mrouter3.umiacs.umd.edu) (128.8.132.61)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 13:16:21 +0000
Received: from [192.168.93.25] (unknown [128.8.118.5])
	by mrouter3.umiacs.umd.edu (Postfix) with ESMTP id 93E5513D28A
	for <common-user@hadoop.apache.org>; Mon, 31 Aug 2009 09:15:59 -0400 (EDT)
Message-ID: <4A9BCD0F.7090404@umd.edu>
Date: Mon, 31 Aug 2009 09:15:59 -0400
From: Jimmy Lin <jimmylin@umd.edu>
User-Agent: Thunderbird 2.0.0.23 (Windows/20090812)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Deadline for early-bird registration today!! NSF/Google/IBM CLuE
 PI Meeting: October 5, 2009 in Mountain View, California
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 8bit
X-Virus-Checked: Checked by ClamAV on apache.org

Dear Hadoopers,

Reminder for those who wish to attend the NSF/Google/IBM CLuE PI Meeting 
on 10/5... the deadline for early-bird registration is today!

We are happy to announce two keynotes:

* Dr. Luiz Barroso, Google Distinguished Engineer, who has worked deeply 
in a large number of computing system areas.  He is also co-author with 
Urs Holzle of the book "The Datacenter as a Computer - an introduction 
to the design of warehouse-scale machines," 2009.

* Dr. Hamid Pirahesh, IBM fellow, ACM Fellow, and a senior manager 
responsible for the exploratory database department at IBM Almaden 
Research Center in San Jose, California.

Event details reposted below.  Hope to see everyone there!

Best,
Jimmy


==CLuE PI Meeting 2009==

Monday, October 5, 2009
Mountain View, California (Exact Location TBA)

Sponsored by the National Science Foundation, Google, IBM
Organized by the University of Maryland Cloud Computing Center

Website: https://wiki.umiacs.umd.edu/ccc/index.php/CLuE_PI_Meeting_2009
Registration: http://clue2009.eventbrite.com/
               (Early-bird registration ends 8/31)

= What's this event about?

In October 2007, Google and IBM announced the first pilot phase of the 
Academic Cloud Computing Initiative (ACCI), which granted several 
prominent U.S. universities access to a large computer cluster running 
Hadoop, an open source distributed computing platform inspired by 
Googles file system and MapReduce programming model. In February 2008, 
the ACCI partnered with the National Science Foundation to provide grant 
funding to academic researchers interested in exploring large-data 
applications that could take advantage of this infrastructure. This 
resulted in the creation of the Cluster Exploratory (CLuE) program led 
by Dr. Jim French, which currently funds 14 projects from 17 universities.

Nearing the two year anniversary of this collaboration, the National 
Science Foundation, Google, and IBM will be jointly sponsoring a meeting 
for the CLuE project principal investigators (PIs). This will event will 
be open to the publicin fact, the explicit goal of this event is to 
showcase the exciting research currently underway in academia and 
promote closer ties with the broader "cloud computing" community in the 
bay area.  Register now!

= Who's speaking?

Most of the meeting will consist of plenary talks by the following people:

* Daniel Abadi (Yale University): "HadoopDB An Architectural Hybrid of 
MapReduce and DBMS Technologies for Analytical Workloads"

* Jamie Callan (Carnegie Mellon University): "Topic-Partitioned Search 
Engine Indexes"

* Andrew Connolly (University of Washington): "Scaling the Universe 
through MapReduce"

* Bill Howe (University of Washington) and Claudio Silva (University of 
Utah)

* Chen Li (University of California, Irvine): "Large-Scale Data Cleaning 
Using Hadoop"

* Jimmy Lin (University of Maryland): "Data-Intensive Text Processing 
with MapReduce"

* Sam Madden (MIT): "A Performance and Usability Comparison of Hadoop 
and Relational Database Systems"

* Mihai Pop (University of Maryland): "Commodity Computing in Genomics 
Research"

* Naphtali Rishe (Florida International University): "Experience with 
Geospatial Data in MapReduce"

* Suresh Jagannathan and Ananth Grama (Purdue University): "Relaxed 
Synchronization and Eager Scheduling in MapReduce"

* Stephan Vogel (Carnegie Mellon University)

* Ben Zhao and Xifeng Yan (University of California, Santa Barbara): 
"Scalable Graph Processing in Data Center Environments"

We are also anticipating keynotes from both Google and IBM.

The meeting will be capped off with a poster reception in the early 
evening, where representatives of all CLuE projects will present their 
work in a more informal setting. The speakers above will be joined by 
the follow presenters in the poster session:

* James Allan (University of Massachusetts, Amherst)

* Jason Lawrence (University of Virginia)

* Chaitanya Baru and Sriram Krishnan (San Diego Supercomputer 
Center/University of California, San Diego)



From common-user-return-17178-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 13:22:26 2009
Return-Path: <common-user-return-17178-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 68644 invoked from network); 31 Aug 2009 13:22:26 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 13:22:26 -0000
Received: (qmail 96259 invoked by uid 500); 31 Aug 2009 13:22:24 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 96175 invoked by uid 500); 31 Aug 2009 13:22:23 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 96165 invoked by uid 99); 31 Aug 2009 13:22:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 13:22:23 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [128.8.132.61] (HELO mrouter3.umiacs.umd.edu) (128.8.132.61)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 13:22:13 +0000
Received: from [192.168.93.25] (unknown [128.8.118.5])
	by mrouter3.umiacs.umd.edu (Postfix) with ESMTP id 1D2B513D28A
	for <common-user@hadoop.apache.org>; Mon, 31 Aug 2009 09:21:53 -0400 (EDT)
Message-ID: <4A9BCE71.4060605@umd.edu>
Date: Mon, 31 Aug 2009 09:21:53 -0400
From: Jimmy Lin <jimmylin@umd.edu>
User-Agent: Thunderbird 2.0.0.23 (Windows/20090812)
MIME-Version: 1.0
To: common-user@hadoop.apache.org
Subject: Talk in DC area: MapReduce and Parallel DBMSs: A Comparison of Approaches
 to Large-Scale Data Analysis
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Dear Hadoopers,

For those of you in the DC area, you might be interested in this talk at 
the University of Maryland this week...

Best,
Jimmy

------

MapReduce and Parallel DBMSs: A Comparison of Approaches to Large-Scale 
Data Analysis

Complete info at http://tinyurl.com/knh83k

Andy Pavlo (Brown University)
(http://www.cs.brown.edu/~pavlo/)

Thursday, September 3, 2009
4pm, AVW 3258
(Directions: http://www.umiacs.umd.edu/about/directions.htm)

= Abstract

The MapReduce (MR) paradigm has been heralded as a revolutionary new 
platform for large-scale, massively parallel data access. Some 
proponents claim that the extreme scalability of MR will relegate 
relational database management systems (DBMS) to the status legacy 
technology. In this talk, however, we discuss the results from our 
recent benchmark study from that suggest that using MR systems to 
perform tasks that are best suited for DBMSs yields less than 
satisfactory results. This leads us to conclude that MR is more akin to 
an Extract-Transform-Load (ETL) system than a DBMS, as it is quickly 
able to load and analyze large amounts of data in an ad hoc manner. As 
such, it is complementary to DBMS technology, rather than a competitor. 
We also discuss the various differences in the architectural decisions 
of MR systems and database systems, and provide insight on how the two 
systems should complement one another.

= About the Speaker

Andrew Pavlo is a third year Computer Science PhD student at Brown 
University's Data Management Group under the guidance of Dr. Stanley Zdonik.


From common-user-return-17180-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 13:35:54 2009
Return-Path: <common-user-return-17180-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 71722 invoked from network); 31 Aug 2009 13:35:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 13:35:54 -0000
Received: (qmail 14072 invoked by uid 500); 31 Aug 2009 13:35:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 13943 invoked by uid 500); 31 Aug 2009 13:35:48 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 13919 invoked by uid 99); 31 Aug 2009 13:35:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 13:35:48 +0000
X-ASF-Spam-Status: No, hits=3.3 required=10.0
	tests=DATE_IN_FUTURE_12_24,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zjffdu@gmail.com designates 209.85.216.204 as permitted sender)
Received: from [209.85.216.204] (HELO mail-px0-f204.google.com) (209.85.216.204)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 13:35:37 +0000
Received: by pxi42 with SMTP id 42so92598pxi.20
        for <multiple recipients>; Mon, 31 Aug 2009 06:35:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:from:to:references
         :in-reply-to:subject:date:message-id:mime-version:content-type
         :content-transfer-encoding:x-mailer:thread-index:content-language;
        bh=fCcaphZI2ibYQcIiTnoVDvRwnPn6g615W81Zme4STG4=;
        b=bCDip/UKZCLVqaILwLvM+szamNWkra8bGT7YPXZafAd0ey4tM38cdBbLJJdtxYwk8d
         lLrBQt0M7P/Q8CjUBNC3It/jwgrGVA6BIWlJMS+XkXdIv7na4PYCoegv5JI3ZA7WOXTC
         SRnx4Ubve+b00sksWZr9631pG60WvXMcLoOrI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=from:to:references:in-reply-to:subject:date:message-id:mime-version
         :content-type:content-transfer-encoding:x-mailer:thread-index
         :content-language;
        b=sc6BFLTZ6R2y6ptrM3DgJ1FCG3Vsk0N/FIHlEFOWIB56I7mYneWIq9x/+/b3uWh5WH
         Xrmezzxed1VGoZUhKcwuIb+SZ+3JONJoBhCjDCQoVyiRCNkdhjcnrjyvfFeShX7KSYmV
         tfN6iFFbOd8taftwycOUBmvV9Np5OEHIgKP7Y=
Received: by 10.115.96.16 with SMTP id y16mr2631359wal.38.1251725716497;
        Mon, 31 Aug 2009 06:35:16 -0700 (PDT)
Received: from zjf ([58.247.235.164])
        by mx.google.com with ESMTPS id n9sm4296726wag.58.2009.08.31.06.35.14
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Mon, 31 Aug 2009 06:35:16 -0700 (PDT)
From: "zjffdu" <zjffdu@gmail.com>
To: <common-user@hadoop.apache.org>,
	<core-user@hadoop.apache.org>
References: <77938bc20908310340g63c6b29aw25a4edd16f1fc840@mail.gmail.com>
In-Reply-To: <77938bc20908310340g63c6b29aw25a4edd16f1fc840@mail.gmail.com>
Subject: RE: Datanode high memory usage
Date: Mon, 31 Aug 2009 21:36:52 -0700
Message-ID: <007e01ca2abd$d659b7f0$830d27d0$@com>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="gb2312"
Content-Transfer-Encoding: quoted-printable
X-Mailer: Microsoft Office Outlook 12.0
Thread-Index: AcoqJ42GQu6xCZDZQhanh8j1xkBViwAlbWkg
Content-Language: zh-cn
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Stas,

What does 700MB represent for ? total memory usage of OS or only the =
task
process.

There three process related to hadoop on datanode.=20

1. DataNode deamon for DFS (only one)
2. TaskTracker for MapReduce (only one)
3. Map Task or Reduce Task (several tasks on one machine, depending on =
your
configration)

=20

-----Original Message-----
From: Stas Oskin [mailto:stas.oskin@gmail.com]=20
Sent: 2009=C4=EA8=D4=C231=C8=D5 3:41
To: core-user@hadoop.apache.org
Subject: Datanode high memory usage

Hi.

I measured the Datanode memory usage, and noticed they take up to 700 MB =
of
RAM.

As their main job is to store files to disk, any idea why they take so =
much
RAM?

Thanks for any information.


From common-user-return-17179-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 13:35:54 2009
Return-Path: <common-user-return-17179-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 71703 invoked from network); 31 Aug 2009 13:35:54 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 13:35:54 -0000
Received: (qmail 14029 invoked by uid 500); 31 Aug 2009 13:35:48 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 13941 invoked by uid 500); 31 Aug 2009 13:35:48 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 13924 invoked by uid 500); 31 Aug 2009 13:35:48 -0000
Delivered-To: apmail-hadoop-core-user@hadoop.apache.org
Received: (qmail 13919 invoked by uid 99); 31 Aug 2009 13:35:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 13:35:48 +0000
X-ASF-Spam-Status: No, hits=3.3 required=10.0
	tests=DATE_IN_FUTURE_12_24,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zjffdu@gmail.com designates 209.85.216.204 as permitted sender)
Received: from [209.85.216.204] (HELO mail-px0-f204.google.com) (209.85.216.204)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 13:35:37 +0000
Received: by pxi42 with SMTP id 42so92598pxi.20
        for <multiple recipients>; Mon, 31 Aug 2009 06:35:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:received:received:from:to:references
         :in-reply-to:subject:date:message-id:mime-version:content-type
         :content-transfer-encoding:x-mailer:thread-index:content-language;
        bh=fCcaphZI2ibYQcIiTnoVDvRwnPn6g615W81Zme4STG4=;
        b=bCDip/UKZCLVqaILwLvM+szamNWkra8bGT7YPXZafAd0ey4tM38cdBbLJJdtxYwk8d
         lLrBQt0M7P/Q8CjUBNC3It/jwgrGVA6BIWlJMS+XkXdIv7na4PYCoegv5JI3ZA7WOXTC
         SRnx4Ubve+b00sksWZr9631pG60WvXMcLoOrI=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=from:to:references:in-reply-to:subject:date:message-id:mime-version
         :content-type:content-transfer-encoding:x-mailer:thread-index
         :content-language;
        b=sc6BFLTZ6R2y6ptrM3DgJ1FCG3Vsk0N/FIHlEFOWIB56I7mYneWIq9x/+/b3uWh5WH
         Xrmezzxed1VGoZUhKcwuIb+SZ+3JONJoBhCjDCQoVyiRCNkdhjcnrjyvfFeShX7KSYmV
         tfN6iFFbOd8taftwycOUBmvV9Np5OEHIgKP7Y=
Received: by 10.115.96.16 with SMTP id y16mr2631359wal.38.1251725716497;
        Mon, 31 Aug 2009 06:35:16 -0700 (PDT)
Received: from zjf ([58.247.235.164])
        by mx.google.com with ESMTPS id n9sm4296726wag.58.2009.08.31.06.35.14
        (version=TLSv1/SSLv3 cipher=RC4-MD5);
        Mon, 31 Aug 2009 06:35:16 -0700 (PDT)
From: "zjffdu" <zjffdu@gmail.com>
To: <common-user@hadoop.apache.org>,
	<core-user@hadoop.apache.org>
References: <77938bc20908310340g63c6b29aw25a4edd16f1fc840@mail.gmail.com>
In-Reply-To: <77938bc20908310340g63c6b29aw25a4edd16f1fc840@mail.gmail.com>
Subject: RE: Datanode high memory usage
Date: Mon, 31 Aug 2009 21:36:52 -0700
Message-ID: <007e01ca2abd$d659b7f0$830d27d0$@com>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="gb2312"
Content-Transfer-Encoding: quoted-printable
X-Mailer: Microsoft Office Outlook 12.0
Thread-Index: AcoqJ42GQu6xCZDZQhanh8j1xkBViwAlbWkg
Content-Language: zh-cn
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Stas,

What does 700MB represent for ? total memory usage of OS or only the =
task
process.

There three process related to hadoop on datanode.=20

1. DataNode deamon for DFS (only one)
2. TaskTracker for MapReduce (only one)
3. Map Task or Reduce Task (several tasks on one machine, depending on =
your
configration)

=20

-----Original Message-----
From: Stas Oskin [mailto:stas.oskin@gmail.com]=20
Sent: 2009=C4=EA8=D4=C231=C8=D5 3:41
To: core-user@hadoop.apache.org
Subject: Datanode high memory usage

Hi.

I measured the Datanode memory usage, and noticed they take up to 700 MB =
of
RAM.

As their main job is to store files to disk, any idea why they take so =
much
RAM?

Thanks for any information.


From common-user-return-17181-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 13:54:20 2009
Return-Path: <common-user-return-17181-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 76119 invoked from network); 31 Aug 2009 13:54:20 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 13:54:20 -0000
Received: (qmail 38294 invoked by uid 500); 31 Aug 2009 13:54:18 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 38223 invoked by uid 500); 31 Aug 2009 13:54:17 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 38213 invoked by uid 99); 31 Aug 2009 13:54:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 13:54:17 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.218.214 as permitted sender)
Received: from [209.85.218.214] (HELO mail-bw0-f214.google.com) (209.85.218.214)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 13:54:09 +0000
Received: by bwz10 with SMTP id 10so1950506bwz.29
        for <common-user@hadoop.apache.org>; Mon, 31 Aug 2009 06:53:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=h+uqCv+GGxubyOAXBoDHpn//T7TXUpHOGAfn3cfFBSQ=;
        b=Xy3pfGu2VQA5vFCj9q+8Zf2moLLeUx0GExCcjKs3pzJ/DJBbwDDkig5UURcuLKh5WD
         QTU19XK6sAOyuUeglqvHQNwfZ2EiYqAi1WypaZ7pndmhrRzpVvNHK1JBDpOxhSYb3ZP1
         XWWtZ5pyBRBGEfKhLT8CLxzplcfrdaFkMuAk8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=ZL47IJD/6LVRE+e5BI0cYFV559EBg4nEx4zvKbce98ZVsolFzzKqSbImezczlzn7fO
         r6QBOGscXpxH2QJ2tQFOUztjaQNzsdleLLIv+yuQJNwty3r4ir6vX3p++GiOe+3wxzdJ
         RLFXM5U8aCDQxSU3PdozXdWl+cvM44/3RrGSQ=
MIME-Version: 1.0
Received: by 10.223.54.23 with SMTP id o23mr1702452fag.72.1251726827860; Mon, 
	31 Aug 2009 06:53:47 -0700 (PDT)
In-Reply-To: <007e01ca2abd$d659b7f0$830d27d0$@com>
References: <77938bc20908310340g63c6b29aw25a4edd16f1fc840@mail.gmail.com>
	 <007e01ca2abd$d659b7f0$830d27d0$@com>
Date: Mon, 31 Aug 2009 16:53:47 +0300
Message-ID: <77938bc20908310653t13ef7031i25487d7c818fef8b@mail.gmail.com>
Subject: Re: Datanode high memory usage
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0015174757a4ee317b0472705ca4
X-Virus-Checked: Checked by ClamAV on apache.org

--0015174757a4ee317b0472705ca4
Content-Type: text/plain; charset=GB2312
Content-Transfer-Encoding: 7bit

Hi.


> What does 700MB represent for ? total memory usage of OS or only the task
> process.
>
>
The Datanode task process - I'm running just it to find out how actually RAM
it takes.

Regards.

--0015174757a4ee317b0472705ca4--

From common-user-return-17182-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 15:40:45 2009
Return-Path: <common-user-return-17182-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 1826 invoked from network); 31 Aug 2009 15:40:45 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 15:40:45 -0000
Received: (qmail 85696 invoked by uid 500); 31 Aug 2009 15:40:42 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 85637 invoked by uid 500); 31 Aug 2009 15:40:42 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 85627 invoked by uid 99); 31 Aug 2009 15:40:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 15:40:42 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zjffdu@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-iw0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 15:40:33 +0000
Received: by iwn6 with SMTP id 6so1829854iwn.5
        for <common-user@hadoop.apache.org>; Mon, 31 Aug 2009 08:40:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=TCFwm0UswiI3AzcyjzOXBe9HWAIy1v7YJ1LyEy9lRzM=;
        b=sfTmYT8hpMazE65qzLeoMVc7ZIVW4oha7JTql8ZKAr7yttwW1ASiZPvDduFHBtrn1R
         0fJD6lpYDO1ncva8y0srMZMxXEVewFud7ZqItQpBqySxSjBMDYFy4khW8jj39HsHQGDV
         Wq9XJYbtA2XGY78vkhFRfa5zWq4Q7gVsUx8a8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=MWFr1yWGUsNMk73mbl7XTLr1VNtfac9Lt/NKnKM5fviQ3IWa2YdwxGK0Uepwd776Hj
         0kyhXWhQeSsnO2bgNYateIEmRDZrO9v3DWLS2FUinFffO59vih1UmJFnG6cNIZGmodF5
         GIKv2EjOo5XKDYIgLShntU2fOZTCNX0Fkd6K0=
MIME-Version: 1.0
Received: by 10.231.120.136 with SMTP id d8mr7287204ibr.14.1251733212396; Mon, 
	31 Aug 2009 08:40:12 -0700 (PDT)
In-Reply-To: <77938bc20908310653t13ef7031i25487d7c818fef8b@mail.gmail.com>
References: <77938bc20908310340g63c6b29aw25a4edd16f1fc840@mail.gmail.com>
	 <007e01ca2abd$d659b7f0$830d27d0$@com>
	 <77938bc20908310653t13ef7031i25487d7c818fef8b@mail.gmail.com>
Date: Mon, 31 Aug 2009 08:40:12 -0700
Message-ID: <8211a1320908310840p59e56e16o2e933a151a951334@mail.gmail.com>
Subject: Re: Datanode high memory usage
From: zhang jianfeng <zjffdu@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0016e644c18e7a7e83047271d92c
X-Virus-Checked: Checked by ClamAV on apache.org

--0016e644c18e7a7e83047271d92c
Content-Type: text/plain; charset=UTF-8

I think what you see is reduce task, because in reduce task, you have three
steps:
copy , sort, and reudce.  The copy and  sort steps may cost a lot of memory.



2009/8/31 Stas Oskin <stas.oskin@gmail.com>

> Hi.
>
>
> > What does 700MB represent for ? total memory usage of OS or only the task
> > process.
> >
> >
> The Datanode task process - I'm running just it to find out how actually
> RAM
> it takes.
>
> Regards.
>

--0016e644c18e7a7e83047271d92c--

From common-user-return-17183-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 16:08:17 2009
Return-Path: <common-user-return-17183-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 8877 invoked from network); 31 Aug 2009 16:08:16 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 16:08:16 -0000
Received: (qmail 26252 invoked by uid 500); 31 Aug 2009 16:08:14 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 26165 invoked by uid 500); 31 Aug 2009 16:08:14 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 26148 invoked by uid 99); 31 Aug 2009 16:08:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 16:08:14 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 16:08:06 +0000
Received: by fxm25 with SMTP id 25so2921604fxm.29
        for <common-user@hadoop.apache.org>; Mon, 31 Aug 2009 09:07:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=dGYCr1s4Vf8fth91czjTnCGR4jvrQ/Dt6DJXD4BWV2U=;
        b=s7tVVPC9yr3ro5gJf/aesxEcC7aaWBvX3b2mqz9hKvyZ9TK/Q0DXlIFJSbxYGMxPTz
         cpHK1knBs+nk0utPb/y5V3kWMUtzisX/zPevGdFQ2b8G8ehxcaH3r5lgGmU3G4p0O3oh
         WaBtIUyxWSIEiCFMRoGeqiMTpg2MUvQfxXqCA=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=CGPoKeGhUhfexjmeiJBE+y0xg+/pADQGPjQgzNG/fUNloblkMxZf+Lgt2JRAY8MxO7
         HHTBU6Mi/LMlbCV+nn0+owIokjKZzpjzYoq+5HYFN/cRh/wDBPyBbBDTg1bSXk3JMFES
         2IX0gwJGXSUhPYIJpykRIXwnSmzEvGbimZEck=
MIME-Version: 1.0
Received: by 10.223.143.79 with SMTP id t15mr1808662fau.13.1251734865302; Mon, 
	31 Aug 2009 09:07:45 -0700 (PDT)
In-Reply-To: <8211a1320908310840p59e56e16o2e933a151a951334@mail.gmail.com>
References: <77938bc20908310340g63c6b29aw25a4edd16f1fc840@mail.gmail.com>
	 <007e01ca2abd$d659b7f0$830d27d0$@com>
	 <77938bc20908310653t13ef7031i25487d7c818fef8b@mail.gmail.com>
	 <8211a1320908310840p59e56e16o2e933a151a951334@mail.gmail.com>
Date: Mon, 31 Aug 2009 19:07:44 +0300
Message-ID: <77938bc20908310907g542e50d2me9a6f31e8d4ba3d4@mail.gmail.com>
Subject: Re: Datanode high memory usage
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0023545bda28ffd71a0472723b8d
X-Virus-Checked: Checked by ClamAV on apache.org

--0023545bda28ffd71a0472723b8d
Content-Type: text/plain; charset=ISO-8859-1

Hi.


I think what you see is reduce task, because in reduce task, you have three
> steps:
> copy , sort, and reudce.  The copy and  sort steps may cost a lot of
> memory.
>
>
>
Nope, I just running the Datanode and copying files to HDFS - no reduce
tasks are running.

How typically large is a standard Datanode?

Regards.

--0023545bda28ffd71a0472723b8d--

From common-user-return-17184-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 16:48:24 2009
Return-Path: <common-user-return-17184-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 19539 invoked from network); 31 Aug 2009 16:48:24 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 16:48:24 -0000
Received: (qmail 87593 invoked by uid 500); 31 Aug 2009 16:48:21 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 87520 invoked by uid 500); 31 Aug 2009 16:48:21 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 87510 invoked by uid 99); 31 Aug 2009 16:48:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 16:48:21 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jim.twensky@gmail.com designates 209.85.146.182 as permitted sender)
Received: from [209.85.146.182] (HELO wa-out-1112.google.com) (209.85.146.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 16:48:12 +0000
Received: by wa-out-1112.google.com with SMTP id j32so543182waf.29
        for <common-user@hadoop.apache.org>; Mon, 31 Aug 2009 09:47:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=RELWJCqXKp8LomxkK1npAYBYpIuE29QTwNHWc0GciqQ=;
        b=I8CttBlP+qIqyOcv1uk32d88ozHDMHkOYUh9Ebay9mAGVteNqM2xaIkZvG94XBdiCU
         TKdMsJqJVA/EQlxvfKZHuUIbocUn3xyquEYBQHEqXOuW/Nb95s5lF7H9yR9n7yl18kXW
         WFFPezerPiKdSDcbd++Ga/bRMg4RXGetFAtQU=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=sDVu7JtT8S03t9d2K7Hpwp0ELRIESkF/3ChunEr3TYptn/ObH6Z9AIkA/BKyP9EePe
         7eUpDkqtzmQxj1tcMGI/rXNbcx6HHVpG/LFxs9ckwnYaLfgvQkKvr99PImONKoOR1vFd
         l7ccv2MbuvQqsshZWIpRN1jXNTqHpyEsu/PUI=
MIME-Version: 1.0
Received: by 10.114.31.14 with SMTP id e14mr523223wae.78.1251737270845; Mon, 
	31 Aug 2009 09:47:50 -0700 (PDT)
In-Reply-To: <4061df20908310219w17e32c36mc57eabd31b86af9c@mail.gmail.com>
References: <8211a1320908241749x71f4d762j3256e6a0be0e22f3@mail.gmail.com>
	 <4061df20908310219w17e32c36mc57eabd31b86af9c@mail.gmail.com>
Date: Mon, 31 Aug 2009 09:47:50 -0700
Message-ID: <7a8854060908310947n5784768byc6e00908882d33@mail.gmail.com>
Subject: Re: Does hadoop delete the intermediate data
From: Jim Twensky <jim.twensky@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Jeff,

The problem may also be related to the large log files if you use the
cluster for too many jobs. Check out your hadoop log directory and see
how big it is. You can decrease the maximum size of a log file using
one of the hadoop configuration files under conf.

Jim

On Mon, Aug 31, 2009 at 2:19 AM, Chandraprakash
Bhagtani<cpbhagtani@gmail.com> wrote:
> Hadoop does delete the intermediate data after the job completes.
> Jobtracker sends signal to Tasktracker to delete intermediate data
> when the job completes.
>
> The problem in your case might be some of your running job might not
> have been killed gracefully or Jobtracker failed for some reason.
>
> --
> Thanks & Regards,
> Chandra Prakash Bhagtani,
>
> On Tue, Aug 25, 2009 at 6:19 AM, zhang jianfeng <zjffdu@gmail.com> wrote:
>
>> Hi all,
>>
>> I found my cluster=92s space usage increase over time although I did not
>> upload new data. =A0And there's a lot of files under folder /tmp .
>>
>> So I guess hadoop won=92t delete the intermediate data(output of mapper)=
.
>>
>> Am I right ?
>>
>>
>> Thank you.
>>
>> Jeff zhang
>>
>

From common-user-return-17185-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 17:05:34 2009
Return-Path: <common-user-return-17185-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 28024 invoked from network); 31 Aug 2009 17:05:34 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 17:05:34 -0000
Received: (qmail 11932 invoked by uid 500); 31 Aug 2009 17:05:31 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 11881 invoked by uid 500); 31 Aug 2009 17:05:31 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 11871 invoked by uid 99); 31 Aug 2009 17:05:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 17:05:31 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jim.twensky@gmail.com designates 209.85.216.204 as permitted sender)
Received: from [209.85.216.204] (HELO mail-px0-f204.google.com) (209.85.216.204)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 17:05:21 +0000
Received: by pxi42 with SMTP id 42so219220pxi.20
        for <common-user@hadoop.apache.org>; Mon, 31 Aug 2009 10:05:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type
         :content-transfer-encoding;
        bh=agE39vNyTTnyGWgBn42/I+/4JGVDN1Z2qRhlJFKmqpM=;
        b=Gt+Mg2Fn8Wx/GVquSBHnGI4dpM+i34CNO9aqoMAMQ9boCyfUPUOiXVblB9Zhd0jCgj
         vE7nxB/AZLdwhv2gXJLec8V65ZCWLalvARYGCTRq9i7U1iptd3kJKA904QvQtfSWqvee
         J0Ib+ZCfVJXfQBXesphRiHmYawvrZD5vC5Uws=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        b=CADnfcN+UFmv5wxCEspdEtkE+PCn2T7ZrJ4wsWiQlNPHMGmOYJVcBb3kN8a2dkrVHx
         64HSTm1vY3raaEwv9RKO2d5xBk+3iZxjbxE868ke64CL0aJoVaOLLKj/Dgn7p2VdTrdM
         IHtGYgg2Re9FaBh2NOEqkAQ/hZF5HzOpbKz7U=
MIME-Version: 1.0
Received: by 10.115.113.9 with SMTP id q9mr2841607wam.224.1251738299985; Mon, 
	31 Aug 2009 10:04:59 -0700 (PDT)
In-Reply-To: <77938bc20908310907g542e50d2me9a6f31e8d4ba3d4@mail.gmail.com>
References: <77938bc20908310340g63c6b29aw25a4edd16f1fc840@mail.gmail.com>
	 <007e01ca2abd$d659b7f0$830d27d0$@com>
	 <77938bc20908310653t13ef7031i25487d7c818fef8b@mail.gmail.com>
	 <8211a1320908310840p59e56e16o2e933a151a951334@mail.gmail.com>
	 <77938bc20908310907g542e50d2me9a6f31e8d4ba3d4@mail.gmail.com>
Date: Mon, 31 Aug 2009 10:04:59 -0700
Message-ID: <7a8854060908311004ncd63e7cv9ea388a3e86d25f1@mail.gmail.com>
Subject: Re: Datanode high memory usage
From: Jim Twensky <jim.twensky@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

The maximum and minimum amount of memory to be used by the task
trackers can be specified inside the configuration files under conf.
For instance, in order to allocate a maximum of 512 MB, you need to
set:

<property>
  <name>mapred.child.java.opts</name>
  <value>
     -Xmx512M
  </value>
</property>

Hope that helps.

Jim

On Mon, Aug 31, 2009 at 9:07 AM, Stas Oskin<stas.oskin@gmail.com> wrote:
> Hi.
>
>
> I think what you see is reduce task, because in reduce task, you have thr=
ee
>> steps:
>> copy , sort, and reudce. =A0The copy and =A0sort steps may cost a lot of
>> memory.
>>
>>
>>
> Nope, I just running the Datanode and copying files to HDFS - no reduce
> tasks are running.
>
> How typically large is a standard Datanode?
>
> Regards.
>

From common-user-return-17186-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 17:10:25 2009
Return-Path: <common-user-return-17186-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 30116 invoked from network); 31 Aug 2009 17:10:25 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 17:10:25 -0000
Received: (qmail 19191 invoked by uid 500); 31 Aug 2009 17:10:22 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 19105 invoked by uid 500); 31 Aug 2009 17:10:22 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 19094 invoked by uid 99); 31 Aug 2009 17:10:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 17:10:22 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of stas.oskin@gmail.com designates 209.85.220.225 as permitted sender)
Received: from [209.85.220.225] (HELO mail-fx0-f225.google.com) (209.85.220.225)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 17:10:14 +0000
Received: by fxm25 with SMTP id 25so2959611fxm.29
        for <common-user@hadoop.apache.org>; Mon, 31 Aug 2009 10:09:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:in-reply-to:references
         :date:message-id:subject:from:to:content-type;
        bh=iqDrShv1c0v/1FI2U2eoZ35cUp3ljmzCbwU/w+PcP4k=;
        b=eLUdKqEK2PFbXkhAjmS4b8Coaxshx2fq1T8XEQ0DMdOIDD+c4e92bz3Mf8xoiDqJLE
         45E8+sUYMqW9DF1s+ITmjdns/sCQYknlfvTy2qWMMN6JJKrHMSkrQxT5XrhMxCVD8jFT
         RbTVfx/QBlN6XgEx0OjTf5oSWYwktKrbMVDQ8=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        b=hIyrlmAIaeEQR6Qy3FEZcQQy+vwrq9wmeErjWDnDbAyIAqx60T4MepY4/b61eQgr3K
         q6udQL3dmqwwARHBEg4NYOaxuFmSaaKbZ9vOc45dh2Zh7FcOcEwTIA3TYIF9dd3j4Aq8
         S9AR+6Rb5ylPx+oisHesR4Q8yb857QMTFaj6I=
MIME-Version: 1.0
Received: by 10.223.144.70 with SMTP id y6mr1890385fau.12.1251738593073; Mon, 
	31 Aug 2009 10:09:53 -0700 (PDT)
In-Reply-To: <7a8854060908311004ncd63e7cv9ea388a3e86d25f1@mail.gmail.com>
References: <77938bc20908310340g63c6b29aw25a4edd16f1fc840@mail.gmail.com>
	 <007e01ca2abd$d659b7f0$830d27d0$@com>
	 <77938bc20908310653t13ef7031i25487d7c818fef8b@mail.gmail.com>
	 <8211a1320908310840p59e56e16o2e933a151a951334@mail.gmail.com>
	 <77938bc20908310907g542e50d2me9a6f31e8d4ba3d4@mail.gmail.com>
	 <7a8854060908311004ncd63e7cv9ea388a3e86d25f1@mail.gmail.com>
Date: Mon, 31 Aug 2009 20:09:53 +0300
Message-ID: <77938bc20908311009n3e6a6ebg7c268d2a5ab46530@mail.gmail.com>
Subject: Re: Datanode high memory usage
From: Stas Oskin <stas.oskin@gmail.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=0022158df8f73123280472731a5f
X-Virus-Checked: Checked by ClamAV on apache.org

--0022158df8f73123280472731a5f
Content-Type: text/plain; charset=ISO-8859-1

Hi.


> <property>
>  <name>mapred.child.java.opts</name>
>  <value>
>     -Xmx512M
>  </value>
> </property>
>
>
This has effect even if I not using any reduce tasks?

Regards.

--0022158df8f73123280472731a5f--

From common-user-return-17187-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 20:35:06 2009
Return-Path: <common-user-return-17187-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 98365 invoked from network); 31 Aug 2009 20:35:06 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 20:35:06 -0000
Received: (qmail 47426 invoked by uid 500); 31 Aug 2009 20:35:03 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 47356 invoked by uid 500); 31 Aug 2009 20:35:03 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 47346 invoked by uid 99); 31 Aug 2009 20:35:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 20:35:03 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of tarandeep@gmail.com designates 209.85.219.208 as permitted sender)
Received: from [209.85.219.208] (HELO mail-ew0-f208.google.com) (209.85.219.208)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 20:34:54 +0000
Received: by ewy4 with SMTP id 4so1931080ewy.36
        for <common-user@hadoop.apache.org>; Mon, 31 Aug 2009 13:34:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=gamma;
        h=domainkey-signature:mime-version:received:from:date:message-id
         :subject:to:content-type;
        bh=gvJoAV0hYsslGX/lbCsVmK36ZZK5OPAOBBLXV8JFWho=;
        b=qmgl5SOSTeJuVo1ciUGOJbpTNUFR7ESLMz5admN6OFryEi2HQMSGdvjlJ+BXZcIfBx
         F75UnrBPc83EOxq0qvPfWGyu52+lHX1Ej4prjDEvsS5FkjrK3pi7T0DjHucJtVXsYWRY
         GsWRFhlZKyKvam4wZU0fyCGx5QAGtDV0aieIs=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=gamma;
        h=mime-version:from:date:message-id:subject:to:content-type;
        b=QcqfOZa/N/nqlAUQ92jDbLzYjcVA29jGaWfoPa4q7kpGIvgF0Wjs8iWKUwojrX1Wre
         wi4j255oHyy2wg1mdOQlgzNcPaopkWe+TxvRH4mbz4TjfjJR7y0Y4sL4jZBJP/zJDTns
         WnQEjp8EsT+Ry2wfs3YRAkum5U2gXIsTFeL1c=
MIME-Version: 1.0
Received: by 10.211.130.6 with SMTP id h6mr5943721ebn.97.1251750874134; Mon, 
	31 Aug 2009 13:34:34 -0700 (PDT)
From: Tarandeep Singh <tarandeep@gmail.com>
Date: Mon, 31 Aug 2009 13:34:14 -0700
Message-ID: <e75c02ef0908311334x513e3365odb1cf10f15b784a8@mail.gmail.com>
Subject: Use third party classes during MR job
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=00504502cf98333b8e047275f68d
X-Virus-Checked: Checked by ClamAV on apache.org

--00504502cf98333b8e047275f68d
Content-Type: text/plain; charset=ISO-8859-1

Hi,

How can I use third party classes during execution of Map Reduce job?
I know there are some ways to do this -

i) have a lib directory inside my app.jar file that contains all third party
jars
ii) Use DistribtuedCache.addfiletoclasspath( )

I can't use (i) because at time of submitting my jar to Hadoop, the classes
don't exist (they get created later on).

I have used (ii) in past to add jar files, but it is not working on .class
files. Any suggestions ?

Thanks,
Tarandeep

--00504502cf98333b8e047275f68d--

From common-user-return-17188-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org Mon Aug 31 21:20:03 2009
Return-Path: <common-user-return-17188-apmail-hadoop-common-user-archive=hadoop.apache.org@hadoop.apache.org>
Delivered-To: apmail-hadoop-common-user-archive@www.apache.org
Received: (qmail 7429 invoked from network); 31 Aug 2009 21:20:03 -0000
Received: from hermes.apache.org (HELO mail.apache.org) (140.211.11.3)
  by minotaur.apache.org with SMTP; 31 Aug 2009 21:20:03 -0000
Received: (qmail 4678 invoked by uid 500); 31 Aug 2009 21:20:01 -0000
Delivered-To: apmail-hadoop-common-user-archive@hadoop.apache.org
Received: (qmail 4607 invoked by uid 500); 31 Aug 2009 21:20:00 -0000
Mailing-List: contact common-user-help@hadoop.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:common-user-help@hadoop.apache.org>
List-Unsubscribe: <mailto:common-user-unsubscribe@hadoop.apache.org>
List-Post: <mailto:common-user@hadoop.apache.org>
List-Id: <common-user.hadoop.apache.org>
Reply-To: common-user@hadoop.apache.org
Delivered-To: mailing list common-user@hadoop.apache.org
Received: (qmail 4597 invoked by uid 99); 31 Aug 2009 21:20:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 21:20:00 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=HTML_MESSAGE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 209.85.222.174 is neither permitted nor denied by domain of kpeterson@biz360.com)
Received: from [209.85.222.174] (HELO mail-pz0-f174.google.com) (209.85.222.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 31 Aug 2009 21:19:51 +0000
Received: by pzk4 with SMTP id 4so3267607pzk.29
        for <common-user@hadoop.apache.org>; Mon, 31 Aug 2009 14:19:29 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.164.11 with SMTP id m11mr1212838rve.275.1251753569822; 
	Mon, 31 Aug 2009 14:19:29 -0700 (PDT)
In-Reply-To: <25193896.post@talk.nabble.com>
References: <25193896.post@talk.nabble.com>
Date: Mon, 31 Aug 2009 14:19:29 -0700
Message-ID: <f27b3fc0908311419u7bb21b64v752163ef1892a603@mail.gmail.com>
Subject: Re: DistCp - NoClassDefFoundError
From: Kevin Peterson <kpeterson@biz360.com>
To: common-user@hadoop.apache.org
Content-Type: multipart/alternative; boundary=000e0cd213e2e02a310472769628
X-Virus-Checked: Checked by ClamAV on apache.org

--000e0cd213e2e02a310472769628
Content-Type: text/plain; charset=ISO-8859-1

On Fri, Aug 28, 2009 at 10:34 AM, mpiller <mark@themidnightcoders.com>wrote:

>
> I am using the DistCp class inside of my application to copy final output
> files out into S3 (this is per Amazon's recommendation). However, when I
> run
> the program I get the following exception:
>
> java.lang.NoClassDefFoundError: org/apache/hadoop/tools/DistCp
>
>
I generally run DistCp from the command line. I'd look into the bin/hadoop
script to see what it actually runs when you do distcp. It may be that the
jar isn't in the classpath normally.

--000e0cd213e2e02a310472769628--

